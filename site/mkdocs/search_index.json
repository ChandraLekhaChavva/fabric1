{
    "docs": [
        {
            "location": "/",
            "text": "Incubation Notice\n\n\nThis project is a Hyperledger project in \nIncubation\n. It was proposed to the\ncommunity and documented \nhere\n. Information on what\n\nIncubation\n entails can be found in the \nHyperledger Project Lifecycle\ndocument\n.\n\n\n\n\n\n\n\n\n\n\nHyperledger Fabric\n\n\nThe fabric is an implementation of blockchain technology, leveraging familiar\nand proven technologies. It is a modular architecture allowing pluggable\nimplementations of various function. It features powerful container technology\nto host any mainstream language for smart contracts development.\n\n\nReleases\n\n\nThe fabric releases are documented\n\nhere\n. We have just\nreleased our first release under the governance of the Hyperledger Project -\nv0.5-developer-preview.\n\n\nContributing to the project\n\n\nWe welcome contributions to the Hyperledger Project in many forms. There\ns\nalways plenty to do! Full details of how to contribute to this project are\ndocumented in the \nFabric developer\ns guide\n below.\n\n\nTo contribute to this documentation, create an issue for any requests for\nclarification or to highlight any errors, or you may clone and update the\n\nsource\n, and submit a\nGerrit review (essentially the same process as for fabric development).\n\n\nMaintainers\n\n\nThe project\ns \nmaintainers\n: are responsible for reviewing and\nmerging all patches submitted for review and they guide the over-all technical\ndirection of the project within the guidelines established by the Hyperledger\nProject\ns Technical Steering Committee (TSC).\n\n\nCommunication \n\n\nWe use \nHyperledger Slack\n for communication and\nGoogle Hangouts\n for screen sharing between developers.\n\n\nHyperledger Fabric Documentation\n\n\nThe Hyperledger\n\nfabric\n is an\nimplementation of blockchain technology, that has been collaboratively developed\nunder the Linux Foundation\ns \nHyperledger Project\n. It\nleverages familiar and proven technologies, and offers a modular architecture\nthat allows pluggable implementations of various function including membership\nservices, consensus, and smart contracts (Chaincode) execution. It features\npowerful container technology to host any mainstream language for smart\ncontracts development.\n\n\nStill Have Questions?\n\n\nWe try to maintain a comprehensive set of documentation for various audiences.\nHowever, we realize that often there are questions that remain unanswered. For\nany technical questions relating to the Hyperledger Fabric project not answered\nin this documentation, please use\n\nStackOverflow\n.\n\n\nTOC\n\n\nBelow, you\nll find the following sections:\n\n\n\n\nGetting started\n\n\nQuickstart\n\n\n\n\nDeveloper guides\n\n\n\n\n\n\nFabric developer\ns guide\n\n\n\n\nChaincode developer\ns guide\n\n\n\n\nAPI developer\ns guide\n\n\n\n\n\n\nOperations guide\n\n\n\n\n\n\nGetting started\n\n\nIf you are new to the project, you can begin by reviewing the following links.\nIf you\nd prefer to dive right in, see the\n\nQuickstart\n section, below.\n\n\n\n\nWhitepaper WG\n:\nwhere the community is developing a whitepaper to explain the motivation and\ngoals for the project.\n\n\nRequirements WG\n:\nwhere the community is developing use cases and requirements.\n\n\nCanonical use cases\n\n\nGlossary\n: to understand the terminology that we use throughout\nthe Fabric project\ns documentation.\n\n\nFabric FAQs\n\n\n\n\nQuickstart documentation\n\n\n\n\nDevelopment environment set-up\n: if you are considering\nhelping with development of the Hyperledger Fabric or Fabric-API projects\nthemselves, this guide will help you install and configure all you\nll need. The\ndevelopment environment is also useful (but, not necessary) for developing\nblockchain applications and/or Chaincode.\n\n\nNetwork setup\n: This document covers setting up a\nnetwork on your local machine for development.\n\n\nChaincode development environment\n: Chaincode\ndevelopers need a way to test and debug their Chaincode without having to set up\na complete peer network. This document describes how to write, build, and test\nChaincode in a local development environment.\n\n\nAPIs\n: This document covers the available APIs for\ninteracting with a peer node.\n\n\n\n\nDeveloper guides\n\n\nFabric developer guide\n\n\nWhen you are ready to start contributing to the Hyperledger fabric project, we\nstrongly recommend that you read the \nprotocol specification\n\nfor the technical details so that you have a better understanding of how the\ncode fits together.\n\n\n\n\nMaking code contributions\n: First, you\nll want to familiarize\nyourself with the project\ns contribution guidelines.\n\n\nSetting up the development environment\n: after that, you\nwill want to set up your development environment.\n\n\nBuilding the fabric core\n: next, try building the project\nin your local development environment to ensure that everything is set up\ncorrectly.\n\n\nBuilding outside of Vagrant\n:\nfor the adventurous, you might try to build outside of the standard Vagrant\ndevelopment environment.\n\n\nLogging control\n: describes how to tweak the logging\nlevels of various components within the fabric.\n\n\nLicense header\n: every source file must include this\nlicense header modified to include a copyright statement for the principle\nauthor(s).\n\n\n\n\nChaincode developer guide\n\n\n\n\nSetting up the development environment\n: when developing\nand testing Chaincode, or an application that leverages the fabric API or SDK,\nyou\nll probably want to run the fabric locally on your laptop to test. You can\nuse the same setup that Fabric developers use.\n\n\nSetting Up a Network For Development\n: alternately, you\ncan follow these instructions for setting up a local network for Chaincode\ndevelopment without the entire fabric development environment setup.\n\n\nWriting, Building, and Running Chaincode in a Development\nEnvironment\n: a step-by-step guide to writing and\ntesting Chaincode.\n\n\nChaincode FAQ\n: a FAQ for all of your burning questions\nrelating to Chaincode.\n\n\n\n\nAPI developer guide\n\n\n\n\nAPIs - CLI, REST, and Node.js\n\n\nCLI\n: working with the command-line interface.\n\n\nREST\n: working with the REST API.\n\n\nNode.js SDK\n: working with the Node.js SDK.\n\n\n\n\n\n\n\n\nOperations guide\n\n\n\n\nSetting Up a Network\n: instructions for setting up a\nnetwork of fabric peers.\n\n\nCertificate Authority (CA) Setup\n: setting up a CA to\nsupport identity, security (authentication/authorization), privacy and\nconfidentiality.\n\n\nApplication ACL\n: working with access control lists.\n\n\n\n\nLicense \n\n\nThe Hyperledger Project uses the \nApache License Version 2.0\n software\nlicense.",
            "title": "Home"
        },
        {
            "location": "/#incubation-notice",
            "text": "This project is a Hyperledger project in  Incubation . It was proposed to the\ncommunity and documented  here . Information on what Incubation  entails can be found in the  Hyperledger Project Lifecycle\ndocument .",
            "title": "Incubation Notice"
        },
        {
            "location": "/#hyperledger-fabric",
            "text": "The fabric is an implementation of blockchain technology, leveraging familiar\nand proven technologies. It is a modular architecture allowing pluggable\nimplementations of various function. It features powerful container technology\nto host any mainstream language for smart contracts development.",
            "title": "Hyperledger Fabric"
        },
        {
            "location": "/#releases",
            "text": "The fabric releases are documented here . We have just\nreleased our first release under the governance of the Hyperledger Project -\nv0.5-developer-preview.",
            "title": "Releases"
        },
        {
            "location": "/#contributing-to-the-project",
            "text": "We welcome contributions to the Hyperledger Project in many forms. There s\nalways plenty to do! Full details of how to contribute to this project are\ndocumented in the  Fabric developer s guide  below.  To contribute to this documentation, create an issue for any requests for\nclarification or to highlight any errors, or you may clone and update the source , and submit a\nGerrit review (essentially the same process as for fabric development).",
            "title": "Contributing to the project"
        },
        {
            "location": "/#maintainers",
            "text": "The project s  maintainers : are responsible for reviewing and\nmerging all patches submitted for review and they guide the over-all technical\ndirection of the project within the guidelines established by the Hyperledger\nProject s Technical Steering Committee (TSC).",
            "title": "Maintainers"
        },
        {
            "location": "/#communication",
            "text": "We use  Hyperledger Slack  for communication and\nGoogle Hangouts  for screen sharing between developers.",
            "title": "Communication "
        },
        {
            "location": "/#hyperledger-fabric-documentation",
            "text": "The Hyperledger fabric  is an\nimplementation of blockchain technology, that has been collaboratively developed\nunder the Linux Foundation s  Hyperledger Project . It\nleverages familiar and proven technologies, and offers a modular architecture\nthat allows pluggable implementations of various function including membership\nservices, consensus, and smart contracts (Chaincode) execution. It features\npowerful container technology to host any mainstream language for smart\ncontracts development.",
            "title": "Hyperledger Fabric Documentation"
        },
        {
            "location": "/#still-have-questions",
            "text": "We try to maintain a comprehensive set of documentation for various audiences.\nHowever, we realize that often there are questions that remain unanswered. For\nany technical questions relating to the Hyperledger Fabric project not answered\nin this documentation, please use StackOverflow .",
            "title": "Still Have Questions?"
        },
        {
            "location": "/#toc",
            "text": "Below, you ll find the following sections:   Getting started  Quickstart   Developer guides    Fabric developer s guide   Chaincode developer s guide   API developer s guide    Operations guide",
            "title": "TOC"
        },
        {
            "location": "/#getting-started",
            "text": "If you are new to the project, you can begin by reviewing the following links.\nIf you d prefer to dive right in, see the Quickstart  section, below.   Whitepaper WG :\nwhere the community is developing a whitepaper to explain the motivation and\ngoals for the project.  Requirements WG :\nwhere the community is developing use cases and requirements.  Canonical use cases  Glossary : to understand the terminology that we use throughout\nthe Fabric project s documentation.  Fabric FAQs",
            "title": "Getting started"
        },
        {
            "location": "/#quickstart-documentation",
            "text": "Development environment set-up : if you are considering\nhelping with development of the Hyperledger Fabric or Fabric-API projects\nthemselves, this guide will help you install and configure all you ll need. The\ndevelopment environment is also useful (but, not necessary) for developing\nblockchain applications and/or Chaincode.  Network setup : This document covers setting up a\nnetwork on your local machine for development.  Chaincode development environment : Chaincode\ndevelopers need a way to test and debug their Chaincode without having to set up\na complete peer network. This document describes how to write, build, and test\nChaincode in a local development environment.  APIs : This document covers the available APIs for\ninteracting with a peer node.",
            "title": "Quickstart documentation"
        },
        {
            "location": "/#developer-guides",
            "text": "",
            "title": "Developer guides"
        },
        {
            "location": "/#fabric-developer-guide",
            "text": "When you are ready to start contributing to the Hyperledger fabric project, we\nstrongly recommend that you read the  protocol specification \nfor the technical details so that you have a better understanding of how the\ncode fits together.   Making code contributions : First, you ll want to familiarize\nyourself with the project s contribution guidelines.  Setting up the development environment : after that, you\nwill want to set up your development environment.  Building the fabric core : next, try building the project\nin your local development environment to ensure that everything is set up\ncorrectly.  Building outside of Vagrant :\nfor the adventurous, you might try to build outside of the standard Vagrant\ndevelopment environment.  Logging control : describes how to tweak the logging\nlevels of various components within the fabric.  License header : every source file must include this\nlicense header modified to include a copyright statement for the principle\nauthor(s).",
            "title": "Fabric developer guide"
        },
        {
            "location": "/#chaincode-developer-guide",
            "text": "Setting up the development environment : when developing\nand testing Chaincode, or an application that leverages the fabric API or SDK,\nyou ll probably want to run the fabric locally on your laptop to test. You can\nuse the same setup that Fabric developers use.  Setting Up a Network For Development : alternately, you\ncan follow these instructions for setting up a local network for Chaincode\ndevelopment without the entire fabric development environment setup.  Writing, Building, and Running Chaincode in a Development\nEnvironment : a step-by-step guide to writing and\ntesting Chaincode.  Chaincode FAQ : a FAQ for all of your burning questions\nrelating to Chaincode.",
            "title": "Chaincode developer guide"
        },
        {
            "location": "/#api-developer-guide",
            "text": "APIs - CLI, REST, and Node.js  CLI : working with the command-line interface.  REST : working with the REST API.  Node.js SDK : working with the Node.js SDK.",
            "title": "API developer guide"
        },
        {
            "location": "/#operations-guide",
            "text": "Setting Up a Network : instructions for setting up a\nnetwork of fabric peers.  Certificate Authority (CA) Setup : setting up a CA to\nsupport identity, security (authentication/authorization), privacy and\nconfidentiality.  Application ACL : working with access control lists.",
            "title": "Operations guide"
        },
        {
            "location": "/#license",
            "text": "The Hyperledger Project uses the  Apache License Version 2.0  software\nlicense.",
            "title": "License "
        },
        {
            "location": "/glossary/",
            "text": "Roles \n Personas\n\n\nRoles\n\n\n\n\n\n\n\n\n\n\n\n\nChain Member\n\n\n\nEntities that do not participate in the validation process of a blockchain network, but help to maintain the integrity of a network. Unlike Chain transactors, chain members maintain a local copy of the ledger.\n\n\n\n\n\n\n\nChain Transactor\n\n\n\nEntities that have permission to create transactions and query network data.\n\n\n\n\n\n\n\nChain Validator\n\n\n\nEntities that own a stake of a chain network. Each chain validator has a voice in deciding whether a transaction is valid, therefore chain validators can interrogate all transactions sent to their chain.\n\n\n\n\n\n\n\nChain Auditor\n\n\n\nEntities with the permission to interrogate transactions.\n\n\n\n\n\n\n\nParticipants\n\n\n\n\n\n\n\n\n\n\n\n\nSolution User\n\n\n\nEnd users are agnostic about the details of chain networks, they typically initiate transactions on a chain network through applications made available by solutions providers.\n\n\n\nRoles:\n None\n\n\n\n\n\n\n\nSolution Provider\n\n\n\nOrganizations that develop mobile and/or browser based applications for end (solution) users to access chain networks. Some application owners may also be network owners.\n\n\nRoles: Chain Transactor\n\n\n\n\n\n\n\nNetwork Proprietor\n\n\n\nProprietor(s) setup and define the purpose of a chain network. They are the stakeholders of a network.\n\n\nRoles: Chain Transactor, Chain Validator\n\n\n\n\n\n\n\nNetwork Owner\n\n\n\nOwners are stakeholders of a network that can validate transactions. After a network is first launched, its proprietor (who then becomes an owner) will invite business partners to co-own the network (by assigning them validating nodes). Any new owner added to a network must be approved by its existing owners.\n\n\nRoles: Chain Transactor, Chain Validator\n\n\n\n\n\n\n\nNetwork Member\n\n\n\nMembers are participants of a blockchain network that cannot validate transactions but has the right to add users to the network.\n\n\nRoles: Chain Transactor, Chain Member\n\n\n\n\n\n\n\nNetwork Users\n\n\n\nEnd users of a network are also solution users. Unlike network owners and members, users do not own nodes. They transact with the network through an entry point offered by a member or an owner node.\n\n\nRoles: Chain Transactor\n\n\n\n\n\n\n\nNetwork Auditors\n\n\n\nIndividuals or organizations with the permission to interrogate transactions.\n\n\nRoles: Chain Auditor\n\n\n\n\n\n\n\n\n\nBusiness Network\n\n\nTypes of Networks (Business View)\n\n\n\n\n\n\n\n\n\n\n\n\nIndustry Network\n\n\n\nA chain network that services solutions built for a particular industry.\n\n\n\n\n\n\n\nRegional Industry Network\n\n\n\nA chain network that services applications built for a particular industry and region.\n\n\n\n\n\n\n\nApplication Network\n\n\n\nA chain network that only services a single solution.\n\n\n\n\n\n\n\nTypes of Chains (Conceptual View)\n\n\n\n\n\n\n\n\n\n\n\n\nMain Chain\n\n\n\nA business network; each main chain operates one or multiple applications/solutions validated by the same group of organizations.\n\n\n\n\n\n\n\nConfidential Chain\n\n\n\nA special purpose chain created to run confidential business logic that is only accessible by contract stakeholders.\n\n\n\n\n\n\n\n\n\nNetwork Management\n\n\nMember management\n\n\n\n\n\n\n\n\n\n\n\n\nOwner Registration\n\n\n\nThe process of registering and inviting new owner(s) to a blockchain network. Approval from existing network owners is required when adding or deleting a participant with ownership right\n\n\n\n\n\n\n\nMember Registration\n\n\n\nThe process of registering and inviting new network members to a blockchain network.\n\n\n\n\n\n\n\nUser Registration\n\n\n\nThe process of registering new users to a blockchain network. Both members and owners can register users on their own behalf as long as they follow the policy of their network.\n\n\n\n\n\n\n\n\n\nTransactions\n\n\nTypes of Transactions\n\n\n\n\n\n\n\n\n\n\n\n\nDeployment Transaction\n\n\n\nTransactions that deploy a new chaincode to a chain.\n\n\n\n\n\n\n\nInvocation Transaction\n\n\n\nTransactions that invoke a function on a chaincode.\n\n\n\n\n\n\n\nConfidentiality of Transactions\n\n\n\n\n\n\n\n\n\n\n\n\nPublic Transaction\n\n\n\nA transaction with its payload in the open. Anyone with access to a chain network can interrogate the details of public transactions.\n\n\n\n\n\n\n\nConfidential Transaction\n\n\n\nA transaction with its payload cryptographically hidden such that no one besides the stakeholders of a transaction can interrogate its content.\n\n\n\n\n\n\n\nConfidential Chaincode Transaction\n\n\n\nA transaction with its payload encrypted such that only validators can decrypt them. Chaincode confidentiality is determined during deploy time. If a chaincode is deployed as a confidential chaincode, then the payload of all subsequent invocation transactions to that chaincode will be encrypted.\n\n\n\n\n\n\n\nInter-chain Transactions\n\n\n\n\n\n\n\n\n\n\n\n\nInter-Network Transaction\n\n\n\nTransactions between two business networks (main chains).\n\n\n\n\n\n\n\nInter-Chain Transaction\n\n\n\nTransactions between confidential chains and main chains. Chaincodes in a confidential chain can trigger transactions on one or multiple main chain(s).\n\n\n\n\n\n\n\n\n\nNetwork Entities\n\n\nSystems\n\n\n\n\n\n\n\n\n\n\n\n\nApplication Backend\n\n\n\n  Purpose: Backend application service that supports associated mobile and/or browser based applications.\n  \n\n  Key Roles:\n\n  1)    Manages end users and registers them with the membership service\n  \n\n  2)    Initiates transactions requests, and sends the requests to a node\n  \n\n  Owned by: Solution Provider, Network Proprietor\n\n\n\n\n\n\n\nNon Validating Node (Peer)\n\n\n\n  Purpose: Constructs transactions and forwards them to validating nodes. Peer nodes keep a copy of all transaction records so that solution providers can query them locally.\n  \n\n  Key Roles:\n\n  1)    Manages and maintains user certificates issued by the membership service\n\n  2)    Constructs transactions and forwards them to validating nodes \n\n  3)    Maintains a local copy of the ledger, and allows application owners to query information locally.\n  \n\n    Owned by: Solution Provider, Network Auditor\n\n\n\n\n\n\n\nValidating Node (Peer)\n\n\n\n  Purpose: Creates and validates transactions, and maintains the state of chaincodes\n\n  Key Roles:\n\n  1)    Manages and maintains user certificates issued by membership service\n\n  2)    Creates transactions\n\n  3)    Executes and validates transactions with other validating nodes on the network\n\n  4)    Maintains a local copy of ledger\n\n  5)    Participates in consensus and updates ledger\n  \n\n  Owned by: Network Proprietor, Solution Provider (if they belong to the same entity)\n\n\n\n\n\n\n\nMembership Service\n\n\n\n  Purpose: Issues and manages the identity of end users and organizations\n\n  Key Roles:\n\n  1)    Issues enrollment certificate to each end user and organization\n\n  2)    Issues transaction certificates associated to each end user and organization\n\n  3)    Issues TLS certificates for secured communication between Hyperledger fabric entities\n\n  4)    Issues chain specific keys\n  \n\n  Owned by: Third party service provider\n\n\n\n\n\n\n\nMembership Service Components\n\n\n\n\n\n\n\n\n\n\n\n\nRegistration Authority\n\n\n\nAssigns registration username \n registration password pairs to network participants. This username/password pair will be used to acquire enrollment certificate from ECA.\n\n\n\n\n\n\n\nEnrollment Certificate Authority (ECA)\n\n\n\nIssues enrollment certificates (ECert) to network participants that have already registered with a membership service. ECerts are long term certificates used to identify individual entities participating in one or more networks.\n\n\n\n\n\n\n\nTransaction Certificate Authority (TCA)\n\n\n\nIssues transaction certificates (TCerts) to ECert owners. An infinite number of TCerts can be derived from each ECert. TCerts are used by network participants to send transactions. Depending on the level of security requirements, network participants may choose to use a new TCert for every transaction.\n\n\n\n\n\n\n\nTLS-Certificate Authority (TLS-CA)\n\n\n\nIssues TLS certificates to systems that transmit messages in a chain network. TLS certificates are used to secure the communication channel between systems.\n\n\n\n\n\n\n\n\n\nHyperledger Fabric Entities\n\n\nChaincode\n\n\n\n\n\n\n\n\n\n\n\n\nPublic Chaincode\n\n\n\nChaincodes deployed by public transactions, these chaincodes can be invoked by any member of the network.\n\n\n\n\n\n\n\nConfidential Chaincode\n\n\n\nChaincodes deployed by confidential transactions, these chaincodes can only be invoked by validating members (Chain validators) of the network.\n\n\n\n\n\n\n\nAccess Controlled Chaincode\n\n\n\nChaincodes deployed by confidential transactions that also embed the tokens of approved invokers. These invokers are also allowed to invoke confidential chaincodes even though they are not validators.\n\n\n\n\n\n\n\nLedger\n\n\n\n\n\n\n\n\n\n\n\n\nChaincode-State\n\n\n\nHPL provides state support; Chaincodes access internal state storage through state APIs. States are created and updated by transactions calling chaincode functions with state accessing logic.\n\n\n\n\n\n\n\nTransaction List\n\n\n\nAll processed transactions are kept in the ledger in their original form (with payload encrypted for confidential transactions), so that network participants can interrogate past transactions to which they have access permissions.\n\n\n\n\n\n\n\nLedger Hash\n\n\n\nA hash that captures the present snapshot of the ledger. It is a product of all validated transactions processed by the network since the genesis transaction.\n\n\n\n\n\n\n\nNode\n\n\n\n\n\n\n\n\n\n\n\n\nDevOps Service\n\n\n\nThe frontal module on a node that provides APIs for clients to interact with their node and chain network. This module is also responsible to construct transactions, and work with the membership service component to receive and store all types of certificates and encryption keys in its storage.\n\n\n\n\n\n\n\nNode Service\n\n\n\nThe main module on a node that is responsible to process transactions, deploy and execute chaincodes, maintain ledger data, and trigger the consensus process.\n\n\n\n\n\n\n\nConsensus\n\n\n\nThe default consensus algorithm of Hyperledger fabric is an implementation of PBFT.",
            "title": "Glossary"
        },
        {
            "location": "/glossary/#roles-personas",
            "text": "",
            "title": "Roles &amp; Personas"
        },
        {
            "location": "/glossary/#roles",
            "text": "Chain Member  \nEntities that do not participate in the validation process of a blockchain network, but help to maintain the integrity of a network. Unlike Chain transactors, chain members maintain a local copy of the ledger.    Chain Transactor  \nEntities that have permission to create transactions and query network data.    Chain Validator  \nEntities that own a stake of a chain network. Each chain validator has a voice in deciding whether a transaction is valid, therefore chain validators can interrogate all transactions sent to their chain.    Chain Auditor  \nEntities with the permission to interrogate transactions.",
            "title": "Roles"
        },
        {
            "location": "/glossary/#participants",
            "text": "Solution User  \nEnd users are agnostic about the details of chain networks, they typically initiate transactions on a chain network through applications made available by solutions providers.  Roles:  None    Solution Provider  \nOrganizations that develop mobile and/or browser based applications for end (solution) users to access chain networks. Some application owners may also be network owners. \nRoles: Chain Transactor    Network Proprietor  \nProprietor(s) setup and define the purpose of a chain network. They are the stakeholders of a network. \nRoles: Chain Transactor, Chain Validator    Network Owner  \nOwners are stakeholders of a network that can validate transactions. After a network is first launched, its proprietor (who then becomes an owner) will invite business partners to co-own the network (by assigning them validating nodes). Any new owner added to a network must be approved by its existing owners. \nRoles: Chain Transactor, Chain Validator    Network Member  \nMembers are participants of a blockchain network that cannot validate transactions but has the right to add users to the network. \nRoles: Chain Transactor, Chain Member    Network Users  \nEnd users of a network are also solution users. Unlike network owners and members, users do not own nodes. They transact with the network through an entry point offered by a member or an owner node. \nRoles: Chain Transactor    Network Auditors  \nIndividuals or organizations with the permission to interrogate transactions. \nRoles: Chain Auditor",
            "title": "Participants"
        },
        {
            "location": "/glossary/#business-network",
            "text": "",
            "title": "Business Network"
        },
        {
            "location": "/glossary/#types-of-networks-business-view",
            "text": "Industry Network  \nA chain network that services solutions built for a particular industry.    Regional Industry Network  \nA chain network that services applications built for a particular industry and region.    Application Network  \nA chain network that only services a single solution.",
            "title": "Types of Networks (Business View)"
        },
        {
            "location": "/glossary/#types-of-chains-conceptual-view",
            "text": "Main Chain  \nA business network; each main chain operates one or multiple applications/solutions validated by the same group of organizations.    Confidential Chain  \nA special purpose chain created to run confidential business logic that is only accessible by contract stakeholders.",
            "title": "Types of Chains (Conceptual View)"
        },
        {
            "location": "/glossary/#network-management",
            "text": "",
            "title": "Network Management"
        },
        {
            "location": "/glossary/#member-management",
            "text": "Owner Registration  \nThe process of registering and inviting new owner(s) to a blockchain network. Approval from existing network owners is required when adding or deleting a participant with ownership right    Member Registration  \nThe process of registering and inviting new network members to a blockchain network.    User Registration  \nThe process of registering new users to a blockchain network. Both members and owners can register users on their own behalf as long as they follow the policy of their network.",
            "title": "Member management"
        },
        {
            "location": "/glossary/#transactions",
            "text": "",
            "title": "Transactions"
        },
        {
            "location": "/glossary/#types-of-transactions",
            "text": "Deployment Transaction  \nTransactions that deploy a new chaincode to a chain.    Invocation Transaction  \nTransactions that invoke a function on a chaincode.",
            "title": "Types of Transactions"
        },
        {
            "location": "/glossary/#confidentiality-of-transactions",
            "text": "Public Transaction  \nA transaction with its payload in the open. Anyone with access to a chain network can interrogate the details of public transactions.    Confidential Transaction  \nA transaction with its payload cryptographically hidden such that no one besides the stakeholders of a transaction can interrogate its content.    Confidential Chaincode Transaction  \nA transaction with its payload encrypted such that only validators can decrypt them. Chaincode confidentiality is determined during deploy time. If a chaincode is deployed as a confidential chaincode, then the payload of all subsequent invocation transactions to that chaincode will be encrypted.",
            "title": "Confidentiality of Transactions"
        },
        {
            "location": "/glossary/#inter-chain-transactions",
            "text": "Inter-Network Transaction  \nTransactions between two business networks (main chains).    Inter-Chain Transaction  \nTransactions between confidential chains and main chains. Chaincodes in a confidential chain can trigger transactions on one or multiple main chain(s).",
            "title": "Inter-chain Transactions"
        },
        {
            "location": "/glossary/#network-entities",
            "text": "",
            "title": "Network Entities"
        },
        {
            "location": "/glossary/#systems",
            "text": "Application Backend  \n  Purpose: Backend application service that supports associated mobile and/or browser based applications.\n   \n  Key Roles: \n  1)    Manages end users and registers them with the membership service\n   \n  2)    Initiates transactions requests, and sends the requests to a node\n   \n  Owned by: Solution Provider, Network Proprietor    Non Validating Node (Peer)  \n  Purpose: Constructs transactions and forwards them to validating nodes. Peer nodes keep a copy of all transaction records so that solution providers can query them locally.\n   \n  Key Roles: \n  1)    Manages and maintains user certificates issued by the membership service \n  2)    Constructs transactions and forwards them to validating nodes  \n  3)    Maintains a local copy of the ledger, and allows application owners to query information locally.\n   \n    Owned by: Solution Provider, Network Auditor    Validating Node (Peer)  \n  Purpose: Creates and validates transactions, and maintains the state of chaincodes \n  Key Roles: \n  1)    Manages and maintains user certificates issued by membership service \n  2)    Creates transactions \n  3)    Executes and validates transactions with other validating nodes on the network \n  4)    Maintains a local copy of ledger \n  5)    Participates in consensus and updates ledger\n   \n  Owned by: Network Proprietor, Solution Provider (if they belong to the same entity)    Membership Service  \n  Purpose: Issues and manages the identity of end users and organizations \n  Key Roles: \n  1)    Issues enrollment certificate to each end user and organization \n  2)    Issues transaction certificates associated to each end user and organization \n  3)    Issues TLS certificates for secured communication between Hyperledger fabric entities \n  4)    Issues chain specific keys\n   \n  Owned by: Third party service provider",
            "title": "Systems"
        },
        {
            "location": "/glossary/#membership-service-components",
            "text": "Registration Authority  \nAssigns registration username   registration password pairs to network participants. This username/password pair will be used to acquire enrollment certificate from ECA.    Enrollment Certificate Authority (ECA)  \nIssues enrollment certificates (ECert) to network participants that have already registered with a membership service. ECerts are long term certificates used to identify individual entities participating in one or more networks.    Transaction Certificate Authority (TCA)  \nIssues transaction certificates (TCerts) to ECert owners. An infinite number of TCerts can be derived from each ECert. TCerts are used by network participants to send transactions. Depending on the level of security requirements, network participants may choose to use a new TCert for every transaction.    TLS-Certificate Authority (TLS-CA)  \nIssues TLS certificates to systems that transmit messages in a chain network. TLS certificates are used to secure the communication channel between systems.",
            "title": "Membership Service Components"
        },
        {
            "location": "/glossary/#hyperledger-fabric-entities",
            "text": "",
            "title": "Hyperledger Fabric Entities"
        },
        {
            "location": "/glossary/#chaincode",
            "text": "Public Chaincode  \nChaincodes deployed by public transactions, these chaincodes can be invoked by any member of the network.    Confidential Chaincode  \nChaincodes deployed by confidential transactions, these chaincodes can only be invoked by validating members (Chain validators) of the network.    Access Controlled Chaincode  \nChaincodes deployed by confidential transactions that also embed the tokens of approved invokers. These invokers are also allowed to invoke confidential chaincodes even though they are not validators.",
            "title": "Chaincode"
        },
        {
            "location": "/glossary/#ledger",
            "text": "Chaincode-State  \nHPL provides state support; Chaincodes access internal state storage through state APIs. States are created and updated by transactions calling chaincode functions with state accessing logic.    Transaction List  \nAll processed transactions are kept in the ledger in their original form (with payload encrypted for confidential transactions), so that network participants can interrogate past transactions to which they have access permissions.    Ledger Hash  \nA hash that captures the present snapshot of the ledger. It is a product of all validated transactions processed by the network since the genesis transaction.",
            "title": "Ledger"
        },
        {
            "location": "/glossary/#node",
            "text": "DevOps Service  \nThe frontal module on a node that provides APIs for clients to interact with their node and chain network. This module is also responsible to construct transactions, and work with the membership service component to receive and store all types of certificates and encryption keys in its storage.    Node Service  \nThe main module on a node that is responsible to process transactions, deploy and execute chaincodes, maintain ledger data, and trigger the consensus process.    Consensus  \nThe default consensus algorithm of Hyperledger fabric is an implementation of PBFT.",
            "title": "Node"
        },
        {
            "location": "/protocol-spec/",
            "text": "Protocol Specification\n\n\nPreface\n\n\nThis document is the protocol specification for a permissioned blockchain implementation for industry use-cases. It is not intended to be a complete explanation of the implementation, but rather a description of the interfaces and relationships between components in the system and the application.\n\n\nIntended Audience\n\n\nThe intended audience for this specification includes the following groups:\n\n\n\n\nBlockchain vendors who want to implement blockchain systems that conform to this specification\n\n\nTool developers who want to extend the capabilities of the fabric\n\n\nApplication developers who want to leverage blockchain technologies to enrich their applications\n\n\n\n\n\n\nTable of Contents\n\n\n1. Introduction\n\n\n\n\n1.1 What is the fabric?\n\n\n1.2 Why the fabric?\n\n\n1.3 Terminology\n\n\n\n\n2. Fabric\n\n\n\n\n2.1 Architecture\n\n\n2.1.1 Membership Services\n\n\n2.1.2 Blockchain Services\n\n\n2.1.3 Chaincode Services\n\n\n2.1.4 Events\n\n\n2.1.5 Application Programming Interface (API)\n\n\n2.1.6 Command Line Interface (CLI)\n\n\n2.2 Topology\n\n\n2.2.1 Single Validating Peer\n\n\n2.2.2 Multiple Validating Peers\n\n\n2.2.3 Multichain\n\n\n\n\n3. Protocol\n\n\n\n\n3.1 Message\n\n\n3.1.1 Discovery Messages\n\n\n3.1.2 Transaction Messages\n\n\n3.1.2.1 Transaction Data Structure\n\n\n3.1.2.2 Transaction Specification\n\n\n3.1.2.3 Deploy Transaction\n\n\n3.1.2.4 Invoke Transaction\n\n\n3.1.2.5 Query Transaction\n\n\n3.1.3 Synchronization Messages\n\n\n3.1.4 Consensus Messages\n\n\n3.2 Ledger\n\n\n3.2.1 Blockchain\n\n\n3.2.1.1 Block\n\n\n3.2.1.2 Block Hashing\n\n\n3.2.1.3 NonHashData\n\n\n3.2.1.4 Transaction Execution\n\n\n3.2.2 World State\n\n\n3.2.2.1 Hashing the world state\n\n\n3.2.2.1.1 Bucket-tree\n\n\n3.3 Chaincode\n\n\n3.3.1 Virtual Machine Instantiation\n\n\n3.3.2 Chaincode Protocol\n\n\n3.3.2.1 Chaincode Deploy\n\n\n3.3.2.2 Chaincode Invoke\n\n\n3.3.2.3 Chaincode Query\n\n\n3.3.2.4 Chaincode State\n\n\n3.4 Pluggable Consensus Framework\n\n\n3.4.1 Consenter interface\n\n\n3.4.2 CPI interface\n\n\n3.4.3 Inquirer interface\n\n\n3.4.4 Communicator interface\n\n\n3.4.5 SecurityUtils interface\n\n\n3.4.6 LedgerStack interface\n\n\n3.4.7 Executor interface\n\n\n3.4.7.1 Beginning a transaction batch\n\n\n3.4.7.2 Executing transactions\n\n\n3.4.7.3 Committing and rolling-back transactions\n\n\n3.4.8 Ledger interface\n\n\n3.4.8.1 ReadOnlyLedger interface\n\n\n3.4.8.2 UtilLedger interface\n\n\n3.4.8.3 WritableLedger interface\n\n\n3.4.9 RemoteLedgers interface\n\n\n3.4.10 controller package\n\n\n3.4.10.1 controller.NewConsenter\n\n\n3.4.11 helper package\n\n\n3.4.11.1 High-level overview\n\n\n3.4.11.2 helper.ConsensusHandler\n\n\n3.4.11.3 helper.NewConsensusHandler\n\n\n3.4.11.4 helper.Helper\n\n\n3.4.11.5 helper.NewHelper\n\n\n3.4.11.6 helper.HandleMessage\n\n\n3.5 Events\n\n\n3.5.1 Event Stream\n\n\n3.5.1.1 Event Producer\n\n\n3.5.1.2 Event Consumer\n\n\n3.5.2 Event Adapters\n\n\n3.5.3 Event Structure\n\n\n\n\n4. Security\n\n\n\n\n4.1 Business security requirements\n\n\n4.2 User Privacy through Membership Services\n\n\n4.2.1 User/Client Enrollment Process\n\n\n4.2.2 Expiration and revocation of certificates\n\n\n4.3 Transaction security offerings at the infrastructure level\n\n\n4.3.1 Security Lifecycle of Transactions\n\n\n4.3.2 Transaction confidentiality\n\n\n4.3.2.1 Confidentiality against users\n\n\n4.3.2.2 Confidentiality against validators\n\n\n4.3.3 Replay attack resistance\n\n\n4.4 Access control features on the application\n\n\n4.4.1 Invocation access control\n\n\n4.4.2 Read access control\n\n\n4.5 Online wallet service\n\n\n4.6 Network security (TLS)\n\n\n4.7 Restrictions in the current release\n\n\n4.7.1 Simplified client\n\n\n4.7.2 Simplified transaction confidentiality\n\n\n\n\n5. Byzantine Consensus\n\n\n\n\n5.1 Overview\n\n\n5.2 Core PBFT Functions\n\n\n5.2.1 newPbftCore\n\n\n\n\n6. Application Programming Interface\n\n\n\n\n6.1 REST Service\n\n\n6.2 REST API\n\n\n6.2.1 REST Endpoints\n\n\n6.2.1.1 Block API\n\n\n6.2.1.2 Blockchain API\n\n\n6.2.1.3 Chaincode API\n\n\n6.2.1.4 Network API\n\n\n6.2.1.5 Registrar API (member services)\n\n\n6.2.1.6 Transactions API\n\n\n6.3 CLI\n\n\n6.3.1 CLI Commands\n\n\n6.3.1.1 node start\n\n\n6.3.1.2 network login\n\n\n6.3.1.3 chaincode deploy\n\n\n6.3.1.4 chaincode invoke\n\n\n6.3.1.5 chaincode query\n\n\n\n\n7. Application Model\n\n\n\n\n7.1 Composition of an Application\n\n\n7.2 Sample Application\n\n\n\n\n8. Future Directions\n\n\n\n\n8.1 Enterprise Integration\n\n\n8.2 Performance and Scalability\n\n\n8.3 Additional Consensus Plugins\n\n\n8.4 Additional Languages\n\n\n\n\n9.1 Authors\n\n\n9.2 Reviewers\n\n\n9.3 Acknowledgements\n\n\n10. References\n\n\n\n\n1. Introduction\n\n\nThis document specifies the principles, architecture, and protocol of a blockchain implementation suitable for industrial use-cases.\n\n\n1.1 What is the fabric?\n\n\nThe fabric is a ledger of digital events, called transactions, shared among  different participants, each having a stake in the system. The ledger can only be updated by consensus of the participants, and, once recorded, information can never be altered. Each recorded event is cryptographically verifiable with proof of agreement from the participants.\n\n\nTransactions are secured, private, and confidential. Each participant registers with proof of identity to the network membership services to gain access to the system. Transactions are issued with derived certificates unlinkable to the individual participant, offering a complete anonymity on the network. Transaction content is encrypted with sophisticated key derivation functions to ensure only intended participants may see the content, protecting the confidentiality of the business transactions.\n\n\nThe ledger allows compliance with regulations as ledger entries are auditable in whole or in part. In collaboration with participants, auditors may obtain time-based certificates to allow viewing the ledger and linking transactions to provide an accurate assessment of the operations.\n\n\nThe fabric is an implementation of blockchain technology, where Bitcoin could be a simple application built on the fabric. It is a modular architecture allowing components to be plug-and-play by implementing this protocol specification. It features powerful container technology to host any main stream language for smart contracts development. Leveraging familiar and proven technologies is the motto of the fabric architecture.\n\n\n1.2 Why the fabric?\n\n\nEarly blockchain technology serves a set of purposes but is often not well-suited for the needs of specific industries. To meet the demands of modern markets, the fabric is based on an industry-focused design that addresses the multiple and varied requirements of specific industry use cases, extending the learning of the pioneers in this field while also addressing issues such as scalability. The fabric provides a new approach to enable permissioned networks, privacy, and confidentially on multiple blockchain networks.\n\n\n1.3 Terminology\n\n\nThe following terminology is defined within the limited scope of this specification to help readers understand clearly and precisely the concepts described here.\n\n\nTransaction\n is a request to the blockchain to execute a function on the ledger. The function is implemented by a \nchaincode\n.\n\n\nTransactor\n is an entity that issues transactions such as a client application.\n\n\nLedger\n is a sequence of cryptographically linked blocks, containing transactions and current \nworld state\n.\n\n\nWorld State\n is the collection of variables containing the results of executed transactions.\n\n\nChaincode\n is an application-level code (a.k.a. \nsmart contract\n) stored on the ledger as a part of a transaction. Chaincode runs transactions that may modify the world state.\n\n\nValidating Peer\n is a computer node on the network responsible for running consensus, validating transactions, and maintaining the ledger.\n\n\nNon-validating Peer\n is a computer node on the network which functions as a proxy connecting transactors to the neighboring validating peers. A non-validating peer doesn\nt execute transactions but does verify them. It also hosts the event stream server and the REST service.\n\n\nPermissioned Ledger\n is a blockchain network where each entity or node is required to be a member of the network. Anonymous nodes are not allowed to connect.\n\n\nPrivacy\n is required by the chain transactors to conceal their identities on the network. While members of the network may examine the transactions, the transactions can\nt be linked to the transactor without special privilege.\n\n\nConfidentiality\n is the ability to render the transaction content inaccessible to anyone other than the stakeholders of the transaction.\n\n\nAuditability\n of the blockchain is required, as business usage of blockchain needs to comply with regulations to make it easy for regulators to investigate transaction records.\n\n\n2. Fabric\n\n\nThe fabric is made up of the core components described in the subsections below.\n\n\n2.1 Architecture\n\n\nThe reference architecture is aligned in 3 categories: Membership, Blockchain, and Chaincode services. These categories are logical structures, not a physical depiction of partitioning of components into separate processes, address spaces or (virtual) machines.\n\n\n\n\n2.1.1 Membership Services\n\n\nMembership provides services for managing identity, privacy, confidentiality and auditability on the network. In a non-permissioned blockchain, participation does not require authorization and all nodes can equally submit transactions and/or attempt to accumulate them into acceptable blocks, i.e. there are no distinctions of roles. Membership services combine elements of Public Key Infrastructure (PKI) and decentralization/consensus to transform a non-permissioned blockchain into a permissioned blockchain. In the latter, entities register in order to acquire long-term identity credentials (enrollment certificates), and may be distinguished according to entity type. In the case of users, such credentials enable the Transaction Certificate Authority (TCA) to issue pseudonymous credentials. Such credentials, i.e., transaction certificates, are used to authorize submitted transactions. Transaction certificates persist on the blockchain, and enable authorized auditors to cluster otherwise unlinkable transactions.\n\n\n2.1.2 Blockchain Services\n\n\nBlockchain services manage the distributed ledger through a peer-to-peer protocol, built on HTTP/2. The data structures are highly optimized to provide the most efficient hash algorithm for maintaining the world state replication. Different consensus (PBFT, Raft, PoW, PoS) may be plugged in and configured per deployment.\n\n\n2.1.3 Chaincode Services\n\n\nChaincode services provides a secured and lightweight way to sandbox the chaincode execution on the validating nodes. The environment is a \u201clocked down\u201d and secured container along with a set of signed base images containing secure OS and chaincode language, runtime and SDK layers for Go, Java, and Node.js. Other languages can be enabled if required.\n\n\n2.1.4 Events\n\n\nValidating peers and chaincodes can emit events on the network that applications may listen for and take actions on. There is a set of pre-defined events, and chaincodes can generate custom events. Events are consumed by 1 or more event adapters. Adapters may further deliver events using other vehicles such as Web hooks or Kafka.\n\n\n2.1.5 Application Programming Interface (API)\n\n\nThe primary interface to the fabric is a REST API and its variations over Swagger 2.0. The API allows applications to register users, query the blockchain, and to issue transactions. There is a set of APIs specifically for chaincode to interact with the stack to execute transactions and query transaction results.\n\n\n2.1.6 Command Line Interface (CLI)\n\n\nCLI includes a subset of the REST API to enable developers to quickly test chaincodes or query for status of transactions. CLI is implemented in Golang and operable on multiple OS platforms.\n\n\n2.2 Topology\n\n\nA deployment of the fabric can consist of a membership service, many validating peers, non-validating peers, and 1 or more applications. All of these components make up a chain. There can be multiple chains; each one having its own operating parameters and security requirements.\n\n\n2.2.1 Single Validating Peer\n\n\nFunctionally, a non-validating peer is a subset of a validating peer; that is, every capability on a non-validating peer may be enabled on a validating peer, so the simplest network may consist of a single validating peer node. This configuration is most appropriate for a development environment, where a single validating peer may be started up during the edit-compile-debug cycle.\n\n\n\n\nA single validating peer doesn\nt require consensus, and by default uses the \nnoops\n plugin, which executes transactions as they arrive. This gives the developer an immediate feedback during development.\n\n\n2.2.2 Multiple Validating Peers\n\n\nProduction or test networks should be made up of multiple validating and non-validating peers as necessary. Non-validating peers can take workload off the validating peers, such as handling API requests and processing events.\n\n\n\n\nThe validating peers form a mesh-network (every validating peer connects to every other validating peer) to disseminate information. A non-validating peer connects to a neighboring validating peer that it is allowed to connect to. Non-validating peers are optional since applications may communicate directly with validating peers.\n\n\n2.2.3 Multichain\n\n\nEach network of validating and non-validating peers makes up a chain. Many chains may be created to address different needs, similar to having multiple Web sites, each serving a different purpose.\n\n\n3. Protocol\n\n\nThe fabric\ns peer-to-peer communication is built on \ngRPC\n, which allows bi-directional stream-based messaging. It uses \nProtocol Buffers\n to serialize data structures for data transfer between peers. Protocol buffers are a language-neutral, platform-neutral and extensible mechanism for serializing structured data. Data structures, messages, and services are described using \nproto3 language\n notation.\n\n\n3.1 Message\n\n\nMessages passed between nodes are encapsulated by \nMessage\n proto structure, which consists of 4 types: Discovery, Transaction, Synchronization, and Consensus. Each type may define more subtypes embedded in the \npayload\n.\n\n\nmessage Message {\n   enum Type {\n        UNDEFINED = 0;\n\n        DISC_HELLO = 1;\n        DISC_DISCONNECT = 2;\n        DISC_GET_PEERS = 3;\n        DISC_PEERS = 4;\n        DISC_NEWMSG = 5;\n\n        CHAIN_STATUS = 6;\n        CHAIN_TRANSACTION = 7;\n        CHAIN_GET_TRANSACTIONS = 8;\n        CHAIN_QUERY = 9;\n\n        SYNC_GET_BLOCKS = 11;\n        SYNC_BLOCKS = 12;\n        SYNC_BLOCK_ADDED = 13;\n\n        SYNC_STATE_GET_SNAPSHOT = 14;\n        SYNC_STATE_SNAPSHOT = 15;\n        SYNC_STATE_GET_DELTAS = 16;\n        SYNC_STATE_DELTAS = 17;\n\n        RESPONSE = 20;\n        CONSENSUS = 21;\n    }\n    Type type = 1;\n    bytes payload = 2;\n    google.protobuf.Timestamp timestamp = 3;\n}\n\n\n\n\nThe \npayload\n is an opaque byte array containing other objects such as \nTransaction\n or \nResponse\n depending on the type of the message. For example, if the \ntype\n is \nCHAIN_TRANSACTION\n, the \npayload\n is a \nTransaction\n object.\n\n\n3.1.1 Discovery Messages\n\n\nUpon start up, a peer runs discovery protocol if \nCORE_PEER_DISCOVERY_ROOTNODE\n is specified. \nCORE_PEER_DISCOVERY_ROOTNODE\n is the IP address of another peer on the network (any peer) that serves as the starting point for discovering all the peers on the network. The protocol sequence begins with \nDISC_HELLO\n, whose \npayload\n is a \nHelloMessage\n object, containing its endpoint:\n\n\nmessage HelloMessage {\n  PeerEndpoint peerEndpoint = 1;\n  uint64 blockNumber = 2;\n}\nmessage PeerEndpoint {\n    PeerID ID = 1;\n    string address = 2;\n    enum Type {\n      UNDEFINED = 0;\n      VALIDATOR = 1;\n      NON_VALIDATOR = 2;\n    }\n    Type type = 3;\n    bytes pkiID = 4;\n}\n\nmessage PeerID {\n    string name = 1;\n}\n\n\n\n\nDefinition of fields:\n\n\n\n\nPeerID\n is any name given to the peer at start up or defined in the config file\n\n\nPeerEndpoint\n describes the endpoint and whether it\ns a validating or a non-validating peer\n\n\npkiID\n is the cryptographic ID of the peer\n\n\naddress\n is host or IP address and port of the peer in the format \nip:port\n\n\nblockNumber\n is the height of the blockchain the peer currently has\n\n\n\n\nIf the block height received upon \nDISC_HELLO\n is higher than the current block height of the peer, it immediately initiates the synchronization protocol to catch up with the network.\n\n\nAfter \nDISC_HELLO\n, peer sends \nDISC_GET_PEERS\n periodically to discover any additional peers joining the network. In response to \nDISC_GET_PEERS\n, a peer sends \nDISC_PEERS\n with \npayload\n containing an array of \nPeerEndpoint\n. Other discovery message types are not used at this point.\n\n\n3.1.2 Transaction Messages\n\n\nThere are 3 types of transactions: Deploy, Invoke and Query. A deploy transaction installs the specified chaincode on the chain, while invoke and query transactions call a function of a deployed chaincode. Another type in consideration is Create transaction, where a deployed chaincode may be instantiated on the chain and is addressable. This type has not been implemented as of this writing.\n\n\n3.1.2.1 Transaction Data Structure\n\n\nMessages with type \nCHAIN_TRANSACTION\n or \nCHAIN_QUERY\n carry a \nTransaction\n object in the \npayload\n:\n\n\nmessage Transaction {\n    enum Type {\n        UNDEFINED = 0;\n        CHAINCODE_DEPLOY = 1;\n        CHAINCODE_INVOKE = 2;\n        CHAINCODE_QUERY = 3;\n        CHAINCODE_TERMINATE = 4;\n    }\n    Type type = 1;\n    string uuid = 5;\n    bytes chaincodeID = 2;\n    bytes payloadHash = 3;\n\n    ConfidentialityLevel confidentialityLevel = 7;\n    bytes nonce = 8;\n    bytes cert = 9;\n    bytes signature = 10;\n\n    bytes metadata = 4;\n    google.protobuf.Timestamp timestamp = 6;\n}\n\nmessage TransactionPayload {\n    bytes payload = 1;\n}\n\nenum ConfidentialityLevel {\n    PUBLIC = 0;\n    CONFIDENTIAL = 1;\n}\n\n\n\n\n\nDefinition of fields:\n\n- \ntype\n - The type of the transaction, which is 1 of the following:\n    - \nUNDEFINED\n - Reserved for future use.\n  - \nCHAINCODE_DEPLOY\n - Represents the deployment of a new chaincode.\n    - \nCHAINCODE_INVOKE\n - Represents a chaincode function execution that may read and modify the world state.\n    - \nCHAINCODE_QUERY\n - Represents a chaincode function execution that may only read the world state.\n    - \nCHAINCODE_TERMINATE\n - Marks a chaincode as inactive so that future functions of the chaincode can no longer be invoked.\n- \nchaincodeID\n - The ID of a chaincode which is a hash of the chaincode source, path to the source code, constructor function, and parameters.\n- \npayloadHash\n - Bytes defining the hash of \nTransactionPayload.payload\n.\n- \nmetadata\n - Bytes defining any associated transaction metadata that the application may use.\n- \nuuid\n - A unique ID for the transaction.\n- \ntimestamp\n - A timestamp of when the transaction request was received by the peer.\n- \nconfidentialityLevel\n - Level of data confidentiality. There are currently 2 levels. Future releases may define more levels.\n- \nnonce\n - Used for security.\n- \ncert\n - Certificate of the transactor.\n- \nsignature\n - Signature of the transactor.\n- \nTransactionPayload.payload\n - Bytes defining the payload of the transaction. As the payload can be large, only the payload hash is included directly in the transaction message.\n\n\nMore detail on transaction security can be found in section 4.\n\n\n3.1.2.2 Transaction Specification\n\n\nA transaction is always associated with a chaincode specification which defines the chaincode and the execution environment such as language and security context. Currently there is an implementation that uses Golang for writing chaincode. Other languages may be added in the future.\n\n\nmessage ChaincodeSpec {\n    enum Type {\n        UNDEFINED = 0;\n        GOLANG = 1;\n        NODE = 2;\n    }\n    Type type = 1;\n    ChaincodeID chaincodeID = 2;\n    ChaincodeInput ctorMsg = 3;\n    int32 timeout = 4;\n    string secureContext = 5;\n    ConfidentialityLevel confidentialityLevel = 6;\n    bytes metadata = 7;\n}\n\nmessage ChaincodeID {\n    string path = 1;\n    string name = 2;\n}\n\nmessage ChaincodeInput {\n    string function = 1;\n    repeated string args  = 2;\n}\n\n\n\n\nDefinition of fields:\n\n- \nchaincodeID\n - The chaincode source code path and name.\n- \nctorMsg\n - Function name and argument parameters to call.\n- \ntimeout\n - Time in milliseconds to execute the transaction.\n- \nconfidentialityLevel\n - Confidentiality level of this transaction.\n- \nsecureContext\n - Security context of the transactor.\n- \nmetadata\n - Any data the application wants to pass along.\n\n\nThe peer, receiving the \nchaincodeSpec\n, wraps it in an appropriate transaction message and broadcasts to the network.\n\n\n3.1.2.3 Deploy Transaction\n\n\nTransaction \ntype\n of a deploy transaction is \nCHAINCODE_DEPLOY\n and the payload contains an object of \nChaincodeDeploymentSpec\n.\n\n\nmessage ChaincodeDeploymentSpec {\n    ChaincodeSpec chaincodeSpec = 1;\n    google.protobuf.Timestamp effectiveDate = 2;\n    bytes codePackage = 3;\n}\n\n\n\n\nDefinition of fields:\n\n- \nchaincodeSpec\n - See section 3.1.2.2, above.\n- \neffectiveDate\n - Time when the chaincode is ready to accept invocations.\n- \ncodePackage\n - gzip of the chaincode source.\n\n\nThe validating peers always verify the hash of the \ncodePackage\n when they deploy the chaincode to make sure the package has not been tampered with since the deploy transaction entered the network.\n\n\n3.1.2.4 Invoke Transaction\n\n\nTransaction \ntype\n of an invoke transaction is \nCHAINCODE_INVOKE\n and the \npayload\n contains an object of \nChaincodeInvocationSpec\n.\n\n\nmessage ChaincodeInvocationSpec {\n    ChaincodeSpec chaincodeSpec = 1;\n}\n\n\n\n\n3.1.2.5 Query Transaction\n\n\nA query transaction is similar to an invoke transaction, but the message \ntype\n is \nCHAINCODE_QUERY\n.\n\n\n3.1.3 Synchronization Messages\n\n\nSynchronization protocol starts with discovery, described above in section 3.1.1, when a peer realizes that it\ns behind or its current block is not the same with others. A peer broadcasts either \nSYNC_GET_BLOCKS\n, \nSYNC_STATE_GET_SNAPSHOT\n, or \nSYNC_STATE_GET_DELTAS\n and receives \nSYNC_BLOCKS\n, \nSYNC_STATE_SNAPSHOT\n, or \nSYNC_STATE_DELTAS\n respectively.\n\n\nThe installed consensus plugin (e.g. pbft) dictates how synchronization protocol is being applied. Each message is designed for a specific situation:\n\n\nSYNC_GET_BLOCKS\n requests for a range of contiguous blocks expressed in the message \npayload\n, which is an object of \nSyncBlockRange\n. The correlationId specified is included in the \nSyncBlockRange\n of any replies to this message.\n\n\nmessage SyncBlockRange {\n    uint64 correlationId = 1;\n    uint64 start = 2;\n    uint64 end = 3;\n}\n\n\n\n\nA receiving peer responds with a \nSYNC_BLOCKS\n message whose \npayload\n contains an object of \nSyncBlocks\n\n\nmessage SyncBlocks {\n    SyncBlockRange range = 1;\n    repeated Block blocks = 2;\n}\n\n\n\n\nThe \nstart\n and \nend\n indicate the starting and ending blocks inclusively. The order in which blocks are returned is defined by the \nstart\n and \nend\n values. For example, if \nstart\n=3 and \nend\n=5, the order of blocks will be 3, 4, 5. If \nstart\n=5 and \nend\n=3, the order will be 5, 4, 3.\n\n\nSYNC_STATE_GET_SNAPSHOT\n requests for the snapshot of the current world state. The \npayload\n is an object of \nSyncStateSnapshotRequest\n\n\nmessage SyncStateSnapshotRequest {\n  uint64 correlationId = 1;\n}\n\n\n\n\nThe \ncorrelationId\n is used by the requesting peer to keep track of the response messages. A receiving peer replies with \nSYNC_STATE_SNAPSHOT\n message whose \npayload\n is an instance of \nSyncStateSnapshot\n\n\nmessage SyncStateSnapshot {\n    bytes delta = 1;\n    uint64 sequence = 2;\n    uint64 blockNumber = 3;\n    SyncStateSnapshotRequest request = 4;\n}\n\n\n\n\nThis message contains the snapshot or a chunk of the snapshot on the stream, and in which case, the sequence indicate the order starting at 0. The terminating message will have len(delta) == 0.\n\n\nSYNC_STATE_GET_DELTAS\n requests for the state deltas of a range of contiguous blocks. By default, the Ledger maintains 500 transition deltas. A delta(j) is a state transition between block(i) and block(j) where i = j-1. The message \npayload\n contains an instance of \nSyncStateDeltasRequest\n\n\nmessage SyncStateDeltasRequest {\n    SyncBlockRange range = 1;\n}\n\n\n\n\nA receiving peer responds with \nSYNC_STATE_DELTAS\n, whose \npayload\n is an instance of \nSyncStateDeltas\n\n\nmessage SyncStateDeltas {\n    SyncBlockRange range = 1;\n    repeated bytes deltas = 2;\n}\n\n\n\n\nA delta may be applied forward (from i to j) or backward (from j to i) in the state transition.\n\n\n3.1.4 Consensus Messages\n\n\nConsensus deals with transactions, so a \nCONSENSUS\n message is initiated internally by the consensus framework when it receives a \nCHAIN_TRANSACTION\n message. The framework converts \nCHAIN_TRANSACTION\n into \nCONSENSUS\n then broadcasts to the validating nodes with the same \npayload\n. The consensus plugin receives this message and process according to its internal algorithm. The plugin may create custom subtypes to manage consensus finite state machine. See section 3.4 for more details.\n\n\n3.2 Ledger\n\n\nThe ledger consists of two primary pieces, the blockchain and the world state. The blockchain is a series of linked blocks that is used to record transactions within the ledger. The world state is a key-value database that chaincodes may use to store state when executed by a transaction.\n\n\n3.2.1 Blockchain\n\n\n3.2.1.1 Block\n\n\nThe blockchain is defined as a linked list of blocks as each block contains the hash of the previous block in the chain. The two other important pieces of information that a block contains are the list of transactions contained within the block and the hash of the world state after executing all transactions in the block.\n\n\nmessage Block {\n  version = 1;\n  google.protobuf.Timestamp timestamp = 2;\n  bytes transactionsHash = 3;\n  bytes stateHash = 4;\n  bytes previousBlockHash = 5;\n  bytes consensusMetadata = 6;\n  NonHashData nonHashData = 7;\n}\n\nmessage BlockTransactions {\n  repeated Transaction transactions = 1;\n}\n\n\n\n\n\n\nversion\n - Version used to track any protocol changes.\n\n\ntimestamp\n - The timestamp to be filled in by the block proposer.\n\n\ntransactionsHash\n - The merkle root hash of the block\ns transactions.\n\n\nstateHash\n - The merkle root hash of the world state.\n\n\npreviousBlockHash\n - The hash of the previous block.\n\n\nconsensusMetadata\n - Optional metadata that the consensus may include in a block.\n\n\nnonHashData\n - A \nNonHashData\n message that is set to nil before computing the hash of the block, but stored as part of the block in the database.\n\n\nBlockTransactions.transactions\n - An array of Transaction messages. Transactions are not included in the block directly due to their size.\n\n\n\n\n3.2.1.2 Block Hashing\n\n\n\n\nThe \npreviousBlockHash\n hash is calculated using the following algorithm.\n\n\n\n\nSerialize the Block message to bytes using the protocol buffer library.\n\n\n\n\n\n\nHash the serialized block message to 512 bits of output using the SHA3 SHAKE256 algorithm as described in \nFIPS 202\n.\n\n\n\n\n\n\nThe \ntransactionHash\n is the root of the transaction merkle tree. Defining the merkle tree implementation is a TODO.\n\n\n\n\n\n\nThe \nstateHash\n is defined in section 3.2.2.1.\n\n\n\n\n\n\n3.2.1.3 NonHashData\n\n\nThe NonHashData message is used to store block metadata that is not required to be the same value on all peers. These are suggested values.\n\n\nmessage NonHashData {\n  google.protobuf.Timestamp localLedgerCommitTimestamp = 1;\n  repeated TransactionResult transactionResults = 2;\n}\n\nmessage TransactionResult {\n  string uuid = 1;\n  bytes result = 2;\n  uint32 errorCode = 3;\n  string error = 4;\n}\n\n\n\n\n\n\n\n\nlocalLedgerCommitTimestamp\n - A timestamp indicating when the block was commited to the local ledger.\n\n\n\n\n\n\nTransactionResult\n - An array of transaction results.\n\n\n\n\n\n\nTransactionResult.uuid\n - The ID of the transaction.\n\n\n\n\n\n\nTransactionResult.result\n - The return value of the transaction.\n\n\n\n\n\n\nTransactionResult.errorCode\n - A code that can be used to log errors associated with the transaction.\n\n\n\n\n\n\nTransactionResult.error\n - A string that can be used to log errors associated with the transaction.\n\n\n\n\n\n\n3.2.1.4 Transaction Execution\n\n\nA transaction defines either the deployment of a chaincode or the execution of a chaincode. All transactions within a block are run before recording a block in the ledger. When chaincodes execute, they may modify the world state. The hash of the world state is then recorded in the block.\n\n\n3.2.2 World State\n\n\nThe \nworld state\n of a peer refers to the collection of the \nstates\n of all the deployed chaincodes. Further, the state of a chaincode is represented as a collection of key-value pairs. Thus, logically, the world state of a peer is also a collection of key-value pairs where key consists of a tuple \n{chaincodeID, ckey}\n. Here, we use the term \nkey\n to represent a key in the world state i.e., a tuple \n{chaincodeID, ckey}\n and we use the term \ncKey\n to represent a unique key within a chaincode.\n\n\nFor the purpose of the description below, \nchaincodeID\n is assumed to be a valid utf8 string and \nckey\n and the \nvalue\n can be a sequence of one or more arbitrary bytes.\n\n\n3.2.2.1 Hashing the world state\n\n\nDuring the functioning of a network, many occasions such as committing transactions and synchronizing peers may require computing a crypto-hash of the world state observed by a peer. For instance, the consensus protocol may require to ensure that a \nminimum\n number of peers in the network observe the same world state.\n\n\nSince, computing the crypto-hash of the world state could be an expensive operation, this is highly desirable to organize the world state such that it enables an efficient crypto-hash computation of the world state when a change occurs in the world state. Further, different organization designs may be suitable under different workloads conditions.\n\n\nBecause the fabric is expected to function under a variety of scenarios leading to different workloads conditions, a pluggable mechanism is supported for organizing the world state.\n\n\n3.2.2.1.1 Bucket-tree\n\n\nBucket-tree\n is one of the implementations for organizing the world state. For the purpose of the description below, a key in the world state is represented as a concatenation of the two components (\nchaincodeID\n and \nckey\n)  separated by a \nnil\n byte i.e., \nkey\n = \nchaincodeID\n+\nnil\n+\ncKey\n.\n\n\nThis method models a \nmerkle-tree\n on top of buckets of a \nhash table\n in order to compute the crypto-hash of the \nworld state\n.\n\n\nAt the core of this method, the \nkey-values\n of the world state are assumed to be stored in a hash-table that consists of a pre-decided number of buckets (\nnumBuckets\n). A hash function (\nhashFunction\n) is employed to determine the bucket number that should contain a given key. Please note that the \nhashFunction\n does not represent a crypto-hash method such as SHA3, rather this is a regular programming language hash function that decides the bucket number for a given key.\n\n\nFor modeling the merkle-tree, the ordered buckets act as leaf nodes of the tree - lowest numbered bucket being the left most leaf node in the tree. For constructing the second-last level of the tree, a pre-decided number of leaf nodes (\nmaxGroupingAtEachLevel\n), starting from left, are grouped together and for each such group, a node is inserted at the second-last level that acts as a common parent for all the leaf nodes in the group. Note that the number of children for the last parent node may be less than \nmaxGroupingAtEachLevel\n. This grouping method of constructing the next higher level is repeated until the root node of the tree is constructed.\n\n\nAn example setup with configuration \n{numBuckets=10009 and maxGroupingAtEachLevel=10}\n will result in a tree with number of nodes at different level as depicted in the following table.\n\n\n\n\n\n\n\n\nLevel\n\n\nNumber of nodes\n\n\n\n\n\n\n\n\n\n\n0\n\n\n1\n\n\n\n\n\n\n1\n\n\n2\n\n\n\n\n\n\n2\n\n\n11\n\n\n\n\n\n\n3\n\n\n101\n\n\n\n\n\n\n4\n\n\n1001\n\n\n\n\n\n\n5\n\n\n10009\n\n\n\n\n\n\n\n\nFor computing the crypto-hash of the world state, the crypto-hash of each bucket is computed and is assumed to be the crypto-hash of leaf-nodes of the merkle-tree. In order to compute crypto-hash of a bucket, the key-values present in the bucket are first serialized and crypto-hash function is applied on the serialized bytes. For serializing the key-values of a bucket, all the key-values with a common chaincodeID prefix are serialized separately and then appending together, in the ascending order of chaincodeIDs. For serializing the key-values of a chaincodeID, the following information is concatenated:\n   1. Length of chaincodeID (number of bytes in the chaincodeID)\n   - The utf8 bytes of the chaincodeID\n   - Number of key-values for the chaincodeID\n   - For each key-value (in sorted order of the ckey)\n      - Length of the ckey\n      - ckey bytes\n      - Length of the value\n      - value bytes\n\n\nFor all the numeric types in the above list of items (e.g., Length of chaincodeID), protobuf\ns varint encoding is assumed to be used. The purpose of the above encoding is to achieve a byte representation of the key-values within a bucket that can not be arrived at by any other combination of key-values and also to reduce the overall size of the serialized bytes.\n\n\nFor example, consider a bucket that contains three key-values namely, \nchaincodeID1_key1:value1, chaincodeID1_key2:value2, and chaincodeID2_key1:value1\n. The serialized bytes for the bucket would logically look as - \n12 + chaincodeID1 + 2 + 4 + key1 + 6 + value1 + 4 + key2 + 6 + value2 + 12 + chaincodeID2 + 1 + 4 + key1 + 6 + value1\n\n\nIf a bucket has no key-value present, the crypto-hash is considered as \nnil\n.\n\n\nThe crypto-hash of an intermediate node and root node are computed just like in a standard merkle-tree i.e., applying a crypto-hash function on the bytes obtained by concatenating the crypto-hash of all the children nodes, from left to right. Further, if a child has a crypto-hash as \nnil\n, the crypto-hash of the child is omitted when concatenating the children crypto-hashes. If the node has a single child, the crypto-hash of the child is assumed to be the crypto-hash of the node. Finally, the crypto-hash of the root node is considered as the crypto-hash of the world state.\n\n\nThe above method offers performance benefits for computing crypto-hash when a few key-values change in the state. The major benefits include\n  - Computation of crypto-hashes of the unchanged buckets can be skipped\n  - The depth and breadth of the merkle-tree can be controlled by configuring the parameters \nnumBuckets\n and \nmaxGroupingAtEachLevel\n. Both depth and breadth of the tree has different implication on the performance cost incurred by and resource demand of different resources (namely - disk I/O, storage, and memory)\n\n\nIn a particular deployment, all the peer nodes are expected to use same values for the configurations \nnumBuckets, maxGroupingAtEachLevel, and hashFunction\n. Further, if any of these configurations are to be changed at a later stage, the configurations should be changed on all the peer nodes so that the comparison of crypto-hashes across peer nodes is meaningful. Also, this may require to migrate the existing data based on the implementation. For example, an implementation is expected to store the last computed crypto-hashes for all the nodes in the tree which would need to be recalculated.\n\n\n3.3 Chaincode\n\n\nChaincode is an application-level code deployed as a transaction (see section 3.1.2) to be distributed to the network and managed by each validating peer as isolated sandbox. Though any virtualization technology can support the sandbox, currently Docker container is utilized to run the chaincode. The protocol described in this section enables different virtualization support implementation to plug and play.\n\n\n3.3.1 Virtual Machine Instantiation\n\n\nA virtual machine implements the VM interface:  \n\n\ntype VM interface {\n    build(ctxt context.Context, id string, args []string, env []string, attachstdin bool, attachstdout bool, reader io.Reader) error\n    start(ctxt context.Context, id string, args []string, env []string, attachstdin bool, attachstdout bool) error\n    stop(ctxt context.Context, id string, timeout uint, dontkill bool, dontremove bool) error\n}\n\n\n\n\nThe fabric instantiates the VM when it processes a Deploy transaction or other transactions on the chaincode while the VM for that chaincode is not running (either crashed or previously brought down due to inactivity). Each chaincode image is built by the \nbuild\n function, started by \nstart\n and stopped by \nstop\n function.\n\n\nOnce the chaincode container is up, it makes a gRPC connection back to the validating peer that started the chaincode, and that establishes the channel for Invoke and Query transactions on the chaincode.\n\n\n3.3.2 Chaincode Protocol\n\n\nCommunication between a validating peer and its chaincodes is based on a bidirectional gRPC stream. There is a shim layer on the chaincode container to handle the message protocol between the chaincode and the validating peer using protobuf message.\n\n\nmessage ChaincodeMessage {\n\n    enum Type {\n        UNDEFINED = 0;\n        REGISTER = 1;\n        REGISTERED = 2;\n        INIT = 3;\n        READY = 4;\n        TRANSACTION = 5;\n        COMPLETED = 6;\n        ERROR = 7;\n        GET_STATE = 8;\n        PUT_STATE = 9;\n        DEL_STATE = 10;\n        INVOKE_CHAINCODE = 11;\n        INVOKE_QUERY = 12;\n        RESPONSE = 13;\n        QUERY = 14;\n        QUERY_COMPLETED = 15;\n        QUERY_ERROR = 16;\n        RANGE_QUERY_STATE = 17;\n    }\n\n    Type type = 1;\n    google.protobuf.Timestamp timestamp = 2;\n    bytes payload = 3;\n    string uuid = 4;\n}\n\n\n\n\nDefinition of fields:\n\n- \nType\n is the type of the message.\n- \npayload\n is the payload of the message. Each payload depends on the \nType\n.\n- \nuuid\n is a unique identifier of the message.\n\n\nThe message types are described in the following sub-sections.\n\n\nA chaincode implements the \nChaincode\n interface, which is called by the validating peer when it processes Deploy, Invoke or Query transactions.\n\n\ntype Chaincode interface {\ni   Init(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n    Invoke(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n    Query(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n}\n\n\n\n\nInit\n, \nInvoke\n and \nQuery\n functions take \nfunction\n and \nargs\n as parameters to be used by those methods to support a variety of transactions. \nInit\n is a constructor function, which will only be invoked by the Deploy transaction. The \nQuery\n function is not allowed to modify the state of the chaincode; it can only read and calculate the return value as a byte array.\n\n\n3.3.2.1 Chaincode Deploy\n\n\nUpon deploy (chaincode container is started), the shim layer sends a one time \nREGISTER\n message to the validating peer with the \npayload\n containing the \nChaincodeID\n. The validating peer responds with \nREGISTERED\n or \nERROR\n on success or failure respectively. The shim closes the connection and exits if it receives an \nERROR\n.\n\n\nAfter registration, the validating peer sends \nINIT\n with the \npayload\n containing a \nChaincodeInput\n object. The shim calls the \nInit\n function with the parameters from the \nChaincodeInput\n, enabling the chaincode to perform any initialization, such as setting up the persistent state.\n\n\nThe shim responds with \nRESPONSE\n or \nERROR\n message depending on the returned value from the chaincode \nInit\n function. If there are no errors, the chaincode initialization is complete and is ready to receive Invoke and Query transactions.\n\n\n3.3.2.2 Chaincode Invoke\n\n\nWhen processing an invoke transaction, the validating peer sends a \nTRANSACTION\n message to the chaincode container shim, which in turn calls the chaincode \nInvoke\n function, passing the parameters from the \nChaincodeInput\n object. The shim responds to the validating peer with \nRESPONSE\n or \nERROR\n message, indicating the completion of the function. If \nERROR\n is received, the \npayload\n contains the error message generated by the chaincode.\n\n\n3.3.2.3 Chaincode Query\n\n\nSimilar to an invoke transaction, when processing a query, the validating peer sends a \nQUERY\n message to the chaincode container shim, which in turn calls the chaincode \nQuery\n function, passing the parameters from the \nChaincodeInput\n object. The \nQuery\n function may return a state value or an error, which the shim forwards to the validating peer using \nRESPONSE\n or \nERROR\n messages respectively.\n\n\n3.3.2.4 Chaincode State\n\n\nEach chaincode may define its own persistent state variables. For example, a chaincode may create assets such as TVs, cars, or stocks using state variables to hold the assets attributes. During \nInvoke\n function processing, the chaincode may update the state variables, for example, changing an asset owner. A chaincode manipulates the state variables by using the following message types:\n\n\nPUT_STATE\n\n\nChaincode sends a \nPUT_STATE\n message to persist a key-value pair, with the \npayload\n containing \nPutStateInfo\n object.\n\n\nmessage PutStateInfo {\n    string key = 1;\n    bytes value = 2;\n}\n\n\n\n\nGET_STATE\n\n\nChaincode sends a \nGET_STATE\n message to retrieve the value whose key is specified in the \npayload\n.\n\n\nDEL_STATE\n\n\nChaincode sends a \nDEL_STATE\n message to delete the value whose key is specified in the \npayload\n.\n\n\nRANGE_QUERY_STATE\n\n\nChaincode sends a \nRANGE_QUERY_STATE\n message to get a range of values. The message \npayload\n contains a \nRangeQueryStateInfo\n object.\n\n\nmessage RangeQueryState {\n    string startKey = 1;\n    string endKey = 2;\n}\n\n\n\n\nThe \nstartKey\n and \nendKey\n are inclusive and assumed to be in lexical order. The validating peer responds with \nRESPONSE\n message whose \npayload\n is a \nRangeQueryStateResponse\n object.\n\n\nmessage RangeQueryStateResponse {\n    repeated RangeQueryStateKeyValue keysAndValues = 1;\n    bool hasMore = 2;\n    string ID = 3;\n}\nmessage RangeQueryStateKeyValue {\n    string key = 1;\n    bytes value = 2;\n}\n\n\n\n\nIf \nhasMore=true\n in the response, this indicates that additional keys are available in the requested range. The chaincode can request the next set of keys and values by sending a \nRangeQueryStateNext\n message with an ID that matches the ID returned in the response.\n\n\nmessage RangeQueryStateNext {\n    string ID = 1;\n}\n\n\n\n\nWhen the chaincode is finished reading from the range, it should send a \nRangeQueryStateClose\n message with the ID it wishes to close.\n\n\nmessage RangeQueryStateClose {\n  string ID = 1;\n}\n\n\n\n\nINVOKE_CHAINCODE\n\n\nChaincode may call another chaincode in the same transaction context by sending an \nINVOKE_CHAINCODE\n message to the validating peer with the \npayload\n containing a \nChaincodeSpec\n object.\n\n\nQUERY_CHAINCODE\n\n\nChaincode may query another chaincode in the same transaction context by sending a \nQUERY_CHAINCODE\n message with the \npayload\n containing a \nChaincodeSpec\n object.\n\n\n3.4 Pluggable Consensus Framework\n\n\nThe consensus framework defines the interfaces that every consensus \nplugin\n implements:\n\n\n\n\nconsensus.Consenter\n: interface that  allows consensus plugin to receive messages from the network.\n\n\nconsensus.CPI\n:  \nConsensus Programming Interface\n (\nCPI\n) is used by consensus plugin to interact with rest of the stack. This interface is split in two parts:\n\n\nconsensus.Communicator\n: used to send (broadcast and unicast) messages to other validating peers.\n\n\nconsensus.LedgerStack\n: which is used as an interface to the execution framework as well as the ledger.\n\n\n\n\n\n\n\n\nAs described below in more details, \nconsensus.LedgerStack\n encapsulates, among other interfaces, the \nconsensus.Executor\n interface, which is the key part of the consensus framework. Namely, \nconsensus.Executor\n interface allows for a (batch of) transaction to be started, executed, rolled back if necessary, previewed, and potentially committed. A particular property that every consensus plugin needs to satisfy is that batches (blocks)  of transactions are committed to the ledger (via \nconsensus.Executor.CommitTxBatch\n) in total order across all validating peers (see \nconsensus.Executor\n interface description below for more details).\n\n\nCurrently, consensus framework consists of 3 packages \nconsensus\n, \ncontroller\n, and \nhelper\n. The primary reason for \ncontroller\n and \nhelper\n packages is to avoid \nimport cycle\n in Go (golang) and minimize code changes for plugin to update.\n\n\n\n\ncontroller\n package specifies the consensus plugin used by a validating peer.\n\n\nhelper\n package is a shim around a consensus plugin that helps it interact with the rest of the stack, such as maintaining message handlers to other peers.\n\n\n\n\nThere are 2 consensus plugins provided: \npbft\n and \nnoops\n:\n\n\n\n\npbft\n package contains consensus plugin that implements the \nPBFT\n [1] consensus protocol. See section 5 for more detail.\n\n\nnoops\n is a \ndummy\n consensus plugin for development and test purposes. It doesn\nt perform consensus but processes all consensus messages. It also serves as a good simple sample to start learning how to code a consensus plugin.\n\n\n\n\n3.4.1 \nConsenter\n interface\n\n\nDefinition:\n\n\ntype Consenter interface {\n    RecvMsg(msg *pb.Message) error\n}\n\n\n\n\nThe plugin\ns entry point for (external) client requests, and consensus messages generated internally (i.e. from the consensus module) during the consensus process. The \ncontroller.NewConsenter\n creates the plugin \nConsenter\n. \nRecvMsg\n processes the incoming transactions in order to reach consensus.\n\n\nSee \nhelper.HandleMessage\n below to understand how the peer interacts with this interface.\n\n\n3.4.2 \nCPI\n interface\n\n\nDefinition:\n\n\ntype CPI interface {\n    Inquirer\n    Communicator\n    SecurityUtils\n    LedgerStack\n}\n\n\n\n\nCPI\n allows the plugin to interact with the stack. It is implemented by the \nhelper.Helper\n object. Recall that this object:\n\n\n\n\nIs instantiated when the \nhelper.NewConsensusHandler\n is called.\n\n\nIs accessible to the plugin author when they construct their plugin\ns \nconsensus.Consenter\n object.\n\n\n\n\n3.4.3 \nInquirer\n interface\n\n\nDefinition:\n\n\ntype Inquirer interface {\n        GetNetworkInfo() (self *pb.PeerEndpoint, network []*pb.PeerEndpoint, err error)\n        GetNetworkHandles() (self *pb.PeerID, network []*pb.PeerID, err error)\n}\n\n\n\n\nThis interface is a part of the \nconsensus.CPI\n interface. It is used to get the handles of the validating peers in the network (\nGetNetworkHandles\n) as well as details about the those validating peers (\nGetNetworkInfo\n):\n\n\nNote that the peers are identified by a \npb.PeerID\n object. This is a protobuf message (in the \nprotos\n package), currently defined as (notice that this definition will likely be modified):\n\n\nmessage PeerID {\n    string name = 1;\n}\n\n\n\n\n3.4.4 \nCommunicator\n interface\n\n\nDefinition:\n\n\ntype Communicator interface {\n    Broadcast(msg *pb.Message) error\n    Unicast(msg *pb.Message, receiverHandle *pb.PeerID) error\n}\n\n\n\n\nThis interface is a part of the \nconsensus.CPI\n interface. It is used to communicate with other peers on the network (\nhelper.Broadcast\n, \nhelper.Unicast\n):\n\n\n3.4.5 \nSecurityUtils\n interface\n\n\nDefinition:\n\n\ntype SecurityUtils interface {\n        Sign(msg []byte) ([]byte, error)\n        Verify(peerID *pb.PeerID, signature []byte, message []byte) error\n}\n\n\n\n\nThis interface is a part of the \nconsensus.CPI\n interface. It is used to handle the cryptographic operations of message signing (\nSign\n) and verifying signatures (\nVerify\n)\n\n\n3.4.6 \nLedgerStack\n interface\n\n\nDefinition:\n\n\ntype LedgerStack interface {\n    Executor\n    Ledger\n    RemoteLedgers\n}\n\n\n\n\nA key member of the \nCPI\n interface, \nLedgerStack\n groups interaction of consensus with the rest of the fabric, such as the execution of transactions, querying, and updating the ledger. This interface supports querying the local blockchain and state, updating the local blockchain and state, and querying the blockchain and state of other nodes in the consensus network. It consists of three parts: \nExecutor\n, \nLedger\n and \nRemoteLedgers\n interfaces. These are described in the following.\n\n\n3.4.7 \nExecutor\n interface\n\n\nDefinition:\n\n\ntype Executor interface {\n    BeginTxBatch(id interface{}) error\n    ExecTXs(id interface{}, txs []*pb.Transaction) ([]byte, []error)  \n    CommitTxBatch(id interface{}, transactions []*pb.Transaction, transactionsResults []*pb.TransactionResult, metadata []byte) error  \n    RollbackTxBatch(id interface{}) error  \n    PreviewCommitTxBatchBlock(id interface{}, transactions []*pb.Transaction, metadata []byte) (*pb.Block, error)  \n}\n\n\n\n\nThe executor interface is the most frequently utilized portion of the \nLedgerStack\n interface, and is the only piece which is strictly necessary for a consensus network to make progress. The interface allows for a transaction to be started, executed, rolled back if necessary, previewed, and potentially committed. This interface is comprised of the following methods.\n\n\n3.4.7.1 Beginning a transaction batch\n\n\nBeginTxBatch(id interface{}) error\n\n\n\n\nThis call accepts an arbitrary \nid\n, deliberately opaque, as a way for the consensus plugin to ensure only the transactions associated with this particular batch are executed. For instance, in the pbft implementation, this \nid\n is the an encoded hash of the transactions to be executed.\n\n\n3.4.7.2 Executing transactions\n\n\nExecTXs(id interface{}, txs []*pb.Transaction) ([]byte, []error)\n\n\n\n\nThis call accepts an array of transactions to execute against the current state of the ledger and returns the current state hash in addition to an array of errors corresponding to the array of transactions. Note that a transaction resulting in an error has no effect on whether a transaction batch is safe to commit. It is up to the consensus plugin to determine the behavior which should occur when failing transactions are encountered. This call is safe to invoke multiple times.\n\n\n3.4.7.3 Committing and rolling-back transactions\n\n\nRollbackTxBatch(id interface{}) error\n\n\n\n\nThis call aborts an execution batch. This will undo the changes to the current state, and restore the ledger to its previous state. It concludes the batch begun with \nBeginBatchTx\n and a new one must be created before executing any transactions.\n\n\nPreviewCommitTxBatchBlock(id interface{}, transactions []*pb.Transaction, metadata []byte) (*pb.Block, error)\n\n\n\n\nThis call is most useful for consensus plugins which wish to test for non-deterministic transaction execution. The hashable portions of the block returned are guaranteed to be identical to the block which would be committed if \nCommitTxBatch\n were immediately invoked. This guarantee is violated if any new transactions are executed.\n\n\nCommitTxBatch(id interface{}, transactions []*pb.Transaction, transactionsResults []*pb.TransactionResult, metadata []byte) error\n\n\n\n\nThis call commits a block to the blockchain. Blocks must be committed to a blockchain in total order. \nCommitTxBatch\n concludes the transaction batch, and a new call to \nBeginTxBatch\n must be made before any new transactions are executed and committed.\n\n\n3.4.8 \nLedger\n interface\n\n\nDefinition:\n\n\ntype Ledger interface {\n    ReadOnlyLedger\n    UtilLedger\n    WritableLedger\n}\n\n\n\n\nLedger\n interface is intended to allow the consensus plugin to interrogate and possibly update the current state and blockchain. It is comprised of the three interfaces described below.\n\n\n3.4.8.1 \nReadOnlyLedger\n interface\n\n\nDefinition:\n\n\ntype ReadOnlyLedger interface {\n    GetBlock(id uint64) (block *pb.Block, err error)\n    GetCurrentStateHash() (stateHash []byte, err error)\n    GetBlockchainSize() (uint64, error)\n}\n\n\n\n\nReadOnlyLedger\n interface is intended to query the local copy of the ledger without the possibility of modifying it. It is comprised of the following functions.\n\n\nGetBlockchainSize() (uint64, error)\n\n\n\n\nThis call returns the current length of the blockchain ledger. In general, this function should never fail, though in the unlikely event that this occurs, the error is passed to the caller to decide what if any recovery is necessary. The block with the highest number will have block number \nGetBlockchainSize()-1\n.\n\n\nNote that in the event that the local copy of the blockchain ledger is corrupt or incomplete, this call will return the highest block number in the chain, plus one. This allows for a node to continue operating from the current state/block even when older blocks are corrupt or missing.\n\n\nGetBlock(id uint64) (block *pb.Block, err error)\n\n\n\n\nThis call returns the block from the blockchain with block number \nid\n. In general, this call should not fail, except when the block queried exceeds the current blocklength, or when the underlying blockchain has somehow become corrupt. A failure of \nGetBlock\n has a possible resolution of using the state transfer mechanism to retrieve it.\n\n\nGetCurrentStateHash() (stateHash []byte, err error)\n\n\n\n\nThis call returns the current state hash for the ledger. In general, this function should never fail, though in the unlikely event that this occurs, the error is passed to the caller to decide what if any recovery is necessary.\n\n\n3.4.8.2 \nUtilLedger\n interface\n\n\nDefinition:\n\n\ntype UtilLedger interface {\n    HashBlock(block *pb.Block) ([]byte, error)\n    VerifyBlockchain(start, finish uint64) (uint64, error)\n}\n\n\n\n\nUtilLedger\n  interface defines some useful utility functions which are provided by the local ledger. Overriding these functions in a mock interface can be useful for testing purposes. This interface is comprised of two functions.\n\n\nHashBlock(block *pb.Block) ([]byte, error)\n\n\n\n\nAlthough \n*pb.Block\n has a \nGetHash\n method defined, for mock testing, overriding this method can be very useful. Therefore, it is recommended that the \nGetHash\n method never be directly invoked, but instead invoked via this \nUtilLedger.HashBlock\n interface. In general, this method should never fail, but the error is still passed to the caller to decide what if any recovery is appropriate.\n\n\nVerifyBlockchain(start, finish uint64) (uint64, error)\n\n\n\n\nThis utility method is intended for verifying large sections of the blockchain. It proceeds from a high block \nstart\n to a lower block \nfinish\n, returning the block number of the first block whose \nPreviousBlockHash\n does not match the block hash of the previous block as well as an error. Note, this generally indicates the last good block number, not the first bad block number.\n\n\n3.4.8.3 \nWritableLedger\n interface\n\n\nDefinition:\n\n\ntype WritableLedger interface {\n    PutBlock(blockNumber uint64, block *pb.Block) error\n    ApplyStateDelta(id interface{}, delta *statemgmt.StateDelta) error\n    CommitStateDelta(id interface{}) error\n    RollbackStateDelta(id interface{}) error\n    EmptyState() error\n}\n\n\n\n\nWritableLedger\n  interface allows for the caller to update the blockchain. Note that this is \nNOT\n intended for use in normal operation of a consensus plugin. The current state should be modified by executing transactions using the \nExecutor\n interface, and new blocks will be generated when transactions are committed. This interface is instead intended primarily for state transfer or corruption recovery. In particular, functions in this interface should \nNEVER\n be exposed directly via consensus messages, as this could result in violating the immutability promises of the blockchain concept. This interface is comprised of the following functions.\n\n\n-\n    \nPutBlock(blockNumber uint64, block *pb.Block) error\n\n\nThis function takes a provided, raw block, and inserts it into the blockchain at the given blockNumber. Note that this intended to be an unsafe interface, so no error or sanity checking is performed. Inserting a block with a number higher than the current block height is permitted, similarly overwriting existing already committed blocks is also permitted. Remember, this does not affect the auditability or immutability of the chain, as the hashing techniques make it computationally infeasible to forge a block earlier in the chain. Any attempt to rewrite the blockchain history is therefore easily detectable. This is generally only useful to the state transfer API.\n\n\n\n-\n    \nApplyStateDelta(id interface{}, delta *statemgmt.StateDelta) error\n\n\nThis function takes a state delta, and applies it to the current state. The delta will be applied to transition a state forward or backwards depending on the construction of the state delta. Like the `Executor` methods, `ApplyStateDelta` accepts an opaque interface `id` which should also be passed into `CommitStateDelta` or `RollbackStateDelta` as appropriate.\n\n\n\n-\n    \nCommitStateDelta(id interface{}) error\n\n\nThis function commits the state delta which was applied in `ApplyStateDelta`. This is intended to be invoked after the caller to `ApplyStateDelta` has verified the state via the state hash obtained via `GetCurrentStateHash()`. This call takes the same `id` which was passed into `ApplyStateDelta`.\n\n\n\n-\n    \nRollbackStateDelta(id interface{}) error\n\n\nThis function unapplies a state delta which was applied in `ApplyStateDelta`. This is intended to be invoked after the caller to `ApplyStateDelta` has detected the state hash obtained via `GetCurrentStateHash()` is incorrect. This call takes the same `id` which was passed into `ApplyStateDelta`.\n\n\n\n-\n    \nEmptyState() error\n\n\nThis function will delete the entire current state, resulting in a pristine empty state. It is intended to be called before loading an entirely new state via deltas. This is generally only useful to the state transfer API.\n\n\n\n3.4.9 \nRemoteLedgers\n interface\n\n\nDefinition:\n\n\ntype RemoteLedgers interface {\n    GetRemoteBlocks(peerID uint64, start, finish uint64) (\n-chan *pb.SyncBlocks, error)\n    GetRemoteStateSnapshot(peerID uint64) (\n-chan *pb.SyncStateSnapshot, error)\n    GetRemoteStateDeltas(peerID uint64, start, finish uint64) (\n-chan *pb.SyncStateDeltas, error)\n}\n\n\n\n\nThe \nRemoteLedgers\n interface exists primarily to enable state transfer and to interrogate the blockchain state at  other replicas. Just like the \nWritableLedger\n interface, it is not intended to be used in normal operation and is designed to be used for catchup, error recovery, etc. For all functions in this interface it is the caller\ns responsibility to enforce timeouts. This interface contains the following functions.\n\n\n\n\n\n\nGetRemoteBlocks(peerID uint64, start, finish uint64) (\n-chan *pb.SyncBlocks, error)\n\n\nThis function attempts to retrieve a stream of \n*pb.SyncBlocks\n from the peer designated by \npeerID\n for the range from \nstart\n to \nfinish\n. In general, \nstart\n should be specified with a higher block number than \nfinish\n, as the blockchain must be validated from end to beginning. The caller must validate that the desired block is being returned, as it is possible that slow results from another request could appear on this channel. Invoking this call for the same \npeerID\n a second time will cause the first channel to close.\n\n\n\n\n\n\n```\nGetRemoteStateSnapshot(peerID uint64) (\n-chan *pb.SyncStateSnapshot, error)\n```\n\n\n\nThis function attempts to retrieve a stream of \n*pb.SyncStateSnapshot\n from the peer designated by \npeerID\n. To apply the result, the existing state should first be emptied via the \nWritableLedger\n \nEmptyState\n call, then the contained deltas in the stream should be applied sequentially.\n\n\n\n\n\n\n-\n    \nGetRemoteStateDeltas(peerID uint64, start, finish uint64) (\n-chan *pb.SyncStateDeltas, error)\n\n\nThis function attempts to retrieve a stream of `*pb.SyncStateDeltas` from the peer designated by `peerID` for the range from `start` to `finish`. The caller must validated that the desired block delta is being returned, as it is possible that slow results from another request could appear on this channel. Invoking this call for the same `peerID` a second time will cause the first channel to close.\n\n\n\n3.4.10 \ncontroller\n package\n\n\n3.4.10.1 controller.NewConsenter\n\n\nSignature:\n\n\nfunc NewConsenter(cpi consensus.CPI) (consenter consensus.Consenter)\n\n\n\n\nThis function reads the \npeer.validator.consensus\n value in \ncore.yaml\n configuration file, which is the  configuration file for the \npeer\n process. The value of the \npeer.validator.consensus\n key defines whether the validating peer will run with the \nnoops\n consensus plugin or the \npbft\n one. (Notice that this should eventually be changed to either \nnoops\n or \ncustom\n. In case of \ncustom\n, the validating peer will run with the consensus plugin defined in \nconsensus/config.yaml\n.)\n\n\nThe plugin author needs to edit the function\ns body so that it routes to the right constructor for their package. For example, for \npbft\n we point to the \npbft.GetPlugin\n constructor.\n\n\nThis function is called by \nhelper.NewConsensusHandler\n when setting the \nconsenter\n field of the returned message handler. The input argument \ncpi\n is the output of the \nhelper.NewHelper\n constructor and implements the \nconsensus.CPI\n interface.\n\n\n3.4.11 \nhelper\n package\n\n\n3.4.11.1 High-level overview\n\n\nA validating peer establishes a message handler (\nhelper.ConsensusHandler\n) for every connected peer, via the \nhelper.NewConsesusHandler\n function (a handler factory). Every incoming message is inspected on its type (\nhelper.HandleMessage\n); if it\ns a message for which consensus needs to be reached, it\ns passed on to the peer\ns consenter object (\nconsensus.Consenter\n). Otherwise it\ns passed on to the next message handler in the stack.\n\n\n3.4.11.2 helper.ConsensusHandler\n\n\nDefinition:\n\n\ntype ConsensusHandler struct {\n    chatStream  peer.ChatStream\n    consenter   consensus.Consenter\n    coordinator peer.MessageHandlerCoordinator\n    done        chan struct{}\n    peerHandler peer.MessageHandler\n}\n\n\n\n\nWithin the context of consensus, we focus only on the \ncoordinator\n and \nconsenter\n fields. The \ncoordinator\n, as the name implies, is used to coordinate between the peer\ns message handlers. This is, for instance, the object that is accessed when the peer wishes to \nBroadcast\n. The \nconsenter\n receives the messages for which consensus needs to be reached and processes them.\n\n\nNotice that \nfabric/peer/peer.go\n defines the \npeer.MessageHandler\n (interface), and \npeer.MessageHandlerCoordinator\n (interface) types.\n\n\n3.4.11.3 helper.NewConsensusHandler\n\n\nSignature:\n\n\nfunc NewConsensusHandler(coord peer.MessageHandlerCoordinator, stream peer.ChatStream, initiatedStream bool, next peer.MessageHandler) (peer.MessageHandler, error)\n\n\n\n\nCreates a \nhelper.ConsensusHandler\n object. Sets the same \ncoordinator\n for every message handler. Also sets the \nconsenter\n equal to: \ncontroller.NewConsenter(NewHelper(coord))\n\n\n3.4.11.4 helper.Helper\n\n\nDefinition:\n\n\ntype Helper struct {\n    coordinator peer.MessageHandlerCoordinator\n}\n\n\n\n\nContains the reference to the validating peer\ns \ncoordinator\n. Is the object that implements the \nconsensus.CPI\n interface for the peer.\n\n\n3.4.11.5 helper.NewHelper\n\n\nSignature:\n\n\nfunc NewHelper(mhc peer.MessageHandlerCoordinator) consensus.CPI\n\n\n\n\nReturns a \nhelper.Helper\n object whose \ncoordinator\n is set to the input argument \nmhc\n (the \ncoordinator\n field of the \nhelper.ConsensusHandler\n message handler). This object implements the \nconsensus.CPI\n interface, thus allowing the plugin to interact with the stack.\n\n\n3.4.11.6 helper.HandleMessage\n\n\nRecall that the \nhelper.ConsesusHandler\n object returned by \nhelper.NewConsensusHandler\n implements the \npeer.MessageHandler\n interface:\n\n\ntype MessageHandler interface {\n    RemoteLedger\n    HandleMessage(msg *pb.Message) error\n    SendMessage(msg *pb.Message) error\n    To() (pb.PeerEndpoint, error)\n    Stop() error\n}\n\n\n\n\nWithin the context of consensus, we focus only on the \nHandleMessage\n method. Signature:\n\n\nfunc (handler *ConsensusHandler) HandleMessage(msg *pb.Message) error\n\n\n\n\nThe function inspects the \nType\n of the incoming \nMessage\n. There are four cases:\n\n\n\n\nEqual to \npb.Message_CONSENSUS\n: passed to the handler\ns \nconsenter.RecvMsg\n function.\n\n\nEqual to \npb.Message_CHAIN_TRANSACTION\n (i.e. an external deployment request): a response message is sent to the user first, then the message is passed to the \nconsenter.RecvMsg\n function.\n\n\nEqual to \npb.Message_CHAIN_QUERY\n (i.e. a query): passed to the \nhelper.doChainQuery\n method so as to get executed locally.\n\n\nOtherwise: passed to the \nHandleMessage\n method of the next handler down the stack.\n\n\n\n\n3.5 Events\n\n\nThe event framework provides the ability to generate and consume predefined and custom events. There are 3 basic components:\n  - Event stream\n  - Event adapters\n  - Event structures\n\n\n3.5.1 Event Stream\n\n\nAn event stream is a gRPC channel capable of sending and receiving events. Each consumer establishes an event stream to the event framework and expresses the events that it is interested in. the event producer only sends appropriate events to the consumers who have connected to the producer over the event stream.\n\n\nThe event stream initializes the buffer and timeout parameters. The buffer holds the number of events waiting for delivery, and the timeout has 3 options when the buffer is full:\n\n\n\n\nIf timeout is less than 0, drop the newly arriving events\n\n\nIf timeout is 0, block on the event until the buffer becomes available\n\n\nIf timeout is greater than 0, wait for the specified timeout and drop the event if the buffer remains full after the timeout\n\n\n\n\n3.5.1.1 Event Producer\n\n\nThe event producer exposes a function to send an event, \nSend(e *pb.Event)\n, where \nEvent\n is either a pre-defined \nBlock\n or a \nGeneric\n event. More events will be defined in the future to include other elements of the fabric.\n\n\nmessage Generic {\n    string eventType = 1;\n    bytes payload = 2;\n}\n\n\n\n\nThe \neventType\n and \npayload\n are freely defined by the event producer. For example, JSON data may be used in the \npayload\n. The \nGeneric\n event may also be emitted by the chaincode or plugins to communicate with consumers.\n\n\n3.5.1.2 Event Consumer\n\n\nThe event consumer enables external applications to listen to events. Each event consumer registers an event adapter with the event stream. The consumer framework can be viewed as a bridge between the event stream and the adapter. A typical use of the event consumer framework is:\n\n\nadapter = \nadapter supplied by the client application to register and receive events\n\nconsumerClient = NewEventsClient(\nevent consumer address\n, adapter)\nconsumerClient.Start()\n...\n...\nconsumerClient.Stop()\n\n\n\n\n3.5.2 Event Adapters\n\n\nThe event adapter encapsulates three facets of event stream interaction:\n  - an interface that returns the list of all events of interest\n  - an interface called by the event consumer framework on receipt of an event\n  - an interface called by the event consumer framework when the event bus terminates\n\n\nThe reference implementation provides Golang specific language binding.\n\n\n      EventAdapter interface {\n         GetInterestedEvents() ([]*ehpb.Interest, error)\n         Recv(msg *ehpb.Event) (bool,error)\n         Disconnected(err error)\n      }\n\n\n\n\nUsing gRPC as the event bus protocol allows the event consumer framework to be ported to different language bindings without affecting the event producer framework.\n\n\n3.5.3 Event Structure\n\n\nThis section details the message structures of the event system. Messages are described directly in Golang for simplicity.\n\n\nThe core message used for communication between the event consumer and producer is the Event.\n\n\n    message Event {\n        oneof Event {\n            //consumer events\n            Register register = 1;\n\n            //producer events\n            Block block = 2;\n            Generic generic = 3;\n       }\n    }\n\n\n\n\nPer the above definition, an event has to be one of \nRegister\n, \nBlock\n or \nGeneric\n.\n\n\nAs mentioned in the previous sections, a consumer creates an event bus by establishing a connection with the producer and sending a \nRegister\n event. The \nRegister\n event is essentially an array of \nInterest\n messages declaring the events of interest to the consumer.\n\n\n    message Interest {\n        enum ResponseType {\n            //don't send events (used to cancel interest)\n            DONTSEND = 0;\n            //send protobuf objects\n            PROTOBUF = 1;\n            //marshall into JSON structure\n            JSON = 2;\n        }\n        string eventType = 1;\n        ResponseType responseType = 2;\n    }\n\n\n\n\nEvents can be sent directly as protobuf structures or can be sent as JSON structures by specifying the \nresponseType\n appropriately.\n\n\nCurrently, the producer framework can generate a \nBlock\n or a \nGeneric\n event. A \nBlock\n is a message used for encapsulating properties of a block in the blockchain.\n\n\n4. Security\n\n\nThis section discusses the setting depicted in the figure below.\nIn particular, the system consists of the following entities:\nmembership management infrastructure, i.e., a set of entities that are\nresponsible for identifying an individual user (using any form of identification\nconsidered in the system, e.g., credit cards, id-cards), open an account for\nthat user to be able to register, and issue the necessary credentials to\nsuccessfully create transactions and deploy or invoke chaincode successfully\nthrough the fabric.\n\n\n * Peers, that are classified as validating peers, and non-validating peers.\n   Validating peers (also known as validators) order and process (check validity, execute,\n   and add to the blockchain) user-messages (transactions) submitted to the network.\n   Non validating peers (also known as peers) receive user transactions on behalf of users,\n   and after some fundamental validity checks, they forward the transactions to their\n   neighboring validating peers. Peers maintain an up-to-date copy of the blockchain,\n   but in contradiction to validators, they do not execute transactions\n   (a process also known as \ntransaction validation\n).\n * End users of the system, that have registered to our membership service administration,\n   after having demonstrated ownership of what is considered \nidentity\n in the system,\n   and have obtained credentials to install the client-software and submit transactions\n   to the system.\n * Client-software, the software that needs to be installed at the client side for the\n   latter to be able to complete his registration to our membership service and submit\n   transactions to the system.\n * Online wallets, entities that are trusted by a user to maintain that user\ns credentials,\n   and submit transactions solely upon user request to the network. Online wallets come\n   with their own software at the client-side, that is usually light-weight, as the\n   client only needs to authenticate himself and his requests to the wallet.\n   While it can be the case that peers can play the role of \nonline wallet\n for a set of\n   users, in the following sessions the security of online wallets is detailed separately.\n\n\nUsers who wish to make use of the fabric, open an account at the membership management\nadministration, by proving ownership of identity as discussed in previous sections, new chaincodes\nare announced to the blockchain network by the chaincode creator (developer) through the means\nof a deployment transaction that the client-software would construct on behalf of the developer.\nSuch transaction is first received by a peer or validator, and afterwards circulated\nin the entire network of validators, this transaction is executed and finds its place to\nthe blockchain network. Users can also invoke a function of an already deployed chain-code\nthrough an invocation transaction.\n\n\nThe next section provides a summary of the business goals of the system that drive the security requirements. We then overview the security components and their operation and show how this design fulfills the security requirements.\n\n\n4.1 Business security requirements\n\n\nThis section presents business security requirements that are relevant to the context of the fabric.\n\nIncorporation of identity and role management.\n\n\nIn order to adequately support real business applications it is necessary to progress beyond ensuring cryptographic continuity. A workable B2B system must consequently move towards addressing proven/demonstrated identities or other attributes relevant to conducting business. Business transactions and consumer interactions with financial institutions need to be unambiguously mapped to account holders. Business contracts typically require demonstrable affiliation with specific institutions and/or possession of other specific properties of transacting parties. Accountability and non-frameability are two reasons that identity management is a critical component of such systems.\n\n\nAccountability means that users of the system, individuals, or corporations, who misbehave can be traced back and be set accountable for their actions. In many cases, members of a B2B system are required to use their identities (in some form) to participate in the system, in a way such that accountability is guaranteed. Accountability and non-frameability are both essential security requirements in B2B systems and they are closely related. That is, a B2B system should guarantee that an honest user of such system cannot be framed to be accused as responsible for transactions originated by other users.\n\n\nIn addition a B2B system should be renewable and flexible in order to accommodate changes of participants\u2019s roles and/or affiliations.\n\n\nTransactional privacy.\n\n\nIn B2B relationships there is a strong need for transactional privacy, i.e., allowing the end-user of a system to control the degree to which it interacts and shares information with its environment. For example, a corporation doing business through a transactional B2B system requires that its transactions are not visible to other corporations or industrial partners that are not authorized to share classified information with.\n\n\nTransactional privacy in the fabric is offered by the mechanisms to achieve two properties with respect to non authorized users:\n\n\n\n\n\n\nTransaction anonymity, where the owner of a transaction is hidden among the so called \nanonymity set\n, which in the fabric, is the set of users.\n\n\n\n\n\n\nTransaction unlinkability, where two or more transactions of the same user should not be linked as such.\n\n\n\n\n\n\nClearly depending on the context, non-authorized users can be anyone outside the system, or a subset of users.\n\n\nTransactional privacy is strongly associated to the confidentiality of the content of a contractual agreement between two or more members of a B2B system, as well as to the anonymity and unlinkability of any authentication mechanism that should be in place within transactions.\n\n\nReconciling transactional privacy with identity management.\n\n\nAs described later in this document, the approach taken here to reconcile identity management with user privacy and to enable competitive institutions to transact effectively on a common blockchain (for both intra- and inter-institutional transactions) is as follows:\n\n\n\n\n\n\nadd certificates to transactions to implement a \u201cpermissioned\u201d blockchain\n\n\n\n\n\n\nutilize a two-level system:\n\n\n\n\n\n\n(relatively) static enrollment certificates (ECerts), acquired via registration with an enrollment certificate authority (CA).\n\n\n\n\n\n\ntransaction certificates (TCerts) that faithfully but pseudonymously represent enrolled users, acquired via a transaction CA.\n\n\n\n\n\n\noffer mechanisms to conceal the content of transactions to unauthorized members of the system.\n\n\n\n\n\n\nAudit support.\n Commercial systems are occasionally subjected to audits. Auditors in such cases should be given the means to check a certain transaction, or a certain group of transactions, the activity of a particular user of the system, or the operation of the system itself. Thus, such capabilities should be offered by any system featuring transactions containing contractual agreements between business partners.\n\n\n4.2 User Privacy through Membership Services\n\n\nMembership Services consists of an infrastructure of several entities that together manage the identity and privacy of users on the network. These services validate user\u2019s identity, register the user in the system, and provide all the credentials needed for him/her to be an active and compliant participant able to create and/or invoke transactions. A Public Key Infrastructure (PKI) is a framework based on public key cryptography that ensures not only the secure exchange of data over public networks but also affirms the identity of the other party. A PKI manages the generation, distribution and revocation of keys and digital certificates. Digital certificates are used to establish user credentials and to sign messages. Signing messages with a certificate ensures that the message has not been altered. Typically a PKI has a Certificate Authority (CA), a Registration Authority (RA), a certificate database, and a certificate storage. The RA is a trusted party that authenticates users and vets the legitimacy of data, certificates or other evidence submitted to support the user\u2019s request for one or more certificates that reflect that user\u2019s identity or other properties. A CA, upon advice from an RA, issues digital certificates for specific uses and is certified directly or hierarchically by a root CA. Alternatively, the user-facing communications and due diligence responsibilities of the RA can be subsumed as part of the CA. Membership Services is composed of the entities shown in the following figure. Introduction of such full PKI reinforces the strength of this system for B2B (over, e.g. Bitcoin).\n\n\n\n\nRoot Certificate Authority (Root CA):\n entity that represents the trust anchor for the PKI scheme. Digital certificates verification follows a chain of trust. The Root CA is the top-most CA in the PKI hierarchy.\n\n\nRegistration Authority (RA):\n a trusted entity that can ascertain the validity and identity of users who want to participate in the permissioned blockchain. It is responsible for out-of-band communication with the user to validate his/her identity and role. It creates registration credentials needed for enrollment and information on root of trust.\n\n\nEnrollment Certificate Authority (ECA):\n  responsible for issuing Enrollment Certificates (ECerts) after validating the registration credentials provided by the user.\n\n\nTransaction Certificate Authority (TCA):\n responsible for issuing Transaction Certificates (TCerts) after validating the enrollment credentials provided by the user.\n\n\nTLS Certificate Authority (TLS-CA):\n responsible for issuing TLS certificates and credentials that allow the user to make use of its network. It validates the credential(s) or evidence provided by the user that justifies issuance of a TLS certificate that includes specific information pertaining to the user.\n\n\nIn this specification, membership services is expressed through the following associated certificates issued by the PKI:\n\n\nEnrollment Certificates (ECerts)\n\nECerts are long-term certificates. They are issued for all roles, i.e. users, non-validating peers, and validating peers. In the case of users, who submit transactions for candidate incorporation into the blockchain and who also own TCerts (discussed below), there are two possible structure and usage models for ECerts:\n\n\n\n\n\n\nModel A:  ECerts contain the identity/enrollmentID of their owner and can be used to offer only nominal entity-authentication for TCert requests and/or within transactions. They contain the public part of two key pairs \u2013 a signature key-pair and an encryption/key agreement key-pair. ECerts are accessible to everyone.\n\n\n\n\n\n\nModel B: ECerts contain the identity/enrollmentID of their owner and can be used to offer only nominal entity-authentication for TCert requests. They contain the public part of a signature key-pair, i.e., a signature verification public key. ECerts are preferably accessible to only TCA and auditors, as relying parties. They are invisible to transactions, and thus (unlike TCerts) their signature key pairs do not play a non-repudiation role at that level.\n\n\n\n\n\n\nTransaction Certificates (TCerts)\n\nTCerts are short-term certificates for each transaction. They are issued by the TCA upon authenticated user-request. They securely authorize a transaction and may be configured to not reveal the identities of who is involved in the transaction or to selectively reveal such identity/enrollmentID information. They include the public part of a signature key-pair, and may be configured to also include the public part of a key agreement key pair. They are issued only to users. They are uniquely associated to the owner \u2013 they may be configured so that this association is known only by the TCA (and to authorized auditors). TCerts may be configured to not carry information of the identity of the user. They enable the user not only to anonymously participate in the system but also prevent linkability of transactions.\n\n\nHowever, auditability and accountability requirements assume that the TCA is able to retrieve TCerts of a given identity, or retrieve the owner of a specific TCert. For details on how TCerts are used in deployment and invocation transactions see Section 4.3, Transaction Security offerings at the infrastructure level.\n\n\nTCerts can accommodate encryption or key agreement public keys (as well as digital signature verification public keys).\nIf TCerts are thus equipped, then enrollment certificates need not also contain encryption or key agreement public keys.\n\n\nSuch a key agreement public key, Key_Agreement_TCertPub_Key, can be generated by the transaction certificate authority (TCA) using a method that is the same as that used to generate the Signature_Verification_TCertPub_Key, but using an index value of TCertIndex + 1 rather than TCertIndex, where TCertIndex is hidden within the TCert by the TCA for recovery by the TCert owner.\n\n\nThe structure of a Transaction Certificate (TCert) is as follows:\n\n TCertID \u2013 transaction certificate ID (preferably generated by TCA randomly in order to avoid unintended linkability via the Hidden Enrollment ID field).\n\n Hidden Enrollment ID: AES_Encrypt\nK\n(enrollmentID), where key K = [HMAC(Pre-K, TCertID)]\n256-bit truncation\n and where three distinct key distribution scenarios for Pre-K are defined below as (a), (b) and (c).\n\n Hidden Private Keys Extraction: AES_Encrypt\nTCertOwner_EncryptKey\n(TCertIndex || known padding/parity check vector) where || denotes concatenation, and where each batch has a unique (per batch) time-stamp/random offset that is added to a counter (initialized at 1 in this implementation) in order to generate TCertIndex. The counter can be incremented by 2 each time in order to accommodate generation by the TCA of the public keys and recovery by the TCert owner of the private keys of both types, i.e., signature key pairs and key agreement key pairs.\n\n Sign Verification Public Key \u2013 TCert signature verification public key.\n\n Key Agreement Public Key \u2013 TCert key agreement public key.\n\n Validity period \u2013 the time window during which the transaction certificate can be used for the outer/external signature of a transaction.\n\n\nThere are at least three useful ways to consider configuring the key distribution scenario for the Hidden Enrollment ID field:\n\n(a)\n Pre-K is distributed during enrollment to user clients, peers and auditors, and is available to the TCA and authorized auditors. It may, for example, be derived from K\nchain\n (described subsequently in this specification) or be independent of key(s) used for chaincode confidentiality.\n\n\n(b)\n Pre-K is available to validators, the TCA and authorized auditors. K is made available by a validator to a user (under TLS) in response to a successful query transaction. The query transaction can have the same format as the invocation transaction. Corresponding to Example 1 below, the querying user would learn the enrollmentID of the user who created the Deployment Transaction if the querying user owns one of the TCerts in the ACL of the Deployment Transaction. Corresponding to Example 2 below, the querying user would learn the enrollmentID of the user who created the Deployment Transaction if the enrollmentID of the TCert used to query matches one of the affiliations/roles in the Access Control field of the Deployment Transaction.\n\n\nExample 1:\n\n\n\n\nExample 2:\n\n\n\n\n(c)\n Pre-K is available to the TCA and authorized auditors. The TCert-specific K can be distributed the TCert owner (under TLS) along with the TCert, for each TCert in the batch. This enables targeted release by the TCert owner of K (and thus trusted notification of the TCert owner\u2019s enrollmentID). Such targeted release can use key agreement public keys of the intended recipients and/or PK\nchain\n where SK\nchain\n is available to validators as described subsequently in this specification. Such targeted release to other contract participants can be incorporated into a transaction or done out-of-band.\n\n\nIf the TCerts are used in conjunction with ECert Model A above, then using (c) where K is not distributed to the TCert owner may suffice.\nIf the TCerts are used in conjunction with ECert Model A above, then the Key Agreement Public Key field of the TCert may not be necessary.\n\n\nThe Transaction Certificate Authority (TCA) returns TCerts in batches, each batch contains the KeyDF_Key (Key-Derivation-Function Key) which is not included within every TCert but delivered to the client with the batch of TCerts (using TLS). The KeyDF_Key allows the TCert owner to derive TCertOwner_EncryptKey which in turn enables recovery of TCertIndex from AES_Encrypt\nTCertOwner_EncryptKey\n(TCertIndex || known padding/parity check vector).\n\n\nTLS-Certificates (TLS-Certs)\n\nTLS-Certs are certificates used for system/component-to-system/component communications. They carry the identity of their owner and are used for network level security.\n\n\nThis implementation of membership services provides the following basic functionality: there is no expiration/revocation of ECerts; expiration of TCerts is provided via the validity period time window; there is no revocation of TCerts. The ECA, TCA, and TLS CA certificates are self-signed, where the TLS CA is provisioned as a trust anchor.\n\n\n4.2.1 User/Client Enrollment Process\n\n\nThe next figure has a high-level description of the user enrollment process. It has an offline and an online phase.\n\n\n\n\nOffline Process:\n in Step 1, each user/non-validating peer/validating peer has to present strong identification credentials (proof of ID) to a Registration Authority (RA) offline. This has to be done out-of-band to provide the evidence needed by the RA to create (and store) an account for the user. In Step 2, the RA returns the associated username/password and trust anchor (TLS-CA Cert in this implementation) to the user. If the user has access to a local client then this is one way the client can be securely provisioned with the TLS-CA certificate as trust anchor.\n\n\nOnline Phase:\n In Step 3, the user connects to the client to request to be enrolled in the system. The user sends his username and password to the client. On behalf of the user, the client sends the request to the PKI framework, Step 4, and receives a package, Step 5, containing several certificates, some of which should correspond to private/secret keys held by the client. Once the client verifies that the all the crypto material in the package is correct/valid, it stores the certificates in local storage and notifies the user. At this point the user enrollment has been completed.\n\n\n\n\nFigure 4 shows a detailed description of the enrollment process. The PKI framework has the following entities \u2013 RA, ECA, TCA and TLS-CA. After Step 1, the RA calls the function \u201cAddEntry\u201d to enter the (username/password) in its database. At this point the user has been formally registered into the system database. The client needs the TLS-CA certificate (as trust anchor) to verify that the TLS handshake is set up appropriately with the server. In Step 4, the client sends the registration request to the ECA along with its enrollment public key and additional identity information such as username and password (under the TLS record layer protocol). The ECA verifies that such user really exists in the database. Once it establishes this assurance the user has the right to submit his/her enrollment public key and the ECA will certify it. This enrollment information is of a one-time use. The ECA updates the database marking that this registration request information (username/password) cannot be used again. The ECA constructs, signs and sends back to the client an enrollment certificate (ECert) that contains the user\u2019s enrollment public key (Step 5). It also sends the ECA Certificate (ECA-Cert) needed in future steps (client will need to prove to the TCA that his/her ECert was created by the proper ECA). (Although the ECA-Cert is self-signed in the initial implementation, the TCA and TLS-CA and ECA are co-located.) The client verifies, in Step 6, that the public key inside the ECert is the one originally submitted by the client (i.e. that the ECA is not cheating). It also verifies that all the expected information within the ECert is present and properly formed.\n\n\nSimilarly, In Step 7, the client sends a registration request to the TLS-CA along with its public key and identity information. The TLS-CA verifies that such user is in the database. The TLS-CA generates, and signs a TLS-Cert that contains the user\u2019s TLS public key (Step 8). TLS-CA sends the TLS-Cert and its certificate (TLS-CA Cert). Step 9 is analogous to Step 6, the client verifies that the public key inside the TLS Cert is the one originally submitted by the client and that the information in the TLS Cert is complete and properly formed. In Step 10, the client saves all certificates in local storage for both certificates. At this point the user enrollment has been completed.\n\n\nIn this implementation the enrollment process for validators is the same as that for peers. However, it is possible that a different implementation would have validators enroll directly through an on-line process.\n\n\n\n\n\n\nClient:\n Request for TCerts batch needs to include (in addition to count), ECert and signature of request using ECert private key (where Ecert private key is pulled from Local Storage).\n\n\nTCA generates TCerts for batch:\n Generates key derivation function key, KeyDF_Key, as HMAC(TCA_KDF_Key, EnrollPub_Key). Generates each TCert public key (using TCertPub_Key = EnrollPub_Key + ExpansionValue G, where 384-bit ExpansionValue = HMAC(Expansion_Key, TCertIndex) and 384-bit Expansion_Key = HMAC(KeyDF_Key, \u201c2\u201d)). Generates each AES_Encrypt\nTCertOwner_EncryptKey\n(TCertIndex || known padding/parity check vector), where || denotes concatenation and where TCertOwner_EncryptKey is derived as [HMAC(KeyDF_Key, \u201c1\u201d)]\n256-bit truncation\n.\n\n\nClient:\n Deriving TCert private key from a TCert in order to be able to deploy or invoke or query: KeyDF_Key and ECert private key need to be pulled from Local Storage. KeyDF_Key is used to derive TCertOwner_EncryptKey as [HMAC(KeyDF_Key, \u201c1\u201d)]\n256-bit truncation\n; then TCertOwner_EncryptKey is used to decrypt the TCert field AES_Encrypt\nTCertOwner_EncryptKey\n(TCertIndex || known padding/parity check vector); then TCertIndex is used to derive TCert private key: TCertPriv_Key = (EnrollPriv_Key + ExpansionValue) modulo n, where 384-bit ExpansionValue = HMAC(Expansion_Key, TCertIndex) and 384-bit Expansion_Key = HMAC(KeyDF_Key, \u201c2\u201d).\n\n\n4.2.2 Expiration and revocation of certificates\n\n\nIt is practical to support expiration of transaction certificates. The time window during which a transaction certificate can be used is expressed by a \u2018validity period\u2019 field. The challenge regarding support of expiration lies in the distributed nature of the system. That is, all validating entities must share the same information; i.e. be consistent with respect to the expiration of the validity period associated with the transactions to be executed and validated. To guarantee that the expiration of validity periods is done in a consistent manner across all validators, the concept of validity period identifier is introduced. This identifier acts as a logical clock enabling the system to uniquely identify a validity period. At genesis time the \u201ccurrent validity period\u201d of the chain gets initialized by the TCA. It is essential that this validity period identifier is given monotonically increasing values over time, such that it imposes a total order among validity periods.\n\n\nA special type of transactions, system transactions, and the validity period identified are used together to announce the expiration of a validity period to the Blockchain. System transactions refer to contracts that have been defined in the genesis block and are part of the infrastructure. The validity period identified is updated periodically by the TCA invoking a system chaincode. Note that only the TCA should be allowed to update the validity period. The TCA sets the validity period for each transaction certificate by setting the appropriate integer values in the following two fields that define a range: \u2018not-before\u2019 and \u2018not-after\u2019 fields.\n\n\nTCert Expiration:\nAt the time of processing a TCert, validators read from the state table associated with the ledger the value of \u2018current validity period\u2019 to check if the outer certificate associated with the transaction being evaluated is currently valid. That is, the current value in the state table has to be within the range defined by TCert sub-fields \u2018not-before\u2019 and \u2018not-after\u2019. If this is the case, the validator continues processing the transaction. In the case that the current value is not within range, the TCert has expired or is not yet valid and the validator should stop processing the transaction.\n\n\nECert Expiration:\nEnrollment certificates have different validity period length(s) than those in transaction certificates.\n\n\nRevocation is supported in the form of Certificate Revocation Lists (CRLs). CRLs identify revoked certificates. Changes to the CRLs, incremental differences, are announced through the Blockchain.\n\n\n4.3 Transaction security offerings at the infrastructure level\n\n\nTransactions in the fabric are user-messages submitted to be included\nin the ledger. As discussed in previous sections, these messages have a\nspecific structure, and enable users to deploy new chaincodes, invoke existing\nchaincodes, or query the state of existing chaincodes.\nTherefore, the way transactions are formed, announced and processed plays\nan important role to the privacy and security offerings of the entire system.\n\n\nOn one hand our membership service provides the means to authenticate transactions as\nhaving originated by valid users of the system, to disassociate transactions with user identities,\nbut while efficiently tracing the transactions a particular individual under certain conditions\n(law enforcement, auditing). In other words, membership services offer to transactions authentication\nmechanisms that marry user-privacy with accountability and non-repudiation.\n\n\nOn the other hand, membership services alone cannot offer full privacy of user-activities within\nthe fabric. First of all, for privacy provisions offered by the fabric to be complete,\nprivacy-preserving authentication mechanisms need to be accompanied by transaction confidentiality.\nThis becomes clear if one considers that the content of a chaincode, may leak information on who may have\ncreated it, and thus break the privacy of that chaincode\ns creator. The first subsection\ndiscusses transaction confidentiality.\n\n\n\n\n\n\n\n\nEnforcing access control for the invocation of chaincode is an important security requirement.\nThe fabric exposes to the application (e.g., chaincode creator) the means for the application\nto perform its own invocation access control, while leveraging the fabric\ns membership services.\nSection 4.4 elaborates on this.\n\n\n\n\n\nReplay attacks is another crucial aspect of the security of the chaincode,\nas a malicious user may copy a transaction that was added to the Blockchain\nin the past, and replay it in the network to distort its operation.\nThis is the topic of Section 4.3.3.\n\n\nThe rest of this Section presents an overview of how security mechanisms in the\ninfrastructure are incorporated in the transactions\n lifecycle,\nand details each security mechanism separately.\n\n\n4.3.1 Security Lifecycle of Transactions\n\n\nTransactions are created on the client side. The client can be either plain\nclient, or a more specialized application, i.e., piece of\nsoftware that handles (server) or invokes (client) specific chaincodes\nthrough the blockchain. Such applications are built on top of the\nplatform (client) and are detailed in Section 4.4.\n\n\nDevelopers of new chaincodes create a new deploy transaction by passing to\nthe fabric infrastructure:\n\n the confidentiality/security version or type they want the transaction to conform with,\n\n the set of users who wish to be given access to parts of the chaincode and\n  a proper representation of their (read) access rights\n\n\n\n the chaincode specification,\n\n code metadata, containing information that should be passed to the chaincode\n  at the time of its execution\n  (e.g., configuration parameters), and\n* transaction metadata, that is attached to the transaction structure,\n  and is only used by the application that deployed the chaincode.\n\n\nInvoke and query transactions corresponding to chaincodes with confidentiality\nrestrictions are created using a similar approach. The transactor provides the\nidentifier of the chaincode to be executed, the name of the function to be\ninvoked and its arguments. Optionally, the invoker can pass to the\ntransaction creation function, code invocation metadata, that will be provided\nto the chaincode at the time of its execution. Transaction metadata is another\nfield that the application of the invoker or the invoker himself can leverage\nfor their own purposes.\n\n\nFinally transactions at the client side, are signed by a certificate of their\ncreator and released to the network of validators.\nValidators receive the confidential transactions, and pass them through the following phases:\n\n \npre-validation\n phase, where validators validate the transaction certificate against the accepted root certificate authority,\n  verify transaction certificate signature included in the transaction (statically), and check whether the transaction is a replay (see, later section for details on replay attack protection).\n\n \nconsensus\n phase, where the validators add this transaction to the total order of transactions (ultimately included in the ledger)\n\n \npre-execution\n phase, where validators verify the validity of the transaction / enrollment certificate against the current validity period,\n  decrypt the transaction (if the transaction is encrypted), and check that the transaction\ns plaintext is correctly formed(e.g., invocation access control is respected, included TCerts are correctly formed);\n  mini replay-attack check is also performed here within the transactions of the currently processed block.\n\n \nexecution\n phase, where the (decrypted) chaincode is passed to a container, along with the associated code metadata, and is executed\n\n \ncommit* phase, where (encrypted) updates of that chaincodes state is committed to the ledger with the transaction itself.\n\n\n4.3.2 Transaction confidentiality\n\n\nTransaction confidentiality requires that under the request of the developer, the plain-text\nof a chaincode, i.e., code, description, is not accessible or inferable (assuming a computational\nattacker) by any unauthorized entities(i.e., user or peer not authorized by the developer).\nFor the latter, it is important that for chaincodes with confidentiality requirements the\ncontent of both \ndeploy\n and \ninvoke\n transactions remains concealed. In the same spirit,\nnon-authorized parties, should not be able to associate invocations (invoke transactions) of a\nchaincode to the chaincode itself (deploy transaction) or these invocations to each other.\n\n\nAdditional requirements for any candidate solution is that it respects and supports the privacy\nand security provisions of the underlying membership service. In addition, it should not prevent\nthe enforcement of any invocation access control of the chain-code functions in the fabric, or\nthe implementation of enforcement of access-control mechanisms on the application (See Subsection 4.4).\n\n\nIn the following is provided the specification of transaction confidentiality\nmechanisms at the granularity of users. The last subsection provides some guidelines\non how to extend this functionality at the level of validators.\nInformation on the features supported in current release and its security\nprovisions, you can find in Section 4.7.\n\n\nThe goal is to achieve a design that will allow for granting or restricting\naccess to an entity to any subset of the following parts of a chain-code:\n1. chaincode content, i.e., complete (source) code of the\n   chaincode,\n\n\n2. chaincode function headers, i.e., the prototypes of the functions included in a chaincode,\n\n\n\n\n3. chaincode [invocations \n] state, i.e., successive updates to the state of a specific chaincode,\n   when one or more functions of its are invoked\n4. all the above\n\n\nNotice, that this design offers the application the capability to leverage the fabric\ns\nmembership service infrastructure and its public key infrastructure to build their own access\ncontrol policies and enforcement mechanisms.\n\n\n4.3.2.1 Confidentiality against users\n\n\nTo support fine-grained confidentiality control, i.e., restrict read-access to the\nplain-text of a chaincode to a subset of users that the chaincode creator\ndefines, a chain is bound to a single long-term encryption key-pair\n(PK\nchain\n, SK\nchain\n).\nThough initially this key-pair is to be stored and maintained by each chain\ns\nPKI, in later releases, however, this restriction will be moved away,\nas chains (and the associated key-pairs) can be triggered through the Blockchain\nby any user with \nspecial\n (admin) privileges (See, Section 4.3.2.2).\n\n\nSetup\n. At enrollment phase, users obtain (as before) an enrollment certificate,\ndenoted by Cert\nu\ni\n for user u\ni\n, while each\nvalidator v\nj\n obtain its enrollment certificate denoted by\nCert\nv\nj\n. Enrollment would grant users and validators the\nfollowing credentials:\n\n\n\n\nUsers:\n\n\n\n\na. claim and grant themselves signing key-pair (spk\nu\n, ssk\nu\n),\n\n\nb. claim and grant themselves encryption key-pair (epk\nu\n, esk\nu\n),\n\n\nc. obtain the encryption (public) key of the chain PK\nchain\n\n\n\n\nValidators:\n\n\n\n\na. claim and grant themselves signing key-pair (spk\nv\n, ssk\nv\n),\n\n\nb. claim and grant themselves an encryption key-pair (epk\nv\n, esk\nv\n),\n\n\nc. obtain the decryption (secret) key of the chain SK\nchain\n\n\nThus, enrollment certificates contain the public part of two key-pairs:\n\n one signature key-pair [denoted by (spk\nv\nj\n,ssk\nv\nj\n)\n  for validators and by (spk\nu\ni\n, ssk\nu\ni\n) for users], and\n\n an encryption key-pair [denoted by (epk\nv\nj\n,esk\nv\nj\n)\n  for validators and (epk\nu\ni\n, esk\nu\ni\n) for users]\n\n\nChain, validator and user enrollment public keys are accessible to everyone.\n\n\nIn addition to enrollment certificates, users who wish to anonymously\nparticipate in transactions issue transaction certificates. For simplicity\ntransaction certificates of a user u\ni\n are denoted by\nTCert\nu\ni\n. Transaction certificates include the public part\nof a signature key-pair denoted by\n\n(tpk\nu\ni\n,tsk\nu\ni\n).\n\n\nThe following section provides a high level description of how transaction\nformat accommodates read-access restrictions at the granularity of users.\n\n\nStructure of deploy transaction.\n\nThe following figure depicts the structure of a typical deploy\ntransaction with confidentiality enabled.\n\n\n\n\nOne can notice that a deployment transaction consists of several sections:\n\n Section \ngeneral-info\n: contains the administration details of the\n  transaction, i.e., which chain this transaction corresponds to (chained),\n  the type of transaction (that is set to \ndeplTrans\n), the version number of\n  confidentiality policy implemented, its creator identifier (expressed by means\n  of transaction certificate TCert of enrollment certificate Cert), and a Nonce,\n  that facilitates primarily replay-attack resistance techniques.\n\n Section \ncode-info\n: contains information on the chain-code source code,\n  and function headers. As shown in the figure below, there is a symmetric key\n  used for the source-code of the chaincode (K\nC\n), and another\n  symmetric key used for the function prototypes (K\nH\n). A signature of\n  the creator of the chaincode is included on the plain-text code such that\n  the latter cannot be detached from the transaction and replayed by another\n  party.\n\n Section \nchain-validators\n: where appropriate key material is passed to the\n  validators for the latter to be able to (i) decrypt the chain-code source\n  (K\nC\n), (ii) decrypt the headers,  and\n  (iii) encrypt the state when the chain-code has been\n  invoked accordingly(K\nS\n). In particular, the chain-code creator\n  generates an encryption key-pair for the chain-code it deploys\n  (PK\nC\n, SK\nC\n). It then uses PK\nC\n\n  to encrypt all the keys associated to the chain-code:\n  \n [(\ncode\n,K\nC\n) ,(\nheadr\n,K\nH\n),(\ncode-state\n,K\nS\n), Sig\nTCert\nu\nc\n(*)]\nPK\nc\n, \n\n  and passes the secret key SK\nC\n to the validators using the\n  chain-specific public key:\n  \n[(\nchaincode\n,SK\nC\n), Sig\nTCert\nu\nc\n(\n)]\nPK\nchain\n.\n\n\n Section \ncontract-users*: where the public encryption keys of the contract users,\n  i.e., users who are given read-access to parts of the chaincode, are used to encrypt\n  the keys  associated to their access rights:\n\n\n\n\n\n\nSK\nc\n for the users to be able to read any message associated to\n     that chain-code (invocation, state, etc),\n\n\n\n\n\n\nK\nC\n for the user to be able to read only the contract code,\n\n\n\n\n\n\nK\nH\n for the user to only be able to read the headers,\n\n\n\n\n\n\nK\nS\n for the user to be able to read the state associated to that contract.\n\n\n\n\n\n\nFinally users are given the contract\ns public key PK\nc\n,\n  for them to be able to encrypt information related to that contract for the validators\n  (or any in possession of SK\nc\n) to be able to read it. Transaction certificate\n  of each contract user is appended to the transaction and follows that user\ns message.\n  This is done for users to be able to easily search the blockchain\n  for transactions they have been part of. Notice that the deployment transaction also\n  appends a message to the creator u\nc\n of the chain-code, for the\n  latter to be able to retrieve this transaction through parsing the ledger and without\n  keeping any state locally.\n\n\nThe entire transaction is signed by a certificate of the chaincode creator, i.e., enrollment\nor transaction certificate as decided by the latter.\nTwo noteworthy points:\n\n Messages that are included in a transaction in an encrypted format, i.e., code-functions, code-hdrs,\n  are signed before they are encrypted using the same TCert the entire transaction is signed with, or\n  even with a different TCert or the ECert of the user (if the transaction deployment should carry the identity\n  of its owner. A binding to the underlying transaction carrier should be included in the signed message, e.g.,\n  the hash of the TCert the transaction is signed, such that mix\\\nmatch attacks are not possible.\n  Though we detail such attacks in Section 4.4, in these cases an attacker who sees a transaction should not be able\n  to isolate the ciphertext corresponding to, e.g., code-info, and use it for another transaction of her own.\n  Clearly, such an ability would disrupt the operation of the system, as a chaincode that was first created by user A,\n  will now also belong to malicious user B (who is not even able to read it).\n\n To offer the ability to the users to cross-verify they are given access to the\n  correct key, i.e., to the same key as the other contract users, transaction\n  ciphertexts that are encrypted with a key K are accompanied by a commitment\n  to K, while the opening of this commitment value is passed to all users who\n  are entitled access to K in contract-users, and chain-validator sections.\n  \n\n  In this way, anyone who is entitled access to that key can verify that the key\n  has been properly passed to it. This part is omitted in the figure above to\n  avoid confusion.\n\n\nStructure of invoke transaction.\n\nA transaction invoking the chain-code triggering the execution of a function of the chain-code with\nuser-specified arguments is structured as depicted in the figure below.\n\n\n\n\nInvocation transaction as in the case of deployment transaction consists of a\n\ngeneral-info\n section, a \ncode-info\n section, a section for the \nchain-validators\n,\nand one for the \ncontract users\n, signed altogether with one of the invoker\ns\ntransaction certificates.\n\n\n\n\n\n\nGeneral-info follows the same structure as the corresponding section of the\ndeployment transaction.\nThe only difference relates to the transaction type that is now set to \nInvocTx\n,\nand the chain-code identifier or name that is now encrypted under the\nchain-specific encryption (public) key.\n\n\n\n\n\n\nCode-info exhibits the same structure as the one of the deployment transaction.\nCode payload, as in the case of deployment transaction, consists of function\ninvocation details (the name of the function invoked, and associated arguments),\ncode-metadata provided by the application and the transaction\ns creator\n(invoker\ns u) certificate, TCert\nu\n. Code payload is signed by the\ntransaction certificate TCert\nu\n of the invoker u, as in the case\nof deploy transactions. As in the case of\ndeploy transactions, code-metadata, and tx-metadata, are fields that are\nprovided by the application and can be used (as described in Section 4.4),\nfor the latter to implement their own access control mechanisms and roles.\n\n\n\n\n\n\nFinally, contract-users and chain-validator sections provide the key the payload\nis encrypted with, the invoker\ns key, and the chain encryption key respectively.\nUpon receiving such transactions, the validators decrypt [code-name]\nPK\nchain\n using the\nchain-specific secret key SK\nchain\n and obtain the invoked chain-code identifier.\nGiven the latter, validators retrieve from their local storage the chaincode\ns\ndecryption key SK\nc\n, and use it to decrypt chain-validators\n message,\nthat would equip them with the symmetric key K\nI\n the invocation\ntransaction\ns payload was encrypted with.\nGiven the latter, validators decrypt code-info, and execute the chain-code\nfunction with the specified arguments,\nand the code-metadata attached(See, Section 4.4 for more details on the use of\ncode-metadata). While the chain-code is executed, updates of the state of that\nchain-code are possible.\nThese are encrypted using the state-specific key K\ns\n that was defined\nduring that chain-code\ns deployment. In particular, K\ns\n is used the\nsame way K\niTx\n is used in the design of our current release\n(See, Section 4.7).\n\n\n\n\n\n\nStructure of query transaction.\n\nQuery transactions have the same format as invoke transactions.\nThe only difference is that Query transactions do not affect the state\nof the chaincode, and thus there is no need for the state to be retrieved\n(decrypted) and/or updated (encrypted) after the execution of the chaincode\ncompletes.\n\n\n4.3.2.2 Confidentiality against validators\n\n\nThis section deals with ways of how to support execution of certain transactions\nunder a different (or subset) sets of validators in the current chain. This\nsection inhibits IP restrictions and will be expanded in the following few weeks.\n\n\n4.3.3 Replay attack resistance\n\n\nIn replay attacks the attacker \nreplays\n a message it \neavesdropped\n on the network or \nsaw\n on the Blockchain.\nReplay attacks are a big problem here, as they can incur into the validating entities re-doing a computationally intensive\nprocess (chaincode invocation) and/or affect the state of the corresponding chaincode, while it requires minimal or no\npower from the attacker side. To make matters worse, if a transaction was a payment transaction, replays could\npotentially incur into the payment being performed more than once, without this being the original intention of the payer.\nExisting systems resist replay attacks as follows:\n\n Record hashes of transactions in the system. This solution would require that validators maintain a log of the hash of\n  each transaction that has ever been announced through the network, and compare a new transaction against their locally\n  stored transaction record. Clearly such approach cannot scale for large networks, and could easily result into validators\n  spending a lot of time to do the check of whether a transaction has been replayed, than executing the actual transaction.\n\n Leverage state that is maintained per user identity (Ethereum). Ethereum keeps some state, e.g., counter (initially set to 1)\n  for each identity/pseudonym in the system. Users also maintain their own counter (initially set to 0) for each\n  identity/pseudonym of theirs. Each time a user sends a transaction using an identity/pseudonym of his, he increases\n  his local counter by one and adds the resulting value to the transaction. The transaction is subsequently signed by that\n  user identity and released to the network. When picking up this transaction, validators check the counter value included\n  within and compare it with the one they have stored locally; if the value is the same, they increase the local value of\n  that identity\ns counter and accept the transaction. Otherwise, they reject the transaction as invalid or replay.\n  Although this would work well in cases where we have limited number of user identities/pseudonyms (e.g., not too large),\n  it would ultimately not scale in a system where users use a different identifier (transaction certificate) per transaction,\n  and thus have a number of user pseudonyms proportional to the number of transactions.\n\n\nOther asset management systems, e.g., Bitcoin, though not directly dealing with replay attacks, they resist them. In systems\nthat manage (digital) assets, state is maintained on a per asset basis, i.e., validators only keep a record of who owns what.\nResistance to replay attacks come as a direct result from this, as replays of transactions would be immediately be\ndeemed as invalid by the protocol (since can only be shown to be derived from older owners of an asset/coin). While this would\nbe appropriate for asset management systems, this does not abide with the needs of a Blockchain systems with more generic\nuse than asset management.\n\n\nIn the fabric, replay attack protection uses a hybrid approach.\nThat is, users add in the transaction a nonce that is generated in a different manner\ndepending on whether the transaction is anonymous (followed and signed by a transaction certificate) or not\n(followed and signed by a long term enrollment certificate). More specifically:\n\n\n\n\nUsers submitting a transaction with their enrollment certificate should include in that\n  transaction a nonce that is a function of the nonce they used in the previous transaction\n  they issued with the same certificate (e.g., a counter function or a hash). The nonce included\n  in the first transaction of each enrollment certificate can be either pre-fixed by the system\n  (e.g., included in the genesis block) or chosen by the user. In the first case, the genesis block\n  would need to include nonceall , i.e., a fixed number and the nonce used by user with identity\n  IDA for his first enrollment certificate signed transaction would be\n  \nnonce\nround\n0\nIDA\n \n- hash(IDA, nonce\nall\n),\n\n  where IDA appears in the enrollment certificate. From that point onward successive transactions of\n  that user with enrollment certificate would include a nonce as follows\n  \nnonce\nround\ni\nIDA\n \n- hash(nonce\nround\n{i-1}\nIDA\n),\n\n  that is the nonce of the ith transaction would be using the hash of the nonce used in the {i-1}th transaction of that certificate.\n  Validators here continue to process a transaction they receive, as long as it satisfies the condition mentioned above.\n  Upon successful validation of transaction\ns format, the validators update their database with that nonce.\n\n\n\n\nStorage overhead\n:\n\n\n\n\n\n\non the user side: only the most recently used nonce,\n\n\n\n\n\n\non validator side: O(n), where n is the number of users.\n\n\n\n\nUsers submitting a transaction with a transaction certificate\n  should include in the transaction a random nonce, that would guarantee that\n  two transactions do not result into the same hash. Validators add the hash of\n  this transaction in their local database if the transaction certificate used within\n  it has not expired. To avoid storing large amounts of hashes, validity periods of transaction certificates\n  are leveraged. In particular validators maintain an updated record of received\n  transactions\n hashes within the current or future validity period.\n\n\n\n\nStorage overhead\n (only makes sense for validators here):  O(m), where m is the approximate number of\n  transactions within a validity period and corresponding validity period identifier (see below).\n\n\n4.4 Access control features on the application\n\n\nAn application, is a piece of software that runs on top of a Blockchain client software, and,\nperforms a special task over the Blockchain, i.e., restaurant table reservation.\nApplication software have a version of\ndeveloper, enabling the latter to generate and manage a couple of chaincodes that are necessary for\nthe business this application serves, and a client-version that would allow the application\ns end-users\nto make use of the application, by invoking these chain-codes.\nThe use of the Blockchain can be transparent to the application end-users or not.\n\n\nThis section describes how an application leveraging chaincodes can implement its own access control policies,\nand guidelines on how our Membership services PKI can be leveraged for the same purpose.\n\n\nThe presentation is divided into enforcement of invocation access control,\nand enforcement of read-access control by the application.\n\n\n4.4.1 Invocation access control\n\n\nTo allow the application to implement its own invocation access control at the\napplication layer securely, special support by the fabric must be provided.\nIn the following we elaborate on the tools exposed by the fabric to the\napplication for this purpose, and provide guidelines on how these should be used\nby the application for the latter to enforce access control securely.\n\n\nSupport from the infrastructure.\n\nFor the chaincode creator, let it be, \nu\nc\n,\nto be able to implement its own invocation access control at\nthe application layer securely, special support by the fabric must be provided.\nMore specifically fabric layer gives access to following capabilities:\n\n\n\n\n\n\nThe client-application can request the fabric to sign and verify any message with specific transaction certificates or enrollment certificate the client owns; this is expressed via the Certificate Handler interface\n\n\n\n\n\n\nThe client-application can request the fabric a unique \nbinding\n to be used to bind authentication data of the application to the underlying transaction transporting it; this is expressed via the Transaction Handler interface\n\n\n\n\n\n\nSupport for a transaction format, that allows for the application to specify metadata, that are passed to the chain-code at deployment, and invocation time; the latter denoted by code-metadata.\n\n\n\n\n\n\nThe \nCertificate Handler\n interface allows to sign and verify any message using signing key-pair underlying the associated certificate.\nThe certificate can be a TCert or an ECert.\n\n\n// CertificateHandler exposes methods to deal with an ECert/TCert\ntype CertificateHandler interface {\n\n    // GetCertificate returns the certificate's DER\n    GetCertificate() []byte\n\n    // Sign signs msg using the signing key corresponding to the certificate\n    Sign(msg []byte) ([]byte, error)\n\n    // Verify verifies msg using the verifying key corresponding to the certificate\n    Verify(signature []byte, msg []byte) error\n\n    // GetTransactionHandler returns a new transaction handler relative to this certificate\n    GetTransactionHandler() (TransactionHandler, error)\n}\n\n\n\n\nThe \nTransaction Handler\n interface allows to create transactions and give access to the underlying \nbinding\n that can be leveraged to link\napplication data to the underlying transaction. Bindings are a concept that have been introduced in network transport protocols (See, https://tools.ietf.org/html/rfc5056),\nknown as \nchannel bindings\n, that \nallows applications to establish that the two end-points of a secure channel at one network layer are the same as at a higher layer\nby binding authentication at the higher layer to the channel at the lower layer.\nThis allows applications to delegate session protection to lower layers, which has various performance benefits.\n\nTransaction bindings offer the ability to uniquely identify the fabric layer of the transaction that serves as the container that\napplication data uses to be added to the ledger.\n\n\n// TransactionHandler represents a single transaction that can be uniquely determined or identified by the output of the GetBinding method.\n// This transaction is linked to a single Certificate (TCert or ECert).\ntype TransactionHandler interface {\n\n    // GetCertificateHandler returns the certificate handler relative to the certificate mapped to this transaction\n    GetCertificateHandler() (CertificateHandler, error)\n\n    // GetBinding returns a binding to the underlying transaction (container)\n    GetBinding() ([]byte, error)\n\n    // NewChaincodeDeployTransaction is used to deploy chaincode\n    NewChaincodeDeployTransaction(chaincodeDeploymentSpec *obc.ChaincodeDeploymentSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeExecute is used to execute chaincode's functions\n    NewChaincodeExecute(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeQuery is used to query chaincode's functions\n    NewChaincodeQuery(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n}\n\n\n\n\nFor version 1, \nbinding\n consists of the \nhash\n(TCert, Nonce), where TCert, is the transaction certificate\nused to sign the entire transaction, while Nonce, is the nonce number used within.\n\n\nThe \nClient\n interface is more generic, and offers a mean to get instances of the previous interfaces.\n\n\ntype Client interface {\n\n    ...\n\n    // GetEnrollmentCertHandler returns a CertificateHandler whose certificate is the enrollment certificate\n    GetEnrollmentCertificateHandler() (CertificateHandler, error)\n\n    // GetTCertHandlerNext returns a CertificateHandler whose certificate is the next available TCert\n    GetTCertificateHandlerNext() (CertificateHandler, error)\n\n    // GetTCertHandlerFromDER returns a CertificateHandler whose certificate is the one passed\n    GetTCertificateHandlerFromDER(der []byte) (CertificateHandler, error)\n\n}\n\n\n\n\nTo support application-level access control lists for controlling chaincode\ninvocation, the fabric\ns transaction and chaincode specification format\nhave an additional field to store application-specific metadata.\nThis field is depicted in both figures 1, by code-metadata. The content of this field is decided\nby the application, at the transaction creation time.\nThe fabric layer treats it as an unstructured stream of bytes.\n\n\n\nmessage ChaincodeSpec {\n\n    ...\n\n    ConfidentialityLevel confidentialityLevel;\n    bytes metadata;\n\n    ...\n}\n\n\nmessage Transaction {\n    ...\n\n    bytes payload;\n    bytes metadata;\n\n    ...\n}\n\n\n\n\nTo assist chaincode execution, at the chain-code invocation time, the validators provide the\nchaincode with additional information, like the metadata and the binding.\n\n\nApplication invocation access control.\n\nThis section describes how the application can leverage the means provided by the fabric\nto implement its own access control on its chain-code functions.\nIn the scenario considered here, the following entities are identified:\n\n\n\n\n\n\nC\n: is a chaincode that contains a single function, e.g., called \nhello\n;\n\n\n\n\n\n\nu\nc\n: is the \nC\n deployer;\n\n\n\n\n\n\nu\ni\n: is a user who is authorized to invoke \nC\ns functions. User u\nc\n wants to ensure that only u\ni\n can invoke the function \nhello\n.\n\n\n\n\n\n\nDeployment of a Chaincode:\n At deployment time, u\nc\n has full control on the deployment transaction\ns metadata,\n and can be used to store a list of ACLs (one per function), or a list of roles that are needed by the application. The format which is used to store these ACLs is up to the deployer\ns application, as the chain-code is the one\nwho would need to parse the metadata at execution time.\nTo define each of these lists/roles, u\nc\n can use any TCerts/Certs of the u\ni\n (or, if applicable, or other users who have been assigned that privilege or role). Let this be TCert\nu\ni\n.\nThe exchange of TCerts or Certs among the developer and authorized users is done through an out-of-band channel.\n\n\nAssume that the application of u\nc\ns requires that to invoke the \nhello\n function, a certain message \nM\n has to be authenticated by an authorized invoker (u\ni\n, in our example).\nOne can distinguish the following two cases:\n\n\n\n\n\n\nM\n is one of the chaincode\ns function arguments;\n\n\n\n\n\n\nM\n is the invocation message itself, i.e., function-name, function-arguments.\n\n\n\n\n\n\nChaincode invocation:\n\nTo invoke C, u\ni\ns application needs to sign \nM\n using the TCert/ECert, that was used to identify u\ni\ns participation in the chain-code at the associated\ndeployment transaction\ns metadata, i.e., TCert\nu\ni\n. More specifically, u\ni\ns client application does the following:\n\n\n\n\n\n\nRetrieves a CertificateHandler for Cert\nu\ni\n, \ncHandler\n;\n\n\n\n\n\n\nobtains a new TransactionHandler to issue the execute transaction, \ntxHandler\n relative to his next available TCert or his ECert;\n\n\n\n\n\n\ngets \ntxHandler\ns \nbinding\n by invoking \ntxHandler.getBinding()\n;\n\n\n\n\n\n\nsigns \nM\n || txBinding\n by invoking \ncHandler.Sign(\nM\n || txBinding\n)\n, let \nsigma\n be the output of the signing function;\n\n\n\n\n\n\nissues a new execute transaction by invoking, \ntxHandler.NewChaincodeExecute(\n)\n. Now, \nsigma\n can be included in the transaction as one of the arguments that are passed to the function (case 1) or as part of the code-metadata section of the payload(case 2).\n\n\n\n\n\n\nChaincode processing:\n\nThe validators, who receive the execute transaction issued u\ni\n, will provide to \nhello\n the following information:\n\n\n\n\n\n\nThe \nbinding\n of the execute transaction, that can be independently computed at the validator side;\n\n\n\n\n\n\nThe \nmetadata\n of the execute transaction (code-metadata section of the transaction);\n\n\n\n\n\n\nThe \nmetadata\n of the deploy transaction (code-metadata component of the corresponding deployment transaction).\n\n\n\n\n\n\nNotice that \nsigma\n is either part of the arguments of the invoked function, or stored inside the code-metadata of the invocation transaction (properly formatted by the client-application).\nApplication ACLs are included in the code-metadata section, that is also passed to the chain-code at execution time.\nFunction \nhello\n is responsible for checking that \nsigma\n is indeed a valid signature issued by TCert\nu\ni\n, on \nM\n || \ntxBinding\n.\n\n\n4.4.2 Read access control\n\n\nThis section describes how the fabric\ns infrastructure offers support to the application to\nenforce its own read-access control policies at the level of users. As in the case of invocation access\ncontrol, the first part describes the infrastructure features that can be leveraged by the application for this\npurpose, and the last part details on the way applications should use these tools.\n\n\nFor the purpose of this discussion, we leverage a similar example as before, i.e.,\n\n\n\n\n\n\nC\n: is a chaincode that contains a single function, e.g., called \nhello\n;\n\n\n\n\n\n\nu\nA\n: is the \nC\ns deployer, also known as application;\n\n\n\n\n\n\nu\nr\n: is a user who is authorized to read \nC\ns functions. User u\nA\n wants to ensure that only u\nr\n can read the function \nhello\n.\n\n\n\n\n\n\nSupport from the infrastructure.\n\nFor \nu\nA\n to be able to implement its own read access control at the application layer securely, our infrastructure is required to\nsupport the transaction format for code deployment and invocation, as depicted in the two figures below.\n\n\n\n\n\n\nMore specifically fabric layer is required to provide the following functionality:\n\n\n\n\n\n\nProvide minimal encryption capability such that data is only decryptable by a validator\ns (infrastructure) side; this means that the infrastructure should move closer to our future version, where an asymmetric encryption scheme is used for encrypting transactions. More specifically, an asymmetric key-pair is used for the chain, denoted by K\nchain\n in the Figures above, but detailed in Section \nTransaction Confidentiality\n.\n\n\n\n\n\n\nThe client-application can request the infrastructure sitting on the client-side to encrypt/decrypt information using a specific public encryption key, or that client\ns long-term decryption key.\n\n\n\n\n\n\nThe transaction format offers the ability to the application to store additional transaction metadata, that can be passed to the client-application after the latter\ns request. Transaction metadata, as opposed to code-metadata, is not encrypted or provided to the chain-code at execution time. Validators treat these metadata as a list of bytes they are not responsible for checking validity of.\n\n\n\n\n\n\nApplication read-access control.\n\nFor this reason the application may request and obtain access to the public encryption key of the user \nu\nr\n; let that be \nPK\nu\nr\n. Optionally,\n\nu\nr\n may be providing \nu\nA\n with a certificate of its, that would be leveraged by the application, say, TCert\nu\nr\n; given the latter,\nthe application would, e.g., be able to trace that user\ns transactions w.r.t. the application\ns chain-codes. TCert\nu\nr\n, and PK\nu\nr\n, are\nexchanged in an out-of-band channel.\n\n\nAt deployment time, application \nu\nA\n performs the following steps:\n\n\n\n\n\n\nUses the underlying infrastructure to encrypt the information of \nC\n, the application would like to make accessible to \nu\nr\n, using PK\nu\nr\n.\n   Let C\nu\nr\n be the resulting ciphertext.\n\n\n\n\n\n\n(optional) C\nu\nr\n can be concatenated with TCert\nu\nr\n\n\n\n\n\n\nPasses the overall string as \nTx-metadata\n of the confidential transaction to be constructed.\n\n\n\n\n\n\nAt invocation time, the client-application on u\nr\ns node, would be able, by obtaining the deployment transaction to retrieve the content of \nC\n.\nIt just needs to retrieve the \ntx-metadata\n field of the associated deployment transaction, and trigger the decryption functionality offered by our Blockchain\ninfrastrucure\ns client, for C\nu\nr\n. Notice that it is the application\ns responsibility to encrypt the correct \nC\n for u\nr\n.\nAlso, the use of \ntx-metadata\n field can be generalized to accommodate application-needs. E.g., it can be that invokers leverage the same field of invocation transactions\nto pass information to the developer of the application, etc.\n\n\nImportant Note:\n \n It is essential to note that validators \ndo not provide\n any decryption oracle to the chain-code\nthroughout its execution. Its infrastructure is though responsible for decrypting the payload of the chain-code itself (as well as\nthe code-metadata fields near it), and provide those to containers for deployment/execution.\n\n\n4.5 Online wallet service\n\n\nThis section describes the security design of a wallet service, which in this case is a node with which end-users can register, store their key material and through which they can perform transactions.\nBecause the wallet service is in possession of the user\ns key material, it is clear that without a secure authorization\nmechanism in place a malicious wallet service could successfully impersonate the user.\nWe thus emphasize that this design corresponds to a wallet service that is \ntrusted\n to only perform transactions\non behalf of its clients, with the consent of the latter.\nThere are two cases for the registration of an end-user to an online wallet service:\n\n\n\n\nWhen the user has registered with the registration authority and acquired his/her \nenrollID, enrollPWD\n,\n   but has not installed the client to trigger and complete the enrollment process;\n\n\nWhen the user has already installed the client, and completed the enrollment phase.\n\n\n\n\nInitially, the user interacts with the online wallet service to issue credentials that would allow him to authenticate\nto the wallet service. That is, the user is given a username, and password, where username identifies the user in the\nmembership service, denoted by AccPub, and password is the associated secret, denoted by AccSec, that is \nshared\n by\nboth user and service.\n\n\nTo enroll through the online wallet service, a user must provide the following request\nobject to the wallet service:\n\n\nAccountRequest /* account request of u \\*/\n{\n    OBCSecCtx ,           /* credentials associated to network \\*/\n    AccPub\nsub\nu\n/sub\n,   /* account identifier of u \\*/\n    AccSecProof\nsub\nu\n/sub\n  /* proof of AccSec\nsub\nu\n/sub\n\\*/\n }\n\n\n\nOBCSecCtx refers to user credentials, which depending on the stage of his enrollment process, can be either his enrollment ID and password, \nenrollID, enrollPWD\n or his enrollment certificate and associated secret key(s)\n(ECert\nu\n, sk\nu\n),  where  sk\nu\n denotes for simplicity signing and decryption secret of the user.\nThe content of AccSecProof\nu\n is an HMAC on the rest fields of request using the shared secret. Nonce-based methods\nsimilar to what we have in the fabric can be used to protect against replays.\nOBCSecCtx would give the online wallet service the necessary information to enroll the user or issue required TCerts.\n\n\nFor subsequent requests, the user u should provide to the wallet service a request of similar format.\n\n\n TransactionRequest /* account request of u \\*/\n {\n      TxDetails,            /* specifications for the new transaction \\*/\n      AccPub\nsub\nu\n/sub\n,       /* account identifier of u \\*/\n      AccSecProof\nsub\nu\n/sub\n   /* proof of AccSec\nsub\nu\n/sub\n \\*/\n }\n\n\n\nHere, TxDetails refer to the information needed by the online service to construct a transaction on behalf of the user, i.e.,\nthe type, and user-specified content of the transaction.\n\n\nAccSecProof\nu\n is again an HMAC on the rest fields of request using the shared secret.\nNonce-based methods similar to what we have in the fabric can be used to protect against replays.\n\n\nTLS connections can be used in each case with server side authentication to secure the request at the\nnetwork layer (confidentiality, replay attack protection, etc)\n\n\n4.6 Network security (TLS)\n\n\nThe TLS CA should be capable of issuing TLS certificates to (non-validating) peers, validators, and individual clients (or browsers capable of storing a private key). Preferably, these certificates are distinguished by type, per above. TLS certificates for CAs of the various types (such as TLS CA, ECA, TCA) could be issued by an intermediate CA (i.e., a CA that is subordinate to the root CA). Where there is not a particular traffic analysis issue, any given TLS connection can be mutually authenticated, except for requests to the TLS CA for TLS certificates.\n\n\nIn the current implementation the only trust anchor is the TLS CA self-signed certificate in order to accommodate the limitation of a single port to communicate with all three (co-located) servers, i.e., the TLS CA, the TCA and the ECA. Consequently, the TLS handshake is established with the TLS CA, which passes the resultant session keys to the co-located TCA and ECA. The trust in validity of the TCA and ECA self-signed certificates is therefore inherited from trust in the TLS CA. In an implementation that does not thus elevate the TLS CA above other CAs, the trust anchor should be replaced with a root CA under which the TLS CA and all other CAs are certified.\n\n\n4.7 Restrictions in the current release\n\n\nThis section lists the restrictions of the current release of the fabric.\nA particular focus is given on client operations and the design of transaction confidentiality,\nas depicted in Sections 4.7.1 and 4.7.2.\n\n\n\n\nClient side enrollment and transaction creation is performed entirely by a\n   non-validating peer that is trusted not to impersonate the user.\n   See, Section 4.7.1 for more information.\n\n\nA minimal set of confidentiality properties where a chaincode is accessible\n   by any entity that is member of the system, i.e., validators and users who\n   have registered through Hyperledger Fabric\ns Membership Services and is not accessible by anyone else.\n   The latter include any party that has access to the storage area where the\n   ledger is maintained, or other entities that are able to see the transactions\n   that are announced in the validator network. The design of the first release\n   is detailed in subsection 4.7.2\n\n\nThe code utilizes self-signed certificates for entities such as the\n   enrollment CA (ECA) and the transaction CA (TCA)\n\n\nReplay attack resistance mechanism is not available\n\n\nInvocation access control can be enforced at the application layer:\n   it is up to the application to leverage the infrastructure\ns tools properly\n   for security to be guaranteed. This means, that if the application fails to\n   \nbind\n the transaction binding offered by the fabric, secure transaction\n   processing may be at risk.\n\n\n\n\n4.7.1 Simplified client\n\n\nClient-side enrollment and transaction creation are performed entirely by a non-validating peer that plays the role of an online wallet.\nIn particular, the end-user leverages their registration credentials \n to open an account to a non-validating peer\nand uses these credentials to further authorize the peer to build transactions on the user\ns behalf. It needs to be noted, that such\na design does not provide secure \nauthorization\n for the peer to submit transactions on behalf of the user, as a malicious peer\ncould impersonate the user. Details on the specifications of a design that deals with the security issues of online wallet can be found is Section 4.5.\nCurrently the maximum number of peers a user can register to and perform transactions through is one.\n\n\n4.7.2 Simplified transaction confidentiality\n\n\nDisclaimer:\n The current version of transaction confidentiality is minimal, and will be used as an intermediate step\nto reach a design that allows for fine grained (invocation) access control enforcement in a subsequent release.\n\n\nIn its current form, confidentiality of transactions is offered solely at the chain-level, i.e., that the\ncontent of a transaction included in a ledger, is readable by all members of that chain, i.e., validators\nand users. At the same time, application auditors who are not members of the system can be given\nthe means to perform auditing by passively observing the blockchain data, while\nguaranteeing that they are given access solely to the transactions related to the application under audit.\nState is encrypted in a way that such auditing requirements are satisfied, while not disrupting the\nproper operation of the underlying consensus network.\n\n\nMore specifically, currently symmetric key encryption is supported in the process of offering transaction confidentiality. In this setting, one of the main challenges that is specific to the blockchain setting,\nis that validators need to run consensus over the state of the blockchain, that, aside from the transactions themselves,\nalso includes the state updates of individual contracts or chaincode. Though this is trivial to do for non-confidential chaincode, for confidential chaincode, one needs to design the state encryption mechanism such that the resulting ciphertexts are semantically secure, and yet, identical if the plaintext state is the same.\n\n\nTo overcome this challenge, the fabric utilizes a key hierarchy that reduces the number of ciphertexts\nthat are encrypted under the same key. At the same time, as some of these keys are used for the generation of IVs,\nthis allows the validating parties to generate exactly the same ciphertext when executing the same transaction\n(this is necessary to remain agnostic to the underlying consensus algorithm) and offers the possibility of controlling audit by disclosing to auditing entities only the most relevant keys.\n\n\nMethod description:\n\nMembership service generates a symmetric key for the ledger (K\nchain\n) that is distributed\nat registration time to all the entities of the blockchain system, i.e., the clients and the\nvalidating entities that have issued credentials through the membership service of the chain.\nAt enrollment phase, user obtain (as before) an enrollment certificate, denoted by Cert\nu\ni\n\nfor user u\ni\n , while each validator v\nj\n obtains its enrollment certificate denoted by Cert\nv\nj\n.\n\n\nEntity enrollment would be enhanced, as follows. In addition to enrollment certificates,\nusers who wish to anonymously participate in transactions issue transaction certificates.\nFor simplicity transaction certificates of a user u\ni\n are denoted by TCert\nu\ni\n.\nTransaction certificates include the public part of a signature key-pair denoted by (tpk\nu\ni\n,tsk\nu\ni\n).\n\n\nIn order to defeat crypto-analysis and enforce confidentiality, the following key hierarchy is considered for generation and validation of confidential transactions:\nTo submit a confidential transaction (Tx) to the ledger, a client first samples a nonce (N), which is required to be unique among all the transactions submitted to the blockchain, and derive a transaction symmetric\nkey (K\nTx\n) by applying the HMAC function keyed with K\nchain\n and on input the nonce, K\nTx\n= HMAC(K\nchain\n, N). From K\nTx\n, the client derives two AES keys:\nK\nTxCID\n as HMAC(K\nTx\n, c\n1\n), K\nTxP\n as HMAC(K\nTx\n, c\n2\n)) to encrypt respectively the chain-code name or identifier CID and code (or payload) P.\nc\n1\n, c\n2\n are public constants. The nonce, the Encrypted Chaincode ID (ECID) and the Encrypted Payload (EP) are added in the transaction Tx structure, that is finally signed and so\nauthenticated. Figure below shows how encryption keys for the client\ns transaction are generated. Arrows in this figure denote application of an HMAC, keyed by the key at the source of the arrow and\nusing the number in the arrow as argument. Deployment/Invocation transactions\n keys are indicated by d/i respectively.\n\n\n\n\nTo validate a confidential transaction Tx submitted to the blockchain by a client,\na validating entity first decrypts ECID and EP by re-deriving K\nTxCID\n and K\nTxP\n\nfrom K\nchain\n and Tx.Nonce as done before. Once the Chaincode ID and the\nPayload are recovered the transaction can be processed.\n\n\n\n\nWhen V validates a confidential transaction, the corresponding chaincode can access and modify the\nchaincode\ns state. V keeps the chaincode\ns state encrypted. In order to do so, V generates symmetric\nkeys as depicted in the figure above. Let iTx be a confidential transaction invoking a function\ndeployed at an early stage by the confidential transaction dTx (notice that iTx can be dTx itself\nin the case, for example, that dTx has a setup function that initializes the chaincode\ns state).\nThen, V generates two symmetric keys  K\nIV\n  and K\nstate\n as follows:\n\n\n\n\nIt computes  as  K\ndTx\n , i.e., the transaction key of the corresponding deployment\n   transaction, and then N\nstate\n = HMAC(K\ndtx\n ,hash(N\ni\n)), where N\ni\n\n   is the nonce appearing in the invocation transaction, and \nhash\n a hash function.\n\n\nIt sets K\nstate\n = HMAC(K\ndTx\n, c\n3\n || N\nstate\n),\n   truncated opportunely deeding on the underlying cipher used to encrypt; c\n3\n is a constant number\n\n\nIt sets K\nIV\n = HMAC(K\ndTx\n, c\n4\n || N\nstate\n); c\n4\n is a constant number\n\n\n\n\nIn order to encrypt a state variable S, a validator first generates the IV as HMAC(K\nIV\n, crt\nstate\n)\nproperly truncated, where crt\nstate\n is a counter value that increases each time a state update\nis requested for the same chaincode invocation. The counter is discarded after the execution of\nthe chaincode terminates. After IV has been generated, V encrypts with authentication (i.e., GSM mode)\nthe value of S concatenated with Nstate(Actually, N\nstate\n  doesn\nt need to be encrypted but\nonly authenticated). To the resulting ciphertext (CT), N\nstate\n and the IV used is appended.\nIn order to decrypt an encrypted state CT|| N\nstate\n , a validator first generates the symmetric\nkeys K\ndTX\n ,K\nstate\n using N\nstate\n and then decrypts CT.\n\n\nGeneration of IVs: In order to be agnostic to any underlying consensus algorithm, all the validating\nparties need a method to produce the same exact ciphertexts. In order to do so, the validators need\nto use the same IVs. Reusing the same IV with the same symmetric key completely breaks the security\nof the underlying cipher. Therefore, the process described before is followed. In particular, V first\nderives an IV generation key K\nIV\n by computing HMAC(K\ndTX\n, c\n4\n || N\nstate\n ),\nwhere c\n4\n is a constant number, and keeps a counter crt\nstate\n for the pair\n(dTx, iTx) with is initially set to 0. Then, each time a new ciphertext has to be generated, the validator\ngenerates a new IV by computing it as the output of HMAC(K\nIV\n, crt\nstate\n)\nand then increments the crt\nstate\n by one.\n\n\nAnother benefit that comes with the above key hierarchy is the ability to enable controlled auditing.\nFor example, while by releasing K\nchain\n one would provide read access to the whole chain,\nby releasing only K\nstate\n for a given pair of transactions (dTx,iTx) access would be granted to a state\nupdated by iTx, and so on.\n\n\nThe following figures demonstrate the format of a deployment and invocation transaction currently available in the code.\n\n\n\n\n\n\nOne can notice that both deployment and invocation transactions consist of two sections:\n\n\n\n\n\n\nSection \ngeneral-info\n: contains the administration details of the transaction, i.e., which chain this transaction corresponds to (is chained to), the type of transaction (that is set to \ndeploymTx\n or \ninvocTx\n), the version number of confidentiality policy implemented, its creator identifier (expressed by means of TCert of Cert) and a nonce (facilitates primarily replay-attack resistance techniques).\n\n\n\n\n\n\nSection \ncode-info\n: contains information on the chain-code source code. For deployment transaction this is essentially the chain-code identifier/name and source code, while for invocation chain-code is the name of the function invoked and its arguments. As shown in the two figures code-info in both transactions are encrypted ultimately using the chain-specific symmetric key K\nchain\n.\n\n\n\n\n\n\n5. Byzantine Consensus\n\n\nThe \npbft\n package is an implementation of the seminal \nPBFT\n consensus protocol [1], which provides consensus among validators despite a threshold of validators acting as \nByzantine\n, i.e., being malicious or failing in an unpredictable manner. In the default configuration, PBFT tolerates up to t\nn/3 Byzantine validators.\n\n\nIn the default configuration, PBFT is designed to run on at least \n3t+1\n validators (replicas), tolerating up to \nt\n potentially faulty (including malicious, or \nByzantine\n) replicas.\n\n\n5.1 Overview\n\n\nThe \npbft\n plugin provides an implementation of the PBFT consensus protocol.\n\n\n5.2 Core PBFT Functions\n\n\nThe following functions control for parallelism using a non-recursive lock and can therefore be invoked from multiple threads in parallel. However, the functions typically run to completion and may invoke functions from the CPI passed in. Care must be taken to prevent livelocks.\n\n\n5.2.1 newPbftCore\n\n\nSignature:\n\n\nfunc newPbftCore(id uint64, config *viper.Viper, consumer innerCPI, ledger consensus.Ledger) *pbftCore\n\n\n\n\nThe \nnewPbftCore\n constructor instantiates a new PBFT box instance, with the specified \nid\n. The \nconfig\n argument defines operating parameters of the PBFT network: number replicas \nN\n, checkpoint period \nK\n, and the timeouts for request completion and view change duration.\n\n\n\n\n\n\n\n\nconfiguration key\n\n\ntype\n\n\nexample value\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\ngeneral.N\n\n\ninteger\n\n\n4\n\n\nNumber of replicas\n\n\n\n\n\n\ngeneral.K\n\n\ninteger\n\n\n10\n\n\nCheckpoint period\n\n\n\n\n\n\ngeneral.timeout.request\n\n\nduration\n\n\n2s\n\n\nMax delay between request reception and execution\n\n\n\n\n\n\ngeneral.timeout.viewchange\n\n\nduration\n\n\n2s\n\n\nMax delay between view-change start and next request execution\n\n\n\n\n\n\n\n\nThe arguments \nconsumer\n and \nledger\n pass in interfaces that are used\nto query the application state and invoke application requests once\nthey have been totally ordered. See the respective sections below for\nthese interfaces.\n\n\n6. Application Programming Interface\n\n\nThe primary interface to the fabric is a REST API. The REST API allows applications to register users, query the blockchain, and to issue transactions. A CLI is also provided to cover a subset of the available APIs for development purposes. The CLI enables developers to quickly test chaincodes or query for status of transactions.\n\n\nApplications interact with a non-validating peer node through the REST API, which will require some form of authentication to ensure the entity has proper privileges. The application is responsible for implementing the appropriate authentication mechanism and the peer node will subsequently sign the outgoing messages with the client identity.\n\n\n \n\nThe fabric API design covers the categories below, though the implementation is incomplete for some of them in the current release. The \nREST API\n section will describe the APIs currently supported.\n\n\n\n\nIdentity - Enrollment to acquire or to revoke a certificate\n\n\nAddress - Target and source of a transaction\n\n\nTransaction - Unit of execution on the ledger\n\n\nChaincode - Program running on the ledger\n\n\nBlockchain - Contents of the ledger\n\n\nNetwork - Information about the blockchain peer network\n\n\nStorage - External store for files or documents\n\n\nEvent Stream - Sub/pub events on the blockchain\n\n\n\n\n6.1 REST Service\n\n\nThe REST service can be enabled (via configuration) on either validating or non-validating peers, but it is recommended to only enable the REST service on non-validating peers on production networks.\n\n\nfunc StartOpenchainRESTServer(server *oc.ServerOpenchain, devops *oc.Devops)\n\n\n\n\nThis function reads the \nrest.address\n value in the \ncore.yaml\n configuration file, which is the configuration file for the \npeer\n process. The value of the \nrest.address\n key defines the default address and port on which the peer will listen for HTTP REST requests.\n\n\nIt is assumed that the REST service receives requests from applications which have already authenticated the end user.\n\n\n6.2 REST API\n\n\nYou can work with the REST API through any tool of your choice. For example, the curl command line utility or a browser based client such as the Firefox Rest Client or Chrome Postman. You can likewise trigger REST requests directly through \nSwagger\n. To obtain the REST API Swagger description, click \nhere\n. The currently available APIs are summarized in the following section.\n\n\n6.2.1 REST Endpoints\n\n\n\n\nBlock\n\n\nGET /chain/blocks/{block-id}\n\n\nBlockchain\n\n\nGET /chain\n\n\nChaincode\n\n\nPOST /chaincode\n\n\nNetwork\n\n\nGET /network/peers\n\n\nRegistrar\n\n\nPOST /registrar\n\n\nGET /registrar/{enrollmentID}\n\n\nDELETE /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}/ecert\n\n\nGET /registrar/{enrollmentID}/tcert\n\n\nTransactions\n\n\nGET /transactions/{UUID}\n\n\n\n\n6.2.1.1 Block API\n\n\n\n\nGET /chain/blocks/{block-id}\n\n\n\n\nUse the Block API to retrieve the contents of various blocks from the blockchain. The returned Block message structure is defined in section \n3.2.1.1\n.\n\n\nBlock Retrieval Request:\n\n\nGET host:port/chain/blocks/173\n\n\n\n\nBlock Retrieval Response:\n\n\n{\n    \ntransactions\n: [\n        {\n            \ntype\n: 3,\n            \nchaincodeID\n: \nEgRteWNj\n,\n            \npayload\n: \nCh4IARIGEgRteWNjGhIKBmludm9rZRIBYRIBYhICMTA=\n,\n            \nuuid\n: \nf5978e82-6d8c-47d1-adec-f18b794f570e\n,\n            \ntimestamp\n: {\n                \nseconds\n: 1453758316,\n                \nnanos\n: 206716775\n            },\n            \ncert\n: \nMIIB/zCCAYWgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMTI1MjE0MTE3WhcNMTYwNDI0MjE0MTE3WjArMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQ4wDAYDVQQDEwVsdWthczB2MBAGByqGSM49AgEGBSuBBAAiA2IABC/BBkt8izf6Ew8UDd62EdWFikJhyCPY5VO9Wxq9JVzt3D6nubx2jO5JdfWt49q8V1Aythia50MZEDpmKhtM6z7LHOU1RxuxdjcYDOvkNJo6pX144U4N1J8/D3A+97qZpKN/MH0wDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwDQYDVR0OBAYEBAECAwQwDwYDVR0jBAgwBoAEAQIDBDA9BgYqAwQFBgcBAf8EMABNbPHZ0e/2EToi0H8mkouuUDwurgBYuUB+vZfeMewBre3wXG0irzMtfwHlfECRDDAKBggqhkjOPQQDAwNoADBlAjAoote5zYFv91lHzpbEwTfJL/+r+CG7oMVFUFuoSlvBSCObK2bDIbNkW4VQ+ZC9GTsCMQC5GCgy2oZdHw/x7XYzG2BiqmRkLRTiCS7vYCVJXLivU65P984HopxW0cEqeFM9co0=\n,\n            \nsignature\n: \nMGUCMCIJaCT3YRsjXt4TzwfmD9hg9pxYnV13kWgf7e1hAW5Nar//05kFtpVlq83X+YtcmAIxAK0IQlCgS6nqQzZEGCLd9r7cg1AkQOT/RgoWB8zcaVjh3bCmgYHsoPAPgMsi3TJktg==\n\n        }\n    ],\n    \nstateHash\n: \n7ftCvPeHIpsvSavxUoZM0u7o67MPU81ImOJIO7ZdMoH2mjnAaAAafYy9MIH3HjrWM1/Zla/Q6LsLzIjuYdYdlQ==\n,\n    \npreviousBlockHash\n: \nlT0InRg4Cvk4cKykWpCRKWDZ9YNYMzuHdUzsaeTeAcH3HdfriLEcTuxrFJ76W4jrWVvTBdI1etxuIV9AO6UF4Q==\n,\n    \nnonHashData\n: {\n        \nlocalLedgerCommitTimestamp\n: {\n            \nseconds\n: 1453758316,\n            \nnanos\n: 250834782\n        }\n    }\n}\n\n\n\n\n6.2.1.2 Blockchain API\n\n\n\n\nGET /chain\n\n\n\n\nUse the Chain API to retrieve the current state of the blockchain. The returned BlockchainInfo message is defined below.\n\n\nmessage BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}\n\n\n\n\n\n\n\n\nheight\n - Number of blocks in the blockchain, including the genesis block.\n\n\n\n\n\n\ncurrentBlockHash\n - The hash of the current or last block.\n\n\n\n\n\n\npreviousBlockHash\n - The hash of the previous block.\n\n\n\n\n\n\nBlockchain Retrieval Request:\n\n\nGET host:port/chain\n\n\n\n\nBlockchain Retrieval Response:\n\n\n{\n    \nheight\n: 174,\n    \ncurrentBlockHash\n: \nlIfbDax2NZMU3rG3cDR11OGicPLp1yebIkia33Zte9AnfqvffK6tsHRyKwsw0hZFZkCGIa9wHVkOGyFTcFxM5w==\n,\n    \npreviousBlockHash\n: \nVlz6Dv5OSy0OZpJvijrU1cmY2cNS5Ar3xX5DxAi/seaHHRPdssrljDeppDLzGx6ZVyayt8Ru6jO+E68IwMrXLQ==\n\n}\n\n\n\n\n6.2.1.3 Chaincode API\n\n\n\n\nPOST /chaincode\n\n\n\n\nUse the Chaincode API to deploy, invoke, and query chaincodes. The deploy request requires the client to supply a \npath\n parameter, pointing to the directory containing the chaincode in the file system. The response to a deploy request is either a message containing a confirmation of successful chaincode deployment or an error, containing a reason for the failure. It also contains the generated chaincode \nname\n in the \nmessage\n field, which is to be used in subsequent invocation and query transactions to uniquely identify the deployed chaincode.\n\n\nTo deploy a chaincode, supply the required ChaincodeSpec payload, defined in section \n3.1.2.2\n.\n\n\nDeploy Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n        \npath\n:\ngithub.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n1000\n, \nb\n, \n2000\n]\n    }\n  },\n  \nid\n: \n1\n  \n}\n\n\n\n\nDeploy Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nid\n: 1\n}\n\n\n\n\nWith security enabled, modify the required payload to include the \nsecureContext\n element passing the enrollment ID of a logged in user as follows:\n\n\nDeploy Request with security enabled:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n        \npath\n:\ngithub.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n1000\n, \nb\n, \n2000\n]\n    },\n    \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: \n1\n  \n}\n\n\n\n\nThe invoke request requires the client to supply a \nname\n parameter, which was previously returned in the response from the deploy transaction. The response to an invocation request is either a message containing a confirmation of successful execution or an error, containing a reason for the failure.\n\n\nTo invoke a function within a chaincode, supply the required ChaincodeSpec payload, defined in section \n3.1.2.2\n.\n\n\nInvoke Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n      \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninvoke\n,\n        \nargs\n:[\na\n, \nb\n, \n100\n]\n    }\n  },\n  \nid\n: \n3\n  \n}\n\n\n\n\nInvoke Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n5a4540e5-902b-422d-a6ab-e70ab36a2e6d\n\n    },\n    \nid\n: 3\n}\n\n\n\n\nWith security enabled, modify the required payload to include the \nsecureContext\n element passing the enrollment ID of a logged in user as follows:\n\n\nInvoke Request with security enabled:\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n      \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninvoke\n,\n        \nargs\n:[\na\n, \nb\n, \n100\n]\n    },\n    \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: \n3\n  \n}\n\n\n\n\nThe query request requires the client to supply a \nname\n parameter, which was previously returned in the response from the deploy transaction. The response to a query request depends on the chaincode implementation. The response will contain a message containing a confirmation of successful execution or an error, containing a reason for the failure. In the case of successful execution, the response will also contain values of requested state variables within the chaincode.\n\n\nTo invoke a query function within a chaincode, supply the required ChaincodeSpec payload, defined in section \n3.1.2.2\n.\n\n\nQuery Request:\n\n\nPOST host:port/chaincode/\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n      \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\nquery\n,\n        \nargs\n:[\na\n]\n    }\n  },\n  \nid\n: \n5\n  \n}\n\n\n\n\nQuery Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n-400\n\n    },\n    \nid\n: 5\n}\n\n\n\n\nWith security enabled, modify the required payload to include the \nsecureContext\n element passing the enrollment ID of a logged in user as follows:\n\n\nQuery Request with security enabled:\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n      \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\nquery\n,\n        \nargs\n:[\na\n]\n    },\n    \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: \n5\n  \n}\n\n\n\n\n6.2.1.4 Network API\n\n\nUse the Network API to retrieve information about the network of peer nodes comprising the blockchain fabric.\n\n\nThe /network/peers endpoint returns a list of all existing network connections for the target peer node. The list includes both validating and non-validating peers. The list of peers is returned as type \nPeersMessage\n, containing an array of \nPeerEndpoint\n, defined in section \n3.1.1\n.\n\n\nmessage PeersMessage {\n    repeated PeerEndpoint peers = 1;\n}\n\n\n\n\nNetwork Request:\n\n\nGET host:port/network/peers\n\n\n\n\nNetwork Response:\n\n\n{\n    \npeers\n: [\n        {\n            \nID\n: {\n                \nname\n: \nvp1\n\n            },\n            \naddress\n: \n172.17.0.4:7051\n,\n            \ntype\n: 1,\n            \npkiID\n: \nrUA+vX2jVCXev6JsXDNgNBMX03IV9mHRPWo6h6SI0KLMypBJLd+JoGGlqFgi+eq/\n\n        },\n        {\n            \nID\n: {\n                \nname\n: \nvp3\n\n            },\n            \naddress\n: \n172.17.0.5:7051\n,\n            \ntype\n: 1,\n            \npkiID\n: \nOBduaZJ72gmM+B9wp3aErQlofE0ulQfXfTHh377ruJjOpsUn0MyvsJELUTHpAbHI\n\n        },\n        {\n            \nID\n: {\n                \nname\n: \nvp2\n\n            },\n            \naddress\n: \n172.17.0.6:7051\n,\n            \ntype\n: 1,\n            \npkiID\n: \nGhtP0Y+o/XVmRNXGF6pcm9KLNTfCZp+XahTBqVRmaIumJZnBpom4ACayVbg4Q/Eb\n\n        }\n    ]\n}\n\n\n\n\n6.2.1.5 Registrar API (member services)\n\n\n\n\nPOST /registrar\n\n\nGET /registrar/{enrollmentID}\n\n\nDELETE /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}/ecert\n\n\nGET /registrar/{enrollmentID}/tcert\n\n\n\n\nUse the Registrar APIs to manage end user registration with the certificate authority (CA). These API endpoints are used to register a user with the CA, determine whether a given user is registered, and to remove any login tokens for a target user from local storage, preventing them from executing any further transactions. The Registrar APIs are also used to retrieve user enrollment and transaction certificates from the system.\n\n\nThe \n/registrar\n endpoint is used to register a user with the CA. The required Secret payload is defined below. The response to the registration request is either a confirmation of successful registration or an error, containing a reason for the failure.\n\n\nmessage Secret {\n    string enrollId = 1;\n    string enrollSecret = 2;\n}\n\n\n\n\n\n\nenrollId\n - Enrollment ID with the certificate authority.\n\n\nenrollSecret\n - Enrollment password with the certificate authority.\n\n\n\n\nEnrollment Request:\n\n\nPOST host:port/registrar\n\n{\n  \nenrollId\n: \nlukas\n,\n  \nenrollSecret\n: \nNPKYL39uKbkj\n\n}\n\n\n\n\nEnrollment Response:\n\n\n{\n    \nOK\n: \nLogin successful for user 'lukas'.\n\n}\n\n\n\n\nThe \nGET /registrar/{enrollmentID}\n endpoint is used to confirm whether a given user is registered with the CA. If so, a confirmation will be returned. Otherwise, an authorization error will result.\n\n\nVerify Enrollment Request:\n\n\nGET host:port/registrar/jim\n\n\n\n\nVerify Enrollment Response:\n\n\n{\n    \nOK\n: \nUser jim is already logged in.\n\n}\n\n\n\n\nVerify Enrollment Request:\n\n\nGET host:port/registrar/alex\n\n\n\n\nVerify Enrollment Response:\n\n\n{\n    \nError\n: \nUser alex must log in.\n\n}\n\n\n\n\nThe \nDELETE /registrar/{enrollmentID}\n endpoint is used to delete login tokens for a target user. If the login tokens are deleted successfully, a confirmation will be returned. Otherwise, an authorization error will result. No payload is required for this endpoint.\n\n\nRemove Enrollment Request:\n\n\nDELETE host:port/registrar/lukas\n\n\n\n\nRemove Enrollment Response:\n\n\n{\n    \nOK\n: \nDeleted login token and directory for user lukas.\n\n}\n\n\n\n\nThe \nGET /registrar/{enrollmentID}/ecert\n endpoint is used to retrieve the enrollment certificate of a given user from local storage. If the target user has already registered with the CA, the response will include a URL-encoded version of the enrollment certificate. If the target user has not yet registered, an error will be returned. If the client wishes to use the returned enrollment certificate after retrieval, keep in mind that it must be URL-decoded.\n\n\nEnrollment Certificate Retrieval Request:\n\n\nGET host:port/registrar/jim/ecert\n\n\n\n\nEnrollment Certificate Retrieval Response:\n\n\n{\n    \nOK\n: \n-----BEGIN+CERTIFICATE-----%0AMIIBzTCCAVSgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwNPQkMwHhcNMTYwMTIxMDYzNjEwWhcNMTYwNDIw%0AMDYzNjEwWjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNP%0AQkMwdjAQBgcqhkjOPQIBBgUrgQQAIgNiAARSLgjGD0omuJKYrJF5ClyYb3sGEGTU%0AH1mombSAOJ6GAOKEULt4L919sbSSChs0AEvTX7UDf4KNaKTrKrqo4khCoboMg1VS%0AXVTTPrJ%2BOxSJTXFZCohVgbhWh6ZZX2tfb7%2BjUDBOMA4GA1UdDwEB%2FwQEAwIHgDAM%0ABgNVHRMBAf8EAjAAMA0GA1UdDgQGBAQBAgMEMA8GA1UdIwQIMAaABAECAwQwDgYG%0AUQMEBQYHAQH%2FBAE0MAoGCCqGSM49BAMDA2cAMGQCMGz2RR0NsJOhxbo0CeVts2C5%0A%2BsAkKQ7v1Llbg78A1pyC5uBmoBvSnv5Dd0w2yOmj7QIwY%2Bn5pkLiwisxWurkHfiD%0AxizmN6vWQ8uhTd3PTdJiEEckjHKiq9pwD%2FGMt%2BWjP7zF%0A-----END+CERTIFICATE-----%0A\n\n}\n\n\n\n\nThe \n/registrar/{enrollmentID}/tcert\n endpoint retrieves the transaction certificates for a given user that has registered with the certificate authority. If the user has registered, a confirmation message will be returned containing an array of URL-encoded transaction certificates. Otherwise, an error will result. The desired number of transaction certificates is specified with the optional \ncount\n query parameter. The default number of returned transaction certificates is 1; and 500 is the maximum number of certificates that can be retrieved with a single request. If the client wishes to use the returned transaction certificates after retrieval, keep in mind that they must be URL-decoded.\n\n\nTransaction Certificate Retrieval Request:\n\n\nGET host:port/registrar/jim/tcert\n\n\n\n\nTransaction Certificate Retrieval Response:\n\n\n{\n    \nOK\n: [\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAQfwJORRED9RAsmSl%2FEowq1STBb%0A%2FoFteymZ96RUr%2BsKmF9PNrrUNvFZFhvukxZZjqhEcGiQqFyRf%2FBnVN%2BbtRzMo38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwSRWQFmErr0SmQO9AFP4GJYzQ%0APQMmcsCjKiJf%2Bw1df%2FLnXunCsCUlf%2FalIUaeSrT7MAoGCCqGSM49BAMDA0gAMEUC%0AIQC%2FnE71FBJd0hwNTLXWmlCJff4Yi0J%2BnDi%2BYnujp%2Fn9nQIgYWg0m0QFzddyJ0%2FF%0AKzIZEJlKgZTt8ZTlGg3BBrgl7qY%3D%0A-----END+CERTIFICATE-----%0A\n\n    ]\n}\n\n\n\n\nTransaction Certificate Retrieval Request:\n\n\nGET host:port/registrar/jim/tcert?count=5\n\n\n\n\nTransaction Certificate Retrieval Response:\n\n\n{\n    \nOK\n: [\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A\n,\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A\n,\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A\n,\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A\n,\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A\n\n    ]\n}\n\n\n\n\n6.2.1.6 Transactions API\n\n\n\n\nGET /transactions/{UUID}\n\n\n\n\nUse the Transaction API to retrieve an individual transaction matching the UUID from the blockchain. The returned transaction message is defined in section \n3.1.2.1\n.\n\n\nTransaction Retrieval Request:\n\n\nGET host:port/transactions/f5978e82-6d8c-47d1-adec-f18b794f570e\n\n\n\n\nTransaction Retrieval Response:\n\n\n{\n    \ntype\n: 3,\n    \nchaincodeID\n: \nEgRteWNj\n,\n    \npayload\n: \nCh4IARIGEgRteWNjGhIKBmludm9rZRIBYRIBYhICMTA=\n,\n    \nuuid\n: \nf5978e82-6d8c-47d1-adec-f18b794f570e\n,\n    \ntimestamp\n: {\n        \nseconds\n: 1453758316,\n        \nnanos\n: 206716775\n    },\n    \ncert\n: \nMIIB/zCCAYWgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMTI1MjE0MTE3WhcNMTYwNDI0MjE0MTE3WjArMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQ4wDAYDVQQDEwVsdWthczB2MBAGByqGSM49AgEGBSuBBAAiA2IABC/BBkt8izf6Ew8UDd62EdWFikJhyCPY5VO9Wxq9JVzt3D6nubx2jO5JdfWt49q8V1Aythia50MZEDpmKhtM6z7LHOU1RxuxdjcYDOvkNJo6pX144U4N1J8/D3A+97qZpKN/MH0wDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwDQYDVR0OBAYEBAECAwQwDwYDVR0jBAgwBoAEAQIDBDA9BgYqAwQFBgcBAf8EMABNbPHZ0e/2EToi0H8mkouuUDwurgBYuUB+vZfeMewBre3wXG0irzMtfwHlfECRDDAKBggqhkjOPQQDAwNoADBlAjAoote5zYFv91lHzpbEwTfJL/+r+CG7oMVFUFuoSlvBSCObK2bDIbNkW4VQ+ZC9GTsCMQC5GCgy2oZdHw/x7XYzG2BiqmRkLRTiCS7vYCVJXLivU65P984HopxW0cEqeFM9co0=\n,\n    \nsignature\n: \nMGUCMCIJaCT3YRsjXt4TzwfmD9hg9pxYnV13kWgf7e1hAW5Nar//05kFtpVlq83X+YtcmAIxAK0IQlCgS6nqQzZEGCLd9r7cg1AkQOT/RgoWB8zcaVjh3bCmgYHsoPAPgMsi3TJktg==\n\n}\n\n\n\n\n6.3 CLI\n\n\nThe CLI includes a subset of the available APIs to enable developers to quickly test and debug chaincodes or query for status of transactions. CLI is implemented in Golang and operable on multiple OS platforms. The currently available CLI commands are summarized in the following section.\n\n\n6.3.1 CLI Commands\n\n\nTo see what CLI commands are currently available in the implementation, execute the following:\n\n\n$ peer\n\n\n\nYou will receive a response similar to below:\n\n\n    Usage:\n      peer [command]\n\n    Available Commands:\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level=\n: Default logging level and overrides, see core.yaml for full syntax\n\n    Use \npeer [command] --help\n for more information about a command.\n\n\n\n\nSome of the available command line arguments for the \npeer\n command are listed below:\n\n\n\n\n\n\n-c\n - constructor: function to trigger in order to initialize the chaincode state upon deployment.\n\n\n\n\n\n\n-l\n - language: specifies the implementation language of the chaincode. Currently, only Golang is supported.\n\n\n\n\n\n\n-n\n - name: chaincode identifier returned from the deployment transaction. Must be used in subsequent invoke and query transactions.\n\n\n\n\n\n\n-p\n - path: identifies chaincode location in the local file system. Must be used as a parameter in the deployment transaction.\n\n\n\n\n\n\n-u\n - username: enrollment ID of a logged in user invoking the transaction.\n\n\n\n\n\n\nNot all of the above commands are fully implemented in the current release. The fully supported commands that are helpful for chaincode development and debugging are described below.\n\n\nNote, that any configuration settings for the peer node listed in the \ncore.yaml\n configuration file, which is the  configuration file for the \npeer\n process, may be modified on the command line with an environment variable. For example, to set the \npeer.id\n or the \npeer.addressAutoDetect\n settings, one may pass the \nCORE_PEER_ID=vp1\n and \nCORE_PEER_ADDRESSAUTODETECT=true\n on the command line.\n\n\n6.3.1.1 node start\n\n\nThe CLI \nnode start\n command will execute the peer process in either the development or production mode. The development mode is meant for running a single peer node locally, together with a local chaincode deployment. This allows a chaincode developer to modify and debug their code without standing up a complete network. An example for starting the peer in development mode follows:\n\n\npeer node start --peer-chaincodedev\n\n\n\n\nTo start the peer process in production mode, modify the above command as follows:\n\n\npeer node start\n\n\n\n\n6.3.1.2 network login\n\n\nThe CLI \nnetwork login\n command will login a user, that is already registered with the CA, through the CLI. To login through the CLI, issue the following command, where \nusername\n is the enrollment ID of a registered user.\n\n\npeer network login \nusername\n\n\n\n\n\nThe example below demonstrates the login process for user \njim\n.\n\n\npeer network login jim\n\n\n\n\nThe command will prompt for a password, which must match the enrollment password for this user registered with the certificate authority. If the password entered does not match the registered password, an error will result.\n\n\n22:21:31.246 [main] login -\n INFO 001 CLI client login...\n22:21:31.247 [main] login -\n INFO 002 Local data store for client loginToken: /var/hyperledger/production/client/\nEnter password for user 'jim': ************\n22:21:40.183 [main] login -\n INFO 003 Logging in user 'jim' on CLI interface...\n22:21:40.623 [main] login -\n INFO 004 Storing login token for user 'jim'.\n22:21:40.624 [main] login -\n INFO 005 Login successful for user 'jim'.\n\n\n\n\nYou can also pass a password for the user with \n-p\n parameter. An example is below.\n\n\npeer network login jim -p 123456\n\n\n\n\n6.3.1.3 chaincode deploy\n\n\nThe CLI \ndeploy\n command creates the docker image for the chaincode and subsequently deploys the package to the validating peer. An example is below.\n\n\npeer chaincode deploy -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\nFunction\n:\ninit\n, \nArgs\n: [\na\n,\n100\n, \nb\n, \n200\n]}'\n\n\n\n\nWith security enabled, the command must be modified to pass an enrollment id of a logged in user with the \n-u\n parameter. An example is below.\n\n\npeer chaincode deploy -u jim -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\nFunction\n:\ninit\n, \nArgs\n: [\na\n,\n100\n, \nb\n, \n200\n]}'\n\n\n\n\nNote:\n If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.\n\n\n6.3.1.4 chaincode invoke\n\n\nThe CLI \ninvoke\n command executes a specified function within the target chaincode. An example is below.\n\n\npeer chaincode invoke -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \ninvoke\n, \nArgs\n: [\na\n, \nb\n, \n10\n]}'\n\n\n\n\nWith security enabled, the command must be modified to pass an enrollment id of a logged in user with the \n-u\n parameter. An example is below.\n\n\npeer chaincode invoke -u jim -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \ninvoke\n, \nArgs\n: [\na\n, \nb\n, \n10\n]}'\n\n\n\n\n6.3.1.5 chaincode query\n\n\nThe CLI \nquery\n command triggers a specified query method within the target chaincode. The response that is returned depends on the chaincode implementation. An example is below.\n\n\npeer chaincode query -l golang -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \nquery\n, \nArgs\n: [\na\n]}'\n\n\n\n\nWith security enabled, the command must be modified to pass an enrollment id of a logged in user with the \n-u\n parameter. An example is below.\n\n\npeer chaincode query -u jim -l golang -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \nquery\n, \nArgs\n: [\na\n]}'\n\n\n\n\n7. Application Model\n\n\n7.1 Composition of an Application\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn application follows a MVC-B architecture \u2013 Model, View, Control, BlockChain.\n\n\n\n\n\n  \nVIEW LOGIC \u2013 Mobile or Web UI interacting with control logic.\n\n  \nCONTROL LOGIC \u2013 Coordinates between UI, Data Model and APIs to drive transitions and chain-code.\n\n  \nDATA MODEL \u2013 Application Data Model \u2013 manages off-chain data, including Documents and large files.\n\n  \nBLOCKCHAIN  LOGIC \u2013 Blockchain logic are extensions of the Controller Logic and Data Model, into the Blockchain realm. Controller logic is enhanced by chaincode, and the data model is enhanced with transactions on the blockchain.\n\n\n\n\n\nFor example, a Bluemix PaaS application using Node.js might have a Web front-end user interface or a native mobile app with backend model on Cloudant data service. The control logic may interact with 1 or more chaincodes to process transactions on the blockchain.\n\n\n\n\n\n\n\n\n\n7.2 Sample Application\n\n\n8. Future Directions\n\n\n8.1 Enterprise Integration\n\n\n8.2 Performance and Scalability\n\n\n8.3 Additional Consensus Plugins\n\n\n8.4 Additional Languages\n\n\n9.1 Authors\n\n\nThe following authors have written sections of this document:  Binh Q Nguyen, Elli Androulaki, Angelo De Caro, Sheehan Anderson, Manish Sethi, Thorsten Kramp, Alessandro Sorniotti, Marko Vukolic, Florian Simon Schubert, Jason K Yellick, Konstantinos Christidis, Srinivasan Muralidharan, Anna D Derbakova, Dulce Ponceleon, David Kravitz, Diego Masini.\n\n\n9.2 Reviewers\n\n\nThe following reviewers have contributed to this document:  Frank Lu, John Wolpert, Bishop Brock, Nitin Gaur, Sharon Weed, Konrad Pabjan.\n\n\n9.3 Acknowledgements\n\n\nThe following contributors have provided invaluable technical input to this specification:\nGennaro Cuomo, Joseph A Latone, Christian Cachin\n\n\n10. References\n\n\n\n\n\n\n[1] Miguel Castro, Barbara Liskov: Practical Byzantine fault tolerance and proactive recovery. ACM Trans. Comput. Syst. 20(4): 398-461 (2002)\n\n\n\n\n\n\n[2] Christian Cachin, Rachid Guerraoui, Lu\u00eds E. T. Rodrigues: Introduction to Reliable and Secure Distributed Programming (2. ed.). Springer 2011, ISBN 978-3-642-15259-7, pp. I-XIX, 1-367\n\n\n\n\n\n\n[3] Tushar Deepak Chandra, Vassos Hadzilacos, Sam Toueg: The Weakest Failure Detector for Solving Consensus. J. ACM 43(4): 685-722 (1996)\n\n\n\n\n\n\n[4] Cynthia Dwork, Nancy A. Lynch, Larry J. Stockmeyer: Consensus in the presence of partial synchrony. J. ACM 35(2): 288-323 (1988)\n\n\n\n\n\n\n[5] Manos Kapritsos, Yang Wang, Vivien Qu\u00e9ma, Allen Clement, Lorenzo Alvisi, Mike Dahlin: All about Eve: Execute-Verify Replication for Multi-Core Servers. OSDI 2012: 237-250\n\n\n\n\n\n\n[6] Pierre-Louis Aublin, Rachid Guerraoui, Nikola Knezevic, Vivien Qu\u00e9ma, Marko Vukolic: The Next 700 BFT Protocols. ACM Trans. Comput. Syst. 32(4): 12:1-12:45 (2015)\n\n\n\n\n\n\n[7] Christian Cachin, Simon Schubert, Marko Vukoli\u0107: \nNon-determinism in Byzantine Fault-Tolerant Replication",
            "title": "Protocol Spec"
        },
        {
            "location": "/protocol-spec/#protocol-specification",
            "text": "",
            "title": "Protocol Specification"
        },
        {
            "location": "/protocol-spec/#preface",
            "text": "This document is the protocol specification for a permissioned blockchain implementation for industry use-cases. It is not intended to be a complete explanation of the implementation, but rather a description of the interfaces and relationships between components in the system and the application.",
            "title": "Preface"
        },
        {
            "location": "/protocol-spec/#intended-audience",
            "text": "The intended audience for this specification includes the following groups:   Blockchain vendors who want to implement blockchain systems that conform to this specification  Tool developers who want to extend the capabilities of the fabric  Application developers who want to leverage blockchain technologies to enrich their applications",
            "title": "Intended Audience"
        },
        {
            "location": "/protocol-spec/#table-of-contents",
            "text": "",
            "title": "Table of Contents"
        },
        {
            "location": "/protocol-spec/#1-introduction",
            "text": "1.1 What is the fabric?  1.2 Why the fabric?  1.3 Terminology",
            "title": "1. Introduction"
        },
        {
            "location": "/protocol-spec/#2-fabric",
            "text": "2.1 Architecture  2.1.1 Membership Services  2.1.2 Blockchain Services  2.1.3 Chaincode Services  2.1.4 Events  2.1.5 Application Programming Interface (API)  2.1.6 Command Line Interface (CLI)  2.2 Topology  2.2.1 Single Validating Peer  2.2.2 Multiple Validating Peers  2.2.3 Multichain",
            "title": "2. Fabric"
        },
        {
            "location": "/protocol-spec/#3-protocol",
            "text": "3.1 Message  3.1.1 Discovery Messages  3.1.2 Transaction Messages  3.1.2.1 Transaction Data Structure  3.1.2.2 Transaction Specification  3.1.2.3 Deploy Transaction  3.1.2.4 Invoke Transaction  3.1.2.5 Query Transaction  3.1.3 Synchronization Messages  3.1.4 Consensus Messages  3.2 Ledger  3.2.1 Blockchain  3.2.1.1 Block  3.2.1.2 Block Hashing  3.2.1.3 NonHashData  3.2.1.4 Transaction Execution  3.2.2 World State  3.2.2.1 Hashing the world state  3.2.2.1.1 Bucket-tree  3.3 Chaincode  3.3.1 Virtual Machine Instantiation  3.3.2 Chaincode Protocol  3.3.2.1 Chaincode Deploy  3.3.2.2 Chaincode Invoke  3.3.2.3 Chaincode Query  3.3.2.4 Chaincode State  3.4 Pluggable Consensus Framework  3.4.1 Consenter interface  3.4.2 CPI interface  3.4.3 Inquirer interface  3.4.4 Communicator interface  3.4.5 SecurityUtils interface  3.4.6 LedgerStack interface  3.4.7 Executor interface  3.4.7.1 Beginning a transaction batch  3.4.7.2 Executing transactions  3.4.7.3 Committing and rolling-back transactions  3.4.8 Ledger interface  3.4.8.1 ReadOnlyLedger interface  3.4.8.2 UtilLedger interface  3.4.8.3 WritableLedger interface  3.4.9 RemoteLedgers interface  3.4.10 controller package  3.4.10.1 controller.NewConsenter  3.4.11 helper package  3.4.11.1 High-level overview  3.4.11.2 helper.ConsensusHandler  3.4.11.3 helper.NewConsensusHandler  3.4.11.4 helper.Helper  3.4.11.5 helper.NewHelper  3.4.11.6 helper.HandleMessage  3.5 Events  3.5.1 Event Stream  3.5.1.1 Event Producer  3.5.1.2 Event Consumer  3.5.2 Event Adapters  3.5.3 Event Structure",
            "title": "3. Protocol"
        },
        {
            "location": "/protocol-spec/#4-security",
            "text": "4.1 Business security requirements  4.2 User Privacy through Membership Services  4.2.1 User/Client Enrollment Process  4.2.2 Expiration and revocation of certificates  4.3 Transaction security offerings at the infrastructure level  4.3.1 Security Lifecycle of Transactions  4.3.2 Transaction confidentiality  4.3.2.1 Confidentiality against users  4.3.2.2 Confidentiality against validators  4.3.3 Replay attack resistance  4.4 Access control features on the application  4.4.1 Invocation access control  4.4.2 Read access control  4.5 Online wallet service  4.6 Network security (TLS)  4.7 Restrictions in the current release  4.7.1 Simplified client  4.7.2 Simplified transaction confidentiality",
            "title": "4. Security"
        },
        {
            "location": "/protocol-spec/#5-byzantine-consensus",
            "text": "5.1 Overview  5.2 Core PBFT Functions  5.2.1 newPbftCore",
            "title": "5. Byzantine Consensus"
        },
        {
            "location": "/protocol-spec/#6-application-programming-interface",
            "text": "6.1 REST Service  6.2 REST API  6.2.1 REST Endpoints  6.2.1.1 Block API  6.2.1.2 Blockchain API  6.2.1.3 Chaincode API  6.2.1.4 Network API  6.2.1.5 Registrar API (member services)  6.2.1.6 Transactions API  6.3 CLI  6.3.1 CLI Commands  6.3.1.1 node start  6.3.1.2 network login  6.3.1.3 chaincode deploy  6.3.1.4 chaincode invoke  6.3.1.5 chaincode query",
            "title": "6. Application Programming Interface"
        },
        {
            "location": "/protocol-spec/#7-application-model",
            "text": "7.1 Composition of an Application  7.2 Sample Application",
            "title": "7. Application Model"
        },
        {
            "location": "/protocol-spec/#8-future-directions",
            "text": "8.1 Enterprise Integration  8.2 Performance and Scalability  8.3 Additional Consensus Plugins  8.4 Additional Languages",
            "title": "8. Future Directions"
        },
        {
            "location": "/protocol-spec/#91-authors",
            "text": "",
            "title": "9.1 Authors"
        },
        {
            "location": "/protocol-spec/#92-reviewers",
            "text": "",
            "title": "9.2 Reviewers"
        },
        {
            "location": "/protocol-spec/#93-acknowledgements",
            "text": "",
            "title": "9.3 Acknowledgements"
        },
        {
            "location": "/protocol-spec/#10-references",
            "text": "",
            "title": "10. References"
        },
        {
            "location": "/protocol-spec/#1-introduction_1",
            "text": "This document specifies the principles, architecture, and protocol of a blockchain implementation suitable for industrial use-cases.",
            "title": "1. Introduction"
        },
        {
            "location": "/protocol-spec/#11-what-is-the-fabric",
            "text": "The fabric is a ledger of digital events, called transactions, shared among  different participants, each having a stake in the system. The ledger can only be updated by consensus of the participants, and, once recorded, information can never be altered. Each recorded event is cryptographically verifiable with proof of agreement from the participants.  Transactions are secured, private, and confidential. Each participant registers with proof of identity to the network membership services to gain access to the system. Transactions are issued with derived certificates unlinkable to the individual participant, offering a complete anonymity on the network. Transaction content is encrypted with sophisticated key derivation functions to ensure only intended participants may see the content, protecting the confidentiality of the business transactions.  The ledger allows compliance with regulations as ledger entries are auditable in whole or in part. In collaboration with participants, auditors may obtain time-based certificates to allow viewing the ledger and linking transactions to provide an accurate assessment of the operations.  The fabric is an implementation of blockchain technology, where Bitcoin could be a simple application built on the fabric. It is a modular architecture allowing components to be plug-and-play by implementing this protocol specification. It features powerful container technology to host any main stream language for smart contracts development. Leveraging familiar and proven technologies is the motto of the fabric architecture.",
            "title": "1.1 What is the fabric?"
        },
        {
            "location": "/protocol-spec/#12-why-the-fabric",
            "text": "Early blockchain technology serves a set of purposes but is often not well-suited for the needs of specific industries. To meet the demands of modern markets, the fabric is based on an industry-focused design that addresses the multiple and varied requirements of specific industry use cases, extending the learning of the pioneers in this field while also addressing issues such as scalability. The fabric provides a new approach to enable permissioned networks, privacy, and confidentially on multiple blockchain networks.",
            "title": "1.2 Why the fabric?"
        },
        {
            "location": "/protocol-spec/#13-terminology",
            "text": "The following terminology is defined within the limited scope of this specification to help readers understand clearly and precisely the concepts described here.  Transaction  is a request to the blockchain to execute a function on the ledger. The function is implemented by a  chaincode .  Transactor  is an entity that issues transactions such as a client application.  Ledger  is a sequence of cryptographically linked blocks, containing transactions and current  world state .  World State  is the collection of variables containing the results of executed transactions.  Chaincode  is an application-level code (a.k.a.  smart contract ) stored on the ledger as a part of a transaction. Chaincode runs transactions that may modify the world state.  Validating Peer  is a computer node on the network responsible for running consensus, validating transactions, and maintaining the ledger.  Non-validating Peer  is a computer node on the network which functions as a proxy connecting transactors to the neighboring validating peers. A non-validating peer doesn t execute transactions but does verify them. It also hosts the event stream server and the REST service.  Permissioned Ledger  is a blockchain network where each entity or node is required to be a member of the network. Anonymous nodes are not allowed to connect.  Privacy  is required by the chain transactors to conceal their identities on the network. While members of the network may examine the transactions, the transactions can t be linked to the transactor without special privilege.  Confidentiality  is the ability to render the transaction content inaccessible to anyone other than the stakeholders of the transaction.  Auditability  of the blockchain is required, as business usage of blockchain needs to comply with regulations to make it easy for regulators to investigate transaction records.",
            "title": "1.3 Terminology"
        },
        {
            "location": "/protocol-spec/#2-fabric_1",
            "text": "The fabric is made up of the core components described in the subsections below.",
            "title": "2. Fabric"
        },
        {
            "location": "/protocol-spec/#21-architecture",
            "text": "The reference architecture is aligned in 3 categories: Membership, Blockchain, and Chaincode services. These categories are logical structures, not a physical depiction of partitioning of components into separate processes, address spaces or (virtual) machines.",
            "title": "2.1 Architecture"
        },
        {
            "location": "/protocol-spec/#211-membership-services",
            "text": "Membership provides services for managing identity, privacy, confidentiality and auditability on the network. In a non-permissioned blockchain, participation does not require authorization and all nodes can equally submit transactions and/or attempt to accumulate them into acceptable blocks, i.e. there are no distinctions of roles. Membership services combine elements of Public Key Infrastructure (PKI) and decentralization/consensus to transform a non-permissioned blockchain into a permissioned blockchain. In the latter, entities register in order to acquire long-term identity credentials (enrollment certificates), and may be distinguished according to entity type. In the case of users, such credentials enable the Transaction Certificate Authority (TCA) to issue pseudonymous credentials. Such credentials, i.e., transaction certificates, are used to authorize submitted transactions. Transaction certificates persist on the blockchain, and enable authorized auditors to cluster otherwise unlinkable transactions.",
            "title": "2.1.1 Membership Services"
        },
        {
            "location": "/protocol-spec/#212-blockchain-services",
            "text": "Blockchain services manage the distributed ledger through a peer-to-peer protocol, built on HTTP/2. The data structures are highly optimized to provide the most efficient hash algorithm for maintaining the world state replication. Different consensus (PBFT, Raft, PoW, PoS) may be plugged in and configured per deployment.",
            "title": "2.1.2 Blockchain Services"
        },
        {
            "location": "/protocol-spec/#213-chaincode-services",
            "text": "Chaincode services provides a secured and lightweight way to sandbox the chaincode execution on the validating nodes. The environment is a \u201clocked down\u201d and secured container along with a set of signed base images containing secure OS and chaincode language, runtime and SDK layers for Go, Java, and Node.js. Other languages can be enabled if required.",
            "title": "2.1.3 Chaincode Services"
        },
        {
            "location": "/protocol-spec/#214-events",
            "text": "Validating peers and chaincodes can emit events on the network that applications may listen for and take actions on. There is a set of pre-defined events, and chaincodes can generate custom events. Events are consumed by 1 or more event adapters. Adapters may further deliver events using other vehicles such as Web hooks or Kafka.",
            "title": "2.1.4 Events"
        },
        {
            "location": "/protocol-spec/#215-application-programming-interface-api",
            "text": "The primary interface to the fabric is a REST API and its variations over Swagger 2.0. The API allows applications to register users, query the blockchain, and to issue transactions. There is a set of APIs specifically for chaincode to interact with the stack to execute transactions and query transaction results.",
            "title": "2.1.5 Application Programming Interface (API)"
        },
        {
            "location": "/protocol-spec/#216-command-line-interface-cli",
            "text": "CLI includes a subset of the REST API to enable developers to quickly test chaincodes or query for status of transactions. CLI is implemented in Golang and operable on multiple OS platforms.",
            "title": "2.1.6 Command Line Interface (CLI)"
        },
        {
            "location": "/protocol-spec/#22-topology",
            "text": "A deployment of the fabric can consist of a membership service, many validating peers, non-validating peers, and 1 or more applications. All of these components make up a chain. There can be multiple chains; each one having its own operating parameters and security requirements.",
            "title": "2.2 Topology"
        },
        {
            "location": "/protocol-spec/#221-single-validating-peer",
            "text": "Functionally, a non-validating peer is a subset of a validating peer; that is, every capability on a non-validating peer may be enabled on a validating peer, so the simplest network may consist of a single validating peer node. This configuration is most appropriate for a development environment, where a single validating peer may be started up during the edit-compile-debug cycle.   A single validating peer doesn t require consensus, and by default uses the  noops  plugin, which executes transactions as they arrive. This gives the developer an immediate feedback during development.",
            "title": "2.2.1 Single Validating Peer"
        },
        {
            "location": "/protocol-spec/#222-multiple-validating-peers",
            "text": "Production or test networks should be made up of multiple validating and non-validating peers as necessary. Non-validating peers can take workload off the validating peers, such as handling API requests and processing events.   The validating peers form a mesh-network (every validating peer connects to every other validating peer) to disseminate information. A non-validating peer connects to a neighboring validating peer that it is allowed to connect to. Non-validating peers are optional since applications may communicate directly with validating peers.",
            "title": "2.2.2 Multiple Validating Peers"
        },
        {
            "location": "/protocol-spec/#223-multichain",
            "text": "Each network of validating and non-validating peers makes up a chain. Many chains may be created to address different needs, similar to having multiple Web sites, each serving a different purpose.",
            "title": "2.2.3 Multichain"
        },
        {
            "location": "/protocol-spec/#3-protocol_1",
            "text": "The fabric s peer-to-peer communication is built on  gRPC , which allows bi-directional stream-based messaging. It uses  Protocol Buffers  to serialize data structures for data transfer between peers. Protocol buffers are a language-neutral, platform-neutral and extensible mechanism for serializing structured data. Data structures, messages, and services are described using  proto3 language  notation.",
            "title": "3. Protocol"
        },
        {
            "location": "/protocol-spec/#31-message",
            "text": "Messages passed between nodes are encapsulated by  Message  proto structure, which consists of 4 types: Discovery, Transaction, Synchronization, and Consensus. Each type may define more subtypes embedded in the  payload .  message Message {\n   enum Type {\n        UNDEFINED = 0;\n\n        DISC_HELLO = 1;\n        DISC_DISCONNECT = 2;\n        DISC_GET_PEERS = 3;\n        DISC_PEERS = 4;\n        DISC_NEWMSG = 5;\n\n        CHAIN_STATUS = 6;\n        CHAIN_TRANSACTION = 7;\n        CHAIN_GET_TRANSACTIONS = 8;\n        CHAIN_QUERY = 9;\n\n        SYNC_GET_BLOCKS = 11;\n        SYNC_BLOCKS = 12;\n        SYNC_BLOCK_ADDED = 13;\n\n        SYNC_STATE_GET_SNAPSHOT = 14;\n        SYNC_STATE_SNAPSHOT = 15;\n        SYNC_STATE_GET_DELTAS = 16;\n        SYNC_STATE_DELTAS = 17;\n\n        RESPONSE = 20;\n        CONSENSUS = 21;\n    }\n    Type type = 1;\n    bytes payload = 2;\n    google.protobuf.Timestamp timestamp = 3;\n}  The  payload  is an opaque byte array containing other objects such as  Transaction  or  Response  depending on the type of the message. For example, if the  type  is  CHAIN_TRANSACTION , the  payload  is a  Transaction  object.",
            "title": "3.1 Message"
        },
        {
            "location": "/protocol-spec/#311-discovery-messages",
            "text": "Upon start up, a peer runs discovery protocol if  CORE_PEER_DISCOVERY_ROOTNODE  is specified.  CORE_PEER_DISCOVERY_ROOTNODE  is the IP address of another peer on the network (any peer) that serves as the starting point for discovering all the peers on the network. The protocol sequence begins with  DISC_HELLO , whose  payload  is a  HelloMessage  object, containing its endpoint:  message HelloMessage {\n  PeerEndpoint peerEndpoint = 1;\n  uint64 blockNumber = 2;\n}\nmessage PeerEndpoint {\n    PeerID ID = 1;\n    string address = 2;\n    enum Type {\n      UNDEFINED = 0;\n      VALIDATOR = 1;\n      NON_VALIDATOR = 2;\n    }\n    Type type = 3;\n    bytes pkiID = 4;\n}\n\nmessage PeerID {\n    string name = 1;\n}  Definition of fields:   PeerID  is any name given to the peer at start up or defined in the config file  PeerEndpoint  describes the endpoint and whether it s a validating or a non-validating peer  pkiID  is the cryptographic ID of the peer  address  is host or IP address and port of the peer in the format  ip:port  blockNumber  is the height of the blockchain the peer currently has   If the block height received upon  DISC_HELLO  is higher than the current block height of the peer, it immediately initiates the synchronization protocol to catch up with the network.  After  DISC_HELLO , peer sends  DISC_GET_PEERS  periodically to discover any additional peers joining the network. In response to  DISC_GET_PEERS , a peer sends  DISC_PEERS  with  payload  containing an array of  PeerEndpoint . Other discovery message types are not used at this point.",
            "title": "3.1.1 Discovery Messages"
        },
        {
            "location": "/protocol-spec/#312-transaction-messages",
            "text": "There are 3 types of transactions: Deploy, Invoke and Query. A deploy transaction installs the specified chaincode on the chain, while invoke and query transactions call a function of a deployed chaincode. Another type in consideration is Create transaction, where a deployed chaincode may be instantiated on the chain and is addressable. This type has not been implemented as of this writing.",
            "title": "3.1.2 Transaction Messages"
        },
        {
            "location": "/protocol-spec/#3121-transaction-data-structure",
            "text": "Messages with type  CHAIN_TRANSACTION  or  CHAIN_QUERY  carry a  Transaction  object in the  payload :  message Transaction {\n    enum Type {\n        UNDEFINED = 0;\n        CHAINCODE_DEPLOY = 1;\n        CHAINCODE_INVOKE = 2;\n        CHAINCODE_QUERY = 3;\n        CHAINCODE_TERMINATE = 4;\n    }\n    Type type = 1;\n    string uuid = 5;\n    bytes chaincodeID = 2;\n    bytes payloadHash = 3;\n\n    ConfidentialityLevel confidentialityLevel = 7;\n    bytes nonce = 8;\n    bytes cert = 9;\n    bytes signature = 10;\n\n    bytes metadata = 4;\n    google.protobuf.Timestamp timestamp = 6;\n}\n\nmessage TransactionPayload {\n    bytes payload = 1;\n}\n\nenum ConfidentialityLevel {\n    PUBLIC = 0;\n    CONFIDENTIAL = 1;\n}  Definition of fields: \n-  type  - The type of the transaction, which is 1 of the following:\n    -  UNDEFINED  - Reserved for future use.\n  -  CHAINCODE_DEPLOY  - Represents the deployment of a new chaincode.\n    -  CHAINCODE_INVOKE  - Represents a chaincode function execution that may read and modify the world state.\n    -  CHAINCODE_QUERY  - Represents a chaincode function execution that may only read the world state.\n    -  CHAINCODE_TERMINATE  - Marks a chaincode as inactive so that future functions of the chaincode can no longer be invoked.\n-  chaincodeID  - The ID of a chaincode which is a hash of the chaincode source, path to the source code, constructor function, and parameters.\n-  payloadHash  - Bytes defining the hash of  TransactionPayload.payload .\n-  metadata  - Bytes defining any associated transaction metadata that the application may use.\n-  uuid  - A unique ID for the transaction.\n-  timestamp  - A timestamp of when the transaction request was received by the peer.\n-  confidentialityLevel  - Level of data confidentiality. There are currently 2 levels. Future releases may define more levels.\n-  nonce  - Used for security.\n-  cert  - Certificate of the transactor.\n-  signature  - Signature of the transactor.\n-  TransactionPayload.payload  - Bytes defining the payload of the transaction. As the payload can be large, only the payload hash is included directly in the transaction message.  More detail on transaction security can be found in section 4.",
            "title": "3.1.2.1 Transaction Data Structure"
        },
        {
            "location": "/protocol-spec/#3122-transaction-specification",
            "text": "A transaction is always associated with a chaincode specification which defines the chaincode and the execution environment such as language and security context. Currently there is an implementation that uses Golang for writing chaincode. Other languages may be added in the future.  message ChaincodeSpec {\n    enum Type {\n        UNDEFINED = 0;\n        GOLANG = 1;\n        NODE = 2;\n    }\n    Type type = 1;\n    ChaincodeID chaincodeID = 2;\n    ChaincodeInput ctorMsg = 3;\n    int32 timeout = 4;\n    string secureContext = 5;\n    ConfidentialityLevel confidentialityLevel = 6;\n    bytes metadata = 7;\n}\n\nmessage ChaincodeID {\n    string path = 1;\n    string name = 2;\n}\n\nmessage ChaincodeInput {\n    string function = 1;\n    repeated string args  = 2;\n}  Definition of fields: \n-  chaincodeID  - The chaincode source code path and name.\n-  ctorMsg  - Function name and argument parameters to call.\n-  timeout  - Time in milliseconds to execute the transaction.\n-  confidentialityLevel  - Confidentiality level of this transaction.\n-  secureContext  - Security context of the transactor.\n-  metadata  - Any data the application wants to pass along.  The peer, receiving the  chaincodeSpec , wraps it in an appropriate transaction message and broadcasts to the network.",
            "title": "3.1.2.2 Transaction Specification"
        },
        {
            "location": "/protocol-spec/#3123-deploy-transaction",
            "text": "Transaction  type  of a deploy transaction is  CHAINCODE_DEPLOY  and the payload contains an object of  ChaincodeDeploymentSpec .  message ChaincodeDeploymentSpec {\n    ChaincodeSpec chaincodeSpec = 1;\n    google.protobuf.Timestamp effectiveDate = 2;\n    bytes codePackage = 3;\n}  Definition of fields: \n-  chaincodeSpec  - See section 3.1.2.2, above.\n-  effectiveDate  - Time when the chaincode is ready to accept invocations.\n-  codePackage  - gzip of the chaincode source.  The validating peers always verify the hash of the  codePackage  when they deploy the chaincode to make sure the package has not been tampered with since the deploy transaction entered the network.",
            "title": "3.1.2.3 Deploy Transaction"
        },
        {
            "location": "/protocol-spec/#3124-invoke-transaction",
            "text": "Transaction  type  of an invoke transaction is  CHAINCODE_INVOKE  and the  payload  contains an object of  ChaincodeInvocationSpec .  message ChaincodeInvocationSpec {\n    ChaincodeSpec chaincodeSpec = 1;\n}",
            "title": "3.1.2.4 Invoke Transaction"
        },
        {
            "location": "/protocol-spec/#3125-query-transaction",
            "text": "A query transaction is similar to an invoke transaction, but the message  type  is  CHAINCODE_QUERY .",
            "title": "3.1.2.5 Query Transaction"
        },
        {
            "location": "/protocol-spec/#313-synchronization-messages",
            "text": "Synchronization protocol starts with discovery, described above in section 3.1.1, when a peer realizes that it s behind or its current block is not the same with others. A peer broadcasts either  SYNC_GET_BLOCKS ,  SYNC_STATE_GET_SNAPSHOT , or  SYNC_STATE_GET_DELTAS  and receives  SYNC_BLOCKS ,  SYNC_STATE_SNAPSHOT , or  SYNC_STATE_DELTAS  respectively.  The installed consensus plugin (e.g. pbft) dictates how synchronization protocol is being applied. Each message is designed for a specific situation:  SYNC_GET_BLOCKS  requests for a range of contiguous blocks expressed in the message  payload , which is an object of  SyncBlockRange . The correlationId specified is included in the  SyncBlockRange  of any replies to this message.  message SyncBlockRange {\n    uint64 correlationId = 1;\n    uint64 start = 2;\n    uint64 end = 3;\n}  A receiving peer responds with a  SYNC_BLOCKS  message whose  payload  contains an object of  SyncBlocks  message SyncBlocks {\n    SyncBlockRange range = 1;\n    repeated Block blocks = 2;\n}  The  start  and  end  indicate the starting and ending blocks inclusively. The order in which blocks are returned is defined by the  start  and  end  values. For example, if  start =3 and  end =5, the order of blocks will be 3, 4, 5. If  start =5 and  end =3, the order will be 5, 4, 3.  SYNC_STATE_GET_SNAPSHOT  requests for the snapshot of the current world state. The  payload  is an object of  SyncStateSnapshotRequest  message SyncStateSnapshotRequest {\n  uint64 correlationId = 1;\n}  The  correlationId  is used by the requesting peer to keep track of the response messages. A receiving peer replies with  SYNC_STATE_SNAPSHOT  message whose  payload  is an instance of  SyncStateSnapshot  message SyncStateSnapshot {\n    bytes delta = 1;\n    uint64 sequence = 2;\n    uint64 blockNumber = 3;\n    SyncStateSnapshotRequest request = 4;\n}  This message contains the snapshot or a chunk of the snapshot on the stream, and in which case, the sequence indicate the order starting at 0. The terminating message will have len(delta) == 0.  SYNC_STATE_GET_DELTAS  requests for the state deltas of a range of contiguous blocks. By default, the Ledger maintains 500 transition deltas. A delta(j) is a state transition between block(i) and block(j) where i = j-1. The message  payload  contains an instance of  SyncStateDeltasRequest  message SyncStateDeltasRequest {\n    SyncBlockRange range = 1;\n}  A receiving peer responds with  SYNC_STATE_DELTAS , whose  payload  is an instance of  SyncStateDeltas  message SyncStateDeltas {\n    SyncBlockRange range = 1;\n    repeated bytes deltas = 2;\n}  A delta may be applied forward (from i to j) or backward (from j to i) in the state transition.",
            "title": "3.1.3 Synchronization Messages"
        },
        {
            "location": "/protocol-spec/#314-consensus-messages",
            "text": "Consensus deals with transactions, so a  CONSENSUS  message is initiated internally by the consensus framework when it receives a  CHAIN_TRANSACTION  message. The framework converts  CHAIN_TRANSACTION  into  CONSENSUS  then broadcasts to the validating nodes with the same  payload . The consensus plugin receives this message and process according to its internal algorithm. The plugin may create custom subtypes to manage consensus finite state machine. See section 3.4 for more details.",
            "title": "3.1.4 Consensus Messages"
        },
        {
            "location": "/protocol-spec/#32-ledger",
            "text": "The ledger consists of two primary pieces, the blockchain and the world state. The blockchain is a series of linked blocks that is used to record transactions within the ledger. The world state is a key-value database that chaincodes may use to store state when executed by a transaction.",
            "title": "3.2 Ledger"
        },
        {
            "location": "/protocol-spec/#321-blockchain",
            "text": "",
            "title": "3.2.1 Blockchain"
        },
        {
            "location": "/protocol-spec/#3211-block",
            "text": "The blockchain is defined as a linked list of blocks as each block contains the hash of the previous block in the chain. The two other important pieces of information that a block contains are the list of transactions contained within the block and the hash of the world state after executing all transactions in the block.  message Block {\n  version = 1;\n  google.protobuf.Timestamp timestamp = 2;\n  bytes transactionsHash = 3;\n  bytes stateHash = 4;\n  bytes previousBlockHash = 5;\n  bytes consensusMetadata = 6;\n  NonHashData nonHashData = 7;\n}\n\nmessage BlockTransactions {\n  repeated Transaction transactions = 1;\n}   version  - Version used to track any protocol changes.  timestamp  - The timestamp to be filled in by the block proposer.  transactionsHash  - The merkle root hash of the block s transactions.  stateHash  - The merkle root hash of the world state.  previousBlockHash  - The hash of the previous block.  consensusMetadata  - Optional metadata that the consensus may include in a block.  nonHashData  - A  NonHashData  message that is set to nil before computing the hash of the block, but stored as part of the block in the database.  BlockTransactions.transactions  - An array of Transaction messages. Transactions are not included in the block directly due to their size.",
            "title": "3.2.1.1 Block"
        },
        {
            "location": "/protocol-spec/#3212-block-hashing",
            "text": "The  previousBlockHash  hash is calculated using the following algorithm.   Serialize the Block message to bytes using the protocol buffer library.    Hash the serialized block message to 512 bits of output using the SHA3 SHAKE256 algorithm as described in  FIPS 202 .    The  transactionHash  is the root of the transaction merkle tree. Defining the merkle tree implementation is a TODO.    The  stateHash  is defined in section 3.2.2.1.",
            "title": "3.2.1.2 Block Hashing"
        },
        {
            "location": "/protocol-spec/#3213-nonhashdata",
            "text": "The NonHashData message is used to store block metadata that is not required to be the same value on all peers. These are suggested values.  message NonHashData {\n  google.protobuf.Timestamp localLedgerCommitTimestamp = 1;\n  repeated TransactionResult transactionResults = 2;\n}\n\nmessage TransactionResult {\n  string uuid = 1;\n  bytes result = 2;\n  uint32 errorCode = 3;\n  string error = 4;\n}    localLedgerCommitTimestamp  - A timestamp indicating when the block was commited to the local ledger.    TransactionResult  - An array of transaction results.    TransactionResult.uuid  - The ID of the transaction.    TransactionResult.result  - The return value of the transaction.    TransactionResult.errorCode  - A code that can be used to log errors associated with the transaction.    TransactionResult.error  - A string that can be used to log errors associated with the transaction.",
            "title": "3.2.1.3 NonHashData"
        },
        {
            "location": "/protocol-spec/#3214-transaction-execution",
            "text": "A transaction defines either the deployment of a chaincode or the execution of a chaincode. All transactions within a block are run before recording a block in the ledger. When chaincodes execute, they may modify the world state. The hash of the world state is then recorded in the block.",
            "title": "3.2.1.4 Transaction Execution"
        },
        {
            "location": "/protocol-spec/#322-world-state",
            "text": "The  world state  of a peer refers to the collection of the  states  of all the deployed chaincodes. Further, the state of a chaincode is represented as a collection of key-value pairs. Thus, logically, the world state of a peer is also a collection of key-value pairs where key consists of a tuple  {chaincodeID, ckey} . Here, we use the term  key  to represent a key in the world state i.e., a tuple  {chaincodeID, ckey}  and we use the term  cKey  to represent a unique key within a chaincode.  For the purpose of the description below,  chaincodeID  is assumed to be a valid utf8 string and  ckey  and the  value  can be a sequence of one or more arbitrary bytes.",
            "title": "3.2.2 World State"
        },
        {
            "location": "/protocol-spec/#3221-hashing-the-world-state",
            "text": "During the functioning of a network, many occasions such as committing transactions and synchronizing peers may require computing a crypto-hash of the world state observed by a peer. For instance, the consensus protocol may require to ensure that a  minimum  number of peers in the network observe the same world state.  Since, computing the crypto-hash of the world state could be an expensive operation, this is highly desirable to organize the world state such that it enables an efficient crypto-hash computation of the world state when a change occurs in the world state. Further, different organization designs may be suitable under different workloads conditions.  Because the fabric is expected to function under a variety of scenarios leading to different workloads conditions, a pluggable mechanism is supported for organizing the world state.",
            "title": "3.2.2.1 Hashing the world state"
        },
        {
            "location": "/protocol-spec/#32211-bucket-tree",
            "text": "Bucket-tree  is one of the implementations for organizing the world state. For the purpose of the description below, a key in the world state is represented as a concatenation of the two components ( chaincodeID  and  ckey )  separated by a  nil  byte i.e.,  key  =  chaincodeID + nil + cKey .  This method models a  merkle-tree  on top of buckets of a  hash table  in order to compute the crypto-hash of the  world state .  At the core of this method, the  key-values  of the world state are assumed to be stored in a hash-table that consists of a pre-decided number of buckets ( numBuckets ). A hash function ( hashFunction ) is employed to determine the bucket number that should contain a given key. Please note that the  hashFunction  does not represent a crypto-hash method such as SHA3, rather this is a regular programming language hash function that decides the bucket number for a given key.  For modeling the merkle-tree, the ordered buckets act as leaf nodes of the tree - lowest numbered bucket being the left most leaf node in the tree. For constructing the second-last level of the tree, a pre-decided number of leaf nodes ( maxGroupingAtEachLevel ), starting from left, are grouped together and for each such group, a node is inserted at the second-last level that acts as a common parent for all the leaf nodes in the group. Note that the number of children for the last parent node may be less than  maxGroupingAtEachLevel . This grouping method of constructing the next higher level is repeated until the root node of the tree is constructed.  An example setup with configuration  {numBuckets=10009 and maxGroupingAtEachLevel=10}  will result in a tree with number of nodes at different level as depicted in the following table.     Level  Number of nodes      0  1    1  2    2  11    3  101    4  1001    5  10009     For computing the crypto-hash of the world state, the crypto-hash of each bucket is computed and is assumed to be the crypto-hash of leaf-nodes of the merkle-tree. In order to compute crypto-hash of a bucket, the key-values present in the bucket are first serialized and crypto-hash function is applied on the serialized bytes. For serializing the key-values of a bucket, all the key-values with a common chaincodeID prefix are serialized separately and then appending together, in the ascending order of chaincodeIDs. For serializing the key-values of a chaincodeID, the following information is concatenated:\n   1. Length of chaincodeID (number of bytes in the chaincodeID)\n   - The utf8 bytes of the chaincodeID\n   - Number of key-values for the chaincodeID\n   - For each key-value (in sorted order of the ckey)\n      - Length of the ckey\n      - ckey bytes\n      - Length of the value\n      - value bytes  For all the numeric types in the above list of items (e.g., Length of chaincodeID), protobuf s varint encoding is assumed to be used. The purpose of the above encoding is to achieve a byte representation of the key-values within a bucket that can not be arrived at by any other combination of key-values and also to reduce the overall size of the serialized bytes.  For example, consider a bucket that contains three key-values namely,  chaincodeID1_key1:value1, chaincodeID1_key2:value2, and chaincodeID2_key1:value1 . The serialized bytes for the bucket would logically look as -  12 + chaincodeID1 + 2 + 4 + key1 + 6 + value1 + 4 + key2 + 6 + value2 + 12 + chaincodeID2 + 1 + 4 + key1 + 6 + value1  If a bucket has no key-value present, the crypto-hash is considered as  nil .  The crypto-hash of an intermediate node and root node are computed just like in a standard merkle-tree i.e., applying a crypto-hash function on the bytes obtained by concatenating the crypto-hash of all the children nodes, from left to right. Further, if a child has a crypto-hash as  nil , the crypto-hash of the child is omitted when concatenating the children crypto-hashes. If the node has a single child, the crypto-hash of the child is assumed to be the crypto-hash of the node. Finally, the crypto-hash of the root node is considered as the crypto-hash of the world state.  The above method offers performance benefits for computing crypto-hash when a few key-values change in the state. The major benefits include\n  - Computation of crypto-hashes of the unchanged buckets can be skipped\n  - The depth and breadth of the merkle-tree can be controlled by configuring the parameters  numBuckets  and  maxGroupingAtEachLevel . Both depth and breadth of the tree has different implication on the performance cost incurred by and resource demand of different resources (namely - disk I/O, storage, and memory)  In a particular deployment, all the peer nodes are expected to use same values for the configurations  numBuckets, maxGroupingAtEachLevel, and hashFunction . Further, if any of these configurations are to be changed at a later stage, the configurations should be changed on all the peer nodes so that the comparison of crypto-hashes across peer nodes is meaningful. Also, this may require to migrate the existing data based on the implementation. For example, an implementation is expected to store the last computed crypto-hashes for all the nodes in the tree which would need to be recalculated.",
            "title": "3.2.2.1.1 Bucket-tree"
        },
        {
            "location": "/protocol-spec/#33-chaincode",
            "text": "Chaincode is an application-level code deployed as a transaction (see section 3.1.2) to be distributed to the network and managed by each validating peer as isolated sandbox. Though any virtualization technology can support the sandbox, currently Docker container is utilized to run the chaincode. The protocol described in this section enables different virtualization support implementation to plug and play.",
            "title": "3.3 Chaincode"
        },
        {
            "location": "/protocol-spec/#331-virtual-machine-instantiation",
            "text": "A virtual machine implements the VM interface:    type VM interface {\n    build(ctxt context.Context, id string, args []string, env []string, attachstdin bool, attachstdout bool, reader io.Reader) error\n    start(ctxt context.Context, id string, args []string, env []string, attachstdin bool, attachstdout bool) error\n    stop(ctxt context.Context, id string, timeout uint, dontkill bool, dontremove bool) error\n}  The fabric instantiates the VM when it processes a Deploy transaction or other transactions on the chaincode while the VM for that chaincode is not running (either crashed or previously brought down due to inactivity). Each chaincode image is built by the  build  function, started by  start  and stopped by  stop  function.  Once the chaincode container is up, it makes a gRPC connection back to the validating peer that started the chaincode, and that establishes the channel for Invoke and Query transactions on the chaincode.",
            "title": "3.3.1 Virtual Machine Instantiation"
        },
        {
            "location": "/protocol-spec/#332-chaincode-protocol",
            "text": "Communication between a validating peer and its chaincodes is based on a bidirectional gRPC stream. There is a shim layer on the chaincode container to handle the message protocol between the chaincode and the validating peer using protobuf message.  message ChaincodeMessage {\n\n    enum Type {\n        UNDEFINED = 0;\n        REGISTER = 1;\n        REGISTERED = 2;\n        INIT = 3;\n        READY = 4;\n        TRANSACTION = 5;\n        COMPLETED = 6;\n        ERROR = 7;\n        GET_STATE = 8;\n        PUT_STATE = 9;\n        DEL_STATE = 10;\n        INVOKE_CHAINCODE = 11;\n        INVOKE_QUERY = 12;\n        RESPONSE = 13;\n        QUERY = 14;\n        QUERY_COMPLETED = 15;\n        QUERY_ERROR = 16;\n        RANGE_QUERY_STATE = 17;\n    }\n\n    Type type = 1;\n    google.protobuf.Timestamp timestamp = 2;\n    bytes payload = 3;\n    string uuid = 4;\n}  Definition of fields: \n-  Type  is the type of the message.\n-  payload  is the payload of the message. Each payload depends on the  Type .\n-  uuid  is a unique identifier of the message.  The message types are described in the following sub-sections.  A chaincode implements the  Chaincode  interface, which is called by the validating peer when it processes Deploy, Invoke or Query transactions.  type Chaincode interface {\ni   Init(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n    Invoke(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n    Query(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n}  Init ,  Invoke  and  Query  functions take  function  and  args  as parameters to be used by those methods to support a variety of transactions.  Init  is a constructor function, which will only be invoked by the Deploy transaction. The  Query  function is not allowed to modify the state of the chaincode; it can only read and calculate the return value as a byte array.",
            "title": "3.3.2 Chaincode Protocol"
        },
        {
            "location": "/protocol-spec/#3321-chaincode-deploy",
            "text": "Upon deploy (chaincode container is started), the shim layer sends a one time  REGISTER  message to the validating peer with the  payload  containing the  ChaincodeID . The validating peer responds with  REGISTERED  or  ERROR  on success or failure respectively. The shim closes the connection and exits if it receives an  ERROR .  After registration, the validating peer sends  INIT  with the  payload  containing a  ChaincodeInput  object. The shim calls the  Init  function with the parameters from the  ChaincodeInput , enabling the chaincode to perform any initialization, such as setting up the persistent state.  The shim responds with  RESPONSE  or  ERROR  message depending on the returned value from the chaincode  Init  function. If there are no errors, the chaincode initialization is complete and is ready to receive Invoke and Query transactions.",
            "title": "3.3.2.1 Chaincode Deploy"
        },
        {
            "location": "/protocol-spec/#3322-chaincode-invoke",
            "text": "When processing an invoke transaction, the validating peer sends a  TRANSACTION  message to the chaincode container shim, which in turn calls the chaincode  Invoke  function, passing the parameters from the  ChaincodeInput  object. The shim responds to the validating peer with  RESPONSE  or  ERROR  message, indicating the completion of the function. If  ERROR  is received, the  payload  contains the error message generated by the chaincode.",
            "title": "3.3.2.2 Chaincode Invoke"
        },
        {
            "location": "/protocol-spec/#3323-chaincode-query",
            "text": "Similar to an invoke transaction, when processing a query, the validating peer sends a  QUERY  message to the chaincode container shim, which in turn calls the chaincode  Query  function, passing the parameters from the  ChaincodeInput  object. The  Query  function may return a state value or an error, which the shim forwards to the validating peer using  RESPONSE  or  ERROR  messages respectively.",
            "title": "3.3.2.3 Chaincode Query"
        },
        {
            "location": "/protocol-spec/#3324-chaincode-state",
            "text": "Each chaincode may define its own persistent state variables. For example, a chaincode may create assets such as TVs, cars, or stocks using state variables to hold the assets attributes. During  Invoke  function processing, the chaincode may update the state variables, for example, changing an asset owner. A chaincode manipulates the state variables by using the following message types:",
            "title": "3.3.2.4 Chaincode State"
        },
        {
            "location": "/protocol-spec/#put_state",
            "text": "Chaincode sends a  PUT_STATE  message to persist a key-value pair, with the  payload  containing  PutStateInfo  object.  message PutStateInfo {\n    string key = 1;\n    bytes value = 2;\n}",
            "title": "PUT_STATE"
        },
        {
            "location": "/protocol-spec/#get_state",
            "text": "Chaincode sends a  GET_STATE  message to retrieve the value whose key is specified in the  payload .",
            "title": "GET_STATE"
        },
        {
            "location": "/protocol-spec/#del_state",
            "text": "Chaincode sends a  DEL_STATE  message to delete the value whose key is specified in the  payload .",
            "title": "DEL_STATE"
        },
        {
            "location": "/protocol-spec/#range_query_state",
            "text": "Chaincode sends a  RANGE_QUERY_STATE  message to get a range of values. The message  payload  contains a  RangeQueryStateInfo  object.  message RangeQueryState {\n    string startKey = 1;\n    string endKey = 2;\n}  The  startKey  and  endKey  are inclusive and assumed to be in lexical order. The validating peer responds with  RESPONSE  message whose  payload  is a  RangeQueryStateResponse  object.  message RangeQueryStateResponse {\n    repeated RangeQueryStateKeyValue keysAndValues = 1;\n    bool hasMore = 2;\n    string ID = 3;\n}\nmessage RangeQueryStateKeyValue {\n    string key = 1;\n    bytes value = 2;\n}  If  hasMore=true  in the response, this indicates that additional keys are available in the requested range. The chaincode can request the next set of keys and values by sending a  RangeQueryStateNext  message with an ID that matches the ID returned in the response.  message RangeQueryStateNext {\n    string ID = 1;\n}  When the chaincode is finished reading from the range, it should send a  RangeQueryStateClose  message with the ID it wishes to close.  message RangeQueryStateClose {\n  string ID = 1;\n}",
            "title": "RANGE_QUERY_STATE"
        },
        {
            "location": "/protocol-spec/#invoke_chaincode",
            "text": "Chaincode may call another chaincode in the same transaction context by sending an  INVOKE_CHAINCODE  message to the validating peer with the  payload  containing a  ChaincodeSpec  object.",
            "title": "INVOKE_CHAINCODE"
        },
        {
            "location": "/protocol-spec/#query_chaincode",
            "text": "Chaincode may query another chaincode in the same transaction context by sending a  QUERY_CHAINCODE  message with the  payload  containing a  ChaincodeSpec  object.",
            "title": "QUERY_CHAINCODE"
        },
        {
            "location": "/protocol-spec/#34-pluggable-consensus-framework",
            "text": "The consensus framework defines the interfaces that every consensus  plugin  implements:   consensus.Consenter : interface that  allows consensus plugin to receive messages from the network.  consensus.CPI :   Consensus Programming Interface  ( CPI ) is used by consensus plugin to interact with rest of the stack. This interface is split in two parts:  consensus.Communicator : used to send (broadcast and unicast) messages to other validating peers.  consensus.LedgerStack : which is used as an interface to the execution framework as well as the ledger.     As described below in more details,  consensus.LedgerStack  encapsulates, among other interfaces, the  consensus.Executor  interface, which is the key part of the consensus framework. Namely,  consensus.Executor  interface allows for a (batch of) transaction to be started, executed, rolled back if necessary, previewed, and potentially committed. A particular property that every consensus plugin needs to satisfy is that batches (blocks)  of transactions are committed to the ledger (via  consensus.Executor.CommitTxBatch ) in total order across all validating peers (see  consensus.Executor  interface description below for more details).  Currently, consensus framework consists of 3 packages  consensus ,  controller , and  helper . The primary reason for  controller  and  helper  packages is to avoid  import cycle  in Go (golang) and minimize code changes for plugin to update.   controller  package specifies the consensus plugin used by a validating peer.  helper  package is a shim around a consensus plugin that helps it interact with the rest of the stack, such as maintaining message handlers to other peers.   There are 2 consensus plugins provided:  pbft  and  noops :   pbft  package contains consensus plugin that implements the  PBFT  [1] consensus protocol. See section 5 for more detail.  noops  is a  dummy  consensus plugin for development and test purposes. It doesn t perform consensus but processes all consensus messages. It also serves as a good simple sample to start learning how to code a consensus plugin.",
            "title": "3.4 Pluggable Consensus Framework"
        },
        {
            "location": "/protocol-spec/#341-consenter-interface",
            "text": "Definition:  type Consenter interface {\n    RecvMsg(msg *pb.Message) error\n}  The plugin s entry point for (external) client requests, and consensus messages generated internally (i.e. from the consensus module) during the consensus process. The  controller.NewConsenter  creates the plugin  Consenter .  RecvMsg  processes the incoming transactions in order to reach consensus.  See  helper.HandleMessage  below to understand how the peer interacts with this interface.",
            "title": "3.4.1 Consenter interface"
        },
        {
            "location": "/protocol-spec/#342-cpi-interface",
            "text": "Definition:  type CPI interface {\n    Inquirer\n    Communicator\n    SecurityUtils\n    LedgerStack\n}  CPI  allows the plugin to interact with the stack. It is implemented by the  helper.Helper  object. Recall that this object:   Is instantiated when the  helper.NewConsensusHandler  is called.  Is accessible to the plugin author when they construct their plugin s  consensus.Consenter  object.",
            "title": "3.4.2 CPI interface"
        },
        {
            "location": "/protocol-spec/#343-inquirer-interface",
            "text": "Definition:  type Inquirer interface {\n        GetNetworkInfo() (self *pb.PeerEndpoint, network []*pb.PeerEndpoint, err error)\n        GetNetworkHandles() (self *pb.PeerID, network []*pb.PeerID, err error)\n}  This interface is a part of the  consensus.CPI  interface. It is used to get the handles of the validating peers in the network ( GetNetworkHandles ) as well as details about the those validating peers ( GetNetworkInfo ):  Note that the peers are identified by a  pb.PeerID  object. This is a protobuf message (in the  protos  package), currently defined as (notice that this definition will likely be modified):  message PeerID {\n    string name = 1;\n}",
            "title": "3.4.3 Inquirer interface"
        },
        {
            "location": "/protocol-spec/#344-communicator-interface",
            "text": "Definition:  type Communicator interface {\n    Broadcast(msg *pb.Message) error\n    Unicast(msg *pb.Message, receiverHandle *pb.PeerID) error\n}  This interface is a part of the  consensus.CPI  interface. It is used to communicate with other peers on the network ( helper.Broadcast ,  helper.Unicast ):",
            "title": "3.4.4 Communicator interface"
        },
        {
            "location": "/protocol-spec/#345-securityutils-interface",
            "text": "Definition:  type SecurityUtils interface {\n        Sign(msg []byte) ([]byte, error)\n        Verify(peerID *pb.PeerID, signature []byte, message []byte) error\n}  This interface is a part of the  consensus.CPI  interface. It is used to handle the cryptographic operations of message signing ( Sign ) and verifying signatures ( Verify )",
            "title": "3.4.5 SecurityUtils interface"
        },
        {
            "location": "/protocol-spec/#346-ledgerstack-interface",
            "text": "Definition:  type LedgerStack interface {\n    Executor\n    Ledger\n    RemoteLedgers\n}  A key member of the  CPI  interface,  LedgerStack  groups interaction of consensus with the rest of the fabric, such as the execution of transactions, querying, and updating the ledger. This interface supports querying the local blockchain and state, updating the local blockchain and state, and querying the blockchain and state of other nodes in the consensus network. It consists of three parts:  Executor ,  Ledger  and  RemoteLedgers  interfaces. These are described in the following.",
            "title": "3.4.6 LedgerStack interface"
        },
        {
            "location": "/protocol-spec/#347-executor-interface",
            "text": "Definition:  type Executor interface {\n    BeginTxBatch(id interface{}) error\n    ExecTXs(id interface{}, txs []*pb.Transaction) ([]byte, []error)  \n    CommitTxBatch(id interface{}, transactions []*pb.Transaction, transactionsResults []*pb.TransactionResult, metadata []byte) error  \n    RollbackTxBatch(id interface{}) error  \n    PreviewCommitTxBatchBlock(id interface{}, transactions []*pb.Transaction, metadata []byte) (*pb.Block, error)  \n}  The executor interface is the most frequently utilized portion of the  LedgerStack  interface, and is the only piece which is strictly necessary for a consensus network to make progress. The interface allows for a transaction to be started, executed, rolled back if necessary, previewed, and potentially committed. This interface is comprised of the following methods.",
            "title": "3.4.7 Executor interface"
        },
        {
            "location": "/protocol-spec/#3471-beginning-a-transaction-batch",
            "text": "BeginTxBatch(id interface{}) error  This call accepts an arbitrary  id , deliberately opaque, as a way for the consensus plugin to ensure only the transactions associated with this particular batch are executed. For instance, in the pbft implementation, this  id  is the an encoded hash of the transactions to be executed.",
            "title": "3.4.7.1 Beginning a transaction batch"
        },
        {
            "location": "/protocol-spec/#3472-executing-transactions",
            "text": "ExecTXs(id interface{}, txs []*pb.Transaction) ([]byte, []error)  This call accepts an array of transactions to execute against the current state of the ledger and returns the current state hash in addition to an array of errors corresponding to the array of transactions. Note that a transaction resulting in an error has no effect on whether a transaction batch is safe to commit. It is up to the consensus plugin to determine the behavior which should occur when failing transactions are encountered. This call is safe to invoke multiple times.",
            "title": "3.4.7.2 Executing transactions"
        },
        {
            "location": "/protocol-spec/#3473-committing-and-rolling-back-transactions",
            "text": "RollbackTxBatch(id interface{}) error  This call aborts an execution batch. This will undo the changes to the current state, and restore the ledger to its previous state. It concludes the batch begun with  BeginBatchTx  and a new one must be created before executing any transactions.  PreviewCommitTxBatchBlock(id interface{}, transactions []*pb.Transaction, metadata []byte) (*pb.Block, error)  This call is most useful for consensus plugins which wish to test for non-deterministic transaction execution. The hashable portions of the block returned are guaranteed to be identical to the block which would be committed if  CommitTxBatch  were immediately invoked. This guarantee is violated if any new transactions are executed.  CommitTxBatch(id interface{}, transactions []*pb.Transaction, transactionsResults []*pb.TransactionResult, metadata []byte) error  This call commits a block to the blockchain. Blocks must be committed to a blockchain in total order.  CommitTxBatch  concludes the transaction batch, and a new call to  BeginTxBatch  must be made before any new transactions are executed and committed.",
            "title": "3.4.7.3 Committing and rolling-back transactions"
        },
        {
            "location": "/protocol-spec/#348-ledger-interface",
            "text": "Definition:  type Ledger interface {\n    ReadOnlyLedger\n    UtilLedger\n    WritableLedger\n}  Ledger  interface is intended to allow the consensus plugin to interrogate and possibly update the current state and blockchain. It is comprised of the three interfaces described below.",
            "title": "3.4.8 Ledger interface"
        },
        {
            "location": "/protocol-spec/#3481-readonlyledger-interface",
            "text": "Definition:  type ReadOnlyLedger interface {\n    GetBlock(id uint64) (block *pb.Block, err error)\n    GetCurrentStateHash() (stateHash []byte, err error)\n    GetBlockchainSize() (uint64, error)\n}  ReadOnlyLedger  interface is intended to query the local copy of the ledger without the possibility of modifying it. It is comprised of the following functions.  GetBlockchainSize() (uint64, error)  This call returns the current length of the blockchain ledger. In general, this function should never fail, though in the unlikely event that this occurs, the error is passed to the caller to decide what if any recovery is necessary. The block with the highest number will have block number  GetBlockchainSize()-1 .  Note that in the event that the local copy of the blockchain ledger is corrupt or incomplete, this call will return the highest block number in the chain, plus one. This allows for a node to continue operating from the current state/block even when older blocks are corrupt or missing.  GetBlock(id uint64) (block *pb.Block, err error)  This call returns the block from the blockchain with block number  id . In general, this call should not fail, except when the block queried exceeds the current blocklength, or when the underlying blockchain has somehow become corrupt. A failure of  GetBlock  has a possible resolution of using the state transfer mechanism to retrieve it.  GetCurrentStateHash() (stateHash []byte, err error)  This call returns the current state hash for the ledger. In general, this function should never fail, though in the unlikely event that this occurs, the error is passed to the caller to decide what if any recovery is necessary.",
            "title": "3.4.8.1 ReadOnlyLedger interface"
        },
        {
            "location": "/protocol-spec/#3482-utilledger-interface",
            "text": "Definition:  type UtilLedger interface {\n    HashBlock(block *pb.Block) ([]byte, error)\n    VerifyBlockchain(start, finish uint64) (uint64, error)\n}  UtilLedger   interface defines some useful utility functions which are provided by the local ledger. Overriding these functions in a mock interface can be useful for testing purposes. This interface is comprised of two functions.  HashBlock(block *pb.Block) ([]byte, error)  Although  *pb.Block  has a  GetHash  method defined, for mock testing, overriding this method can be very useful. Therefore, it is recommended that the  GetHash  method never be directly invoked, but instead invoked via this  UtilLedger.HashBlock  interface. In general, this method should never fail, but the error is still passed to the caller to decide what if any recovery is appropriate.  VerifyBlockchain(start, finish uint64) (uint64, error)  This utility method is intended for verifying large sections of the blockchain. It proceeds from a high block  start  to a lower block  finish , returning the block number of the first block whose  PreviousBlockHash  does not match the block hash of the previous block as well as an error. Note, this generally indicates the last good block number, not the first bad block number.",
            "title": "3.4.8.2 UtilLedger interface"
        },
        {
            "location": "/protocol-spec/#3483-writableledger-interface",
            "text": "Definition:  type WritableLedger interface {\n    PutBlock(blockNumber uint64, block *pb.Block) error\n    ApplyStateDelta(id interface{}, delta *statemgmt.StateDelta) error\n    CommitStateDelta(id interface{}) error\n    RollbackStateDelta(id interface{}) error\n    EmptyState() error\n}  WritableLedger   interface allows for the caller to update the blockchain. Note that this is  NOT  intended for use in normal operation of a consensus plugin. The current state should be modified by executing transactions using the  Executor  interface, and new blocks will be generated when transactions are committed. This interface is instead intended primarily for state transfer or corruption recovery. In particular, functions in this interface should  NEVER  be exposed directly via consensus messages, as this could result in violating the immutability promises of the blockchain concept. This interface is comprised of the following functions.  -\n     PutBlock(blockNumber uint64, block *pb.Block) error  This function takes a provided, raw block, and inserts it into the blockchain at the given blockNumber. Note that this intended to be an unsafe interface, so no error or sanity checking is performed. Inserting a block with a number higher than the current block height is permitted, similarly overwriting existing already committed blocks is also permitted. Remember, this does not affect the auditability or immutability of the chain, as the hashing techniques make it computationally infeasible to forge a block earlier in the chain. Any attempt to rewrite the blockchain history is therefore easily detectable. This is generally only useful to the state transfer API.  -\n     ApplyStateDelta(id interface{}, delta *statemgmt.StateDelta) error  This function takes a state delta, and applies it to the current state. The delta will be applied to transition a state forward or backwards depending on the construction of the state delta. Like the `Executor` methods, `ApplyStateDelta` accepts an opaque interface `id` which should also be passed into `CommitStateDelta` or `RollbackStateDelta` as appropriate.  -\n     CommitStateDelta(id interface{}) error  This function commits the state delta which was applied in `ApplyStateDelta`. This is intended to be invoked after the caller to `ApplyStateDelta` has verified the state via the state hash obtained via `GetCurrentStateHash()`. This call takes the same `id` which was passed into `ApplyStateDelta`.  -\n     RollbackStateDelta(id interface{}) error  This function unapplies a state delta which was applied in `ApplyStateDelta`. This is intended to be invoked after the caller to `ApplyStateDelta` has detected the state hash obtained via `GetCurrentStateHash()` is incorrect. This call takes the same `id` which was passed into `ApplyStateDelta`.  -\n     EmptyState() error  This function will delete the entire current state, resulting in a pristine empty state. It is intended to be called before loading an entirely new state via deltas. This is generally only useful to the state transfer API.",
            "title": "3.4.8.3 WritableLedger interface"
        },
        {
            "location": "/protocol-spec/#349-remoteledgers-interface",
            "text": "Definition:  type RemoteLedgers interface {\n    GetRemoteBlocks(peerID uint64, start, finish uint64) ( -chan *pb.SyncBlocks, error)\n    GetRemoteStateSnapshot(peerID uint64) ( -chan *pb.SyncStateSnapshot, error)\n    GetRemoteStateDeltas(peerID uint64, start, finish uint64) ( -chan *pb.SyncStateDeltas, error)\n}  The  RemoteLedgers  interface exists primarily to enable state transfer and to interrogate the blockchain state at  other replicas. Just like the  WritableLedger  interface, it is not intended to be used in normal operation and is designed to be used for catchup, error recovery, etc. For all functions in this interface it is the caller s responsibility to enforce timeouts. This interface contains the following functions.    GetRemoteBlocks(peerID uint64, start, finish uint64) ( -chan *pb.SyncBlocks, error)  This function attempts to retrieve a stream of  *pb.SyncBlocks  from the peer designated by  peerID  for the range from  start  to  finish . In general,  start  should be specified with a higher block number than  finish , as the blockchain must be validated from end to beginning. The caller must validate that the desired block is being returned, as it is possible that slow results from another request could appear on this channel. Invoking this call for the same  peerID  a second time will cause the first channel to close.    ```\nGetRemoteStateSnapshot(peerID uint64) ( -chan *pb.SyncStateSnapshot, error)\n```  This function attempts to retrieve a stream of  *pb.SyncStateSnapshot  from the peer designated by  peerID . To apply the result, the existing state should first be emptied via the  WritableLedger   EmptyState  call, then the contained deltas in the stream should be applied sequentially.    -\n     GetRemoteStateDeltas(peerID uint64, start, finish uint64) ( -chan *pb.SyncStateDeltas, error)  This function attempts to retrieve a stream of `*pb.SyncStateDeltas` from the peer designated by `peerID` for the range from `start` to `finish`. The caller must validated that the desired block delta is being returned, as it is possible that slow results from another request could appear on this channel. Invoking this call for the same `peerID` a second time will cause the first channel to close.",
            "title": "3.4.9 RemoteLedgers interface"
        },
        {
            "location": "/protocol-spec/#3410-controller-package",
            "text": "",
            "title": "3.4.10 controller package"
        },
        {
            "location": "/protocol-spec/#34101-controllernewconsenter",
            "text": "Signature:  func NewConsenter(cpi consensus.CPI) (consenter consensus.Consenter)  This function reads the  peer.validator.consensus  value in  core.yaml  configuration file, which is the  configuration file for the  peer  process. The value of the  peer.validator.consensus  key defines whether the validating peer will run with the  noops  consensus plugin or the  pbft  one. (Notice that this should eventually be changed to either  noops  or  custom . In case of  custom , the validating peer will run with the consensus plugin defined in  consensus/config.yaml .)  The plugin author needs to edit the function s body so that it routes to the right constructor for their package. For example, for  pbft  we point to the  pbft.GetPlugin  constructor.  This function is called by  helper.NewConsensusHandler  when setting the  consenter  field of the returned message handler. The input argument  cpi  is the output of the  helper.NewHelper  constructor and implements the  consensus.CPI  interface.",
            "title": "3.4.10.1 controller.NewConsenter"
        },
        {
            "location": "/protocol-spec/#3411-helper-package",
            "text": "",
            "title": "3.4.11 helper package"
        },
        {
            "location": "/protocol-spec/#34111-high-level-overview",
            "text": "A validating peer establishes a message handler ( helper.ConsensusHandler ) for every connected peer, via the  helper.NewConsesusHandler  function (a handler factory). Every incoming message is inspected on its type ( helper.HandleMessage ); if it s a message for which consensus needs to be reached, it s passed on to the peer s consenter object ( consensus.Consenter ). Otherwise it s passed on to the next message handler in the stack.",
            "title": "3.4.11.1 High-level overview"
        },
        {
            "location": "/protocol-spec/#34112-helperconsensushandler",
            "text": "Definition:  type ConsensusHandler struct {\n    chatStream  peer.ChatStream\n    consenter   consensus.Consenter\n    coordinator peer.MessageHandlerCoordinator\n    done        chan struct{}\n    peerHandler peer.MessageHandler\n}  Within the context of consensus, we focus only on the  coordinator  and  consenter  fields. The  coordinator , as the name implies, is used to coordinate between the peer s message handlers. This is, for instance, the object that is accessed when the peer wishes to  Broadcast . The  consenter  receives the messages for which consensus needs to be reached and processes them.  Notice that  fabric/peer/peer.go  defines the  peer.MessageHandler  (interface), and  peer.MessageHandlerCoordinator  (interface) types.",
            "title": "3.4.11.2 helper.ConsensusHandler"
        },
        {
            "location": "/protocol-spec/#34113-helpernewconsensushandler",
            "text": "Signature:  func NewConsensusHandler(coord peer.MessageHandlerCoordinator, stream peer.ChatStream, initiatedStream bool, next peer.MessageHandler) (peer.MessageHandler, error)  Creates a  helper.ConsensusHandler  object. Sets the same  coordinator  for every message handler. Also sets the  consenter  equal to:  controller.NewConsenter(NewHelper(coord))",
            "title": "3.4.11.3 helper.NewConsensusHandler"
        },
        {
            "location": "/protocol-spec/#34114-helperhelper",
            "text": "Definition:  type Helper struct {\n    coordinator peer.MessageHandlerCoordinator\n}  Contains the reference to the validating peer s  coordinator . Is the object that implements the  consensus.CPI  interface for the peer.",
            "title": "3.4.11.4 helper.Helper"
        },
        {
            "location": "/protocol-spec/#34115-helpernewhelper",
            "text": "Signature:  func NewHelper(mhc peer.MessageHandlerCoordinator) consensus.CPI  Returns a  helper.Helper  object whose  coordinator  is set to the input argument  mhc  (the  coordinator  field of the  helper.ConsensusHandler  message handler). This object implements the  consensus.CPI  interface, thus allowing the plugin to interact with the stack.",
            "title": "3.4.11.5 helper.NewHelper"
        },
        {
            "location": "/protocol-spec/#34116-helperhandlemessage",
            "text": "Recall that the  helper.ConsesusHandler  object returned by  helper.NewConsensusHandler  implements the  peer.MessageHandler  interface:  type MessageHandler interface {\n    RemoteLedger\n    HandleMessage(msg *pb.Message) error\n    SendMessage(msg *pb.Message) error\n    To() (pb.PeerEndpoint, error)\n    Stop() error\n}  Within the context of consensus, we focus only on the  HandleMessage  method. Signature:  func (handler *ConsensusHandler) HandleMessage(msg *pb.Message) error  The function inspects the  Type  of the incoming  Message . There are four cases:   Equal to  pb.Message_CONSENSUS : passed to the handler s  consenter.RecvMsg  function.  Equal to  pb.Message_CHAIN_TRANSACTION  (i.e. an external deployment request): a response message is sent to the user first, then the message is passed to the  consenter.RecvMsg  function.  Equal to  pb.Message_CHAIN_QUERY  (i.e. a query): passed to the  helper.doChainQuery  method so as to get executed locally.  Otherwise: passed to the  HandleMessage  method of the next handler down the stack.",
            "title": "3.4.11.6 helper.HandleMessage"
        },
        {
            "location": "/protocol-spec/#35-events",
            "text": "The event framework provides the ability to generate and consume predefined and custom events. There are 3 basic components:\n  - Event stream\n  - Event adapters\n  - Event structures",
            "title": "3.5 Events"
        },
        {
            "location": "/protocol-spec/#351-event-stream",
            "text": "An event stream is a gRPC channel capable of sending and receiving events. Each consumer establishes an event stream to the event framework and expresses the events that it is interested in. the event producer only sends appropriate events to the consumers who have connected to the producer over the event stream.  The event stream initializes the buffer and timeout parameters. The buffer holds the number of events waiting for delivery, and the timeout has 3 options when the buffer is full:   If timeout is less than 0, drop the newly arriving events  If timeout is 0, block on the event until the buffer becomes available  If timeout is greater than 0, wait for the specified timeout and drop the event if the buffer remains full after the timeout",
            "title": "3.5.1 Event Stream"
        },
        {
            "location": "/protocol-spec/#3511-event-producer",
            "text": "The event producer exposes a function to send an event,  Send(e *pb.Event) , where  Event  is either a pre-defined  Block  or a  Generic  event. More events will be defined in the future to include other elements of the fabric.  message Generic {\n    string eventType = 1;\n    bytes payload = 2;\n}  The  eventType  and  payload  are freely defined by the event producer. For example, JSON data may be used in the  payload . The  Generic  event may also be emitted by the chaincode or plugins to communicate with consumers.",
            "title": "3.5.1.1 Event Producer"
        },
        {
            "location": "/protocol-spec/#3512-event-consumer",
            "text": "The event consumer enables external applications to listen to events. Each event consumer registers an event adapter with the event stream. The consumer framework can be viewed as a bridge between the event stream and the adapter. A typical use of the event consumer framework is:  adapter =  adapter supplied by the client application to register and receive events \nconsumerClient = NewEventsClient( event consumer address , adapter)\nconsumerClient.Start()\n...\n...\nconsumerClient.Stop()",
            "title": "3.5.1.2 Event Consumer"
        },
        {
            "location": "/protocol-spec/#352-event-adapters",
            "text": "The event adapter encapsulates three facets of event stream interaction:\n  - an interface that returns the list of all events of interest\n  - an interface called by the event consumer framework on receipt of an event\n  - an interface called by the event consumer framework when the event bus terminates  The reference implementation provides Golang specific language binding.        EventAdapter interface {\n         GetInterestedEvents() ([]*ehpb.Interest, error)\n         Recv(msg *ehpb.Event) (bool,error)\n         Disconnected(err error)\n      }  Using gRPC as the event bus protocol allows the event consumer framework to be ported to different language bindings without affecting the event producer framework.",
            "title": "3.5.2 Event Adapters"
        },
        {
            "location": "/protocol-spec/#353-event-structure",
            "text": "This section details the message structures of the event system. Messages are described directly in Golang for simplicity.  The core message used for communication between the event consumer and producer is the Event.      message Event {\n        oneof Event {\n            //consumer events\n            Register register = 1;\n\n            //producer events\n            Block block = 2;\n            Generic generic = 3;\n       }\n    }  Per the above definition, an event has to be one of  Register ,  Block  or  Generic .  As mentioned in the previous sections, a consumer creates an event bus by establishing a connection with the producer and sending a  Register  event. The  Register  event is essentially an array of  Interest  messages declaring the events of interest to the consumer.      message Interest {\n        enum ResponseType {\n            //don't send events (used to cancel interest)\n            DONTSEND = 0;\n            //send protobuf objects\n            PROTOBUF = 1;\n            //marshall into JSON structure\n            JSON = 2;\n        }\n        string eventType = 1;\n        ResponseType responseType = 2;\n    }  Events can be sent directly as protobuf structures or can be sent as JSON structures by specifying the  responseType  appropriately.  Currently, the producer framework can generate a  Block  or a  Generic  event. A  Block  is a message used for encapsulating properties of a block in the blockchain.",
            "title": "3.5.3 Event Structure"
        },
        {
            "location": "/protocol-spec/#4-security_1",
            "text": "This section discusses the setting depicted in the figure below.\nIn particular, the system consists of the following entities:\nmembership management infrastructure, i.e., a set of entities that are\nresponsible for identifying an individual user (using any form of identification\nconsidered in the system, e.g., credit cards, id-cards), open an account for\nthat user to be able to register, and issue the necessary credentials to\nsuccessfully create transactions and deploy or invoke chaincode successfully\nthrough the fabric. \n * Peers, that are classified as validating peers, and non-validating peers.\n   Validating peers (also known as validators) order and process (check validity, execute,\n   and add to the blockchain) user-messages (transactions) submitted to the network.\n   Non validating peers (also known as peers) receive user transactions on behalf of users,\n   and after some fundamental validity checks, they forward the transactions to their\n   neighboring validating peers. Peers maintain an up-to-date copy of the blockchain,\n   but in contradiction to validators, they do not execute transactions\n   (a process also known as  transaction validation ).\n * End users of the system, that have registered to our membership service administration,\n   after having demonstrated ownership of what is considered  identity  in the system,\n   and have obtained credentials to install the client-software and submit transactions\n   to the system.\n * Client-software, the software that needs to be installed at the client side for the\n   latter to be able to complete his registration to our membership service and submit\n   transactions to the system.\n * Online wallets, entities that are trusted by a user to maintain that user s credentials,\n   and submit transactions solely upon user request to the network. Online wallets come\n   with their own software at the client-side, that is usually light-weight, as the\n   client only needs to authenticate himself and his requests to the wallet.\n   While it can be the case that peers can play the role of  online wallet  for a set of\n   users, in the following sessions the security of online wallets is detailed separately.  Users who wish to make use of the fabric, open an account at the membership management\nadministration, by proving ownership of identity as discussed in previous sections, new chaincodes\nare announced to the blockchain network by the chaincode creator (developer) through the means\nof a deployment transaction that the client-software would construct on behalf of the developer.\nSuch transaction is first received by a peer or validator, and afterwards circulated\nin the entire network of validators, this transaction is executed and finds its place to\nthe blockchain network. Users can also invoke a function of an already deployed chain-code\nthrough an invocation transaction.  The next section provides a summary of the business goals of the system that drive the security requirements. We then overview the security components and their operation and show how this design fulfills the security requirements.",
            "title": "4. Security"
        },
        {
            "location": "/protocol-spec/#41-business-security-requirements",
            "text": "This section presents business security requirements that are relevant to the context of the fabric. Incorporation of identity and role management.  In order to adequately support real business applications it is necessary to progress beyond ensuring cryptographic continuity. A workable B2B system must consequently move towards addressing proven/demonstrated identities or other attributes relevant to conducting business. Business transactions and consumer interactions with financial institutions need to be unambiguously mapped to account holders. Business contracts typically require demonstrable affiliation with specific institutions and/or possession of other specific properties of transacting parties. Accountability and non-frameability are two reasons that identity management is a critical component of such systems.  Accountability means that users of the system, individuals, or corporations, who misbehave can be traced back and be set accountable for their actions. In many cases, members of a B2B system are required to use their identities (in some form) to participate in the system, in a way such that accountability is guaranteed. Accountability and non-frameability are both essential security requirements in B2B systems and they are closely related. That is, a B2B system should guarantee that an honest user of such system cannot be framed to be accused as responsible for transactions originated by other users.  In addition a B2B system should be renewable and flexible in order to accommodate changes of participants\u2019s roles and/or affiliations.  Transactional privacy.  In B2B relationships there is a strong need for transactional privacy, i.e., allowing the end-user of a system to control the degree to which it interacts and shares information with its environment. For example, a corporation doing business through a transactional B2B system requires that its transactions are not visible to other corporations or industrial partners that are not authorized to share classified information with.  Transactional privacy in the fabric is offered by the mechanisms to achieve two properties with respect to non authorized users:    Transaction anonymity, where the owner of a transaction is hidden among the so called  anonymity set , which in the fabric, is the set of users.    Transaction unlinkability, where two or more transactions of the same user should not be linked as such.    Clearly depending on the context, non-authorized users can be anyone outside the system, or a subset of users.  Transactional privacy is strongly associated to the confidentiality of the content of a contractual agreement between two or more members of a B2B system, as well as to the anonymity and unlinkability of any authentication mechanism that should be in place within transactions.  Reconciling transactional privacy with identity management.  As described later in this document, the approach taken here to reconcile identity management with user privacy and to enable competitive institutions to transact effectively on a common blockchain (for both intra- and inter-institutional transactions) is as follows:    add certificates to transactions to implement a \u201cpermissioned\u201d blockchain    utilize a two-level system:    (relatively) static enrollment certificates (ECerts), acquired via registration with an enrollment certificate authority (CA).    transaction certificates (TCerts) that faithfully but pseudonymously represent enrolled users, acquired via a transaction CA.    offer mechanisms to conceal the content of transactions to unauthorized members of the system.    Audit support.  Commercial systems are occasionally subjected to audits. Auditors in such cases should be given the means to check a certain transaction, or a certain group of transactions, the activity of a particular user of the system, or the operation of the system itself. Thus, such capabilities should be offered by any system featuring transactions containing contractual agreements between business partners.",
            "title": "4.1 Business security requirements"
        },
        {
            "location": "/protocol-spec/#42-user-privacy-through-membership-services",
            "text": "Membership Services consists of an infrastructure of several entities that together manage the identity and privacy of users on the network. These services validate user\u2019s identity, register the user in the system, and provide all the credentials needed for him/her to be an active and compliant participant able to create and/or invoke transactions. A Public Key Infrastructure (PKI) is a framework based on public key cryptography that ensures not only the secure exchange of data over public networks but also affirms the identity of the other party. A PKI manages the generation, distribution and revocation of keys and digital certificates. Digital certificates are used to establish user credentials and to sign messages. Signing messages with a certificate ensures that the message has not been altered. Typically a PKI has a Certificate Authority (CA), a Registration Authority (RA), a certificate database, and a certificate storage. The RA is a trusted party that authenticates users and vets the legitimacy of data, certificates or other evidence submitted to support the user\u2019s request for one or more certificates that reflect that user\u2019s identity or other properties. A CA, upon advice from an RA, issues digital certificates for specific uses and is certified directly or hierarchically by a root CA. Alternatively, the user-facing communications and due diligence responsibilities of the RA can be subsumed as part of the CA. Membership Services is composed of the entities shown in the following figure. Introduction of such full PKI reinforces the strength of this system for B2B (over, e.g. Bitcoin).   Root Certificate Authority (Root CA):  entity that represents the trust anchor for the PKI scheme. Digital certificates verification follows a chain of trust. The Root CA is the top-most CA in the PKI hierarchy.  Registration Authority (RA):  a trusted entity that can ascertain the validity and identity of users who want to participate in the permissioned blockchain. It is responsible for out-of-band communication with the user to validate his/her identity and role. It creates registration credentials needed for enrollment and information on root of trust.  Enrollment Certificate Authority (ECA):   responsible for issuing Enrollment Certificates (ECerts) after validating the registration credentials provided by the user.  Transaction Certificate Authority (TCA):  responsible for issuing Transaction Certificates (TCerts) after validating the enrollment credentials provided by the user.  TLS Certificate Authority (TLS-CA):  responsible for issuing TLS certificates and credentials that allow the user to make use of its network. It validates the credential(s) or evidence provided by the user that justifies issuance of a TLS certificate that includes specific information pertaining to the user.  In this specification, membership services is expressed through the following associated certificates issued by the PKI:  Enrollment Certificates (ECerts) \nECerts are long-term certificates. They are issued for all roles, i.e. users, non-validating peers, and validating peers. In the case of users, who submit transactions for candidate incorporation into the blockchain and who also own TCerts (discussed below), there are two possible structure and usage models for ECerts:    Model A:  ECerts contain the identity/enrollmentID of their owner and can be used to offer only nominal entity-authentication for TCert requests and/or within transactions. They contain the public part of two key pairs \u2013 a signature key-pair and an encryption/key agreement key-pair. ECerts are accessible to everyone.    Model B: ECerts contain the identity/enrollmentID of their owner and can be used to offer only nominal entity-authentication for TCert requests. They contain the public part of a signature key-pair, i.e., a signature verification public key. ECerts are preferably accessible to only TCA and auditors, as relying parties. They are invisible to transactions, and thus (unlike TCerts) their signature key pairs do not play a non-repudiation role at that level.    Transaction Certificates (TCerts) \nTCerts are short-term certificates for each transaction. They are issued by the TCA upon authenticated user-request. They securely authorize a transaction and may be configured to not reveal the identities of who is involved in the transaction or to selectively reveal such identity/enrollmentID information. They include the public part of a signature key-pair, and may be configured to also include the public part of a key agreement key pair. They are issued only to users. They are uniquely associated to the owner \u2013 they may be configured so that this association is known only by the TCA (and to authorized auditors). TCerts may be configured to not carry information of the identity of the user. They enable the user not only to anonymously participate in the system but also prevent linkability of transactions.  However, auditability and accountability requirements assume that the TCA is able to retrieve TCerts of a given identity, or retrieve the owner of a specific TCert. For details on how TCerts are used in deployment and invocation transactions see Section 4.3, Transaction Security offerings at the infrastructure level.  TCerts can accommodate encryption or key agreement public keys (as well as digital signature verification public keys).\nIf TCerts are thus equipped, then enrollment certificates need not also contain encryption or key agreement public keys.  Such a key agreement public key, Key_Agreement_TCertPub_Key, can be generated by the transaction certificate authority (TCA) using a method that is the same as that used to generate the Signature_Verification_TCertPub_Key, but using an index value of TCertIndex + 1 rather than TCertIndex, where TCertIndex is hidden within the TCert by the TCA for recovery by the TCert owner.  The structure of a Transaction Certificate (TCert) is as follows:  TCertID \u2013 transaction certificate ID (preferably generated by TCA randomly in order to avoid unintended linkability via the Hidden Enrollment ID field).  Hidden Enrollment ID: AES_Encrypt K (enrollmentID), where key K = [HMAC(Pre-K, TCertID)] 256-bit truncation  and where three distinct key distribution scenarios for Pre-K are defined below as (a), (b) and (c).  Hidden Private Keys Extraction: AES_Encrypt TCertOwner_EncryptKey (TCertIndex || known padding/parity check vector) where || denotes concatenation, and where each batch has a unique (per batch) time-stamp/random offset that is added to a counter (initialized at 1 in this implementation) in order to generate TCertIndex. The counter can be incremented by 2 each time in order to accommodate generation by the TCA of the public keys and recovery by the TCert owner of the private keys of both types, i.e., signature key pairs and key agreement key pairs.  Sign Verification Public Key \u2013 TCert signature verification public key.  Key Agreement Public Key \u2013 TCert key agreement public key.  Validity period \u2013 the time window during which the transaction certificate can be used for the outer/external signature of a transaction.  There are at least three useful ways to consider configuring the key distribution scenario for the Hidden Enrollment ID field: (a)  Pre-K is distributed during enrollment to user clients, peers and auditors, and is available to the TCA and authorized auditors. It may, for example, be derived from K chain  (described subsequently in this specification) or be independent of key(s) used for chaincode confidentiality.  (b)  Pre-K is available to validators, the TCA and authorized auditors. K is made available by a validator to a user (under TLS) in response to a successful query transaction. The query transaction can have the same format as the invocation transaction. Corresponding to Example 1 below, the querying user would learn the enrollmentID of the user who created the Deployment Transaction if the querying user owns one of the TCerts in the ACL of the Deployment Transaction. Corresponding to Example 2 below, the querying user would learn the enrollmentID of the user who created the Deployment Transaction if the enrollmentID of the TCert used to query matches one of the affiliations/roles in the Access Control field of the Deployment Transaction.  Example 1:   Example 2:   (c)  Pre-K is available to the TCA and authorized auditors. The TCert-specific K can be distributed the TCert owner (under TLS) along with the TCert, for each TCert in the batch. This enables targeted release by the TCert owner of K (and thus trusted notification of the TCert owner\u2019s enrollmentID). Such targeted release can use key agreement public keys of the intended recipients and/or PK chain  where SK chain  is available to validators as described subsequently in this specification. Such targeted release to other contract participants can be incorporated into a transaction or done out-of-band.  If the TCerts are used in conjunction with ECert Model A above, then using (c) where K is not distributed to the TCert owner may suffice.\nIf the TCerts are used in conjunction with ECert Model A above, then the Key Agreement Public Key field of the TCert may not be necessary.  The Transaction Certificate Authority (TCA) returns TCerts in batches, each batch contains the KeyDF_Key (Key-Derivation-Function Key) which is not included within every TCert but delivered to the client with the batch of TCerts (using TLS). The KeyDF_Key allows the TCert owner to derive TCertOwner_EncryptKey which in turn enables recovery of TCertIndex from AES_Encrypt TCertOwner_EncryptKey (TCertIndex || known padding/parity check vector).  TLS-Certificates (TLS-Certs) \nTLS-Certs are certificates used for system/component-to-system/component communications. They carry the identity of their owner and are used for network level security.  This implementation of membership services provides the following basic functionality: there is no expiration/revocation of ECerts; expiration of TCerts is provided via the validity period time window; there is no revocation of TCerts. The ECA, TCA, and TLS CA certificates are self-signed, where the TLS CA is provisioned as a trust anchor.",
            "title": "4.2 User Privacy through Membership Services"
        },
        {
            "location": "/protocol-spec/#421-userclient-enrollment-process",
            "text": "The next figure has a high-level description of the user enrollment process. It has an offline and an online phase.   Offline Process:  in Step 1, each user/non-validating peer/validating peer has to present strong identification credentials (proof of ID) to a Registration Authority (RA) offline. This has to be done out-of-band to provide the evidence needed by the RA to create (and store) an account for the user. In Step 2, the RA returns the associated username/password and trust anchor (TLS-CA Cert in this implementation) to the user. If the user has access to a local client then this is one way the client can be securely provisioned with the TLS-CA certificate as trust anchor.  Online Phase:  In Step 3, the user connects to the client to request to be enrolled in the system. The user sends his username and password to the client. On behalf of the user, the client sends the request to the PKI framework, Step 4, and receives a package, Step 5, containing several certificates, some of which should correspond to private/secret keys held by the client. Once the client verifies that the all the crypto material in the package is correct/valid, it stores the certificates in local storage and notifies the user. At this point the user enrollment has been completed.   Figure 4 shows a detailed description of the enrollment process. The PKI framework has the following entities \u2013 RA, ECA, TCA and TLS-CA. After Step 1, the RA calls the function \u201cAddEntry\u201d to enter the (username/password) in its database. At this point the user has been formally registered into the system database. The client needs the TLS-CA certificate (as trust anchor) to verify that the TLS handshake is set up appropriately with the server. In Step 4, the client sends the registration request to the ECA along with its enrollment public key and additional identity information such as username and password (under the TLS record layer protocol). The ECA verifies that such user really exists in the database. Once it establishes this assurance the user has the right to submit his/her enrollment public key and the ECA will certify it. This enrollment information is of a one-time use. The ECA updates the database marking that this registration request information (username/password) cannot be used again. The ECA constructs, signs and sends back to the client an enrollment certificate (ECert) that contains the user\u2019s enrollment public key (Step 5). It also sends the ECA Certificate (ECA-Cert) needed in future steps (client will need to prove to the TCA that his/her ECert was created by the proper ECA). (Although the ECA-Cert is self-signed in the initial implementation, the TCA and TLS-CA and ECA are co-located.) The client verifies, in Step 6, that the public key inside the ECert is the one originally submitted by the client (i.e. that the ECA is not cheating). It also verifies that all the expected information within the ECert is present and properly formed.  Similarly, In Step 7, the client sends a registration request to the TLS-CA along with its public key and identity information. The TLS-CA verifies that such user is in the database. The TLS-CA generates, and signs a TLS-Cert that contains the user\u2019s TLS public key (Step 8). TLS-CA sends the TLS-Cert and its certificate (TLS-CA Cert). Step 9 is analogous to Step 6, the client verifies that the public key inside the TLS Cert is the one originally submitted by the client and that the information in the TLS Cert is complete and properly formed. In Step 10, the client saves all certificates in local storage for both certificates. At this point the user enrollment has been completed.  In this implementation the enrollment process for validators is the same as that for peers. However, it is possible that a different implementation would have validators enroll directly through an on-line process.    Client:  Request for TCerts batch needs to include (in addition to count), ECert and signature of request using ECert private key (where Ecert private key is pulled from Local Storage).  TCA generates TCerts for batch:  Generates key derivation function key, KeyDF_Key, as HMAC(TCA_KDF_Key, EnrollPub_Key). Generates each TCert public key (using TCertPub_Key = EnrollPub_Key + ExpansionValue G, where 384-bit ExpansionValue = HMAC(Expansion_Key, TCertIndex) and 384-bit Expansion_Key = HMAC(KeyDF_Key, \u201c2\u201d)). Generates each AES_Encrypt TCertOwner_EncryptKey (TCertIndex || known padding/parity check vector), where || denotes concatenation and where TCertOwner_EncryptKey is derived as [HMAC(KeyDF_Key, \u201c1\u201d)] 256-bit truncation .  Client:  Deriving TCert private key from a TCert in order to be able to deploy or invoke or query: KeyDF_Key and ECert private key need to be pulled from Local Storage. KeyDF_Key is used to derive TCertOwner_EncryptKey as [HMAC(KeyDF_Key, \u201c1\u201d)] 256-bit truncation ; then TCertOwner_EncryptKey is used to decrypt the TCert field AES_Encrypt TCertOwner_EncryptKey (TCertIndex || known padding/parity check vector); then TCertIndex is used to derive TCert private key: TCertPriv_Key = (EnrollPriv_Key + ExpansionValue) modulo n, where 384-bit ExpansionValue = HMAC(Expansion_Key, TCertIndex) and 384-bit Expansion_Key = HMAC(KeyDF_Key, \u201c2\u201d).",
            "title": "4.2.1 User/Client Enrollment Process"
        },
        {
            "location": "/protocol-spec/#422-expiration-and-revocation-of-certificates",
            "text": "It is practical to support expiration of transaction certificates. The time window during which a transaction certificate can be used is expressed by a \u2018validity period\u2019 field. The challenge regarding support of expiration lies in the distributed nature of the system. That is, all validating entities must share the same information; i.e. be consistent with respect to the expiration of the validity period associated with the transactions to be executed and validated. To guarantee that the expiration of validity periods is done in a consistent manner across all validators, the concept of validity period identifier is introduced. This identifier acts as a logical clock enabling the system to uniquely identify a validity period. At genesis time the \u201ccurrent validity period\u201d of the chain gets initialized by the TCA. It is essential that this validity period identifier is given monotonically increasing values over time, such that it imposes a total order among validity periods.  A special type of transactions, system transactions, and the validity period identified are used together to announce the expiration of a validity period to the Blockchain. System transactions refer to contracts that have been defined in the genesis block and are part of the infrastructure. The validity period identified is updated periodically by the TCA invoking a system chaincode. Note that only the TCA should be allowed to update the validity period. The TCA sets the validity period for each transaction certificate by setting the appropriate integer values in the following two fields that define a range: \u2018not-before\u2019 and \u2018not-after\u2019 fields.  TCert Expiration:\nAt the time of processing a TCert, validators read from the state table associated with the ledger the value of \u2018current validity period\u2019 to check if the outer certificate associated with the transaction being evaluated is currently valid. That is, the current value in the state table has to be within the range defined by TCert sub-fields \u2018not-before\u2019 and \u2018not-after\u2019. If this is the case, the validator continues processing the transaction. In the case that the current value is not within range, the TCert has expired or is not yet valid and the validator should stop processing the transaction.  ECert Expiration:\nEnrollment certificates have different validity period length(s) than those in transaction certificates.  Revocation is supported in the form of Certificate Revocation Lists (CRLs). CRLs identify revoked certificates. Changes to the CRLs, incremental differences, are announced through the Blockchain.",
            "title": "4.2.2 Expiration and revocation of certificates"
        },
        {
            "location": "/protocol-spec/#43-transaction-security-offerings-at-the-infrastructure-level",
            "text": "Transactions in the fabric are user-messages submitted to be included\nin the ledger. As discussed in previous sections, these messages have a\nspecific structure, and enable users to deploy new chaincodes, invoke existing\nchaincodes, or query the state of existing chaincodes.\nTherefore, the way transactions are formed, announced and processed plays\nan important role to the privacy and security offerings of the entire system.  On one hand our membership service provides the means to authenticate transactions as\nhaving originated by valid users of the system, to disassociate transactions with user identities,\nbut while efficiently tracing the transactions a particular individual under certain conditions\n(law enforcement, auditing). In other words, membership services offer to transactions authentication\nmechanisms that marry user-privacy with accountability and non-repudiation.  On the other hand, membership services alone cannot offer full privacy of user-activities within\nthe fabric. First of all, for privacy provisions offered by the fabric to be complete,\nprivacy-preserving authentication mechanisms need to be accompanied by transaction confidentiality.\nThis becomes clear if one considers that the content of a chaincode, may leak information on who may have\ncreated it, and thus break the privacy of that chaincode s creator. The first subsection\ndiscusses transaction confidentiality.    Enforcing access control for the invocation of chaincode is an important security requirement.\nThe fabric exposes to the application (e.g., chaincode creator) the means for the application\nto perform its own invocation access control, while leveraging the fabric s membership services.\nSection 4.4 elaborates on this.   Replay attacks is another crucial aspect of the security of the chaincode,\nas a malicious user may copy a transaction that was added to the Blockchain\nin the past, and replay it in the network to distort its operation.\nThis is the topic of Section 4.3.3.  The rest of this Section presents an overview of how security mechanisms in the\ninfrastructure are incorporated in the transactions  lifecycle,\nand details each security mechanism separately.",
            "title": "4.3 Transaction security offerings at the infrastructure level"
        },
        {
            "location": "/protocol-spec/#431-security-lifecycle-of-transactions",
            "text": "Transactions are created on the client side. The client can be either plain\nclient, or a more specialized application, i.e., piece of\nsoftware that handles (server) or invokes (client) specific chaincodes\nthrough the blockchain. Such applications are built on top of the\nplatform (client) and are detailed in Section 4.4.  Developers of new chaincodes create a new deploy transaction by passing to\nthe fabric infrastructure:  the confidentiality/security version or type they want the transaction to conform with,  the set of users who wish to be given access to parts of the chaincode and\n  a proper representation of their (read) access rights   the chaincode specification,  code metadata, containing information that should be passed to the chaincode\n  at the time of its execution\n  (e.g., configuration parameters), and\n* transaction metadata, that is attached to the transaction structure,\n  and is only used by the application that deployed the chaincode.  Invoke and query transactions corresponding to chaincodes with confidentiality\nrestrictions are created using a similar approach. The transactor provides the\nidentifier of the chaincode to be executed, the name of the function to be\ninvoked and its arguments. Optionally, the invoker can pass to the\ntransaction creation function, code invocation metadata, that will be provided\nto the chaincode at the time of its execution. Transaction metadata is another\nfield that the application of the invoker or the invoker himself can leverage\nfor their own purposes.  Finally transactions at the client side, are signed by a certificate of their\ncreator and released to the network of validators.\nValidators receive the confidential transactions, and pass them through the following phases:   pre-validation  phase, where validators validate the transaction certificate against the accepted root certificate authority,\n  verify transaction certificate signature included in the transaction (statically), and check whether the transaction is a replay (see, later section for details on replay attack protection).   consensus  phase, where the validators add this transaction to the total order of transactions (ultimately included in the ledger)   pre-execution  phase, where validators verify the validity of the transaction / enrollment certificate against the current validity period,\n  decrypt the transaction (if the transaction is encrypted), and check that the transaction s plaintext is correctly formed(e.g., invocation access control is respected, included TCerts are correctly formed);\n  mini replay-attack check is also performed here within the transactions of the currently processed block.   execution  phase, where the (decrypted) chaincode is passed to a container, along with the associated code metadata, and is executed   commit* phase, where (encrypted) updates of that chaincodes state is committed to the ledger with the transaction itself.",
            "title": "4.3.1 Security Lifecycle of Transactions"
        },
        {
            "location": "/protocol-spec/#432-transaction-confidentiality",
            "text": "Transaction confidentiality requires that under the request of the developer, the plain-text\nof a chaincode, i.e., code, description, is not accessible or inferable (assuming a computational\nattacker) by any unauthorized entities(i.e., user or peer not authorized by the developer).\nFor the latter, it is important that for chaincodes with confidentiality requirements the\ncontent of both  deploy  and  invoke  transactions remains concealed. In the same spirit,\nnon-authorized parties, should not be able to associate invocations (invoke transactions) of a\nchaincode to the chaincode itself (deploy transaction) or these invocations to each other.  Additional requirements for any candidate solution is that it respects and supports the privacy\nand security provisions of the underlying membership service. In addition, it should not prevent\nthe enforcement of any invocation access control of the chain-code functions in the fabric, or\nthe implementation of enforcement of access-control mechanisms on the application (See Subsection 4.4).  In the following is provided the specification of transaction confidentiality\nmechanisms at the granularity of users. The last subsection provides some guidelines\non how to extend this functionality at the level of validators.\nInformation on the features supported in current release and its security\nprovisions, you can find in Section 4.7.  The goal is to achieve a design that will allow for granting or restricting\naccess to an entity to any subset of the following parts of a chain-code:\n1. chaincode content, i.e., complete (source) code of the\n   chaincode, \n2. chaincode function headers, i.e., the prototypes of the functions included in a chaincode,  \n3. chaincode [invocations  ] state, i.e., successive updates to the state of a specific chaincode,\n   when one or more functions of its are invoked\n4. all the above  Notice, that this design offers the application the capability to leverage the fabric s\nmembership service infrastructure and its public key infrastructure to build their own access\ncontrol policies and enforcement mechanisms.",
            "title": "4.3.2 Transaction confidentiality"
        },
        {
            "location": "/protocol-spec/#4321-confidentiality-against-users",
            "text": "To support fine-grained confidentiality control, i.e., restrict read-access to the\nplain-text of a chaincode to a subset of users that the chaincode creator\ndefines, a chain is bound to a single long-term encryption key-pair\n(PK chain , SK chain ).\nThough initially this key-pair is to be stored and maintained by each chain s\nPKI, in later releases, however, this restriction will be moved away,\nas chains (and the associated key-pairs) can be triggered through the Blockchain\nby any user with  special  (admin) privileges (See, Section 4.3.2.2).  Setup . At enrollment phase, users obtain (as before) an enrollment certificate,\ndenoted by Cert u i  for user u i , while each\nvalidator v j  obtain its enrollment certificate denoted by\nCert v j . Enrollment would grant users and validators the\nfollowing credentials:   Users:   a. claim and grant themselves signing key-pair (spk u , ssk u ),  b. claim and grant themselves encryption key-pair (epk u , esk u ),  c. obtain the encryption (public) key of the chain PK chain   Validators:   a. claim and grant themselves signing key-pair (spk v , ssk v ),  b. claim and grant themselves an encryption key-pair (epk v , esk v ),  c. obtain the decryption (secret) key of the chain SK chain  Thus, enrollment certificates contain the public part of two key-pairs:  one signature key-pair [denoted by (spk v j ,ssk v j )\n  for validators and by (spk u i , ssk u i ) for users], and  an encryption key-pair [denoted by (epk v j ,esk v j )\n  for validators and (epk u i , esk u i ) for users]  Chain, validator and user enrollment public keys are accessible to everyone.  In addition to enrollment certificates, users who wish to anonymously\nparticipate in transactions issue transaction certificates. For simplicity\ntransaction certificates of a user u i  are denoted by\nTCert u i . Transaction certificates include the public part\nof a signature key-pair denoted by \n(tpk u i ,tsk u i ).  The following section provides a high level description of how transaction\nformat accommodates read-access restrictions at the granularity of users.  Structure of deploy transaction. \nThe following figure depicts the structure of a typical deploy\ntransaction with confidentiality enabled.   One can notice that a deployment transaction consists of several sections:  Section  general-info : contains the administration details of the\n  transaction, i.e., which chain this transaction corresponds to (chained),\n  the type of transaction (that is set to  deplTrans ), the version number of\n  confidentiality policy implemented, its creator identifier (expressed by means\n  of transaction certificate TCert of enrollment certificate Cert), and a Nonce,\n  that facilitates primarily replay-attack resistance techniques.  Section  code-info : contains information on the chain-code source code,\n  and function headers. As shown in the figure below, there is a symmetric key\n  used for the source-code of the chaincode (K C ), and another\n  symmetric key used for the function prototypes (K H ). A signature of\n  the creator of the chaincode is included on the plain-text code such that\n  the latter cannot be detached from the transaction and replayed by another\n  party.  Section  chain-validators : where appropriate key material is passed to the\n  validators for the latter to be able to (i) decrypt the chain-code source\n  (K C ), (ii) decrypt the headers,  and\n  (iii) encrypt the state when the chain-code has been\n  invoked accordingly(K S ). In particular, the chain-code creator\n  generates an encryption key-pair for the chain-code it deploys\n  (PK C , SK C ). It then uses PK C \n  to encrypt all the keys associated to the chain-code:\n    [( code ,K C ) ,( headr ,K H ),( code-state ,K S ), Sig TCert u c (*)] PK c ,  \n  and passes the secret key SK C  to the validators using the\n  chain-specific public key:\n   [( chaincode ,SK C ), Sig TCert u c ( )] PK chain .   Section  contract-users*: where the public encryption keys of the contract users,\n  i.e., users who are given read-access to parts of the chaincode, are used to encrypt\n  the keys  associated to their access rights:    SK c  for the users to be able to read any message associated to\n     that chain-code (invocation, state, etc),    K C  for the user to be able to read only the contract code,    K H  for the user to only be able to read the headers,    K S  for the user to be able to read the state associated to that contract.    Finally users are given the contract s public key PK c ,\n  for them to be able to encrypt information related to that contract for the validators\n  (or any in possession of SK c ) to be able to read it. Transaction certificate\n  of each contract user is appended to the transaction and follows that user s message.\n  This is done for users to be able to easily search the blockchain\n  for transactions they have been part of. Notice that the deployment transaction also\n  appends a message to the creator u c  of the chain-code, for the\n  latter to be able to retrieve this transaction through parsing the ledger and without\n  keeping any state locally.  The entire transaction is signed by a certificate of the chaincode creator, i.e., enrollment\nor transaction certificate as decided by the latter.\nTwo noteworthy points:  Messages that are included in a transaction in an encrypted format, i.e., code-functions, code-hdrs,\n  are signed before they are encrypted using the same TCert the entire transaction is signed with, or\n  even with a different TCert or the ECert of the user (if the transaction deployment should carry the identity\n  of its owner. A binding to the underlying transaction carrier should be included in the signed message, e.g.,\n  the hash of the TCert the transaction is signed, such that mix\\ match attacks are not possible.\n  Though we detail such attacks in Section 4.4, in these cases an attacker who sees a transaction should not be able\n  to isolate the ciphertext corresponding to, e.g., code-info, and use it for another transaction of her own.\n  Clearly, such an ability would disrupt the operation of the system, as a chaincode that was first created by user A,\n  will now also belong to malicious user B (who is not even able to read it).  To offer the ability to the users to cross-verify they are given access to the\n  correct key, i.e., to the same key as the other contract users, transaction\n  ciphertexts that are encrypted with a key K are accompanied by a commitment\n  to K, while the opening of this commitment value is passed to all users who\n  are entitled access to K in contract-users, and chain-validator sections.\n   \n  In this way, anyone who is entitled access to that key can verify that the key\n  has been properly passed to it. This part is omitted in the figure above to\n  avoid confusion.  Structure of invoke transaction. \nA transaction invoking the chain-code triggering the execution of a function of the chain-code with\nuser-specified arguments is structured as depicted in the figure below.   Invocation transaction as in the case of deployment transaction consists of a general-info  section, a  code-info  section, a section for the  chain-validators ,\nand one for the  contract users , signed altogether with one of the invoker s\ntransaction certificates.    General-info follows the same structure as the corresponding section of the\ndeployment transaction.\nThe only difference relates to the transaction type that is now set to  InvocTx ,\nand the chain-code identifier or name that is now encrypted under the\nchain-specific encryption (public) key.    Code-info exhibits the same structure as the one of the deployment transaction.\nCode payload, as in the case of deployment transaction, consists of function\ninvocation details (the name of the function invoked, and associated arguments),\ncode-metadata provided by the application and the transaction s creator\n(invoker s u) certificate, TCert u . Code payload is signed by the\ntransaction certificate TCert u  of the invoker u, as in the case\nof deploy transactions. As in the case of\ndeploy transactions, code-metadata, and tx-metadata, are fields that are\nprovided by the application and can be used (as described in Section 4.4),\nfor the latter to implement their own access control mechanisms and roles.    Finally, contract-users and chain-validator sections provide the key the payload\nis encrypted with, the invoker s key, and the chain encryption key respectively.\nUpon receiving such transactions, the validators decrypt [code-name] PK chain  using the\nchain-specific secret key SK chain  and obtain the invoked chain-code identifier.\nGiven the latter, validators retrieve from their local storage the chaincode s\ndecryption key SK c , and use it to decrypt chain-validators  message,\nthat would equip them with the symmetric key K I  the invocation\ntransaction s payload was encrypted with.\nGiven the latter, validators decrypt code-info, and execute the chain-code\nfunction with the specified arguments,\nand the code-metadata attached(See, Section 4.4 for more details on the use of\ncode-metadata). While the chain-code is executed, updates of the state of that\nchain-code are possible.\nThese are encrypted using the state-specific key K s  that was defined\nduring that chain-code s deployment. In particular, K s  is used the\nsame way K iTx  is used in the design of our current release\n(See, Section 4.7).    Structure of query transaction. \nQuery transactions have the same format as invoke transactions.\nThe only difference is that Query transactions do not affect the state\nof the chaincode, and thus there is no need for the state to be retrieved\n(decrypted) and/or updated (encrypted) after the execution of the chaincode\ncompletes.",
            "title": "4.3.2.1 Confidentiality against users"
        },
        {
            "location": "/protocol-spec/#4322-confidentiality-against-validators",
            "text": "This section deals with ways of how to support execution of certain transactions\nunder a different (or subset) sets of validators in the current chain. This\nsection inhibits IP restrictions and will be expanded in the following few weeks.",
            "title": "4.3.2.2 Confidentiality against validators"
        },
        {
            "location": "/protocol-spec/#433-replay-attack-resistance",
            "text": "In replay attacks the attacker  replays  a message it  eavesdropped  on the network or  saw  on the Blockchain.\nReplay attacks are a big problem here, as they can incur into the validating entities re-doing a computationally intensive\nprocess (chaincode invocation) and/or affect the state of the corresponding chaincode, while it requires minimal or no\npower from the attacker side. To make matters worse, if a transaction was a payment transaction, replays could\npotentially incur into the payment being performed more than once, without this being the original intention of the payer.\nExisting systems resist replay attacks as follows:  Record hashes of transactions in the system. This solution would require that validators maintain a log of the hash of\n  each transaction that has ever been announced through the network, and compare a new transaction against their locally\n  stored transaction record. Clearly such approach cannot scale for large networks, and could easily result into validators\n  spending a lot of time to do the check of whether a transaction has been replayed, than executing the actual transaction.  Leverage state that is maintained per user identity (Ethereum). Ethereum keeps some state, e.g., counter (initially set to 1)\n  for each identity/pseudonym in the system. Users also maintain their own counter (initially set to 0) for each\n  identity/pseudonym of theirs. Each time a user sends a transaction using an identity/pseudonym of his, he increases\n  his local counter by one and adds the resulting value to the transaction. The transaction is subsequently signed by that\n  user identity and released to the network. When picking up this transaction, validators check the counter value included\n  within and compare it with the one they have stored locally; if the value is the same, they increase the local value of\n  that identity s counter and accept the transaction. Otherwise, they reject the transaction as invalid or replay.\n  Although this would work well in cases where we have limited number of user identities/pseudonyms (e.g., not too large),\n  it would ultimately not scale in a system where users use a different identifier (transaction certificate) per transaction,\n  and thus have a number of user pseudonyms proportional to the number of transactions.  Other asset management systems, e.g., Bitcoin, though not directly dealing with replay attacks, they resist them. In systems\nthat manage (digital) assets, state is maintained on a per asset basis, i.e., validators only keep a record of who owns what.\nResistance to replay attacks come as a direct result from this, as replays of transactions would be immediately be\ndeemed as invalid by the protocol (since can only be shown to be derived from older owners of an asset/coin). While this would\nbe appropriate for asset management systems, this does not abide with the needs of a Blockchain systems with more generic\nuse than asset management.  In the fabric, replay attack protection uses a hybrid approach.\nThat is, users add in the transaction a nonce that is generated in a different manner\ndepending on whether the transaction is anonymous (followed and signed by a transaction certificate) or not\n(followed and signed by a long term enrollment certificate). More specifically:   Users submitting a transaction with their enrollment certificate should include in that\n  transaction a nonce that is a function of the nonce they used in the previous transaction\n  they issued with the same certificate (e.g., a counter function or a hash). The nonce included\n  in the first transaction of each enrollment certificate can be either pre-fixed by the system\n  (e.g., included in the genesis block) or chosen by the user. In the first case, the genesis block\n  would need to include nonceall , i.e., a fixed number and the nonce used by user with identity\n  IDA for his first enrollment certificate signed transaction would be\n   nonce round 0 IDA   - hash(IDA, nonce all ), \n  where IDA appears in the enrollment certificate. From that point onward successive transactions of\n  that user with enrollment certificate would include a nonce as follows\n   nonce round i IDA   - hash(nonce round {i-1} IDA ), \n  that is the nonce of the ith transaction would be using the hash of the nonce used in the {i-1}th transaction of that certificate.\n  Validators here continue to process a transaction they receive, as long as it satisfies the condition mentioned above.\n  Upon successful validation of transaction s format, the validators update their database with that nonce.   Storage overhead :    on the user side: only the most recently used nonce,    on validator side: O(n), where n is the number of users.   Users submitting a transaction with a transaction certificate\n  should include in the transaction a random nonce, that would guarantee that\n  two transactions do not result into the same hash. Validators add the hash of\n  this transaction in their local database if the transaction certificate used within\n  it has not expired. To avoid storing large amounts of hashes, validity periods of transaction certificates\n  are leveraged. In particular validators maintain an updated record of received\n  transactions  hashes within the current or future validity period.   Storage overhead  (only makes sense for validators here):  O(m), where m is the approximate number of\n  transactions within a validity period and corresponding validity period identifier (see below).",
            "title": "4.3.3 Replay attack resistance"
        },
        {
            "location": "/protocol-spec/#44-access-control-features-on-the-application",
            "text": "An application, is a piece of software that runs on top of a Blockchain client software, and,\nperforms a special task over the Blockchain, i.e., restaurant table reservation.\nApplication software have a version of\ndeveloper, enabling the latter to generate and manage a couple of chaincodes that are necessary for\nthe business this application serves, and a client-version that would allow the application s end-users\nto make use of the application, by invoking these chain-codes.\nThe use of the Blockchain can be transparent to the application end-users or not.  This section describes how an application leveraging chaincodes can implement its own access control policies,\nand guidelines on how our Membership services PKI can be leveraged for the same purpose.  The presentation is divided into enforcement of invocation access control,\nand enforcement of read-access control by the application.",
            "title": "4.4 Access control features on the application"
        },
        {
            "location": "/protocol-spec/#441-invocation-access-control",
            "text": "To allow the application to implement its own invocation access control at the\napplication layer securely, special support by the fabric must be provided.\nIn the following we elaborate on the tools exposed by the fabric to the\napplication for this purpose, and provide guidelines on how these should be used\nby the application for the latter to enforce access control securely.  Support from the infrastructure. \nFor the chaincode creator, let it be,  u c ,\nto be able to implement its own invocation access control at\nthe application layer securely, special support by the fabric must be provided.\nMore specifically fabric layer gives access to following capabilities:    The client-application can request the fabric to sign and verify any message with specific transaction certificates or enrollment certificate the client owns; this is expressed via the Certificate Handler interface    The client-application can request the fabric a unique  binding  to be used to bind authentication data of the application to the underlying transaction transporting it; this is expressed via the Transaction Handler interface    Support for a transaction format, that allows for the application to specify metadata, that are passed to the chain-code at deployment, and invocation time; the latter denoted by code-metadata.    The  Certificate Handler  interface allows to sign and verify any message using signing key-pair underlying the associated certificate.\nThe certificate can be a TCert or an ECert.  // CertificateHandler exposes methods to deal with an ECert/TCert\ntype CertificateHandler interface {\n\n    // GetCertificate returns the certificate's DER\n    GetCertificate() []byte\n\n    // Sign signs msg using the signing key corresponding to the certificate\n    Sign(msg []byte) ([]byte, error)\n\n    // Verify verifies msg using the verifying key corresponding to the certificate\n    Verify(signature []byte, msg []byte) error\n\n    // GetTransactionHandler returns a new transaction handler relative to this certificate\n    GetTransactionHandler() (TransactionHandler, error)\n}  The  Transaction Handler  interface allows to create transactions and give access to the underlying  binding  that can be leveraged to link\napplication data to the underlying transaction. Bindings are a concept that have been introduced in network transport protocols (See, https://tools.ietf.org/html/rfc5056),\nknown as  channel bindings , that  allows applications to establish that the two end-points of a secure channel at one network layer are the same as at a higher layer\nby binding authentication at the higher layer to the channel at the lower layer.\nThis allows applications to delegate session protection to lower layers, which has various performance benefits. \nTransaction bindings offer the ability to uniquely identify the fabric layer of the transaction that serves as the container that\napplication data uses to be added to the ledger.  // TransactionHandler represents a single transaction that can be uniquely determined or identified by the output of the GetBinding method.\n// This transaction is linked to a single Certificate (TCert or ECert).\ntype TransactionHandler interface {\n\n    // GetCertificateHandler returns the certificate handler relative to the certificate mapped to this transaction\n    GetCertificateHandler() (CertificateHandler, error)\n\n    // GetBinding returns a binding to the underlying transaction (container)\n    GetBinding() ([]byte, error)\n\n    // NewChaincodeDeployTransaction is used to deploy chaincode\n    NewChaincodeDeployTransaction(chaincodeDeploymentSpec *obc.ChaincodeDeploymentSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeExecute is used to execute chaincode's functions\n    NewChaincodeExecute(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeQuery is used to query chaincode's functions\n    NewChaincodeQuery(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n}  For version 1,  binding  consists of the  hash (TCert, Nonce), where TCert, is the transaction certificate\nused to sign the entire transaction, while Nonce, is the nonce number used within.  The  Client  interface is more generic, and offers a mean to get instances of the previous interfaces.  type Client interface {\n\n    ...\n\n    // GetEnrollmentCertHandler returns a CertificateHandler whose certificate is the enrollment certificate\n    GetEnrollmentCertificateHandler() (CertificateHandler, error)\n\n    // GetTCertHandlerNext returns a CertificateHandler whose certificate is the next available TCert\n    GetTCertificateHandlerNext() (CertificateHandler, error)\n\n    // GetTCertHandlerFromDER returns a CertificateHandler whose certificate is the one passed\n    GetTCertificateHandlerFromDER(der []byte) (CertificateHandler, error)\n\n}  To support application-level access control lists for controlling chaincode\ninvocation, the fabric s transaction and chaincode specification format\nhave an additional field to store application-specific metadata.\nThis field is depicted in both figures 1, by code-metadata. The content of this field is decided\nby the application, at the transaction creation time.\nThe fabric layer treats it as an unstructured stream of bytes.  \nmessage ChaincodeSpec {\n\n    ...\n\n    ConfidentialityLevel confidentialityLevel;\n    bytes metadata;\n\n    ...\n}\n\n\nmessage Transaction {\n    ...\n\n    bytes payload;\n    bytes metadata;\n\n    ...\n}  To assist chaincode execution, at the chain-code invocation time, the validators provide the\nchaincode with additional information, like the metadata and the binding.  Application invocation access control. \nThis section describes how the application can leverage the means provided by the fabric\nto implement its own access control on its chain-code functions.\nIn the scenario considered here, the following entities are identified:    C : is a chaincode that contains a single function, e.g., called  hello ;    u c : is the  C  deployer;    u i : is a user who is authorized to invoke  C s functions. User u c  wants to ensure that only u i  can invoke the function  hello .    Deployment of a Chaincode:  At deployment time, u c  has full control on the deployment transaction s metadata,\n and can be used to store a list of ACLs (one per function), or a list of roles that are needed by the application. The format which is used to store these ACLs is up to the deployer s application, as the chain-code is the one\nwho would need to parse the metadata at execution time.\nTo define each of these lists/roles, u c  can use any TCerts/Certs of the u i  (or, if applicable, or other users who have been assigned that privilege or role). Let this be TCert u i .\nThe exchange of TCerts or Certs among the developer and authorized users is done through an out-of-band channel.  Assume that the application of u c s requires that to invoke the  hello  function, a certain message  M  has to be authenticated by an authorized invoker (u i , in our example).\nOne can distinguish the following two cases:    M  is one of the chaincode s function arguments;    M  is the invocation message itself, i.e., function-name, function-arguments.    Chaincode invocation: \nTo invoke C, u i s application needs to sign  M  using the TCert/ECert, that was used to identify u i s participation in the chain-code at the associated\ndeployment transaction s metadata, i.e., TCert u i . More specifically, u i s client application does the following:    Retrieves a CertificateHandler for Cert u i ,  cHandler ;    obtains a new TransactionHandler to issue the execute transaction,  txHandler  relative to his next available TCert or his ECert;    gets  txHandler s  binding  by invoking  txHandler.getBinding() ;    signs  M  || txBinding  by invoking  cHandler.Sign( M  || txBinding ) , let  sigma  be the output of the signing function;    issues a new execute transaction by invoking,  txHandler.NewChaincodeExecute( ) . Now,  sigma  can be included in the transaction as one of the arguments that are passed to the function (case 1) or as part of the code-metadata section of the payload(case 2).    Chaincode processing: \nThe validators, who receive the execute transaction issued u i , will provide to  hello  the following information:    The  binding  of the execute transaction, that can be independently computed at the validator side;    The  metadata  of the execute transaction (code-metadata section of the transaction);    The  metadata  of the deploy transaction (code-metadata component of the corresponding deployment transaction).    Notice that  sigma  is either part of the arguments of the invoked function, or stored inside the code-metadata of the invocation transaction (properly formatted by the client-application).\nApplication ACLs are included in the code-metadata section, that is also passed to the chain-code at execution time.\nFunction  hello  is responsible for checking that  sigma  is indeed a valid signature issued by TCert u i , on  M  ||  txBinding .",
            "title": "4.4.1 Invocation access control"
        },
        {
            "location": "/protocol-spec/#442-read-access-control",
            "text": "This section describes how the fabric s infrastructure offers support to the application to\nenforce its own read-access control policies at the level of users. As in the case of invocation access\ncontrol, the first part describes the infrastructure features that can be leveraged by the application for this\npurpose, and the last part details on the way applications should use these tools.  For the purpose of this discussion, we leverage a similar example as before, i.e.,    C : is a chaincode that contains a single function, e.g., called  hello ;    u A : is the  C s deployer, also known as application;    u r : is a user who is authorized to read  C s functions. User u A  wants to ensure that only u r  can read the function  hello .    Support from the infrastructure. \nFor  u A  to be able to implement its own read access control at the application layer securely, our infrastructure is required to\nsupport the transaction format for code deployment and invocation, as depicted in the two figures below.    More specifically fabric layer is required to provide the following functionality:    Provide minimal encryption capability such that data is only decryptable by a validator s (infrastructure) side; this means that the infrastructure should move closer to our future version, where an asymmetric encryption scheme is used for encrypting transactions. More specifically, an asymmetric key-pair is used for the chain, denoted by K chain  in the Figures above, but detailed in Section  Transaction Confidentiality .    The client-application can request the infrastructure sitting on the client-side to encrypt/decrypt information using a specific public encryption key, or that client s long-term decryption key.    The transaction format offers the ability to the application to store additional transaction metadata, that can be passed to the client-application after the latter s request. Transaction metadata, as opposed to code-metadata, is not encrypted or provided to the chain-code at execution time. Validators treat these metadata as a list of bytes they are not responsible for checking validity of.    Application read-access control. \nFor this reason the application may request and obtain access to the public encryption key of the user  u r ; let that be  PK u r . Optionally, u r  may be providing  u A  with a certificate of its, that would be leveraged by the application, say, TCert u r ; given the latter,\nthe application would, e.g., be able to trace that user s transactions w.r.t. the application s chain-codes. TCert u r , and PK u r , are\nexchanged in an out-of-band channel.  At deployment time, application  u A  performs the following steps:    Uses the underlying infrastructure to encrypt the information of  C , the application would like to make accessible to  u r , using PK u r .\n   Let C u r  be the resulting ciphertext.    (optional) C u r  can be concatenated with TCert u r    Passes the overall string as  Tx-metadata  of the confidential transaction to be constructed.    At invocation time, the client-application on u r s node, would be able, by obtaining the deployment transaction to retrieve the content of  C .\nIt just needs to retrieve the  tx-metadata  field of the associated deployment transaction, and trigger the decryption functionality offered by our Blockchain\ninfrastrucure s client, for C u r . Notice that it is the application s responsibility to encrypt the correct  C  for u r .\nAlso, the use of  tx-metadata  field can be generalized to accommodate application-needs. E.g., it can be that invokers leverage the same field of invocation transactions\nto pass information to the developer of the application, etc.  Important Note:    It is essential to note that validators  do not provide  any decryption oracle to the chain-code\nthroughout its execution. Its infrastructure is though responsible for decrypting the payload of the chain-code itself (as well as\nthe code-metadata fields near it), and provide those to containers for deployment/execution.",
            "title": "4.4.2 Read access control"
        },
        {
            "location": "/protocol-spec/#45-online-wallet-service",
            "text": "This section describes the security design of a wallet service, which in this case is a node with which end-users can register, store their key material and through which they can perform transactions.\nBecause the wallet service is in possession of the user s key material, it is clear that without a secure authorization\nmechanism in place a malicious wallet service could successfully impersonate the user.\nWe thus emphasize that this design corresponds to a wallet service that is  trusted  to only perform transactions\non behalf of its clients, with the consent of the latter.\nThere are two cases for the registration of an end-user to an online wallet service:   When the user has registered with the registration authority and acquired his/her  enrollID, enrollPWD ,\n   but has not installed the client to trigger and complete the enrollment process;  When the user has already installed the client, and completed the enrollment phase.   Initially, the user interacts with the online wallet service to issue credentials that would allow him to authenticate\nto the wallet service. That is, the user is given a username, and password, where username identifies the user in the\nmembership service, denoted by AccPub, and password is the associated secret, denoted by AccSec, that is  shared  by\nboth user and service.  To enroll through the online wallet service, a user must provide the following request\nobject to the wallet service:  AccountRequest /* account request of u \\*/\n{\n    OBCSecCtx ,           /* credentials associated to network \\*/\n    AccPub sub u /sub ,   /* account identifier of u \\*/\n    AccSecProof sub u /sub   /* proof of AccSec sub u /sub \\*/\n }  OBCSecCtx refers to user credentials, which depending on the stage of his enrollment process, can be either his enrollment ID and password,  enrollID, enrollPWD  or his enrollment certificate and associated secret key(s)\n(ECert u , sk u ),  where  sk u  denotes for simplicity signing and decryption secret of the user.\nThe content of AccSecProof u  is an HMAC on the rest fields of request using the shared secret. Nonce-based methods\nsimilar to what we have in the fabric can be used to protect against replays.\nOBCSecCtx would give the online wallet service the necessary information to enroll the user or issue required TCerts.  For subsequent requests, the user u should provide to the wallet service a request of similar format.   TransactionRequest /* account request of u \\*/\n {\n      TxDetails,            /* specifications for the new transaction \\*/\n      AccPub sub u /sub ,       /* account identifier of u \\*/\n      AccSecProof sub u /sub    /* proof of AccSec sub u /sub  \\*/\n }  Here, TxDetails refer to the information needed by the online service to construct a transaction on behalf of the user, i.e.,\nthe type, and user-specified content of the transaction.  AccSecProof u  is again an HMAC on the rest fields of request using the shared secret.\nNonce-based methods similar to what we have in the fabric can be used to protect against replays.  TLS connections can be used in each case with server side authentication to secure the request at the\nnetwork layer (confidentiality, replay attack protection, etc)",
            "title": "4.5 Online wallet service"
        },
        {
            "location": "/protocol-spec/#46-network-security-tls",
            "text": "The TLS CA should be capable of issuing TLS certificates to (non-validating) peers, validators, and individual clients (or browsers capable of storing a private key). Preferably, these certificates are distinguished by type, per above. TLS certificates for CAs of the various types (such as TLS CA, ECA, TCA) could be issued by an intermediate CA (i.e., a CA that is subordinate to the root CA). Where there is not a particular traffic analysis issue, any given TLS connection can be mutually authenticated, except for requests to the TLS CA for TLS certificates.  In the current implementation the only trust anchor is the TLS CA self-signed certificate in order to accommodate the limitation of a single port to communicate with all three (co-located) servers, i.e., the TLS CA, the TCA and the ECA. Consequently, the TLS handshake is established with the TLS CA, which passes the resultant session keys to the co-located TCA and ECA. The trust in validity of the TCA and ECA self-signed certificates is therefore inherited from trust in the TLS CA. In an implementation that does not thus elevate the TLS CA above other CAs, the trust anchor should be replaced with a root CA under which the TLS CA and all other CAs are certified.",
            "title": "4.6 Network security (TLS)"
        },
        {
            "location": "/protocol-spec/#47-restrictions-in-the-current-release",
            "text": "This section lists the restrictions of the current release of the fabric.\nA particular focus is given on client operations and the design of transaction confidentiality,\nas depicted in Sections 4.7.1 and 4.7.2.   Client side enrollment and transaction creation is performed entirely by a\n   non-validating peer that is trusted not to impersonate the user.\n   See, Section 4.7.1 for more information.  A minimal set of confidentiality properties where a chaincode is accessible\n   by any entity that is member of the system, i.e., validators and users who\n   have registered through Hyperledger Fabric s Membership Services and is not accessible by anyone else.\n   The latter include any party that has access to the storage area where the\n   ledger is maintained, or other entities that are able to see the transactions\n   that are announced in the validator network. The design of the first release\n   is detailed in subsection 4.7.2  The code utilizes self-signed certificates for entities such as the\n   enrollment CA (ECA) and the transaction CA (TCA)  Replay attack resistance mechanism is not available  Invocation access control can be enforced at the application layer:\n   it is up to the application to leverage the infrastructure s tools properly\n   for security to be guaranteed. This means, that if the application fails to\n    bind  the transaction binding offered by the fabric, secure transaction\n   processing may be at risk.",
            "title": "4.7 Restrictions in the current release"
        },
        {
            "location": "/protocol-spec/#471-simplified-client",
            "text": "Client-side enrollment and transaction creation are performed entirely by a non-validating peer that plays the role of an online wallet.\nIn particular, the end-user leverages their registration credentials   to open an account to a non-validating peer\nand uses these credentials to further authorize the peer to build transactions on the user s behalf. It needs to be noted, that such\na design does not provide secure  authorization  for the peer to submit transactions on behalf of the user, as a malicious peer\ncould impersonate the user. Details on the specifications of a design that deals with the security issues of online wallet can be found is Section 4.5.\nCurrently the maximum number of peers a user can register to and perform transactions through is one.",
            "title": "4.7.1 Simplified client"
        },
        {
            "location": "/protocol-spec/#472-simplified-transaction-confidentiality",
            "text": "Disclaimer:  The current version of transaction confidentiality is minimal, and will be used as an intermediate step\nto reach a design that allows for fine grained (invocation) access control enforcement in a subsequent release.  In its current form, confidentiality of transactions is offered solely at the chain-level, i.e., that the\ncontent of a transaction included in a ledger, is readable by all members of that chain, i.e., validators\nand users. At the same time, application auditors who are not members of the system can be given\nthe means to perform auditing by passively observing the blockchain data, while\nguaranteeing that they are given access solely to the transactions related to the application under audit.\nState is encrypted in a way that such auditing requirements are satisfied, while not disrupting the\nproper operation of the underlying consensus network.  More specifically, currently symmetric key encryption is supported in the process of offering transaction confidentiality. In this setting, one of the main challenges that is specific to the blockchain setting,\nis that validators need to run consensus over the state of the blockchain, that, aside from the transactions themselves,\nalso includes the state updates of individual contracts or chaincode. Though this is trivial to do for non-confidential chaincode, for confidential chaincode, one needs to design the state encryption mechanism such that the resulting ciphertexts are semantically secure, and yet, identical if the plaintext state is the same.  To overcome this challenge, the fabric utilizes a key hierarchy that reduces the number of ciphertexts\nthat are encrypted under the same key. At the same time, as some of these keys are used for the generation of IVs,\nthis allows the validating parties to generate exactly the same ciphertext when executing the same transaction\n(this is necessary to remain agnostic to the underlying consensus algorithm) and offers the possibility of controlling audit by disclosing to auditing entities only the most relevant keys.  Method description: \nMembership service generates a symmetric key for the ledger (K chain ) that is distributed\nat registration time to all the entities of the blockchain system, i.e., the clients and the\nvalidating entities that have issued credentials through the membership service of the chain.\nAt enrollment phase, user obtain (as before) an enrollment certificate, denoted by Cert u i \nfor user u i  , while each validator v j  obtains its enrollment certificate denoted by Cert v j .  Entity enrollment would be enhanced, as follows. In addition to enrollment certificates,\nusers who wish to anonymously participate in transactions issue transaction certificates.\nFor simplicity transaction certificates of a user u i  are denoted by TCert u i .\nTransaction certificates include the public part of a signature key-pair denoted by (tpk u i ,tsk u i ).  In order to defeat crypto-analysis and enforce confidentiality, the following key hierarchy is considered for generation and validation of confidential transactions:\nTo submit a confidential transaction (Tx) to the ledger, a client first samples a nonce (N), which is required to be unique among all the transactions submitted to the blockchain, and derive a transaction symmetric\nkey (K Tx ) by applying the HMAC function keyed with K chain  and on input the nonce, K Tx = HMAC(K chain , N). From K Tx , the client derives two AES keys:\nK TxCID  as HMAC(K Tx , c 1 ), K TxP  as HMAC(K Tx , c 2 )) to encrypt respectively the chain-code name or identifier CID and code (or payload) P.\nc 1 , c 2  are public constants. The nonce, the Encrypted Chaincode ID (ECID) and the Encrypted Payload (EP) are added in the transaction Tx structure, that is finally signed and so\nauthenticated. Figure below shows how encryption keys for the client s transaction are generated. Arrows in this figure denote application of an HMAC, keyed by the key at the source of the arrow and\nusing the number in the arrow as argument. Deployment/Invocation transactions  keys are indicated by d/i respectively.   To validate a confidential transaction Tx submitted to the blockchain by a client,\na validating entity first decrypts ECID and EP by re-deriving K TxCID  and K TxP \nfrom K chain  and Tx.Nonce as done before. Once the Chaincode ID and the\nPayload are recovered the transaction can be processed.   When V validates a confidential transaction, the corresponding chaincode can access and modify the\nchaincode s state. V keeps the chaincode s state encrypted. In order to do so, V generates symmetric\nkeys as depicted in the figure above. Let iTx be a confidential transaction invoking a function\ndeployed at an early stage by the confidential transaction dTx (notice that iTx can be dTx itself\nin the case, for example, that dTx has a setup function that initializes the chaincode s state).\nThen, V generates two symmetric keys  K IV   and K state  as follows:   It computes  as  K dTx  , i.e., the transaction key of the corresponding deployment\n   transaction, and then N state  = HMAC(K dtx  ,hash(N i )), where N i \n   is the nonce appearing in the invocation transaction, and  hash  a hash function.  It sets K state  = HMAC(K dTx , c 3  || N state ),\n   truncated opportunely deeding on the underlying cipher used to encrypt; c 3  is a constant number  It sets K IV  = HMAC(K dTx , c 4  || N state ); c 4  is a constant number   In order to encrypt a state variable S, a validator first generates the IV as HMAC(K IV , crt state )\nproperly truncated, where crt state  is a counter value that increases each time a state update\nis requested for the same chaincode invocation. The counter is discarded after the execution of\nthe chaincode terminates. After IV has been generated, V encrypts with authentication (i.e., GSM mode)\nthe value of S concatenated with Nstate(Actually, N state   doesn t need to be encrypted but\nonly authenticated). To the resulting ciphertext (CT), N state  and the IV used is appended.\nIn order to decrypt an encrypted state CT|| N state  , a validator first generates the symmetric\nkeys K dTX  ,K state  using N state  and then decrypts CT.  Generation of IVs: In order to be agnostic to any underlying consensus algorithm, all the validating\nparties need a method to produce the same exact ciphertexts. In order to do so, the validators need\nto use the same IVs. Reusing the same IV with the same symmetric key completely breaks the security\nof the underlying cipher. Therefore, the process described before is followed. In particular, V first\nderives an IV generation key K IV  by computing HMAC(K dTX , c 4  || N state  ),\nwhere c 4  is a constant number, and keeps a counter crt state  for the pair\n(dTx, iTx) with is initially set to 0. Then, each time a new ciphertext has to be generated, the validator\ngenerates a new IV by computing it as the output of HMAC(K IV , crt state )\nand then increments the crt state  by one.  Another benefit that comes with the above key hierarchy is the ability to enable controlled auditing.\nFor example, while by releasing K chain  one would provide read access to the whole chain,\nby releasing only K state  for a given pair of transactions (dTx,iTx) access would be granted to a state\nupdated by iTx, and so on.  The following figures demonstrate the format of a deployment and invocation transaction currently available in the code.    One can notice that both deployment and invocation transactions consist of two sections:    Section  general-info : contains the administration details of the transaction, i.e., which chain this transaction corresponds to (is chained to), the type of transaction (that is set to  deploymTx  or  invocTx ), the version number of confidentiality policy implemented, its creator identifier (expressed by means of TCert of Cert) and a nonce (facilitates primarily replay-attack resistance techniques).    Section  code-info : contains information on the chain-code source code. For deployment transaction this is essentially the chain-code identifier/name and source code, while for invocation chain-code is the name of the function invoked and its arguments. As shown in the two figures code-info in both transactions are encrypted ultimately using the chain-specific symmetric key K chain .",
            "title": "4.7.2 Simplified transaction confidentiality"
        },
        {
            "location": "/protocol-spec/#5-byzantine-consensus_1",
            "text": "The  pbft  package is an implementation of the seminal  PBFT  consensus protocol [1], which provides consensus among validators despite a threshold of validators acting as  Byzantine , i.e., being malicious or failing in an unpredictable manner. In the default configuration, PBFT tolerates up to t n/3 Byzantine validators.  In the default configuration, PBFT is designed to run on at least  3t+1  validators (replicas), tolerating up to  t  potentially faulty (including malicious, or  Byzantine ) replicas.",
            "title": "5. Byzantine Consensus"
        },
        {
            "location": "/protocol-spec/#51-overview",
            "text": "The  pbft  plugin provides an implementation of the PBFT consensus protocol.",
            "title": "5.1 Overview"
        },
        {
            "location": "/protocol-spec/#52-core-pbft-functions",
            "text": "The following functions control for parallelism using a non-recursive lock and can therefore be invoked from multiple threads in parallel. However, the functions typically run to completion and may invoke functions from the CPI passed in. Care must be taken to prevent livelocks.",
            "title": "5.2 Core PBFT Functions"
        },
        {
            "location": "/protocol-spec/#521-newpbftcore",
            "text": "Signature:  func newPbftCore(id uint64, config *viper.Viper, consumer innerCPI, ledger consensus.Ledger) *pbftCore  The  newPbftCore  constructor instantiates a new PBFT box instance, with the specified  id . The  config  argument defines operating parameters of the PBFT network: number replicas  N , checkpoint period  K , and the timeouts for request completion and view change duration.     configuration key  type  example value  description      general.N  integer  4  Number of replicas    general.K  integer  10  Checkpoint period    general.timeout.request  duration  2s  Max delay between request reception and execution    general.timeout.viewchange  duration  2s  Max delay between view-change start and next request execution     The arguments  consumer  and  ledger  pass in interfaces that are used\nto query the application state and invoke application requests once\nthey have been totally ordered. See the respective sections below for\nthese interfaces.",
            "title": "5.2.1 newPbftCore"
        },
        {
            "location": "/protocol-spec/#6-application-programming-interface_1",
            "text": "The primary interface to the fabric is a REST API. The REST API allows applications to register users, query the blockchain, and to issue transactions. A CLI is also provided to cover a subset of the available APIs for development purposes. The CLI enables developers to quickly test chaincodes or query for status of transactions.  Applications interact with a non-validating peer node through the REST API, which will require some form of authentication to ensure the entity has proper privileges. The application is responsible for implementing the appropriate authentication mechanism and the peer node will subsequently sign the outgoing messages with the client identity.    \nThe fabric API design covers the categories below, though the implementation is incomplete for some of them in the current release. The  REST API  section will describe the APIs currently supported.   Identity - Enrollment to acquire or to revoke a certificate  Address - Target and source of a transaction  Transaction - Unit of execution on the ledger  Chaincode - Program running on the ledger  Blockchain - Contents of the ledger  Network - Information about the blockchain peer network  Storage - External store for files or documents  Event Stream - Sub/pub events on the blockchain",
            "title": "6. Application Programming Interface"
        },
        {
            "location": "/protocol-spec/#61-rest-service",
            "text": "The REST service can be enabled (via configuration) on either validating or non-validating peers, but it is recommended to only enable the REST service on non-validating peers on production networks.  func StartOpenchainRESTServer(server *oc.ServerOpenchain, devops *oc.Devops)  This function reads the  rest.address  value in the  core.yaml  configuration file, which is the configuration file for the  peer  process. The value of the  rest.address  key defines the default address and port on which the peer will listen for HTTP REST requests.  It is assumed that the REST service receives requests from applications which have already authenticated the end user.",
            "title": "6.1 REST Service"
        },
        {
            "location": "/protocol-spec/#62-rest-api",
            "text": "You can work with the REST API through any tool of your choice. For example, the curl command line utility or a browser based client such as the Firefox Rest Client or Chrome Postman. You can likewise trigger REST requests directly through  Swagger . To obtain the REST API Swagger description, click  here . The currently available APIs are summarized in the following section.",
            "title": "6.2 REST API"
        },
        {
            "location": "/protocol-spec/#621-rest-endpoints",
            "text": "Block  GET /chain/blocks/{block-id}  Blockchain  GET /chain  Chaincode  POST /chaincode  Network  GET /network/peers  Registrar  POST /registrar  GET /registrar/{enrollmentID}  DELETE /registrar/{enrollmentID}  GET /registrar/{enrollmentID}/ecert  GET /registrar/{enrollmentID}/tcert  Transactions  GET /transactions/{UUID}",
            "title": "6.2.1 REST Endpoints"
        },
        {
            "location": "/protocol-spec/#6211-block-api",
            "text": "GET /chain/blocks/{block-id}   Use the Block API to retrieve the contents of various blocks from the blockchain. The returned Block message structure is defined in section  3.2.1.1 .  Block Retrieval Request:  GET host:port/chain/blocks/173  Block Retrieval Response:  {\n     transactions : [\n        {\n             type : 3,\n             chaincodeID :  EgRteWNj ,\n             payload :  Ch4IARIGEgRteWNjGhIKBmludm9rZRIBYRIBYhICMTA= ,\n             uuid :  f5978e82-6d8c-47d1-adec-f18b794f570e ,\n             timestamp : {\n                 seconds : 1453758316,\n                 nanos : 206716775\n            },\n             cert :  MIIB/zCCAYWgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMTI1MjE0MTE3WhcNMTYwNDI0MjE0MTE3WjArMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQ4wDAYDVQQDEwVsdWthczB2MBAGByqGSM49AgEGBSuBBAAiA2IABC/BBkt8izf6Ew8UDd62EdWFikJhyCPY5VO9Wxq9JVzt3D6nubx2jO5JdfWt49q8V1Aythia50MZEDpmKhtM6z7LHOU1RxuxdjcYDOvkNJo6pX144U4N1J8/D3A+97qZpKN/MH0wDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwDQYDVR0OBAYEBAECAwQwDwYDVR0jBAgwBoAEAQIDBDA9BgYqAwQFBgcBAf8EMABNbPHZ0e/2EToi0H8mkouuUDwurgBYuUB+vZfeMewBre3wXG0irzMtfwHlfECRDDAKBggqhkjOPQQDAwNoADBlAjAoote5zYFv91lHzpbEwTfJL/+r+CG7oMVFUFuoSlvBSCObK2bDIbNkW4VQ+ZC9GTsCMQC5GCgy2oZdHw/x7XYzG2BiqmRkLRTiCS7vYCVJXLivU65P984HopxW0cEqeFM9co0= ,\n             signature :  MGUCMCIJaCT3YRsjXt4TzwfmD9hg9pxYnV13kWgf7e1hAW5Nar//05kFtpVlq83X+YtcmAIxAK0IQlCgS6nqQzZEGCLd9r7cg1AkQOT/RgoWB8zcaVjh3bCmgYHsoPAPgMsi3TJktg== \n        }\n    ],\n     stateHash :  7ftCvPeHIpsvSavxUoZM0u7o67MPU81ImOJIO7ZdMoH2mjnAaAAafYy9MIH3HjrWM1/Zla/Q6LsLzIjuYdYdlQ== ,\n     previousBlockHash :  lT0InRg4Cvk4cKykWpCRKWDZ9YNYMzuHdUzsaeTeAcH3HdfriLEcTuxrFJ76W4jrWVvTBdI1etxuIV9AO6UF4Q== ,\n     nonHashData : {\n         localLedgerCommitTimestamp : {\n             seconds : 1453758316,\n             nanos : 250834782\n        }\n    }\n}",
            "title": "6.2.1.1 Block API"
        },
        {
            "location": "/protocol-spec/#6212-blockchain-api",
            "text": "GET /chain   Use the Chain API to retrieve the current state of the blockchain. The returned BlockchainInfo message is defined below.  message BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}    height  - Number of blocks in the blockchain, including the genesis block.    currentBlockHash  - The hash of the current or last block.    previousBlockHash  - The hash of the previous block.    Blockchain Retrieval Request:  GET host:port/chain  Blockchain Retrieval Response:  {\n     height : 174,\n     currentBlockHash :  lIfbDax2NZMU3rG3cDR11OGicPLp1yebIkia33Zte9AnfqvffK6tsHRyKwsw0hZFZkCGIa9wHVkOGyFTcFxM5w== ,\n     previousBlockHash :  Vlz6Dv5OSy0OZpJvijrU1cmY2cNS5Ar3xX5DxAi/seaHHRPdssrljDeppDLzGx6ZVyayt8Ru6jO+E68IwMrXLQ== \n}",
            "title": "6.2.1.2 Blockchain API"
        },
        {
            "location": "/protocol-spec/#6213-chaincode-api",
            "text": "POST /chaincode   Use the Chaincode API to deploy, invoke, and query chaincodes. The deploy request requires the client to supply a  path  parameter, pointing to the directory containing the chaincode in the file system. The response to a deploy request is either a message containing a confirmation of successful chaincode deployment or an error, containing a reason for the failure. It also contains the generated chaincode  name  in the  message  field, which is to be used in subsequent invocation and query transactions to uniquely identify the deployed chaincode.  To deploy a chaincode, supply the required ChaincodeSpec payload, defined in section  3.1.2.2 .  Deploy Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n         path : github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  1000 ,  b ,  2000 ]\n    }\n  },\n   id :  1   \n}  Deploy Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     id : 1\n}  With security enabled, modify the required payload to include the  secureContext  element passing the enrollment ID of a logged in user as follows:  Deploy Request with security enabled:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n         path : github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  1000 ,  b ,  2000 ]\n    },\n     secureContext :  lukas \n  },\n   id :  1   \n}  The invoke request requires the client to supply a  name  parameter, which was previously returned in the response from the deploy transaction. The response to an invocation request is either a message containing a confirmation of successful execution or an error, containing a reason for the failure.  To invoke a function within a chaincode, supply the required ChaincodeSpec payload, defined in section  3.1.2.2 .  Invoke Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n       name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     ctorMsg : {\n         function : invoke ,\n         args :[ a ,  b ,  100 ]\n    }\n  },\n   id :  3   \n}  Invoke Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  5a4540e5-902b-422d-a6ab-e70ab36a2e6d \n    },\n     id : 3\n}  With security enabled, modify the required payload to include the  secureContext  element passing the enrollment ID of a logged in user as follows:  Invoke Request with security enabled:  {\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n       name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     ctorMsg : {\n         function : invoke ,\n         args :[ a ,  b ,  100 ]\n    },\n     secureContext :  lukas \n  },\n   id :  3   \n}  The query request requires the client to supply a  name  parameter, which was previously returned in the response from the deploy transaction. The response to a query request depends on the chaincode implementation. The response will contain a message containing a confirmation of successful execution or an error, containing a reason for the failure. In the case of successful execution, the response will also contain values of requested state variables within the chaincode.  To invoke a query function within a chaincode, supply the required ChaincodeSpec payload, defined in section  3.1.2.2 .  Query Request:  POST host:port/chaincode/\n\n{\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n       name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     ctorMsg : {\n         function : query ,\n         args :[ a ]\n    }\n  },\n   id :  5   \n}  Query Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  -400 \n    },\n     id : 5\n}  With security enabled, modify the required payload to include the  secureContext  element passing the enrollment ID of a logged in user as follows:  Query Request with security enabled:  {\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n       name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     ctorMsg : {\n         function : query ,\n         args :[ a ]\n    },\n     secureContext :  lukas \n  },\n   id :  5   \n}",
            "title": "6.2.1.3 Chaincode API"
        },
        {
            "location": "/protocol-spec/#6214-network-api",
            "text": "Use the Network API to retrieve information about the network of peer nodes comprising the blockchain fabric.  The /network/peers endpoint returns a list of all existing network connections for the target peer node. The list includes both validating and non-validating peers. The list of peers is returned as type  PeersMessage , containing an array of  PeerEndpoint , defined in section  3.1.1 .  message PeersMessage {\n    repeated PeerEndpoint peers = 1;\n}  Network Request:  GET host:port/network/peers  Network Response:  {\n     peers : [\n        {\n             ID : {\n                 name :  vp1 \n            },\n             address :  172.17.0.4:7051 ,\n             type : 1,\n             pkiID :  rUA+vX2jVCXev6JsXDNgNBMX03IV9mHRPWo6h6SI0KLMypBJLd+JoGGlqFgi+eq/ \n        },\n        {\n             ID : {\n                 name :  vp3 \n            },\n             address :  172.17.0.5:7051 ,\n             type : 1,\n             pkiID :  OBduaZJ72gmM+B9wp3aErQlofE0ulQfXfTHh377ruJjOpsUn0MyvsJELUTHpAbHI \n        },\n        {\n             ID : {\n                 name :  vp2 \n            },\n             address :  172.17.0.6:7051 ,\n             type : 1,\n             pkiID :  GhtP0Y+o/XVmRNXGF6pcm9KLNTfCZp+XahTBqVRmaIumJZnBpom4ACayVbg4Q/Eb \n        }\n    ]\n}",
            "title": "6.2.1.4 Network API"
        },
        {
            "location": "/protocol-spec/#6215-registrar-api-member-services",
            "text": "POST /registrar  GET /registrar/{enrollmentID}  DELETE /registrar/{enrollmentID}  GET /registrar/{enrollmentID}/ecert  GET /registrar/{enrollmentID}/tcert   Use the Registrar APIs to manage end user registration with the certificate authority (CA). These API endpoints are used to register a user with the CA, determine whether a given user is registered, and to remove any login tokens for a target user from local storage, preventing them from executing any further transactions. The Registrar APIs are also used to retrieve user enrollment and transaction certificates from the system.  The  /registrar  endpoint is used to register a user with the CA. The required Secret payload is defined below. The response to the registration request is either a confirmation of successful registration or an error, containing a reason for the failure.  message Secret {\n    string enrollId = 1;\n    string enrollSecret = 2;\n}   enrollId  - Enrollment ID with the certificate authority.  enrollSecret  - Enrollment password with the certificate authority.   Enrollment Request:  POST host:port/registrar\n\n{\n   enrollId :  lukas ,\n   enrollSecret :  NPKYL39uKbkj \n}  Enrollment Response:  {\n     OK :  Login successful for user 'lukas'. \n}  The  GET /registrar/{enrollmentID}  endpoint is used to confirm whether a given user is registered with the CA. If so, a confirmation will be returned. Otherwise, an authorization error will result.  Verify Enrollment Request:  GET host:port/registrar/jim  Verify Enrollment Response:  {\n     OK :  User jim is already logged in. \n}  Verify Enrollment Request:  GET host:port/registrar/alex  Verify Enrollment Response:  {\n     Error :  User alex must log in. \n}  The  DELETE /registrar/{enrollmentID}  endpoint is used to delete login tokens for a target user. If the login tokens are deleted successfully, a confirmation will be returned. Otherwise, an authorization error will result. No payload is required for this endpoint.  Remove Enrollment Request:  DELETE host:port/registrar/lukas  Remove Enrollment Response:  {\n     OK :  Deleted login token and directory for user lukas. \n}  The  GET /registrar/{enrollmentID}/ecert  endpoint is used to retrieve the enrollment certificate of a given user from local storage. If the target user has already registered with the CA, the response will include a URL-encoded version of the enrollment certificate. If the target user has not yet registered, an error will be returned. If the client wishes to use the returned enrollment certificate after retrieval, keep in mind that it must be URL-decoded.  Enrollment Certificate Retrieval Request:  GET host:port/registrar/jim/ecert  Enrollment Certificate Retrieval Response:  {\n     OK :  -----BEGIN+CERTIFICATE-----%0AMIIBzTCCAVSgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwNPQkMwHhcNMTYwMTIxMDYzNjEwWhcNMTYwNDIw%0AMDYzNjEwWjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNP%0AQkMwdjAQBgcqhkjOPQIBBgUrgQQAIgNiAARSLgjGD0omuJKYrJF5ClyYb3sGEGTU%0AH1mombSAOJ6GAOKEULt4L919sbSSChs0AEvTX7UDf4KNaKTrKrqo4khCoboMg1VS%0AXVTTPrJ%2BOxSJTXFZCohVgbhWh6ZZX2tfb7%2BjUDBOMA4GA1UdDwEB%2FwQEAwIHgDAM%0ABgNVHRMBAf8EAjAAMA0GA1UdDgQGBAQBAgMEMA8GA1UdIwQIMAaABAECAwQwDgYG%0AUQMEBQYHAQH%2FBAE0MAoGCCqGSM49BAMDA2cAMGQCMGz2RR0NsJOhxbo0CeVts2C5%0A%2BsAkKQ7v1Llbg78A1pyC5uBmoBvSnv5Dd0w2yOmj7QIwY%2Bn5pkLiwisxWurkHfiD%0AxizmN6vWQ8uhTd3PTdJiEEckjHKiq9pwD%2FGMt%2BWjP7zF%0A-----END+CERTIFICATE-----%0A \n}  The  /registrar/{enrollmentID}/tcert  endpoint retrieves the transaction certificates for a given user that has registered with the certificate authority. If the user has registered, a confirmation message will be returned containing an array of URL-encoded transaction certificates. Otherwise, an error will result. The desired number of transaction certificates is specified with the optional  count  query parameter. The default number of returned transaction certificates is 1; and 500 is the maximum number of certificates that can be retrieved with a single request. If the client wishes to use the returned transaction certificates after retrieval, keep in mind that they must be URL-decoded.  Transaction Certificate Retrieval Request:  GET host:port/registrar/jim/tcert  Transaction Certificate Retrieval Response:  {\n     OK : [\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAQfwJORRED9RAsmSl%2FEowq1STBb%0A%2FoFteymZ96RUr%2BsKmF9PNrrUNvFZFhvukxZZjqhEcGiQqFyRf%2FBnVN%2BbtRzMo38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwSRWQFmErr0SmQO9AFP4GJYzQ%0APQMmcsCjKiJf%2Bw1df%2FLnXunCsCUlf%2FalIUaeSrT7MAoGCCqGSM49BAMDA0gAMEUC%0AIQC%2FnE71FBJd0hwNTLXWmlCJff4Yi0J%2BnDi%2BYnujp%2Fn9nQIgYWg0m0QFzddyJ0%2FF%0AKzIZEJlKgZTt8ZTlGg3BBrgl7qY%3D%0A-----END+CERTIFICATE-----%0A \n    ]\n}  Transaction Certificate Retrieval Request:  GET host:port/registrar/jim/tcert?count=5  Transaction Certificate Retrieval Response:  {\n     OK : [\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A ,\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A ,\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A ,\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A ,\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A \n    ]\n}",
            "title": "6.2.1.5 Registrar API (member services)"
        },
        {
            "location": "/protocol-spec/#6216-transactions-api",
            "text": "GET /transactions/{UUID}   Use the Transaction API to retrieve an individual transaction matching the UUID from the blockchain. The returned transaction message is defined in section  3.1.2.1 .  Transaction Retrieval Request:  GET host:port/transactions/f5978e82-6d8c-47d1-adec-f18b794f570e  Transaction Retrieval Response:  {\n     type : 3,\n     chaincodeID :  EgRteWNj ,\n     payload :  Ch4IARIGEgRteWNjGhIKBmludm9rZRIBYRIBYhICMTA= ,\n     uuid :  f5978e82-6d8c-47d1-adec-f18b794f570e ,\n     timestamp : {\n         seconds : 1453758316,\n         nanos : 206716775\n    },\n     cert :  MIIB/zCCAYWgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMTI1MjE0MTE3WhcNMTYwNDI0MjE0MTE3WjArMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQ4wDAYDVQQDEwVsdWthczB2MBAGByqGSM49AgEGBSuBBAAiA2IABC/BBkt8izf6Ew8UDd62EdWFikJhyCPY5VO9Wxq9JVzt3D6nubx2jO5JdfWt49q8V1Aythia50MZEDpmKhtM6z7LHOU1RxuxdjcYDOvkNJo6pX144U4N1J8/D3A+97qZpKN/MH0wDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwDQYDVR0OBAYEBAECAwQwDwYDVR0jBAgwBoAEAQIDBDA9BgYqAwQFBgcBAf8EMABNbPHZ0e/2EToi0H8mkouuUDwurgBYuUB+vZfeMewBre3wXG0irzMtfwHlfECRDDAKBggqhkjOPQQDAwNoADBlAjAoote5zYFv91lHzpbEwTfJL/+r+CG7oMVFUFuoSlvBSCObK2bDIbNkW4VQ+ZC9GTsCMQC5GCgy2oZdHw/x7XYzG2BiqmRkLRTiCS7vYCVJXLivU65P984HopxW0cEqeFM9co0= ,\n     signature :  MGUCMCIJaCT3YRsjXt4TzwfmD9hg9pxYnV13kWgf7e1hAW5Nar//05kFtpVlq83X+YtcmAIxAK0IQlCgS6nqQzZEGCLd9r7cg1AkQOT/RgoWB8zcaVjh3bCmgYHsoPAPgMsi3TJktg== \n}",
            "title": "6.2.1.6 Transactions API"
        },
        {
            "location": "/protocol-spec/#63-cli",
            "text": "The CLI includes a subset of the available APIs to enable developers to quickly test and debug chaincodes or query for status of transactions. CLI is implemented in Golang and operable on multiple OS platforms. The currently available CLI commands are summarized in the following section.",
            "title": "6.3 CLI"
        },
        {
            "location": "/protocol-spec/#631-cli-commands",
            "text": "To see what CLI commands are currently available in the implementation, execute the following:  $ peer  You will receive a response similar to below:      Usage:\n      peer [command]\n\n    Available Commands:\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level= : Default logging level and overrides, see core.yaml for full syntax\n\n    Use  peer [command] --help  for more information about a command.  Some of the available command line arguments for the  peer  command are listed below:    -c  - constructor: function to trigger in order to initialize the chaincode state upon deployment.    -l  - language: specifies the implementation language of the chaincode. Currently, only Golang is supported.    -n  - name: chaincode identifier returned from the deployment transaction. Must be used in subsequent invoke and query transactions.    -p  - path: identifies chaincode location in the local file system. Must be used as a parameter in the deployment transaction.    -u  - username: enrollment ID of a logged in user invoking the transaction.    Not all of the above commands are fully implemented in the current release. The fully supported commands that are helpful for chaincode development and debugging are described below.  Note, that any configuration settings for the peer node listed in the  core.yaml  configuration file, which is the  configuration file for the  peer  process, may be modified on the command line with an environment variable. For example, to set the  peer.id  or the  peer.addressAutoDetect  settings, one may pass the  CORE_PEER_ID=vp1  and  CORE_PEER_ADDRESSAUTODETECT=true  on the command line.",
            "title": "6.3.1 CLI Commands"
        },
        {
            "location": "/protocol-spec/#6311-node-start",
            "text": "The CLI  node start  command will execute the peer process in either the development or production mode. The development mode is meant for running a single peer node locally, together with a local chaincode deployment. This allows a chaincode developer to modify and debug their code without standing up a complete network. An example for starting the peer in development mode follows:  peer node start --peer-chaincodedev  To start the peer process in production mode, modify the above command as follows:  peer node start",
            "title": "6.3.1.1 node start"
        },
        {
            "location": "/protocol-spec/#6312-network-login",
            "text": "The CLI  network login  command will login a user, that is already registered with the CA, through the CLI. To login through the CLI, issue the following command, where  username  is the enrollment ID of a registered user.  peer network login  username   The example below demonstrates the login process for user  jim .  peer network login jim  The command will prompt for a password, which must match the enrollment password for this user registered with the certificate authority. If the password entered does not match the registered password, an error will result.  22:21:31.246 [main] login -  INFO 001 CLI client login...\n22:21:31.247 [main] login -  INFO 002 Local data store for client loginToken: /var/hyperledger/production/client/\nEnter password for user 'jim': ************\n22:21:40.183 [main] login -  INFO 003 Logging in user 'jim' on CLI interface...\n22:21:40.623 [main] login -  INFO 004 Storing login token for user 'jim'.\n22:21:40.624 [main] login -  INFO 005 Login successful for user 'jim'.  You can also pass a password for the user with  -p  parameter. An example is below.  peer network login jim -p 123456",
            "title": "6.3.1.2 network login"
        },
        {
            "location": "/protocol-spec/#6313-chaincode-deploy",
            "text": "The CLI  deploy  command creates the docker image for the chaincode and subsequently deploys the package to the validating peer. An example is below.  peer chaincode deploy -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{ Function : init ,  Args : [ a , 100 ,  b ,  200 ]}'  With security enabled, the command must be modified to pass an enrollment id of a logged in user with the  -u  parameter. An example is below.  peer chaincode deploy -u jim -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{ Function : init ,  Args : [ a , 100 ,  b ,  200 ]}'  Note:  If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.",
            "title": "6.3.1.3 chaincode deploy"
        },
        {
            "location": "/protocol-spec/#6314-chaincode-invoke",
            "text": "The CLI  invoke  command executes a specified function within the target chaincode. An example is below.  peer chaincode invoke -n  name_value_returned_from_deploy_command  -c '{ Function :  invoke ,  Args : [ a ,  b ,  10 ]}'  With security enabled, the command must be modified to pass an enrollment id of a logged in user with the  -u  parameter. An example is below.  peer chaincode invoke -u jim -n  name_value_returned_from_deploy_command  -c '{ Function :  invoke ,  Args : [ a ,  b ,  10 ]}'",
            "title": "6.3.1.4 chaincode invoke"
        },
        {
            "location": "/protocol-spec/#6315-chaincode-query",
            "text": "The CLI  query  command triggers a specified query method within the target chaincode. The response that is returned depends on the chaincode implementation. An example is below.  peer chaincode query -l golang -n  name_value_returned_from_deploy_command  -c '{ Function :  query ,  Args : [ a ]}'  With security enabled, the command must be modified to pass an enrollment id of a logged in user with the  -u  parameter. An example is below.  peer chaincode query -u jim -l golang -n  name_value_returned_from_deploy_command  -c '{ Function :  query ,  Args : [ a ]}'",
            "title": "6.3.1.5 chaincode query"
        },
        {
            "location": "/protocol-spec/#7-application-model_1",
            "text": "",
            "title": "7. Application Model"
        },
        {
            "location": "/protocol-spec/#71-composition-of-an-application",
            "text": "An application follows a MVC-B architecture \u2013 Model, View, Control, BlockChain.  \n   VIEW LOGIC \u2013 Mobile or Web UI interacting with control logic. \n   CONTROL LOGIC \u2013 Coordinates between UI, Data Model and APIs to drive transitions and chain-code. \n   DATA MODEL \u2013 Application Data Model \u2013 manages off-chain data, including Documents and large files. \n   BLOCKCHAIN  LOGIC \u2013 Blockchain logic are extensions of the Controller Logic and Data Model, into the Blockchain realm. Controller logic is enhanced by chaincode, and the data model is enhanced with transactions on the blockchain.   \nFor example, a Bluemix PaaS application using Node.js might have a Web front-end user interface or a native mobile app with backend model on Cloudant data service. The control logic may interact with 1 or more chaincodes to process transactions on the blockchain.",
            "title": "7.1 Composition of an Application"
        },
        {
            "location": "/protocol-spec/#72-sample-application",
            "text": "",
            "title": "7.2 Sample Application"
        },
        {
            "location": "/protocol-spec/#8-future-directions_1",
            "text": "",
            "title": "8. Future Directions"
        },
        {
            "location": "/protocol-spec/#81-enterprise-integration",
            "text": "",
            "title": "8.1 Enterprise Integration"
        },
        {
            "location": "/protocol-spec/#82-performance-and-scalability",
            "text": "",
            "title": "8.2 Performance and Scalability"
        },
        {
            "location": "/protocol-spec/#83-additional-consensus-plugins",
            "text": "",
            "title": "8.3 Additional Consensus Plugins"
        },
        {
            "location": "/protocol-spec/#84-additional-languages",
            "text": "",
            "title": "8.4 Additional Languages"
        },
        {
            "location": "/protocol-spec/#91-authors_1",
            "text": "The following authors have written sections of this document:  Binh Q Nguyen, Elli Androulaki, Angelo De Caro, Sheehan Anderson, Manish Sethi, Thorsten Kramp, Alessandro Sorniotti, Marko Vukolic, Florian Simon Schubert, Jason K Yellick, Konstantinos Christidis, Srinivasan Muralidharan, Anna D Derbakova, Dulce Ponceleon, David Kravitz, Diego Masini.",
            "title": "9.1 Authors"
        },
        {
            "location": "/protocol-spec/#92-reviewers_1",
            "text": "The following reviewers have contributed to this document:  Frank Lu, John Wolpert, Bishop Brock, Nitin Gaur, Sharon Weed, Konrad Pabjan.",
            "title": "9.2 Reviewers"
        },
        {
            "location": "/protocol-spec/#93-acknowledgements_1",
            "text": "The following contributors have provided invaluable technical input to this specification:\nGennaro Cuomo, Joseph A Latone, Christian Cachin",
            "title": "9.3 Acknowledgements"
        },
        {
            "location": "/protocol-spec/#10-references_1",
            "text": "[1] Miguel Castro, Barbara Liskov: Practical Byzantine fault tolerance and proactive recovery. ACM Trans. Comput. Syst. 20(4): 398-461 (2002)    [2] Christian Cachin, Rachid Guerraoui, Lu\u00eds E. T. Rodrigues: Introduction to Reliable and Secure Distributed Programming (2. ed.). Springer 2011, ISBN 978-3-642-15259-7, pp. I-XIX, 1-367    [3] Tushar Deepak Chandra, Vassos Hadzilacos, Sam Toueg: The Weakest Failure Detector for Solving Consensus. J. ACM 43(4): 685-722 (1996)    [4] Cynthia Dwork, Nancy A. Lynch, Larry J. Stockmeyer: Consensus in the presence of partial synchrony. J. ACM 35(2): 288-323 (1988)    [5] Manos Kapritsos, Yang Wang, Vivien Qu\u00e9ma, Allen Clement, Lorenzo Alvisi, Mike Dahlin: All about Eve: Execute-Verify Replication for Multi-Core Servers. OSDI 2012: 237-250    [6] Pierre-Louis Aublin, Rachid Guerraoui, Nikola Knezevic, Vivien Qu\u00e9ma, Marko Vukolic: The Next 700 BFT Protocols. ACM Trans. Comput. Syst. 32(4): 12:1-12:45 (2015)    [7] Christian Cachin, Simon Schubert, Marko Vukoli\u0107:  Non-determinism in Byzantine Fault-Tolerant Replication",
            "title": "10. References"
        },
        {
            "location": "/biz/usecases/",
            "text": "Canonical Use Cases\n\n\n\n\nB2B Contract\n\n\nBusiness contracts can be codified to allow two or more parties to automate contractual agreements in a trusted way.  Although information on blockchain is naturally \u201cpublic\u201d, B2B contracts may require privacy control to protect sensitive business information from being disclosed to outside parties that also have access to the ledger.\n\n\n\n\nWhile confidential agreements are a key business case, there are many scenarios where contracts can and should be easily discoverable by all parties on a ledger. For example, a ledger used to create offers (asks) seeking bids, by definition, requires access without restriction. This type of contract may need to be standardized so that bidders can easily find them, effectively creating an electronic trading platform with smart contracts (aka chaincode).\n\n\nPersona\n\n\n\n\n\n\nContract participant \u2013 Contract counter parties\n\n\n\n\n\n\nThird party participant \u2013 A third party stakeholder guaranteeing the integrity of the contract.\n\n\n\n\n\n\nKey Components\n\n\n\n\n\n\nMulti-sig contract activation - When a contract is first deployed by one of the counter parties, it will be in the pending activation state. To activate a contract, signatures from other counterparties and/or third party participants are required.\n\n\n\n\n\n\nMulti-sig contract execution - Some contracts will require one of many signatures to execute. For example, in trade finance, a payment instruction can only be executed if either the recipient or an authorized third party (e.g. UPS) confirms the shipment of the good.\n\n\n\n\n\n\nDiscoverability - If a contract is a business offer seeking bids, it must be easily searchable. In addition, such contracts must have the built-in intelligence to evaluate, select and honor bids.\n\n\n\n\n\n\nAtomicity of contract execution - Atomicity of the contract is needed to guarantee that asset transfers can only occur when payment is received (Delivery vs. Payment). If any step in the execution process fails, the entire transaction must be rolled back.\n\n\n\n\n\n\nContract to chain-code communication - Contracts must be able to communicate with chaincodes that are deployed on the same ledger.\n\n\n\n\n\n\nLonger Duration contract - Timer is required to support B2B contracts that have long execution windows.\n\n\n\n\n\n\nReuseable contracts - Often-used contracts can be standardized for reuse.\n\n\n\n\n\n\nAuditable contractual agreement - Any contract can be made auditable to third parties.\n\n\n\n\n\n\nContract life-cycle management - B2B contracts are unique and cannot always be standardized. An efficient contract management system is needed to enhance the scalability of the ledger network.\n\n\n\n\n\n\nValidation access \u2013 Only nodes with validation rights are allowed to validate transactions of a B2B contract.\n\n\n\n\n\n\nView access \u2013 B2B contracts may include confidential information, so only accounts with predefined access rights are allowed to view and interrogate them.\n\n\n\n\n\n\n\n\nManufacturing Supply Chain\n\n\nFinal assemblers, such as automobile manufacturers, can create a supply chain network managed by its peers and suppliers so that a final assembler can better manage its suppliers and be more responsive to events that would require vehicle recalls (possibly triggered by faulty parts provided by a supplier). The blockchain fabric must provide a standard protocol to allow every participant on a supply chain network to input and track numbered parts that are produced and used on a specific vehicle.\n\n\nWhy is this specific example an abstract use case? Because while all blockchain cases store immutable information, and some add the need for transfer of assets between parties, this case emphasizes the need to provide deep searchability backwards through as many as 5-10 transaction layers. This backwards search capability is the core of establishing provenance of any manufactured good that is made up of other component goods and supplies.\n\n\n\n\nPersona\n\n\n\n\n\n\nFinal Assembler \u2013 The business entity that performs the final assembly of a product.\n\n\n\n\n\n\nPart supplier \u2013 Supplier of parts. Suppliers can also be assemblers by assembling parts that they receive from their  sub-suppliers, and then sending their finished product to the final (root) assembler.\n\n\n\n\n\n\nKey Components\n\n\n\n\n\n\nPayment upon delivery of goods - Integration with off-chain payment systems is required, so that payment instructions can be sent when parts are received.\n\n\n\n\n\n\nThird party Audit -  All supplied parts must be auditable by third parties. For example, regulators might need to track the total number of parts supplied by a specific supplier, for tax accounting purposes.\n\n\n\n\n\n\nObfuscation of shipments - Balances must be obfuscated so that no supplier can deduce the business activities of any other supplier.\n\n\n\n\n\n\nObfuscation of market size - Total balances must be obfuscated so that part suppliers cannot deduce their own market share to use as leverage when negotiating contractual terms.\n\n\n\n\n\n\nValidation Access \u2013 Only nodes with validation rights are allowed to validate transactions (shipment of parts).\n\n\n\n\n\n\nView access \u2013 Only accounts with view access rights are allowed to interrogate balances of shipped parts and available parts.\n\n\n\n\n\n\n\n\nAsset Depository\n\n\nAssets such as financial securities must be able to be dematerialized on a blockchain network so that all stakeholders of an asset type will have direct access to that asset, allowing them to initiate trades and acquire information on an asset without going through layers of intermediaries. Trades should be settled in near real time and all stakeholders must be able to access asset information in near real time. A stakeholder should be able to add business rules on any given asset type, as one example of using automation logic to further reduce operating costs.\n\n\n\nPersona\n\n\n\n\n\n\nInvestor \u2013 Beneficial and legal owner of an asset.\n\n\n\n\n\n\nIssuer \u2013 Business entity that issued the asset which is now dematerialized on the ledger network.\n\n\n\n\n\n\nCustodian \u2013 Hired by investors to manage their assets, and offer other value-add services on top of the assets being managed.\n\n\n\n\n\n\nSecurities Depository \u2013 Depository of dematerialized assets.\n\n\n\n\n\n\nKey Components\n\n\n\n\n\n\nAsset to cash - Integration with off-chain payment systems is necessary so that issuers can make payments to and receive payments from investors.\n\n\n\n\n\n\nReference Rate - Some types of assets (such as floating rate notes) may have attributes linked to external data (such as  reference rate), and such information must be fed into the ledger network.\n\n\n\n\n\n\nAsset Timer - Many types of financial assets have predefined life spans and are required to make periodic payments to their owners, so a timer is required to automate the operation management of these assets.\n\n\n\n\n\n\nAsset Auditor - Asset transactions must be made auditable to third parties. For example, regulators may want to audit transactions and movements of assets to measure market risks.\n\n\n\n\n\n\nObfuscation of account balances - Individual account balances must be obfuscated so that no one can deduce the exact amount that an investor owns.\n\n\n\n\n\n\nValidation Access \u2013 Only nodes with validation rights are allowed to validate transactions that update the balances of an asset type (this could be restricted to CSD and/or the issuer).\n\n\n\n\n\n\nView access \u2013 Only accounts with view access rights are allowed to interrogate the chaincode that defines an asset type. If an asset represents shares of publicly traded companies, then the view access right must be granted to every entity on the network.\n\n\n\n\n\n\n\n\nExtended Use Cases\n\n\nThe following extended use cases examine additional requirements and scenarios.\n\n\nOne Trade, One Contract\n\n\nFrom the time that a trade is captured by the front office until the trade is finally settled, only one contract that specifies the trade will be created and used by all participants. The middle office will enrich the same electronic contract submitted by the front office, and that same contract will then be used by counter parties to confirm and affirm the trade. Finally, securities depository will settle the trade by executing the trading instructions specified on the contract. When dealing with bulk trades, the original contract can be broken down into sub-contracts that are always linked to the original parent contract.\n\n\n\n\n\n\nDirect Communication\n\n\nCompany A announces its intention to raise 2 Billion USD by way of rights issue. Because this is a voluntary action, Company A needs to ensure that complete details of the offer are sent to shareholders in real time, regardless of how many intermediaries are involved in the process (such as receiving/paying agents, CSD, ICSD, local/global custodian banks, asset management firms, etc). Once a shareholder has made a decision, that decision will also be processed and settled (including the new issuance of shares) in real time. If a shareholder sold its rights to a third party, the securities depository must be able to record the new shares under the name of their new rightful owner.\n\n\n\n\n\n\nSeparation of Asset Ownership and Custodian\u2019s Duties\n\n\nAssets should always be owned by their actual owners, and asset owners must be able to allow third-party professionals to manage their assets without having to pass legal ownership of assets to third parties (such as nominee or street name entities). If issuers need to send messages or payments to asset owners (for example, listed share holders), issuers send them directly to asset owners. Third-party asset managers and/or custodians can always buy, sell, and lend assets on behalf of their owners. Under this arrangement, asset custodians can focus on providing value-add services to shareowners, without worrying about asset ownership duties such as managing and redirecting payments from issuers to shareowners.\n\n\n\n\n\n\nInteroperability of Assets\n\n\nIf an organization requires 20,000 units of asset B, but instead owns 10,000 units of asset A, it needs a way to exchange asset A for asset B. Though the current market might not offer enough liquidity to fulfill this trade quickly, there might be plenty of liquidity available between asset A and asset C, and also between asset C and asset B. Instead of settling for market limits on direct trading (A for B) in this case, a chain network connects buyers with \nburied\n sellers, finds the best match (which could be buried under several layers of assets), and executes the transaction.",
            "title": "Usecases"
        },
        {
            "location": "/biz/usecases/#canonical-use-cases",
            "text": "",
            "title": "Canonical Use Cases"
        },
        {
            "location": "/biz/usecases/#b2b-contract",
            "text": "Business contracts can be codified to allow two or more parties to automate contractual agreements in a trusted way.  Although information on blockchain is naturally \u201cpublic\u201d, B2B contracts may require privacy control to protect sensitive business information from being disclosed to outside parties that also have access to the ledger.   While confidential agreements are a key business case, there are many scenarios where contracts can and should be easily discoverable by all parties on a ledger. For example, a ledger used to create offers (asks) seeking bids, by definition, requires access without restriction. This type of contract may need to be standardized so that bidders can easily find them, effectively creating an electronic trading platform with smart contracts (aka chaincode).",
            "title": "B2B Contract"
        },
        {
            "location": "/biz/usecases/#persona",
            "text": "Contract participant \u2013 Contract counter parties    Third party participant \u2013 A third party stakeholder guaranteeing the integrity of the contract.",
            "title": "Persona"
        },
        {
            "location": "/biz/usecases/#key-components",
            "text": "Multi-sig contract activation - When a contract is first deployed by one of the counter parties, it will be in the pending activation state. To activate a contract, signatures from other counterparties and/or third party participants are required.    Multi-sig contract execution - Some contracts will require one of many signatures to execute. For example, in trade finance, a payment instruction can only be executed if either the recipient or an authorized third party (e.g. UPS) confirms the shipment of the good.    Discoverability - If a contract is a business offer seeking bids, it must be easily searchable. In addition, such contracts must have the built-in intelligence to evaluate, select and honor bids.    Atomicity of contract execution - Atomicity of the contract is needed to guarantee that asset transfers can only occur when payment is received (Delivery vs. Payment). If any step in the execution process fails, the entire transaction must be rolled back.    Contract to chain-code communication - Contracts must be able to communicate with chaincodes that are deployed on the same ledger.    Longer Duration contract - Timer is required to support B2B contracts that have long execution windows.    Reuseable contracts - Often-used contracts can be standardized for reuse.    Auditable contractual agreement - Any contract can be made auditable to third parties.    Contract life-cycle management - B2B contracts are unique and cannot always be standardized. An efficient contract management system is needed to enhance the scalability of the ledger network.    Validation access \u2013 Only nodes with validation rights are allowed to validate transactions of a B2B contract.    View access \u2013 B2B contracts may include confidential information, so only accounts with predefined access rights are allowed to view and interrogate them.",
            "title": "Key Components"
        },
        {
            "location": "/biz/usecases/#manufacturing-supply-chain",
            "text": "Final assemblers, such as automobile manufacturers, can create a supply chain network managed by its peers and suppliers so that a final assembler can better manage its suppliers and be more responsive to events that would require vehicle recalls (possibly triggered by faulty parts provided by a supplier). The blockchain fabric must provide a standard protocol to allow every participant on a supply chain network to input and track numbered parts that are produced and used on a specific vehicle.  Why is this specific example an abstract use case? Because while all blockchain cases store immutable information, and some add the need for transfer of assets between parties, this case emphasizes the need to provide deep searchability backwards through as many as 5-10 transaction layers. This backwards search capability is the core of establishing provenance of any manufactured good that is made up of other component goods and supplies.",
            "title": "Manufacturing Supply Chain"
        },
        {
            "location": "/biz/usecases/#persona_1",
            "text": "Final Assembler \u2013 The business entity that performs the final assembly of a product.    Part supplier \u2013 Supplier of parts. Suppliers can also be assemblers by assembling parts that they receive from their  sub-suppliers, and then sending their finished product to the final (root) assembler.",
            "title": "Persona"
        },
        {
            "location": "/biz/usecases/#key-components_1",
            "text": "Payment upon delivery of goods - Integration with off-chain payment systems is required, so that payment instructions can be sent when parts are received.    Third party Audit -  All supplied parts must be auditable by third parties. For example, regulators might need to track the total number of parts supplied by a specific supplier, for tax accounting purposes.    Obfuscation of shipments - Balances must be obfuscated so that no supplier can deduce the business activities of any other supplier.    Obfuscation of market size - Total balances must be obfuscated so that part suppliers cannot deduce their own market share to use as leverage when negotiating contractual terms.    Validation Access \u2013 Only nodes with validation rights are allowed to validate transactions (shipment of parts).    View access \u2013 Only accounts with view access rights are allowed to interrogate balances of shipped parts and available parts.",
            "title": "Key Components"
        },
        {
            "location": "/biz/usecases/#asset-depository",
            "text": "Assets such as financial securities must be able to be dematerialized on a blockchain network so that all stakeholders of an asset type will have direct access to that asset, allowing them to initiate trades and acquire information on an asset without going through layers of intermediaries. Trades should be settled in near real time and all stakeholders must be able to access asset information in near real time. A stakeholder should be able to add business rules on any given asset type, as one example of using automation logic to further reduce operating costs.",
            "title": "Asset Depository"
        },
        {
            "location": "/biz/usecases/#persona_2",
            "text": "Investor \u2013 Beneficial and legal owner of an asset.    Issuer \u2013 Business entity that issued the asset which is now dematerialized on the ledger network.    Custodian \u2013 Hired by investors to manage their assets, and offer other value-add services on top of the assets being managed.    Securities Depository \u2013 Depository of dematerialized assets.",
            "title": "Persona"
        },
        {
            "location": "/biz/usecases/#key-components_2",
            "text": "Asset to cash - Integration with off-chain payment systems is necessary so that issuers can make payments to and receive payments from investors.    Reference Rate - Some types of assets (such as floating rate notes) may have attributes linked to external data (such as  reference rate), and such information must be fed into the ledger network.    Asset Timer - Many types of financial assets have predefined life spans and are required to make periodic payments to their owners, so a timer is required to automate the operation management of these assets.    Asset Auditor - Asset transactions must be made auditable to third parties. For example, regulators may want to audit transactions and movements of assets to measure market risks.    Obfuscation of account balances - Individual account balances must be obfuscated so that no one can deduce the exact amount that an investor owns.    Validation Access \u2013 Only nodes with validation rights are allowed to validate transactions that update the balances of an asset type (this could be restricted to CSD and/or the issuer).    View access \u2013 Only accounts with view access rights are allowed to interrogate the chaincode that defines an asset type. If an asset represents shares of publicly traded companies, then the view access right must be granted to every entity on the network.",
            "title": "Key Components"
        },
        {
            "location": "/biz/usecases/#extended-use-cases",
            "text": "The following extended use cases examine additional requirements and scenarios.",
            "title": "Extended Use Cases"
        },
        {
            "location": "/biz/usecases/#one-trade-one-contract",
            "text": "From the time that a trade is captured by the front office until the trade is finally settled, only one contract that specifies the trade will be created and used by all participants. The middle office will enrich the same electronic contract submitted by the front office, and that same contract will then be used by counter parties to confirm and affirm the trade. Finally, securities depository will settle the trade by executing the trading instructions specified on the contract. When dealing with bulk trades, the original contract can be broken down into sub-contracts that are always linked to the original parent contract.",
            "title": "One Trade, One Contract"
        },
        {
            "location": "/biz/usecases/#direct-communication",
            "text": "Company A announces its intention to raise 2 Billion USD by way of rights issue. Because this is a voluntary action, Company A needs to ensure that complete details of the offer are sent to shareholders in real time, regardless of how many intermediaries are involved in the process (such as receiving/paying agents, CSD, ICSD, local/global custodian banks, asset management firms, etc). Once a shareholder has made a decision, that decision will also be processed and settled (including the new issuance of shares) in real time. If a shareholder sold its rights to a third party, the securities depository must be able to record the new shares under the name of their new rightful owner.",
            "title": "Direct Communication"
        },
        {
            "location": "/biz/usecases/#separation-of-asset-ownership-and-custodians-duties",
            "text": "Assets should always be owned by their actual owners, and asset owners must be able to allow third-party professionals to manage their assets without having to pass legal ownership of assets to third parties (such as nominee or street name entities). If issuers need to send messages or payments to asset owners (for example, listed share holders), issuers send them directly to asset owners. Third-party asset managers and/or custodians can always buy, sell, and lend assets on behalf of their owners. Under this arrangement, asset custodians can focus on providing value-add services to shareowners, without worrying about asset ownership duties such as managing and redirecting payments from issuers to shareowners.",
            "title": "Separation of Asset Ownership and Custodian\u2019s Duties"
        },
        {
            "location": "/biz/usecases/#interoperability-of-assets",
            "text": "If an organization requires 20,000 units of asset B, but instead owns 10,000 units of asset A, it needs a way to exchange asset A for asset B. Though the current market might not offer enough liquidity to fulfill this trade quickly, there might be plenty of liquidity available between asset A and asset C, and also between asset C and asset B. Instead of settling for market limits on direct trading (A for B) in this case, a chain network connects buyers with  buried  sellers, finds the best match (which could be buried under several layers of assets), and executes the transaction.",
            "title": "Interoperability of Assets"
        },
        {
            "location": "/Setup/Chaincode-setup/",
            "text": "Writing, Building, and Running Chaincode in a Development Environment\n\n\nChaincode developers need a way to test and debug their chaincode without having to set up a complete peer network. By default, when you want to interact with chaincode, you need to first \nDeploy\n it using the CLI, REST API, gRPC API, or SDK. Upon receiving this request, the peer node would typically spin up a Docker container with the relevant chaincode. This can make things rather complicated for debugging chaincode under development, because of the turnaround time with the \nlaunch chaincode - debug docker container - fix problem - launch chaincode - lather - rinse - repeat\n cycle. As such, the fabric peer has a \n--peer-chaincodedev\n flag that can be passed on start-up to instruct the peer node not to deploy the chaincode as a Docker container.\n\n\nThe following instructions apply to \ndeveloping\n chaincode in Go or Java. They do not apply to running in a production environment. However, if \ndeveloping\n chaincode in Java, please see the \nJava chaincode setup\n instructions first, to be sure your environment is properly configured.\n\n\nNote:\n We have added support for \nSystem chaincode\n.\n\n\nChoices\n\n\nOnce again, you have the choice of using one of the following approaches:\n\n\n\n\nOption 1\n using the \nVagrant\n \ndevelopment environment\n that is used for developing the fabric itself\n\n\nOption 2\n using Docker for Mac or Windows\n\n\nOption 3\n using Docker toolbox\n\n\n\n\nBy using options \n2\n or \n3\n, above, you avoid having to build everything from scratch, and there\ns no need to keep a clone of the fabric GitHub repos current/up-to-date. Instead, you can simply pull and run the \nfabric-peer\n and \nfabric-membersrvc\n images directly from DockerHub.\n\n\nYou will need multiple terminal windows - essentially one for each component. One runs the validating peer; another  runs the chaincode; the third runs the CLI or REST API commands to execute transactions. Finally, when running with security enabled, an additional fourth window is required to run the \nCertificate Authority (CA)\n server. Detailed instructions are provided in the sections below.\n\n\nOption 1 Vagrant development environment\n\n\nSecurity Setup (optional)\n\n\nFrom the \ndevenv\n subdirectory of your fabric workspace environment, \nssh\n into Vagrant:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant ssh\n\n\n\n\nTo set up the local development environment with security enabled, you must first build and run the \nCertificate Authority (CA)\n server:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake membersrvc \n membersrvc\n\n\n\n\nRunning the above commands builds and runs the CA server with the default setup, which is defined in the \nmembersrvc.yaml\n configuration file. The default configuration includes multiple users who are already registered with the CA; these users are listed in the \neca.users\n section of the configuration file. To register additional users with the CA for testing, modify the \neca.users\n section of the \nmembersrvc.yaml\n file to include additional \nenrollmentID\n and \nenrollmentPW\n pairs. Note the integer that precedes the \nenrollmentPW\n. That integer indicates the role of the user, where 1 = client, 2 = non-validating peer, 4 = validating peer, and 8 = auditor.\n\n\nRunning the validating peer\n\n\nNote:\n To run with security enabled, first modify the \ncore.yaml\n configuration file to set the \nsecurity.enabled\n value to \ntrue\n before building the peer executable. Alternatively, you can enable security by running the peer with the following environment variable: \nCORE_SECURITY_ENABLED=true\n. To enable privacy and confidentiality of transactions (which requires security to also be enabled), modify the \ncore.yaml\n configuration file to set the \nsecurity.privacy\n value to \ntrue\n as well. Alternatively, you can enable privacy by running the peer with the following environment variable: \nCORE_SECURITY_PRIVACY=true\n. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).\n\n\nIn a \nnew\n terminal window, from the \ndevenv\n subdirectory of your fabric workspace environment, \nssh\n into Vagrant:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant ssh\n\n\n\n\nBuild and run the peer process to enable security and privacy after setting \nsecurity.enabled\n and \nsecurity.privacy\n settings to \ntrue\n.\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer\npeer node start --peer-chaincodedev\n\n\n\n\nAlternatively, rather than tweaking the \ncore.yaml\n and rebuilding, you can enable security and privacy on the peer with environment variables:\n\n\nCORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer node start --peer-chaincodedev\n\n\n\n\nNow, you are ready to start \nrunning the chaincode\n.\n\n\nOption 2 Docker for Mac or Windows\n\n\nIf you would prefer to simply run the fabric components as built and published by the Hyperledger project on your Mac or Windows laptop/server using the Docker for \nMac\n or \nWindows\n platform, following these steps. If using \nDocker Toolbox\n, please skip to \nOption 3\n, below.\n\n\nPull images from DockerHub\n\n\nFirst, pull the latest images published by the Hyperledger fabric project from DockerHub.\n\n\ndocker pull hyperledger/fabric-peer:latest\ndocker pull hyperledger/fabric-membersrvc:latest\n\n\n\n\nRunning the Peer and CA\n\n\nTo run the fabric-peer and fabric-membersrvc images, we\nll use \nDocker Compose\n. It significantly simplifies things. To do that, we\nll create a docker-compose.yml file with a description of the two services we\nll be running. Here\ns the docker-compose.yml to launch the two processes:\n\n\nmembersrvc:\n  image: hyperledger/fabric-membersrvc\n  ports:\n    - \n7054:7054\n\n  command: membersrvc\nvp0:\n  image: hyperledger/fabric-peer\n  ports:\n    - \n7050:7050\n\n    - \n7051:7051\n\n    - \n7053:7053\n\n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=unix:///var/run/docker.sock\n    - CORE_LOGGING_LEVEL=DEBUG\n    - CORE_PEER_ID=vp0\n    - CORE_PEER_PKI_ECA_PADDR=membersrvc:7054\n    - CORE_PEER_PKI_TCA_PADDR=membersrvc:7054\n    - CORE_PEER_PKI_TLSCA_PADDR=membersrvc:7054\n    - CORE_SECURITY_ENABLED=true\n    - CORE_SECURITY_ENROLLID=test_vp0\n    - CORE_SECURITY_ENROLLSECRET=MwYpmSRjupbT\n  links:\n    - membersrvc\n  command: sh -c \nsleep 5; peer node start --peer-chaincodedev\n\n\n\n\n\nSave that in a directory with the name \ndocker-compose.yml\n. Then, run \ndocker-compose up\n to start the two processes.\n\n\nNow, you are ready to start \nrunning the chaincode\n.\n\n\nOption 3 Docker Toolbox\n\n\nIf you are using \nDocker Toolbox\n, please follow these instructions.\n\n\nPull images from DockerHub\n\n\nFirst, pull the latest images published by the Hyperledger fabric project from DockerHub.\n\n\n  docker pull hyperledger/fabric-peer:latest\n  docker pull hyperledger/fabric-membersrvc:latest\n\n\n\n\nRunning the Peer and CA\n\n\nTo run the fabric-peer and fabric-membersrvc images, we\nll use \nDocker Compose\n. It significantly simplifies things. To do that, we\nll create a docker-compose.yml file with a description of the two services we\nll be running. Here\ns the docker-compose.yml to launch the two processes:\n\n\nmembersrvc:\n  image: hyperledger/fabric-membersrvc\n  command: membersrvc\nvp0:\n  image: hyperledger/fabric-peer\n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=http://172.17.0.1:2375\n    - CORE_LOGGING_LEVEL=DEBUG\n    - CORE_PEER_ID=vp0\n    - CORE_PEER_PKI_ECA_PADDR=membersrvc:7054\n    - CORE_PEER_PKI_TCA_PADDR=membersrvc:7054\n    - CORE_PEER_PKI_TLSCA_PADDR=membersrvc:7054\n    - CORE_SECURITY_ENABLED=true\n    - CORE_SECURITY_ENROLLID=test_vp0\n    - CORE_SECURITY_ENROLLSECRET=MwYpmSRjupbT\n  links:\n    - membersrvc\n  command: sh -c \nsleep 5; peer node start --peer-chaincodedev\n\n\n\n\n\nSave that in a directory with the name \ndocker-compose.yml\n. Then, run \ndocker-compose up\n to start the two processes.\n\n\nRunning the chaincode\n\n\nStart a \nnew\n terminal window.\n\n\nVagrant\n\n\nIf you are using \nOption 1\n, you\nll need to \nssh\n to Vagrant. Otherwise, \nskip\n this step.\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant ssh\n\n\n\n\nNext, we\nll build the \nchaincode_example02\n code, which is provided in the Hyperledger fabric source code repository. If you are using \nOption 1\n, then you can do this from your clone of the fabric repository.\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\ngo build\n\n\n\n\nNot Vagrant\n\n\nIf you are using either \nOption 2\n or \nOption 3\n, you\nll need to  download the sample chaincode. The chaincode project must be placed somewhere under the \nsrc\n directory in your local \n$GOPATH\n as shown below.\n\n\nmkdir -p $GOPATH/src/github.com/chaincode_example02/\ncd $GOPATH/src/github.com/chaincode_example02\ncurl GET https://raw.githubusercontent.com/hyperledger/fabric/master/examples/chaincode/go/chaincode_example02/chaincode_example02.go \n chaincode_example02.go\n\n\n\n\nNext, you\nll need to clone the Hyperledger fabric to your local $GOPATH, so that you can build your chaincode. \nNote:\n this is a temporary stop-gap until we can provide an independent package for the chaincode shim.\n\n\nmkdir -p $GOPATH/src/github.com/hyperledger\ncd $GOPATH/src/github.com/hyperledger\ngit clone http://gerrit.hyperledger.org/r/fabric\n\n\n\n\nNow, you should be able to build your chaincode.\n\n\ncd $GOPATH/src/github.com/chaincode_example02\ngo build\n\n\n\n\nWhen you are ready to start creating your own Go chaincode, create a new subdirectory under $GOPATH/src. You can copy the \nchaincode_example02\n file to the new directory and modify it.\n\n\nStarting and registering the chaincode\n\n\nRun the following chaincode command to start and register the chaincode with the validating peer:\n\n\nCORE_CHAINCODE_ID_NAME=mycc CORE_PEER_ADDRESS=0.0.0.0:7051 ./chaincode_example02\n\n\n\n\nThe chaincode console will display the message \nReceived REGISTERED, ready for invocations\n, which indicates that the chaincode is ready to receive requests. Follow the steps below to send a chaincode deploy, invoke or query transaction. If the \nReceived REGISTERED\n message is not displayed, then an error has occurred during the deployment; revisit the previous steps to resolve the issue.\n\n\nRunning the CLI or REST API\n\n\n\n\nchaincode deploy via CLI and REST\n\n\nchaincode invoke via CLI and REST\n\n\nchaincode query via CLI and REST\n\n\n\n\nIf you were running with security enabled, see \nRemoving temporary files when security is enabled\n to learn how to clean up the temporary files.\n\n\nSee the \nlogging control\n reference for information on controlling\nlogging output from the \npeer\n and chaincodes.\n\n\nTerminal 3 (CLI or REST API)\n\n\nNote on REST API port\n\n\nThe default REST interface port is \n7050\n. It can be configured in \ncore.yaml\n using the \nrest.address\n property. If using Vagrant, the REST port mapping is defined in \nVagrantfile\n.\n\n\nNote on security functionality\n\n\nCurrent security implementation assumes that end user authentication takes place at the application layer and is not handled by the fabric. Authentication may be performed through any means considered appropriate for the target application. Upon successful user authentication, the application will perform user registration with the CA exactly once. If registration is attempted a second time for the same user, an error will result. During registration, the application sends a request to the certificate authority to verify the user registration and if successful, the CA responds with the user certificates and keys. The enrollment and transaction certificates received from the CA will be stored locally inside \n/var/hyperledger/production/crypto/client/\n directory. This directory resides on a specific peer node which allows the user to transact only through this specific peer while using the stored crypto material. If the end user needs to perform transactions through more then one peer node, the application is responsible for replicating the crypto material to other peer nodes. This is necessary as registering a given user with the CA a second time will fail.\n\n\nWith security enabled, the CLI commands and REST payloads must be modified to include the \nenrollmentID\n of a registered user who is logged in; otherwise an error will result. A registered user can be logged in through the CLI or the REST API by following the instructions below. To log in through the CLI, issue the following commands, where \nusername\n is one of the \nenrollmentID\n values listed in the \neca.users\n section of the \nmembersrvc.yaml\n file.\n\n\nFrom your command line terminal, move to the \ndevenv\n subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:\n\n\n    vagrant ssh\n\n\n\n\nRegister the user though the CLI, substituting for \nusername\n appropriately:\n\n\n    cd $GOPATH/src/github.com/hyperledger/fabric/peer\n    peer network login \nusername\n\n\n\n\n\nThe command will prompt for a password, which must match the \nenrollmentPW\n listed for the target user in the \neca.users\n section of the \nmembersrvc.yaml\n file. If the password entered does not match the \nenrollmentPW\n, an error will result.\n\n\nTo log in through the REST API, send a POST request to the \n/registrar\n endpoint, containing the \nenrollmentID\n and \nenrollmentPW\n listed in the \neca.users\n section of the \nmembersrvc.yaml\n file.\n\n\nREST Request:\n\n\nPOST localhost:7050/registrar\n\n{\n  \nenrollId\n: \njim\n,\n  \nenrollSecret\n: \n6avZQLwcUe9b\n\n}\n\n\n\n\nREST Response:\n\n\n200 OK\n{\n    \nOK\n: \nLogin successful for user 'jim'.\n\n}\n\n\n\n\nchaincode deploy via CLI and REST\n\n\nFirst, send a chaincode deploy transaction, only once, to the validating peer. The CLI connects to the validating peer using the properties defined in the core.yaml file. \nNote:\n The deploy transaction typically requires a \npath\n parameter to locate, build, and deploy the chaincode. However, because these instructions are specific to local development mode and the chaincode is deployed manually, the \nname\n parameter is used instead.\n\n\npeer chaincode deploy -n mycc -c '{\nFunction\n:\ninit\n, \nArgs\n: [\na\n,\n100\n, \nb\n, \n200\n]}'\n\n\n\n\nAlternatively, you can run the chaincode deploy transaction through the REST API.\n\n\nREST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: 1,\n    \nchaincodeID\n:{\n        \nname\n: \nmycc\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n100\n, \nb\n, \n200\n]\n    }\n  },\n  \nid\n: 1\n}\n\n\n\n\nREST Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \nmycc\n\n    },\n    \nid\n: 1\n}\n\n\n\n\nNote:\n When security is enabled, modify the CLI command and the REST API payload to pass the \nenrollmentID\n of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the \nnote on security functionality\n. On the CLI, the \nenrollmentID\n is passed with the \n-u\n parameter; in the REST API, the \nenrollmentID\n is passed with the \nsecureContext\n element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).\n\n\n  CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode deploy -u jim -n mycc -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'\n\n\n\nREST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: 1,\n    \nchaincodeID\n:{\n        \nname\n: \nmycc\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n100\n, \nb\n, \n200\n]\n    },\n    \nsecureContext\n: \njim\n\n  },\n  \nid\n: 1\n}\n\n\n\n\nThe deploy transaction initializes the chaincode by executing a target initializing function. Though the example shows \ninit\n, the name could be arbitrarily chosen by the chaincode developer. You should see the following output in the chaincode window:\n\n\n    2015/11/15 15:19:31 Received INIT(uuid:005dea42-d57f-4983-803e-3232e551bf61), initializing chaincode\n    Aval = 100, Bval = 200\n\n\n\n\nChaincode invoke via CLI and REST\n\n\nRun the chaincode invoking transaction on the CLI as many times as desired. The \n-n\n argument should match the value provided in the chaincode window (started in Vagrant terminal 2):\n\n\n    peer chaincode invoke -l golang -n mycc -c '{\nFunction\n: \ninvoke\n, \nArgs\n: [\na\n, \nb\n, \n10\n]}'\n\n\n\n\nAlternatively, run the chaincode invoking transaction through the REST API.\n\n\nREST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\nmycc\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\ninvoke\n,\n         \nargs\n:[\na\n, \nb\n, \n10\n]\n      }\n  },\n  \nid\n: 3\n}\n\n\n\n\nREST Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n5a4540e5-902b-422d-a6ab-e70ab36a2e6d\n\n    },\n    \nid\n: 3\n}\n\n\n\n\nNote:\n When security is enabled, modify the CLI command and REST API payload to pass the \nenrollmentID\n of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the \nnote on security functionality\n. On the CLI, the \nenrollmentID\n is passed with the \n-u\n parameter; in the REST API, the \nenrollmentID\n is passed with the \nsecureContext\n element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).\n\n\n  CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode invoke -u jim -l golang -n mycc -c '{\"Function\": \"invoke\", \"Args\": [\"a\", \"b\", \"10\"]}'\n\n\n\nREST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\nmycc\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\ninvoke\n,\n         \nargs\n:[\na\n, \nb\n, \n10\n]\n      },\n      \nsecureContext\n: \njim\n\n  },\n  \nid\n: 3\n}\n\n\n\n\nThe invoking transaction runs the specified chaincode function name \ninvoke\n with the arguments. This transaction transfers 10 units from A to B. You should see the following output in the chaincode window:\n\n\n    2015/11/15 15:39:11 Received RESPONSE. Payload 200, Uuid 075d72a4-4d1f-4a1d-a735-4f6f60d597a9\n    Aval = 90, Bval = 210\n\n\n\n\nChaincode query via CLI and REST\n\n\nRun a query on the chaincode to retrieve the desired values. The \n-n\n argument should match the value provided in the chaincode window (started in Vagrant terminal 2):\n\n\n    peer chaincode query -l golang -n mycc -c '{\nFunction\n: \nquery\n, \nArgs\n: [\nb\n]}'\n\n\n\n\nThe response should be similar to the following:\n\n\n    {\nName\n:\nb\n,\nAmount\n:\n210\n}\n\n\n\n\nIf a name other than \na\n or \nb\n is provided in a query sent to \nchaincode_example02\n, you should see an error response similar to the following:\n\n\n    {\nError\n:\nNil amount for c\n}\n\n\n\n\nAlternatively, run the chaincode query transaction through the REST API.\n\n\nREST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\nmycc\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\nquery\n,\n         \nargs\n:[\na\n]\n      }\n  },\n  \nid\n: 5\n}\n\n\n\n\nREST Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n90\n\n    },\n    \nid\n: 5\n}\n\n\n\n\nNote:\n When security is enabled, modify the CLI command and REST API payload to pass the \nenrollmentID\n of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the \nnote on security functionality\n. On the CLI, the \nenrollmentID\n is passed with the \n-u\n parameter; in the REST API, the \nenrollmentID\n is passed with the \nsecureContext\n element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).\n\n\n      CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode query -u jim -l golang -n mycc -c '{\nFunction\n: \nquery\n, \nArgs\n: [\nb\n]}'\n\n\n\n\nREST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\nmycc\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\nquery\n,\n         \nargs\n:[\na\n]\n      },\n      \nsecureContext\n: \njim\n\n  },\n  \nid\n: 5\n}\n\n\n\n\nRemoving temporary files when security is enabled\n\n\nNote:\n this step applies \nONLY\n if you were using Option 1 above. For Option 2 or 3, the cleanup is handled by Docker.\n\n\nAfter the completion of a chaincode test with security enabled, remove the temporary files that were created by the CA server process. To remove the client enrollment certificate, enrollment key, transaction certificate chain, etc., run the following commands. Note, that you must run these commands if you want to register a user who has already been registered previously.\n\n\nFrom your command line terminal, \nssh\n into Vagrant:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant ssh\n\n\n\n\nAnd then run:\n\n\nrm -rf /var/hyperledger/production",
            "title": "Chaincode or Application Developer Setup"
        },
        {
            "location": "/Setup/Chaincode-setup/#writing-building-and-running-chaincode-in-a-development-environment",
            "text": "Chaincode developers need a way to test and debug their chaincode without having to set up a complete peer network. By default, when you want to interact with chaincode, you need to first  Deploy  it using the CLI, REST API, gRPC API, or SDK. Upon receiving this request, the peer node would typically spin up a Docker container with the relevant chaincode. This can make things rather complicated for debugging chaincode under development, because of the turnaround time with the  launch chaincode - debug docker container - fix problem - launch chaincode - lather - rinse - repeat  cycle. As such, the fabric peer has a  --peer-chaincodedev  flag that can be passed on start-up to instruct the peer node not to deploy the chaincode as a Docker container.  The following instructions apply to  developing  chaincode in Go or Java. They do not apply to running in a production environment. However, if  developing  chaincode in Java, please see the  Java chaincode setup  instructions first, to be sure your environment is properly configured.  Note:  We have added support for  System chaincode .",
            "title": "Writing, Building, and Running Chaincode in a Development Environment"
        },
        {
            "location": "/Setup/Chaincode-setup/#choices",
            "text": "Once again, you have the choice of using one of the following approaches:   Option 1  using the  Vagrant   development environment  that is used for developing the fabric itself  Option 2  using Docker for Mac or Windows  Option 3  using Docker toolbox   By using options  2  or  3 , above, you avoid having to build everything from scratch, and there s no need to keep a clone of the fabric GitHub repos current/up-to-date. Instead, you can simply pull and run the  fabric-peer  and  fabric-membersrvc  images directly from DockerHub.  You will need multiple terminal windows - essentially one for each component. One runs the validating peer; another  runs the chaincode; the third runs the CLI or REST API commands to execute transactions. Finally, when running with security enabled, an additional fourth window is required to run the  Certificate Authority (CA)  server. Detailed instructions are provided in the sections below.",
            "title": "Choices"
        },
        {
            "location": "/Setup/Chaincode-setup/#option-1-vagrant-development-environment",
            "text": "",
            "title": "Option 1 Vagrant development environment"
        },
        {
            "location": "/Setup/Chaincode-setup/#security-setup-optional",
            "text": "From the  devenv  subdirectory of your fabric workspace environment,  ssh  into Vagrant:  cd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant ssh  To set up the local development environment with security enabled, you must first build and run the  Certificate Authority (CA)  server:  cd $GOPATH/src/github.com/hyperledger/fabric\nmake membersrvc   membersrvc  Running the above commands builds and runs the CA server with the default setup, which is defined in the  membersrvc.yaml  configuration file. The default configuration includes multiple users who are already registered with the CA; these users are listed in the  eca.users  section of the configuration file. To register additional users with the CA for testing, modify the  eca.users  section of the  membersrvc.yaml  file to include additional  enrollmentID  and  enrollmentPW  pairs. Note the integer that precedes the  enrollmentPW . That integer indicates the role of the user, where 1 = client, 2 = non-validating peer, 4 = validating peer, and 8 = auditor.",
            "title": "Security Setup (optional)"
        },
        {
            "location": "/Setup/Chaincode-setup/#running-the-validating-peer",
            "text": "Note:  To run with security enabled, first modify the  core.yaml  configuration file to set the  security.enabled  value to  true  before building the peer executable. Alternatively, you can enable security by running the peer with the following environment variable:  CORE_SECURITY_ENABLED=true . To enable privacy and confidentiality of transactions (which requires security to also be enabled), modify the  core.yaml  configuration file to set the  security.privacy  value to  true  as well. Alternatively, you can enable privacy by running the peer with the following environment variable:  CORE_SECURITY_PRIVACY=true . If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).  In a  new  terminal window, from the  devenv  subdirectory of your fabric workspace environment,  ssh  into Vagrant:  cd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant ssh  Build and run the peer process to enable security and privacy after setting  security.enabled  and  security.privacy  settings to  true .  cd $GOPATH/src/github.com/hyperledger/fabric\nmake peer\npeer node start --peer-chaincodedev  Alternatively, rather than tweaking the  core.yaml  and rebuilding, you can enable security and privacy on the peer with environment variables:  CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer node start --peer-chaincodedev  Now, you are ready to start  running the chaincode .",
            "title": "Running the validating peer"
        },
        {
            "location": "/Setup/Chaincode-setup/#option-2-docker-for-mac-or-windows",
            "text": "If you would prefer to simply run the fabric components as built and published by the Hyperledger project on your Mac or Windows laptop/server using the Docker for  Mac  or  Windows  platform, following these steps. If using  Docker Toolbox , please skip to  Option 3 , below.",
            "title": "Option 2 Docker for Mac or Windows"
        },
        {
            "location": "/Setup/Chaincode-setup/#pull-images-from-dockerhub",
            "text": "First, pull the latest images published by the Hyperledger fabric project from DockerHub.  docker pull hyperledger/fabric-peer:latest\ndocker pull hyperledger/fabric-membersrvc:latest",
            "title": "Pull images from DockerHub"
        },
        {
            "location": "/Setup/Chaincode-setup/#running-the-peer-and-ca",
            "text": "To run the fabric-peer and fabric-membersrvc images, we ll use  Docker Compose . It significantly simplifies things. To do that, we ll create a docker-compose.yml file with a description of the two services we ll be running. Here s the docker-compose.yml to launch the two processes:  membersrvc:\n  image: hyperledger/fabric-membersrvc\n  ports:\n    -  7054:7054 \n  command: membersrvc\nvp0:\n  image: hyperledger/fabric-peer\n  ports:\n    -  7050:7050 \n    -  7051:7051 \n    -  7053:7053 \n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=unix:///var/run/docker.sock\n    - CORE_LOGGING_LEVEL=DEBUG\n    - CORE_PEER_ID=vp0\n    - CORE_PEER_PKI_ECA_PADDR=membersrvc:7054\n    - CORE_PEER_PKI_TCA_PADDR=membersrvc:7054\n    - CORE_PEER_PKI_TLSCA_PADDR=membersrvc:7054\n    - CORE_SECURITY_ENABLED=true\n    - CORE_SECURITY_ENROLLID=test_vp0\n    - CORE_SECURITY_ENROLLSECRET=MwYpmSRjupbT\n  links:\n    - membersrvc\n  command: sh -c  sleep 5; peer node start --peer-chaincodedev   Save that in a directory with the name  docker-compose.yml . Then, run  docker-compose up  to start the two processes.  Now, you are ready to start  running the chaincode .",
            "title": "Running the Peer and CA"
        },
        {
            "location": "/Setup/Chaincode-setup/#option-3-docker-toolbox",
            "text": "If you are using  Docker Toolbox , please follow these instructions.",
            "title": "Option 3 Docker Toolbox"
        },
        {
            "location": "/Setup/Chaincode-setup/#pull-images-from-dockerhub_1",
            "text": "First, pull the latest images published by the Hyperledger fabric project from DockerHub.    docker pull hyperledger/fabric-peer:latest\n  docker pull hyperledger/fabric-membersrvc:latest",
            "title": "Pull images from DockerHub"
        },
        {
            "location": "/Setup/Chaincode-setup/#running-the-peer-and-ca_1",
            "text": "To run the fabric-peer and fabric-membersrvc images, we ll use  Docker Compose . It significantly simplifies things. To do that, we ll create a docker-compose.yml file with a description of the two services we ll be running. Here s the docker-compose.yml to launch the two processes:  membersrvc:\n  image: hyperledger/fabric-membersrvc\n  command: membersrvc\nvp0:\n  image: hyperledger/fabric-peer\n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=http://172.17.0.1:2375\n    - CORE_LOGGING_LEVEL=DEBUG\n    - CORE_PEER_ID=vp0\n    - CORE_PEER_PKI_ECA_PADDR=membersrvc:7054\n    - CORE_PEER_PKI_TCA_PADDR=membersrvc:7054\n    - CORE_PEER_PKI_TLSCA_PADDR=membersrvc:7054\n    - CORE_SECURITY_ENABLED=true\n    - CORE_SECURITY_ENROLLID=test_vp0\n    - CORE_SECURITY_ENROLLSECRET=MwYpmSRjupbT\n  links:\n    - membersrvc\n  command: sh -c  sleep 5; peer node start --peer-chaincodedev   Save that in a directory with the name  docker-compose.yml . Then, run  docker-compose up  to start the two processes.",
            "title": "Running the Peer and CA"
        },
        {
            "location": "/Setup/Chaincode-setup/#running-the-chaincode",
            "text": "Start a  new  terminal window.",
            "title": "Running the chaincode"
        },
        {
            "location": "/Setup/Chaincode-setup/#vagrant",
            "text": "If you are using  Option 1 , you ll need to  ssh  to Vagrant. Otherwise,  skip  this step.  cd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant ssh  Next, we ll build the  chaincode_example02  code, which is provided in the Hyperledger fabric source code repository. If you are using  Option 1 , then you can do this from your clone of the fabric repository.  cd $GOPATH/src/github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\ngo build",
            "title": "Vagrant"
        },
        {
            "location": "/Setup/Chaincode-setup/#not-vagrant",
            "text": "If you are using either  Option 2  or  Option 3 , you ll need to  download the sample chaincode. The chaincode project must be placed somewhere under the  src  directory in your local  $GOPATH  as shown below.  mkdir -p $GOPATH/src/github.com/chaincode_example02/\ncd $GOPATH/src/github.com/chaincode_example02\ncurl GET https://raw.githubusercontent.com/hyperledger/fabric/master/examples/chaincode/go/chaincode_example02/chaincode_example02.go   chaincode_example02.go  Next, you ll need to clone the Hyperledger fabric to your local $GOPATH, so that you can build your chaincode.  Note:  this is a temporary stop-gap until we can provide an independent package for the chaincode shim.  mkdir -p $GOPATH/src/github.com/hyperledger\ncd $GOPATH/src/github.com/hyperledger\ngit clone http://gerrit.hyperledger.org/r/fabric  Now, you should be able to build your chaincode.  cd $GOPATH/src/github.com/chaincode_example02\ngo build  When you are ready to start creating your own Go chaincode, create a new subdirectory under $GOPATH/src. You can copy the  chaincode_example02  file to the new directory and modify it.",
            "title": "Not Vagrant"
        },
        {
            "location": "/Setup/Chaincode-setup/#starting-and-registering-the-chaincode",
            "text": "Run the following chaincode command to start and register the chaincode with the validating peer:  CORE_CHAINCODE_ID_NAME=mycc CORE_PEER_ADDRESS=0.0.0.0:7051 ./chaincode_example02  The chaincode console will display the message  Received REGISTERED, ready for invocations , which indicates that the chaincode is ready to receive requests. Follow the steps below to send a chaincode deploy, invoke or query transaction. If the  Received REGISTERED  message is not displayed, then an error has occurred during the deployment; revisit the previous steps to resolve the issue.",
            "title": "Starting and registering the chaincode"
        },
        {
            "location": "/Setup/Chaincode-setup/#running-the-cli-or-rest-api",
            "text": "chaincode deploy via CLI and REST  chaincode invoke via CLI and REST  chaincode query via CLI and REST   If you were running with security enabled, see  Removing temporary files when security is enabled  to learn how to clean up the temporary files.  See the  logging control  reference for information on controlling\nlogging output from the  peer  and chaincodes.",
            "title": "Running the CLI or REST API"
        },
        {
            "location": "/Setup/Chaincode-setup/#terminal-3-cli-or-rest-api",
            "text": "",
            "title": "Terminal 3 (CLI or REST API)"
        },
        {
            "location": "/Setup/Chaincode-setup/#note-on-rest-api-port",
            "text": "The default REST interface port is  7050 . It can be configured in  core.yaml  using the  rest.address  property. If using Vagrant, the REST port mapping is defined in  Vagrantfile .",
            "title": "Note on REST API port"
        },
        {
            "location": "/Setup/Chaincode-setup/#note-on-security-functionality",
            "text": "Current security implementation assumes that end user authentication takes place at the application layer and is not handled by the fabric. Authentication may be performed through any means considered appropriate for the target application. Upon successful user authentication, the application will perform user registration with the CA exactly once. If registration is attempted a second time for the same user, an error will result. During registration, the application sends a request to the certificate authority to verify the user registration and if successful, the CA responds with the user certificates and keys. The enrollment and transaction certificates received from the CA will be stored locally inside  /var/hyperledger/production/crypto/client/  directory. This directory resides on a specific peer node which allows the user to transact only through this specific peer while using the stored crypto material. If the end user needs to perform transactions through more then one peer node, the application is responsible for replicating the crypto material to other peer nodes. This is necessary as registering a given user with the CA a second time will fail.  With security enabled, the CLI commands and REST payloads must be modified to include the  enrollmentID  of a registered user who is logged in; otherwise an error will result. A registered user can be logged in through the CLI or the REST API by following the instructions below. To log in through the CLI, issue the following commands, where  username  is one of the  enrollmentID  values listed in the  eca.users  section of the  membersrvc.yaml  file.  From your command line terminal, move to the  devenv  subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:      vagrant ssh  Register the user though the CLI, substituting for  username  appropriately:      cd $GOPATH/src/github.com/hyperledger/fabric/peer\n    peer network login  username   The command will prompt for a password, which must match the  enrollmentPW  listed for the target user in the  eca.users  section of the  membersrvc.yaml  file. If the password entered does not match the  enrollmentPW , an error will result.  To log in through the REST API, send a POST request to the  /registrar  endpoint, containing the  enrollmentID  and  enrollmentPW  listed in the  eca.users  section of the  membersrvc.yaml  file.  REST Request:  POST localhost:7050/registrar\n\n{\n   enrollId :  jim ,\n   enrollSecret :  6avZQLwcUe9b \n}  REST Response:  200 OK\n{\n     OK :  Login successful for user 'jim'. \n}",
            "title": "Note on security functionality"
        },
        {
            "location": "/Setup/Chaincode-setup/#chaincode-deploy-via-cli-and-rest",
            "text": "First, send a chaincode deploy transaction, only once, to the validating peer. The CLI connects to the validating peer using the properties defined in the core.yaml file.  Note:  The deploy transaction typically requires a  path  parameter to locate, build, and deploy the chaincode. However, because these instructions are specific to local development mode and the chaincode is deployed manually, the  name  parameter is used instead.  peer chaincode deploy -n mycc -c '{ Function : init ,  Args : [ a , 100 ,  b ,  200 ]}'  Alternatively, you can run the chaincode deploy transaction through the REST API.  REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type : 1,\n     chaincodeID :{\n         name :  mycc \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  100 ,  b ,  200 ]\n    }\n  },\n   id : 1\n}  REST Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  mycc \n    },\n     id : 1\n}  Note:  When security is enabled, modify the CLI command and the REST API payload to pass the  enrollmentID  of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the  note on security functionality . On the CLI, the  enrollmentID  is passed with the  -u  parameter; in the REST API, the  enrollmentID  is passed with the  secureContext  element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).    CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode deploy -u jim -n mycc -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'  REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type : 1,\n     chaincodeID :{\n         name :  mycc \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  100 ,  b ,  200 ]\n    },\n     secureContext :  jim \n  },\n   id : 1\n}  The deploy transaction initializes the chaincode by executing a target initializing function. Though the example shows  init , the name could be arbitrarily chosen by the chaincode developer. You should see the following output in the chaincode window:      2015/11/15 15:19:31 Received INIT(uuid:005dea42-d57f-4983-803e-3232e551bf61), initializing chaincode\n    Aval = 100, Bval = 200",
            "title": "chaincode deploy via CLI and REST"
        },
        {
            "location": "/Setup/Chaincode-setup/#chaincode-invoke-via-cli-and-rest",
            "text": "Run the chaincode invoking transaction on the CLI as many times as desired. The  -n  argument should match the value provided in the chaincode window (started in Vagrant terminal 2):      peer chaincode invoke -l golang -n mycc -c '{ Function :  invoke ,  Args : [ a ,  b ,  10 ]}'  Alternatively, run the chaincode invoking transaction through the REST API.  REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : mycc \n      },\n       ctorMsg : {\n          function : invoke ,\n          args :[ a ,  b ,  10 ]\n      }\n  },\n   id : 3\n}  REST Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  5a4540e5-902b-422d-a6ab-e70ab36a2e6d \n    },\n     id : 3\n}  Note:  When security is enabled, modify the CLI command and REST API payload to pass the  enrollmentID  of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the  note on security functionality . On the CLI, the  enrollmentID  is passed with the  -u  parameter; in the REST API, the  enrollmentID  is passed with the  secureContext  element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).    CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode invoke -u jim -l golang -n mycc -c '{\"Function\": \"invoke\", \"Args\": [\"a\", \"b\", \"10\"]}'  REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : mycc \n      },\n       ctorMsg : {\n          function : invoke ,\n          args :[ a ,  b ,  10 ]\n      },\n       secureContext :  jim \n  },\n   id : 3\n}  The invoking transaction runs the specified chaincode function name  invoke  with the arguments. This transaction transfers 10 units from A to B. You should see the following output in the chaincode window:      2015/11/15 15:39:11 Received RESPONSE. Payload 200, Uuid 075d72a4-4d1f-4a1d-a735-4f6f60d597a9\n    Aval = 90, Bval = 210",
            "title": "Chaincode invoke via CLI and REST"
        },
        {
            "location": "/Setup/Chaincode-setup/#chaincode-query-via-cli-and-rest",
            "text": "Run a query on the chaincode to retrieve the desired values. The  -n  argument should match the value provided in the chaincode window (started in Vagrant terminal 2):      peer chaincode query -l golang -n mycc -c '{ Function :  query ,  Args : [ b ]}'  The response should be similar to the following:      { Name : b , Amount : 210 }  If a name other than  a  or  b  is provided in a query sent to  chaincode_example02 , you should see an error response similar to the following:      { Error : Nil amount for c }  Alternatively, run the chaincode query transaction through the REST API.  REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : mycc \n      },\n       ctorMsg : {\n          function : query ,\n          args :[ a ]\n      }\n  },\n   id : 5\n}  REST Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  90 \n    },\n     id : 5\n}  Note:  When security is enabled, modify the CLI command and REST API payload to pass the  enrollmentID  of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the  note on security functionality . On the CLI, the  enrollmentID  is passed with the  -u  parameter; in the REST API, the  enrollmentID  is passed with the  secureContext  element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).        CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode query -u jim -l golang -n mycc -c '{ Function :  query ,  Args : [ b ]}'  REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : mycc \n      },\n       ctorMsg : {\n          function : query ,\n          args :[ a ]\n      },\n       secureContext :  jim \n  },\n   id : 5\n}",
            "title": "Chaincode query via CLI and REST"
        },
        {
            "location": "/Setup/Chaincode-setup/#removing-temporary-files-when-security-is-enabled",
            "text": "Note:  this step applies  ONLY  if you were using Option 1 above. For Option 2 or 3, the cleanup is handled by Docker.  After the completion of a chaincode test with security enabled, remove the temporary files that were created by the CA server process. To remove the client enrollment certificate, enrollment key, transaction certificate chain, etc., run the following commands. Note, that you must run these commands if you want to register a user who has already been registered previously.  From your command line terminal,  ssh  into Vagrant:  cd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant ssh  And then run:  rm -rf /var/hyperledger/production",
            "title": "Removing temporary files when security is enabled"
        },
        {
            "location": "/Setup/JAVAChaincode/",
            "text": "Java chaincode\n\n\nNote: This guide generally assumes you have followed the Chaincode development environment setup tutorial \nhere\n.\n\n\nTo get started developing Java chaincode\n\n\n\n\nEnsure you have gradle\n\n\nDownload the binary distribution from \nhttp://gradle.org/gradle-download/\n\n\nUnpack, move to the desired location, and add gradle\ns bin directory to your system path\n\n\nEnsure \ngradle -v\n works from the command-line, and shows version 2.12 or greater\n\n\nOptionally, enable the \ngradle daemon\n for faster builds\n\n\nEnsure you have the Java 1.8 \nJDK\n installed. Also ensure Java\ns directory is on your path with \njava -version\n\n\nAdditionally, you will need to have the \nJAVA HOME\n variable set to your \nJDK\n installation in your system path\n\n\n\n\nFrom your command line terminal, move to the \ndevenv\n subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:\n\n\nvagrant ssh\n\n\n\n\n\n\nBuild and run the peer process.\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer\npeer node start\n\n\n\n\n\n\nThe following steps is for deploying chaincode in non-dev mode.\n\n\n\n\nDeploy the chaincode,\n\n\n\n\n\n\n\n\n    peer chaincode deploy -l java -p /opt/gopath/src/github.com/hyperledger/fabric/examples/chaincode/java/SimpleSample -c '{\nArgs\n: [\ninit\n, \na\n,\n100\n, \nb\n, \n200\n]}'\n\n\n\n\n6d9a704d95284593fe802a5de89f84e86fb975f00830bc6488713f9441b835cf32d9cd07b087b90e5cb57a88360f90a4de39521a5595545ad689cd64791679e9\n\n\n    * This command will give the 'name' for this chaincode, and use this value in all the further commands with the -n (name) parameter\n\n\n    * PS. This may take a few minutes depending on the environment as it deploys the chaincode in the container,\n\n\n\n\n\nInvoke a transfer transaction,\n\n\n\n\n    peer chaincode invoke -l java \\\n    -n 6d9a704d95284593fe802a5de89f84e86fb975f00830bc6488713f9441b835cf32d9cd07b087b90e5cb57a88360f90a4de39521a5595545ad689cd64791679e9 \\\n    -c '{\nArgs\n: [\ntransfer\n, \na\n, \nb\n, \n10\n]}'\n\n\n\n\nc7dde1d7-fae5-4b68-9ab1-928d61d1e346\n\n\n\n\nQuery the values of a and b after the transfer\n\n\n\n\n    peer chaincode query -l java \\\n    -n 6d9a704d95284593fe802a5de89f84e86fb975f00830bc6488713f9441b835cf32d9cd07b087b90e5cb57a88360f90a4de39521a5595545ad689cd64791679e9 \\\n    -c '{ \nArgs\n: [\nquery\n, \na\n]}'\n    {\nName\n:\na\n,\nAmount\n:\n80\n}\n\n\n    peer chaincode query -l java \\\n    -n 6d9a704d95284593fe802a5de89f84e86fb975f00830bc6488713f9441b835cf32d9cd07b087b90e5cb57a88360f90a4de39521a5595545ad689cd64791679e9 \\\n    -c '{ \nArgs\n: [\nquery\n, \nb\n]}'\n    {\nName\n:\nb\n,\nAmount\n:\n220\n}\n\n\n\n\nJava chaincode deployment in DEV Mode\n\n\n\n\nFollow the step 1 to 3 as above,\n\n\nBuild and run the peer process\n\n\n\n\n    cd $GOPATH/src/github.com/hyperledger/fabric\n    make peer\n    peer node start --peer-chaincodedev\n\n\n\n\n\n\nOpen the second Vagrant terminal, and change to Java shim root folder and run gradle build,\n\n\n\n\n    cd $GOPATH/src/github.com/hyperledger/fabric/examples/chaincode/java/SimpleSample\n    gradle -b build.gradle build\n\n\n\n\n\n\n\n\nRun the SimpleSample chaincode using the \ngradle -b build.gradle run\n\n\n\n\n\n\nOpen the third Vagrant terminal to run init and invoke on the chaincode\n\n\npeer chaincode deploy -l java -n SimpleSample -c \n{\nArgs\n: [\ninit\n, \na\n,\n100\n, \nb\n, \n200\n]}\n\n\n\n\n\n\n2016/06/28 19:10:15 Load docker HostConfig: %+v \n{[] [] []  [] false map[] [] false [] [] [] [] host    { 0} [] { map[]} false []  0 0 0 false 0    0 0 0 []}\n19:10:15.461 [crypto] main -\n INFO 002 Log level recognized 'info', set to INFO\nSimpleSample\n\n\n\n\npeer chaincode invoke -l java -n SimpleSample -c '{\"Args\": [\"transfer\", \"a\", \"b\", \"10\"]}'\n\n\n\n2016/06/28 19:11:13 Load docker HostConfig: %+v \n{[] [] []  [] false map[] [] false [] [] [] [] host    { 0} [] { map[]} false []  0 0 0 false 0    0 0 0 []}\n19:11:13.553 [crypto] main -\n INFO 002 Log level recognized 'info', set to INFO\n978ff89e-e4ef-43da-a9f8-625f2f6f04e5\n\n\n\n\npeer chaincode query -l java -n SimpleSample -c '{ \"Args\": [\"query\", \"a\"]}'\n\n\n\n2016/06/28 19:12:19 Load docker HostConfig: %+v \n{[] [] []  [] false map[] [] false [] [] [] [] host    { 0} [] { map[]} false []  0 0 0 false 0    0 0 0 []}\n19:12:19.289 [crypto] main -\n INFO 002 Log level recognized 'info', set to INFO\n{\nName\n:\na\n,\nAmount\n:\n90\n}\n\n\n\n\npeer chaincode query -l java -n SimpleSample -c '{\"Args\": [\"query\", \"b\"]}'\n\n\n\n2016/06/28 19:12:25 Load docker HostConfig: %+v \n{[] [] []  [] false map[] [] false [] [] [] [] host    { 0} [] { map[]} false []  0 0 0 false 0    0 0 0 []}\n19:12:25.667 [crypto] main -\n INFO 002 Log level recognized 'info', set to INFO\n{\nName\n:\nb\n,\nAmount\n:\n210\n}\n\n\n\n\nDeveloping new JAVA chaincode\n\n\n\n\nCreate a new Java project structure.\n\n\nUse existing \nbuild.grade\n from  any example JAVA Chaincode project like \nexamples/chaincode/java/SimpleSample\n.\n\n\nMake your main class extend ChaincodeBase class and implement the following methods from base class.\n\n\npublic String run(ChaincodeStub stub, String function, String[] args)\n\n\npublic String query(ChaincodeStub stub, String function, String[] args)\n\n\npublic String getChaincodeID()\n\n\nModify the \nmainClassName\n in \nbuild.gradle\n to point to your new class.\n\n\nBuild this project using \ngradle -b build.gradle build\n\n\nRun this chaincode after starting a peer in dev-mode as above using \ngradle -b build.gradle run",
            "title": "Java Chaincode Setup"
        },
        {
            "location": "/Setup/JAVAChaincode/#java-chaincode",
            "text": "Note: This guide generally assumes you have followed the Chaincode development environment setup tutorial  here .",
            "title": "Java chaincode"
        },
        {
            "location": "/Setup/JAVAChaincode/#to-get-started-developing-java-chaincode",
            "text": "Ensure you have gradle  Download the binary distribution from  http://gradle.org/gradle-download/  Unpack, move to the desired location, and add gradle s bin directory to your system path  Ensure  gradle -v  works from the command-line, and shows version 2.12 or greater  Optionally, enable the  gradle daemon  for faster builds  Ensure you have the Java 1.8  JDK  installed. Also ensure Java s directory is on your path with  java -version  Additionally, you will need to have the  JAVA HOME  variable set to your  JDK  installation in your system path   From your command line terminal, move to the  devenv  subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:  vagrant ssh    Build and run the peer process.  cd $GOPATH/src/github.com/hyperledger/fabric\nmake peer\npeer node start    The following steps is for deploying chaincode in non-dev mode.   Deploy the chaincode,         peer chaincode deploy -l java -p /opt/gopath/src/github.com/hyperledger/fabric/examples/chaincode/java/SimpleSample -c '{ Args : [ init ,  a , 100 ,  b ,  200 ]}'  6d9a704d95284593fe802a5de89f84e86fb975f00830bc6488713f9441b835cf32d9cd07b087b90e5cb57a88360f90a4de39521a5595545ad689cd64791679e9      * This command will give the 'name' for this chaincode, and use this value in all the further commands with the -n (name) parameter\n\n\n    * PS. This may take a few minutes depending on the environment as it deploys the chaincode in the container,   Invoke a transfer transaction,       peer chaincode invoke -l java \\\n    -n 6d9a704d95284593fe802a5de89f84e86fb975f00830bc6488713f9441b835cf32d9cd07b087b90e5cb57a88360f90a4de39521a5595545ad689cd64791679e9 \\\n    -c '{ Args : [ transfer ,  a ,  b ,  10 ]}'  c7dde1d7-fae5-4b68-9ab1-928d61d1e346   Query the values of a and b after the transfer       peer chaincode query -l java \\\n    -n 6d9a704d95284593fe802a5de89f84e86fb975f00830bc6488713f9441b835cf32d9cd07b087b90e5cb57a88360f90a4de39521a5595545ad689cd64791679e9 \\\n    -c '{  Args : [ query ,  a ]}'\n    { Name : a , Amount : 80 }\n\n\n    peer chaincode query -l java \\\n    -n 6d9a704d95284593fe802a5de89f84e86fb975f00830bc6488713f9441b835cf32d9cd07b087b90e5cb57a88360f90a4de39521a5595545ad689cd64791679e9 \\\n    -c '{  Args : [ query ,  b ]}'\n    { Name : b , Amount : 220 }",
            "title": "To get started developing Java chaincode"
        },
        {
            "location": "/Setup/JAVAChaincode/#java-chaincode-deployment-in-dev-mode",
            "text": "Follow the step 1 to 3 as above,  Build and run the peer process       cd $GOPATH/src/github.com/hyperledger/fabric\n    make peer\n    peer node start --peer-chaincodedev   Open the second Vagrant terminal, and change to Java shim root folder and run gradle build,       cd $GOPATH/src/github.com/hyperledger/fabric/examples/chaincode/java/SimpleSample\n    gradle -b build.gradle build    Run the SimpleSample chaincode using the  gradle -b build.gradle run    Open the third Vagrant terminal to run init and invoke on the chaincode  peer chaincode deploy -l java -n SimpleSample -c  { Args : [ init ,  a , 100 ,  b ,  200 ]}    2016/06/28 19:10:15 Load docker HostConfig: %+v  {[] [] []  [] false map[] [] false [] [] [] [] host    { 0} [] { map[]} false []  0 0 0 false 0    0 0 0 []}\n19:10:15.461 [crypto] main -  INFO 002 Log level recognized 'info', set to INFO\nSimpleSample  peer chaincode invoke -l java -n SimpleSample -c '{\"Args\": [\"transfer\", \"a\", \"b\", \"10\"]}'  2016/06/28 19:11:13 Load docker HostConfig: %+v  {[] [] []  [] false map[] [] false [] [] [] [] host    { 0} [] { map[]} false []  0 0 0 false 0    0 0 0 []}\n19:11:13.553 [crypto] main -  INFO 002 Log level recognized 'info', set to INFO\n978ff89e-e4ef-43da-a9f8-625f2f6f04e5  peer chaincode query -l java -n SimpleSample -c '{ \"Args\": [\"query\", \"a\"]}'  2016/06/28 19:12:19 Load docker HostConfig: %+v  {[] [] []  [] false map[] [] false [] [] [] [] host    { 0} [] { map[]} false []  0 0 0 false 0    0 0 0 []}\n19:12:19.289 [crypto] main -  INFO 002 Log level recognized 'info', set to INFO\n{ Name : a , Amount : 90 }  peer chaincode query -l java -n SimpleSample -c '{\"Args\": [\"query\", \"b\"]}'  2016/06/28 19:12:25 Load docker HostConfig: %+v  {[] [] []  [] false map[] [] false [] [] [] [] host    { 0} [] { map[]} false []  0 0 0 false 0    0 0 0 []}\n19:12:25.667 [crypto] main -  INFO 002 Log level recognized 'info', set to INFO\n{ Name : b , Amount : 210 }",
            "title": "Java chaincode deployment in DEV Mode"
        },
        {
            "location": "/Setup/JAVAChaincode/#developing-new-java-chaincode",
            "text": "Create a new Java project structure.  Use existing  build.grade  from  any example JAVA Chaincode project like  examples/chaincode/java/SimpleSample .  Make your main class extend ChaincodeBase class and implement the following methods from base class.  public String run(ChaincodeStub stub, String function, String[] args)  public String query(ChaincodeStub stub, String function, String[] args)  public String getChaincodeID()  Modify the  mainClassName  in  build.gradle  to point to your new class.  Build this project using  gradle -b build.gradle build  Run this chaincode after starting a peer in dev-mode as above using  gradle -b build.gradle run",
            "title": "Developing new JAVA chaincode"
        },
        {
            "location": "/Setup/Network-setup/",
            "text": "Setting Up a Network\n\n\nThis document covers setting up a network on your local machine for various development and testing activities. Unless you are intending to contribute to the development of the Hyperledger Fabric project, you\nll probably want to follow the more commonly used approach below - \nleveraging published Docker images\n for the various Hyperledger Fabric components, directly. Otherwise, skip down to the \nsecondary approach\n below.\n\n\nLeveraging published Docker images\n\n\nThis approach simply leverages the Docker images that the Hyperledger Fabric project publishes to \nDockerHub\n and either Docker commands or Docker Compose descriptions of the network one wishes to create.\n\n\nInstalling Docker\n\n\nNote:\n When running Docker \nnatively\n on Mac and Windows, there is no IP forwarding support available. Hence, running more than one fabric-peer image is not advised because you do not want to have multiple processes binding to the same port. For most application and chaincode development/testing running with a single fabric peer should not be an issue unless you are interested in performance and resilience testing the fabric\ns capabilities, such as consensus. For more advanced testing, we strongly recommend using the fabric\ns Vagrant \ndevelopment environment\n.\n\n\nWith this approach, there are multiple choices as to how to run Docker: using \nDocker Toolbox\n or one of the new native Docker runtime environments for \nMac OSX\n or \nWindows\n. There are some subtle differences between how Docker runs natively on Mac and Windows versus in a virtualized context on Linux. We\nll call those out where appropriate below, when we get to the point of actually running the various components.\n\n\nPulling the images from DockerHub\n\n\nOnce you have Docker (1.11 or greater) installed and running,\nprior to starting any of the fabric components, you will need to first pull the fabric images from DockerHub.\n\n\n  docker pull hyperledger/fabric-peer:latest\n  docker pull hyperledger/fabric-membersrvc:latest\n\n\n\n\nBuilding your own images\n\n\nNote:\n \nThis approach is not necessarily recommended for most users\n. If you have pulled images from DockerHub as described in the previous section, you may proceed to the \nnext step\n.\n\n\nThe second approach would be to leverage the \ndevelopment environment\n setup (which we will assume you have already established) to build and deploy your own binaries and/or Docker images from a clone of the \nhyperledger/fabric\n GitHub repository. This approach is suitable for developers that might wish to contribute directly to the Hyperledger Fabric project, or that wish to deploy from a fork of the Hyperledger code base.\n\n\nThe following commands should be run from \nwithin\n the Vagrant environment described in \nSetting Up Development Environment\n.\n\n\nTo create the Docker image for the \nhyperledger/fabric-peer\n:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer-image\n\n\n\n\nTo create the Docker image for the \nhyperledger/fabric-membersrvc\n:\n\n\nmake membersrvc-image\n\n\n\n\nStarting up validating peers\n\n\nCheck the available images again with \ndocker images\n. You should see \nhyperledger/fabric-peer\n and \nhyperledger/fabric-membersrvc\n images. For example,\n\n\n$ docker images\nREPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE\nhyperledger/fabric-membersrvc   latest              7d5f6e0bcfac        12 days ago         1.439 GB\nhyperledger/fabric-peer         latest              82ef20d7507c        12 days ago         1.445 GB\n\n\n\n\nIf you don\nt see these, go back to the previous step.\n\n\nWith the relevant Docker images in hand, we can start running the peer and membersrvc services.\n\n\nDetermine value for CORE_VM_ENDPOINT variable\n\n\nNext, we need to determine the address of your docker daemon for the CORE_VM_ENDPOINT. If you are working within the Vagrant development environment, or a Docker Toolbox environment, you can determine this with the \nip add\n command. For example,\n\n\n$ ip add\n\n\n detail removed \n\n\n3: docker0: \nNO-CARRIER,BROADCAST,MULTICAST,UP\n mtu 1500 qdisc noqueue state DOWN group default\n    link/ether 02:42:ad:be:70:cb brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:adff:febe:70cb/64 scope link\n       valid_lft forever preferred_lft forever\n\n\n\n\nYour output might contain something like \ninet 172.17.0.1/16 scope global docker0\n. That means the docker0 interface is on IP address 172.17.0.1. Use that IP address for the \nCORE_VM_ENDPOINT\n option. For more information on the environment variables, see \ncore.yaml\n configuration file in the \nfabric\n repository.\n\n\nIf you are using the native Docker for Mac or Windows, the value for \nCORE_VM_ENDPOINT\n should be set to \nunix:///var/run/docker.sock\n. [TODO] double check this. I believe that \n127.0.0.1:2375\n also works.\n\n\nAssigning a value for CORE_PEER_ID\n\n\nThe ID value of \nCORE_PEER_ID\n must be unique for each validating peer, and it must be a lowercase string. We often use a convention of naming the validating peers vpN where N is an integer starting with 0 for the root node and incrementing N by 1 for each additional peer node started. e.g. vp0, vp1, vp2, \n\n\nConsensus\n\n\nBy default, we are using a consensus plugin called \nNOOPS\n, which doesn\nt really do consensus. If you are running a single peer node, running anything other than \nNOOPS\n makes little sense. If you want to use some other consensus plugin in the context of multiple peer nodes, please see the \nUsing a Consensus Plugin\n section, below.\n\n\nDocker Compose\n\n\nWe\nll be using Docker Compose to launch our various Fabric component containers, as this is the simplest approach. You should have it installed from the initial setup steps. Installing Docker Toolbox or any of the native Docker runtimes should have installed Compose.\n\n\nStart up a validating peer:\n\n\nLet\ns launch the first validating peer (the root node). We\nll set CORE_PEER_ID to vp0 and CORE_VM_ENDPOINT as above. Here\ns the docker-compose.yml for launching a single container within the \nVagrant\n \ndevelopment environment\n:\n\n\nvp0:\n  image: hyperledger/fabric-peer\n  environment:\n    - CORE_PEER_ID=vp0\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=http://172.17.0.1:2375\n    - CORE_LOGGING_LEVEL=DEBUG\n  command: peer node start\n\n\n\n\nYou can launch this Compose file as follows, from the same directory as the docker-compose.yml file:\n\n\n$ docker-compose up\n\n\n\n\nHere\ns the corresponding Docker command:\n\n\n$ docker run --rm -it -e CORE_VM_ENDPOINT=http://172.17.0.1:2375 -e CORE_LOGGING_LEVEL=DEBUG -e CORE_PEER_ID=vp0 -e CORE_PEER_ADDRESSAUTODETECT=true hyperledger/fabric-peer peer node start\n\n\n\n\nIf you are running Docker for Mac or Windows, we\nll need to explicitly map the ports, and we will need a different value for CORE_VM_ENDPOINT as we discussed above.\n\n\nHere\ns the docker-compose.yml for Docker on Mac or Windows:\n\n\nvp0:\n  image: hyperledger/fabric-peer\n  ports:\n    - \n7050:7050\n\n    - \n7051:7051\n\n    - \n7052:7052\n\n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=unix:///var/run/docker.sock\n    - CORE_LOGGING_LEVEL=DEBUG\n  command: peer node start\n\n\n\n\nThis single peer configuration, running the \nNOOPS\n \nconsensus\n plugin, should satisfy many development/test scenarios. \nNOOPS\n is not really providing consensus, it is essentially a no-op that simulates consensus. For instance, if you are simply developing and testing chaincode; this should be adequate unless your chaincode is leveraging membership services for identity, access control, confidentiality and privacy.\n\n\nRunning with the CA\n\n\nIf you want to take advantage of security (authentication and authorization), privacy and confidentiality, then you\nll need to run the Fabric\ns certificate authority (CA). Please refer to the \nCA Setup\n instructions.\n\n\nStart up additional validating peers:\n\n\nFollowing the pattern we established \nabove\n we\nll use \nvp1\n as the ID for the second validating peer. If using Docker Compose, we can simply link the two peer nodes.\nHere\ns the docker-compse.yml for a \nVagrant\n environment with two peer nodes - vp0 and vp1:\n\n\nvp0:\n  image: hyperledger/fabric-peer\n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=http://172.17.0.1:2375\n    - CORE_LOGGING_LEVEL=DEBUG\n  command: peer node start\nvp1:\n  extends:\n    service: vp0\n  environment:\n    - CORE_PEER_ID=vp1\n    - CORE_PEER_DISCOVERY_ROOTNODE=vp0:7051\n  links:\n    - vp0\n\n\n\n\nIf we wanted to use the docker command line to launch another peer, we need to get the IP address of the first validating peer, which will act as the root node to which the new peer(s) will connect. The address is printed out on the terminal window of the first peer (e.g. 172.17.0.2) and should be passed in with the \nCORE_PEER_DISCOVERY_ROOTNODE\n environment variable.\n\n\ndocker run --rm -it -e CORE_VM_ENDPOINT=http://172.17.0.1:2375 -e CORE_PEER_ID=vp1 -e CORE_PEER_ADDRESSAUTODETECT=true -e CORE_PEER_DISCOVERY_ROOTNODE=172.17.0.2:7051 hyperledger/fabric-peer peer node start\n\n\n\n\n\n\n\nUsing a Consensus Plugin\n\n\nA consensus plugin might require some specific configuration that you need to set up. For example, to use the Practical Byzantine Fault Tolerant (PBFT) consensus plugin provided as part of the fabric, perform the following configuration:\n\n\n\n\nIn \ncore.yaml\n, set the \npeer.validator.consensus\n value to \npbft\n\n\nIn \ncore.yaml\n, make sure the \npeer.id\n is set sequentially as \nvpN\n where \nN\n is an integer that starts from \n0\n and goes to \nN-1\n. For example, with 4 validating peers, set the \npeer.id\n to\nvp0\n, \nvp1\n, \nvp2\n, \nvp3\n.\n\n\nIn \nconsensus/pbft/config.yaml\n, set the \ngeneral.mode\n value to \nbatch\n and the \ngeneral.N\n value to the number of validating peers on the network, also set \ngeneral.batchsize\n to the number of transactions per batch.\n\n\nIn \nconsensus/pbft/config.yaml\n, optionally set timer values for the batch period (\ngeneral.timeout.batch\n), the acceptable delay between request and execution (\ngeneral.timeout.request\n), and for view-change (\ngeneral.timeout.viewchange\n)\n\n\n\n\nSee \ncore.yaml\n and \nconsensus/pbft/config.yaml\n for more detail.\n\n\nAll of these setting may be overridden via the command line environment variables, e.g. \nCORE_PEER_VALIDATOR_CONSENSUS_PLUGIN=pbft\n or \nCORE_PBFT_GENERAL_MODE=batch\n\n\nLogging control\n\n\nSee \nLogging Control\n for information on controlling\nlogging output from the \npeer\n and deployed chaincodes.",
            "title": "Fabric Network Setup"
        },
        {
            "location": "/Setup/Network-setup/#setting-up-a-network",
            "text": "This document covers setting up a network on your local machine for various development and testing activities. Unless you are intending to contribute to the development of the Hyperledger Fabric project, you ll probably want to follow the more commonly used approach below -  leveraging published Docker images  for the various Hyperledger Fabric components, directly. Otherwise, skip down to the  secondary approach  below.",
            "title": "Setting Up a Network"
        },
        {
            "location": "/Setup/Network-setup/#leveraging-published-docker-images",
            "text": "This approach simply leverages the Docker images that the Hyperledger Fabric project publishes to  DockerHub  and either Docker commands or Docker Compose descriptions of the network one wishes to create.",
            "title": "Leveraging published Docker images"
        },
        {
            "location": "/Setup/Network-setup/#installing-docker",
            "text": "Note:  When running Docker  natively  on Mac and Windows, there is no IP forwarding support available. Hence, running more than one fabric-peer image is not advised because you do not want to have multiple processes binding to the same port. For most application and chaincode development/testing running with a single fabric peer should not be an issue unless you are interested in performance and resilience testing the fabric s capabilities, such as consensus. For more advanced testing, we strongly recommend using the fabric s Vagrant  development environment .  With this approach, there are multiple choices as to how to run Docker: using  Docker Toolbox  or one of the new native Docker runtime environments for  Mac OSX  or  Windows . There are some subtle differences between how Docker runs natively on Mac and Windows versus in a virtualized context on Linux. We ll call those out where appropriate below, when we get to the point of actually running the various components.",
            "title": "Installing Docker"
        },
        {
            "location": "/Setup/Network-setup/#pulling-the-images-from-dockerhub",
            "text": "Once you have Docker (1.11 or greater) installed and running,\nprior to starting any of the fabric components, you will need to first pull the fabric images from DockerHub.    docker pull hyperledger/fabric-peer:latest\n  docker pull hyperledger/fabric-membersrvc:latest",
            "title": "Pulling the images from DockerHub"
        },
        {
            "location": "/Setup/Network-setup/#building-your-own-images",
            "text": "Note:   This approach is not necessarily recommended for most users . If you have pulled images from DockerHub as described in the previous section, you may proceed to the  next step .  The second approach would be to leverage the  development environment  setup (which we will assume you have already established) to build and deploy your own binaries and/or Docker images from a clone of the  hyperledger/fabric  GitHub repository. This approach is suitable for developers that might wish to contribute directly to the Hyperledger Fabric project, or that wish to deploy from a fork of the Hyperledger code base.  The following commands should be run from  within  the Vagrant environment described in  Setting Up Development Environment .  To create the Docker image for the  hyperledger/fabric-peer :  cd $GOPATH/src/github.com/hyperledger/fabric\nmake peer-image  To create the Docker image for the  hyperledger/fabric-membersrvc :  make membersrvc-image",
            "title": "Building your own images"
        },
        {
            "location": "/Setup/Network-setup/#starting-up-validating-peers",
            "text": "Check the available images again with  docker images . You should see  hyperledger/fabric-peer  and  hyperledger/fabric-membersrvc  images. For example,  $ docker images\nREPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE\nhyperledger/fabric-membersrvc   latest              7d5f6e0bcfac        12 days ago         1.439 GB\nhyperledger/fabric-peer         latest              82ef20d7507c        12 days ago         1.445 GB  If you don t see these, go back to the previous step.  With the relevant Docker images in hand, we can start running the peer and membersrvc services.",
            "title": "Starting up validating peers"
        },
        {
            "location": "/Setup/Network-setup/#determine-value-for-core_vm_endpoint-variable",
            "text": "Next, we need to determine the address of your docker daemon for the CORE_VM_ENDPOINT. If you are working within the Vagrant development environment, or a Docker Toolbox environment, you can determine this with the  ip add  command. For example,  $ ip add  detail removed  \n\n3: docker0:  NO-CARRIER,BROADCAST,MULTICAST,UP  mtu 1500 qdisc noqueue state DOWN group default\n    link/ether 02:42:ad:be:70:cb brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:adff:febe:70cb/64 scope link\n       valid_lft forever preferred_lft forever  Your output might contain something like  inet 172.17.0.1/16 scope global docker0 . That means the docker0 interface is on IP address 172.17.0.1. Use that IP address for the  CORE_VM_ENDPOINT  option. For more information on the environment variables, see  core.yaml  configuration file in the  fabric  repository.  If you are using the native Docker for Mac or Windows, the value for  CORE_VM_ENDPOINT  should be set to  unix:///var/run/docker.sock . [TODO] double check this. I believe that  127.0.0.1:2375  also works.",
            "title": "Determine value for CORE_VM_ENDPOINT variable"
        },
        {
            "location": "/Setup/Network-setup/#assigning-a-value-for-core_peer_id",
            "text": "The ID value of  CORE_PEER_ID  must be unique for each validating peer, and it must be a lowercase string. We often use a convention of naming the validating peers vpN where N is an integer starting with 0 for the root node and incrementing N by 1 for each additional peer node started. e.g. vp0, vp1, vp2,",
            "title": "Assigning a value for CORE_PEER_ID"
        },
        {
            "location": "/Setup/Network-setup/#consensus",
            "text": "By default, we are using a consensus plugin called  NOOPS , which doesn t really do consensus. If you are running a single peer node, running anything other than  NOOPS  makes little sense. If you want to use some other consensus plugin in the context of multiple peer nodes, please see the  Using a Consensus Plugin  section, below.",
            "title": "Consensus"
        },
        {
            "location": "/Setup/Network-setup/#docker-compose",
            "text": "We ll be using Docker Compose to launch our various Fabric component containers, as this is the simplest approach. You should have it installed from the initial setup steps. Installing Docker Toolbox or any of the native Docker runtimes should have installed Compose.",
            "title": "Docker Compose"
        },
        {
            "location": "/Setup/Network-setup/#start-up-a-validating-peer",
            "text": "Let s launch the first validating peer (the root node). We ll set CORE_PEER_ID to vp0 and CORE_VM_ENDPOINT as above. Here s the docker-compose.yml for launching a single container within the  Vagrant   development environment :  vp0:\n  image: hyperledger/fabric-peer\n  environment:\n    - CORE_PEER_ID=vp0\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=http://172.17.0.1:2375\n    - CORE_LOGGING_LEVEL=DEBUG\n  command: peer node start  You can launch this Compose file as follows, from the same directory as the docker-compose.yml file:  $ docker-compose up  Here s the corresponding Docker command:  $ docker run --rm -it -e CORE_VM_ENDPOINT=http://172.17.0.1:2375 -e CORE_LOGGING_LEVEL=DEBUG -e CORE_PEER_ID=vp0 -e CORE_PEER_ADDRESSAUTODETECT=true hyperledger/fabric-peer peer node start  If you are running Docker for Mac or Windows, we ll need to explicitly map the ports, and we will need a different value for CORE_VM_ENDPOINT as we discussed above.  Here s the docker-compose.yml for Docker on Mac or Windows:  vp0:\n  image: hyperledger/fabric-peer\n  ports:\n    -  7050:7050 \n    -  7051:7051 \n    -  7052:7052 \n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=unix:///var/run/docker.sock\n    - CORE_LOGGING_LEVEL=DEBUG\n  command: peer node start  This single peer configuration, running the  NOOPS   consensus  plugin, should satisfy many development/test scenarios.  NOOPS  is not really providing consensus, it is essentially a no-op that simulates consensus. For instance, if you are simply developing and testing chaincode; this should be adequate unless your chaincode is leveraging membership services for identity, access control, confidentiality and privacy.",
            "title": "Start up a validating peer:"
        },
        {
            "location": "/Setup/Network-setup/#running-with-the-ca",
            "text": "If you want to take advantage of security (authentication and authorization), privacy and confidentiality, then you ll need to run the Fabric s certificate authority (CA). Please refer to the  CA Setup  instructions.",
            "title": "Running with the CA"
        },
        {
            "location": "/Setup/Network-setup/#start-up-additional-validating-peers",
            "text": "Following the pattern we established  above  we ll use  vp1  as the ID for the second validating peer. If using Docker Compose, we can simply link the two peer nodes.\nHere s the docker-compse.yml for a  Vagrant  environment with two peer nodes - vp0 and vp1:  vp0:\n  image: hyperledger/fabric-peer\n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=http://172.17.0.1:2375\n    - CORE_LOGGING_LEVEL=DEBUG\n  command: peer node start\nvp1:\n  extends:\n    service: vp0\n  environment:\n    - CORE_PEER_ID=vp1\n    - CORE_PEER_DISCOVERY_ROOTNODE=vp0:7051\n  links:\n    - vp0  If we wanted to use the docker command line to launch another peer, we need to get the IP address of the first validating peer, which will act as the root node to which the new peer(s) will connect. The address is printed out on the terminal window of the first peer (e.g. 172.17.0.2) and should be passed in with the  CORE_PEER_DISCOVERY_ROOTNODE  environment variable.  docker run --rm -it -e CORE_VM_ENDPOINT=http://172.17.0.1:2375 -e CORE_PEER_ID=vp1 -e CORE_PEER_ADDRESSAUTODETECT=true -e CORE_PEER_DISCOVERY_ROOTNODE=172.17.0.2:7051 hyperledger/fabric-peer peer node start",
            "title": "Start up additional validating peers:"
        },
        {
            "location": "/Setup/Network-setup/#using-a-consensus-plugin",
            "text": "A consensus plugin might require some specific configuration that you need to set up. For example, to use the Practical Byzantine Fault Tolerant (PBFT) consensus plugin provided as part of the fabric, perform the following configuration:   In  core.yaml , set the  peer.validator.consensus  value to  pbft  In  core.yaml , make sure the  peer.id  is set sequentially as  vpN  where  N  is an integer that starts from  0  and goes to  N-1 . For example, with 4 validating peers, set the  peer.id  to vp0 ,  vp1 ,  vp2 ,  vp3 .  In  consensus/pbft/config.yaml , set the  general.mode  value to  batch  and the  general.N  value to the number of validating peers on the network, also set  general.batchsize  to the number of transactions per batch.  In  consensus/pbft/config.yaml , optionally set timer values for the batch period ( general.timeout.batch ), the acceptable delay between request and execution ( general.timeout.request ), and for view-change ( general.timeout.viewchange )   See  core.yaml  and  consensus/pbft/config.yaml  for more detail.  All of these setting may be overridden via the command line environment variables, e.g.  CORE_PEER_VALIDATOR_CONSENSUS_PLUGIN=pbft  or  CORE_PBFT_GENERAL_MODE=batch",
            "title": "Using a Consensus Plugin"
        },
        {
            "location": "/Setup/Network-setup/#logging-control",
            "text": "See  Logging Control  for information on controlling\nlogging output from the  peer  and deployed chaincodes.",
            "title": "Logging control"
        },
        {
            "location": "/Setup/NodeSDK-setup/",
            "text": "Hyperledger Fabric Client (HFC) SDK for Node.js\n\n\nThe Hyperledger Fabric Client (HFC) SDK provides a powerful and easy to use API\nto interact with a Hyperledger Fabric blockchain.\n\n\nThis document assumes that you already have set up a Node.js development\nenvironment. If not, go \nhere\n\nto download and install Node.js for your OS. You\nll also want the latest version\nof \nnpm\n installed. For that, execute \nsudo npm install npm -g\n to get the\nlatest version.\n\n\nInstalling the hfc module\n\n\nWe publish the \nhfc\n node module to \nnpm\n. To install \nhfc\n from npm simply\nexecute the following command:\n\n\nnpm install -g hfc\n\n\n\n\nSee \nHyperledger fabric Node.js client SDK\n for more information.\n\n\nHyperledger fabric network\n\n\nFirst, you\nll want to have a running peer node and member services. The\ninstructions for setting up a network are\n\nhere\n. You may also use the \nself contained environment\n that provides the network.",
            "title": "NodeSDK Setup"
        },
        {
            "location": "/Setup/NodeSDK-setup/#hyperledger-fabric-client-hfc-sdk-for-nodejs",
            "text": "The Hyperledger Fabric Client (HFC) SDK provides a powerful and easy to use API\nto interact with a Hyperledger Fabric blockchain.  This document assumes that you already have set up a Node.js development\nenvironment. If not, go  here \nto download and install Node.js for your OS. You ll also want the latest version\nof  npm  installed. For that, execute  sudo npm install npm -g  to get the\nlatest version.",
            "title": "Hyperledger Fabric Client (HFC) SDK for Node.js"
        },
        {
            "location": "/Setup/NodeSDK-setup/#installing-the-hfc-module",
            "text": "We publish the  hfc  node module to  npm . To install  hfc  from npm simply\nexecute the following command:  npm install -g hfc  See  Hyperledger fabric Node.js client SDK  for more information.",
            "title": "Installing the hfc module"
        },
        {
            "location": "/Setup/NodeSDK-setup/#hyperledger-fabric-network",
            "text": "First, you ll want to have a running peer node and member services. The\ninstructions for setting up a network are here . You may also use the  self contained environment  that provides the network.",
            "title": "Hyperledger fabric network"
        },
        {
            "location": "/Setup/ca-setup/",
            "text": "Certificate Authority (CA) Setup\n\n\nThe \nCertificate Authority\n (CA) provides a number of certificate services to users of a blockchain. More specifically, these services relate to \nuser enrollment\n, \ntransactions\n invoked on the blockchain, and \nTLS\n-secured connections between users or components of the blockchain.\n\n\nThis guide builds on either the \nfabric developer\ns setup\n or the prerequisites articulated in the \nfabric network setup\n guide. If you have not already set up your environment with one of those guides, please do so before continuing.\n\n\nEnrollment Certificate Authority\n\n\nThe \nenrollment certificate authority\n (ECA) allows new users to register with the blockchain network and enables registered users to request an \nenrollment certificate pair\n. One certificate is for data signing, one is for data encryption. The public keys to be embedded in the certificates have to be of type ECDSA, whereby the key for data encryption is then converted by the user to be used in an \nECIES\n (Elliptic Curve Integrated Encryption System) fashion.\n\n\nTransaction Certificate Authority\n\n\nOnce a user is enrolled, he or she can also request \ntransaction certificates\n from the \ntransaction certificate authority\n (TCA). These certificates are to be used for deploying Chaincode and for invoking Chaincode transactions on the blockchain. Although a single \ntransaction certificate\n can be used for multiple transactions, for privacy reasons it is recommended that a new \ntransaction certificate\n be used for each transaction.\n\n\nTLS Certificate Authority\n\n\nIn addition to \nenrollment certificates\n and \ntransaction certificates\n, users will need \nTLS certificates\n to secure their communication channels. \nTLS certificates\n can be requested from the \nTLS certificate authority\n (TLSCA).\n\n\nConfiguration\n\n\nAll CA services are provided by a single process, which can be configured by setting parameters in the CA configuration file \nmembersrvc.yaml\n, which is located in the same directory as the CA binary. More specifically, the following parameters can be set:\n\n\n\n\nserver.gomaxprocs\n: limits the number of operating system threads used by the CA.\n\n\nserver.rootpath\n: the root path of the directory where the CA stores its state.\n\n\nserver.cadir\n: the name of the directory where the CA stores its state.\n\n\nserver.port\n: the port at which all CA services listen (multiplexing of services over the same port is provided by \nGRPC\n).\n\n\n\n\nFurthermore, logging levels can be enabled/disabled by adjusting the following settings:\n\n\n\n\nlogging.trace\n (off by default, useful for debugging the code only)\n\n\nlogging.info\n\n\nlogging.warning\n\n\nlogging.error\n\n\nlogging.panic\n\n\n\n\nAlternatively, these fields can be set via environment variables, which\nif set\nhave precedence over entries in the yaml file. The corresponding environment variables are named as follows:\n\n\n    MEMBERSRVC_CA_SERVER_GOMAXPROCS\n    MEMBERSRVC_CA_SERVER_ROOTPATH\n    MEMBERSRVC_CA_SERVER_CADIR\n    MEMBERSRVC_CA_SERVER_PORT\n\n\n\n\nIn addition, the CA may be preloaded with registered users, where each user\ns name, roles, and password are specified:\n\n\n    eca:\n        users:\n            alice: 2 DRJ20pEql15a\n            bob: 4 7avZQLwcUe9q\n\n\n\n\nThe role value is simply a bitmask of the following:\n\n\n    CLIENT = 1;\n    PEER = 2;\n    VALIDATOR = 4;\n    AUDITOR = 8;\n\n\n\n\nFor example, a peer that is also a validator would have a role value of 6.\n\n\nWhen the CA is started for the first time, it will generate all of its required state (e.g., internal databases, CA certificates, blockchain keys, etc.) and writes this state to the directory given in its configuration. The certificates for the CA services (i.e., for the ECA, TCA, and TLSCA) are self-signed as the current default. If those certificates shall be signed by some root CA, this can be done manually by using the \n*.priv\n and \n*.pub\n private and public keys in the CA state directory, and replacing the self-signed \n*.cert\n certificates with root-signed ones. The next time the CA is launched, it will read and use those root-signed certificates.\n\n\nOperating the CA\n\n\nYou can either \nbuild and run\n the CA from source. Or, you can use Docker Compose and work with the published images on DockerHub, or some other Docker registry. Using Docker Compose is by far the simplest approach.\n\n\nDocker Compose\n\n\nHere\ns a sample docker-compose.yml for the CA.\n\n\nmembersrvc:\n  image: hyperledger/fabric-membersrvc\n  command: membersrvc\n\n\n\n\nThe corresponding docker-compose.yml for running Docker on Mac or Windows natively looks like this:\n\n\nmembersrvc:\n  image: hyperledger/fabric-membersrvc\n  ports:\n    - \n7054:7054\n\n  command: membersrvc\n\n\n\n\nIf you are launching one or more \npeer\n nodes in the same docker-compose.yml, then you will want to add a delay to the start of the peer to allow sufficient time for the CA to start, before the peer attempts to connect to it.\n\n\nmembersrvc:\n  image: hyperledger/fabric-membersrvc\n  command: membersrvc\nvp0:\n  image: hyperledger/fabric-peer\n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=http://172.17.0.1:2375\n    - CORE_LOGGING_LEVEL=DEBUG\n    - CORE_PEER_ID=vp0\n    - CORE_SECURITY_ENROLLID=test_vp0\n    - CORE_SECURITY_ENROLLSECRET=MwYpmSRjupbT\n  links:\n    - membersrvc\n  command: sh -c \nsleep 5; peer node start\n\n\n\n\n\nThe corresponding docker-compose.yml for running Docker on Mac or Windows natively looks like this:\n\n\nmembersrvc:\n  image: hyperledger/fabric-membersrvc\n  ports:\n    - \n7054:7054\n\n  command: membersrvc\nvp0:\n  image: hyperledger/fabric-peer\n  ports:\n    - \n7050:7050\n\n    - \n7051:7051\n\n    - \n7052:7052\n\n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=unix:///var/run/docker.sock\n    - CORE_LOGGING_LEVEL=DEBUG\n    - CORE_PEER_ID=vp0\n    - CORE_SECURITY_ENROLLID=test_vp0\n    - CORE_SECURITY_ENROLLSECRET=MwYpmSRjupbT\n  links:\n    - membersrvc\n  command: sh -c \nsleep 5; peer node start\n\n\n\n\n\nBuild and Run\n\n\nThe CA can be built with the following command executed in the \nmembersrvc\n directory:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake membersrvc\n\n\n\n\nThe CA can be started with the following command:\n\n\nbuild/bin/membersrvc\n\n\n\n\nNote:\n the CA must be started before any of the fabric peer nodes, to allow the CA to have initialized before any peer nodes attempt to connect to it.\n\n\nThe CA looks for an \nmembersrvc.yaml\n configuration file in $GOPATH/src/github.com/hyperledger/fabric/membersrvc. If the CA is started for the first time, it creates all its required state (e.g., internal databases, CA certificates, blockchain keys, etc.) and writes that state to the directory given in the CA configuration.",
            "title": "CA Setup"
        },
        {
            "location": "/Setup/ca-setup/#certificate-authority-ca-setup",
            "text": "The  Certificate Authority  (CA) provides a number of certificate services to users of a blockchain. More specifically, these services relate to  user enrollment ,  transactions  invoked on the blockchain, and  TLS -secured connections between users or components of the blockchain.  This guide builds on either the  fabric developer s setup  or the prerequisites articulated in the  fabric network setup  guide. If you have not already set up your environment with one of those guides, please do so before continuing.",
            "title": "Certificate Authority (CA) Setup"
        },
        {
            "location": "/Setup/ca-setup/#enrollment-certificate-authority",
            "text": "The  enrollment certificate authority  (ECA) allows new users to register with the blockchain network and enables registered users to request an  enrollment certificate pair . One certificate is for data signing, one is for data encryption. The public keys to be embedded in the certificates have to be of type ECDSA, whereby the key for data encryption is then converted by the user to be used in an  ECIES  (Elliptic Curve Integrated Encryption System) fashion.",
            "title": "Enrollment Certificate Authority"
        },
        {
            "location": "/Setup/ca-setup/#transaction-certificate-authority",
            "text": "Once a user is enrolled, he or she can also request  transaction certificates  from the  transaction certificate authority  (TCA). These certificates are to be used for deploying Chaincode and for invoking Chaincode transactions on the blockchain. Although a single  transaction certificate  can be used for multiple transactions, for privacy reasons it is recommended that a new  transaction certificate  be used for each transaction.",
            "title": "Transaction Certificate Authority"
        },
        {
            "location": "/Setup/ca-setup/#tls-certificate-authority",
            "text": "In addition to  enrollment certificates  and  transaction certificates , users will need  TLS certificates  to secure their communication channels.  TLS certificates  can be requested from the  TLS certificate authority  (TLSCA).",
            "title": "TLS Certificate Authority"
        },
        {
            "location": "/Setup/ca-setup/#configuration",
            "text": "All CA services are provided by a single process, which can be configured by setting parameters in the CA configuration file  membersrvc.yaml , which is located in the same directory as the CA binary. More specifically, the following parameters can be set:   server.gomaxprocs : limits the number of operating system threads used by the CA.  server.rootpath : the root path of the directory where the CA stores its state.  server.cadir : the name of the directory where the CA stores its state.  server.port : the port at which all CA services listen (multiplexing of services over the same port is provided by  GRPC ).   Furthermore, logging levels can be enabled/disabled by adjusting the following settings:   logging.trace  (off by default, useful for debugging the code only)  logging.info  logging.warning  logging.error  logging.panic   Alternatively, these fields can be set via environment variables, which if set have precedence over entries in the yaml file. The corresponding environment variables are named as follows:      MEMBERSRVC_CA_SERVER_GOMAXPROCS\n    MEMBERSRVC_CA_SERVER_ROOTPATH\n    MEMBERSRVC_CA_SERVER_CADIR\n    MEMBERSRVC_CA_SERVER_PORT  In addition, the CA may be preloaded with registered users, where each user s name, roles, and password are specified:      eca:\n        users:\n            alice: 2 DRJ20pEql15a\n            bob: 4 7avZQLwcUe9q  The role value is simply a bitmask of the following:      CLIENT = 1;\n    PEER = 2;\n    VALIDATOR = 4;\n    AUDITOR = 8;  For example, a peer that is also a validator would have a role value of 6.  When the CA is started for the first time, it will generate all of its required state (e.g., internal databases, CA certificates, blockchain keys, etc.) and writes this state to the directory given in its configuration. The certificates for the CA services (i.e., for the ECA, TCA, and TLSCA) are self-signed as the current default. If those certificates shall be signed by some root CA, this can be done manually by using the  *.priv  and  *.pub  private and public keys in the CA state directory, and replacing the self-signed  *.cert  certificates with root-signed ones. The next time the CA is launched, it will read and use those root-signed certificates.",
            "title": "Configuration"
        },
        {
            "location": "/Setup/ca-setup/#operating-the-ca",
            "text": "You can either  build and run  the CA from source. Or, you can use Docker Compose and work with the published images on DockerHub, or some other Docker registry. Using Docker Compose is by far the simplest approach.",
            "title": "Operating the CA"
        },
        {
            "location": "/Setup/ca-setup/#docker-compose",
            "text": "Here s a sample docker-compose.yml for the CA.  membersrvc:\n  image: hyperledger/fabric-membersrvc\n  command: membersrvc  The corresponding docker-compose.yml for running Docker on Mac or Windows natively looks like this:  membersrvc:\n  image: hyperledger/fabric-membersrvc\n  ports:\n    -  7054:7054 \n  command: membersrvc  If you are launching one or more  peer  nodes in the same docker-compose.yml, then you will want to add a delay to the start of the peer to allow sufficient time for the CA to start, before the peer attempts to connect to it.  membersrvc:\n  image: hyperledger/fabric-membersrvc\n  command: membersrvc\nvp0:\n  image: hyperledger/fabric-peer\n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=http://172.17.0.1:2375\n    - CORE_LOGGING_LEVEL=DEBUG\n    - CORE_PEER_ID=vp0\n    - CORE_SECURITY_ENROLLID=test_vp0\n    - CORE_SECURITY_ENROLLSECRET=MwYpmSRjupbT\n  links:\n    - membersrvc\n  command: sh -c  sleep 5; peer node start   The corresponding docker-compose.yml for running Docker on Mac or Windows natively looks like this:  membersrvc:\n  image: hyperledger/fabric-membersrvc\n  ports:\n    -  7054:7054 \n  command: membersrvc\nvp0:\n  image: hyperledger/fabric-peer\n  ports:\n    -  7050:7050 \n    -  7051:7051 \n    -  7052:7052 \n  environment:\n    - CORE_PEER_ADDRESSAUTODETECT=true\n    - CORE_VM_ENDPOINT=unix:///var/run/docker.sock\n    - CORE_LOGGING_LEVEL=DEBUG\n    - CORE_PEER_ID=vp0\n    - CORE_SECURITY_ENROLLID=test_vp0\n    - CORE_SECURITY_ENROLLSECRET=MwYpmSRjupbT\n  links:\n    - membersrvc\n  command: sh -c  sleep 5; peer node start",
            "title": "Docker Compose"
        },
        {
            "location": "/Setup/ca-setup/#build-and-run",
            "text": "The CA can be built with the following command executed in the  membersrvc  directory:  cd $GOPATH/src/github.com/hyperledger/fabric\nmake membersrvc  The CA can be started with the following command:  build/bin/membersrvc  Note:  the CA must be started before any of the fabric peer nodes, to allow the CA to have initialized before any peer nodes attempt to connect to it.  The CA looks for an  membersrvc.yaml  configuration file in $GOPATH/src/github.com/hyperledger/fabric/membersrvc. If the CA is started for the first time, it creates all its required state (e.g., internal databases, CA certificates, blockchain keys, etc.) and writes that state to the directory given in the CA configuration.",
            "title": "Build and Run"
        },
        {
            "location": "/Setup/logging-control/",
            "text": "Logging Control\n\n\nOverview\n\n\nLogging in the \npeer\n application and in the \nshim\n interface to chaincodes is programmed using facilities provided by the \ngithub.com/op/go-logging\n package. This package supports\n\n\n\n\nLogging control based on the severity of the message\n\n\nLogging control based on the software \nmodule\n generating the message\n\n\nDifferent pretty-printing options based on the severity of the message\n\n\n\n\nAll logs are currently directed to \nstderr\n, and the pretty-printing is currently fixed. However global and module-level control of logging by severity is provided for both users and developers. There are currently no formalized rules for the types of information provided at each severity level, however when submitting bug reports the developers may want to see full logs down to the DEBUG level.\n\n\nIn pretty-printed logs the logging level is indicated both by color and by a 4-character code, e.g, \nERRO\n for ERROR, \nDEBU\n for DEBUG, etc. In the logging context a \nmodule\n is an arbitrary name (string) given by developers to groups of related messages. In the pretty-printed example below, the logging modules \npeer\n, \nrest\n and \nmain\n are generating logs.\n\n\n16:47:09.634 [peer] GetLocalAddress -\n INFO 033 Auto detected peer address: 9.3.158.178:7051\n16:47:09.635 [rest] StartOpenchainRESTServer -\n INFO 035 Initializing the REST service...\n16:47:09.635 [main] serve -\n INFO 036 Starting peer with id=name:\"vp1\" , network id=dev, address=9.3.158.178:7051, discovery.rootnode=, validator=true\n\n\n\nAn arbitrary number of logging modules can be created at runtime, therefore\nthere is no \nmaster list\n of modules, and logging control constructs can not\ncheck whether logging modules actually do or will exist. Also note that the\nlogging module system does not understand hierarchy or wildcarding: You may\nsee module names like \nfoo/bar\n in the code, but the logging system only sees\na flat string. It doesn\nt understand that \nfoo/bar\n is related to \nfoo\n in any\nway, or that \nfoo/*\n might indicate all \nsubmodules\n of foo.\n\n\npeer\n\n\nThe logging level of the \npeer\n command can be controlled from the command line for each invocation using the \n--logging-level\n flag, for example\n\n\npeer node start --logging-level=debug\n\n\n\nThe default logging level for each individual \npeer\n subcommand can also be\nset in the\n\ncore.yaml\n\nfile. For example the key \nlogging.node\n sets the default level for the \nnode\n\nsubcommmand. Comments in the file also explain how the logging level can be\noverridden in various ways by using environment varaibles.\n\n\nLogging severity levels are specified using case-insensitive strings chosen from\n\n\nCRITICAL | ERROR | WARNING | NOTICE | INFO | DEBUG\n\n\n\nThe full logging level specification for the \npeer\n is of the form\n\n\n[\nmodule\n[,\nmodule\n...]=]\nlevel\n[:[\nmodule\n[,\nmodule\n...]=]\nlevel\n...]\n\n\n\nA logging level by itself is taken as the overall default. Otherwise, overrides for individual or groups of modules can be specified using the\n\n\nmodule\n[,\nmodule\n...]=\nlevel\n\n\n\n\nsyntax. Examples of \n specifications (valid for all of\n\n--logging-level\n, environment variable and\n\ncore.yaml\n\nsettings):\n\n\ninfo                                       - Set default to INFO\nwarning:main,db=debug:chaincode=info       - Default WARNING; Override for main,db,chaincode\nchaincode=info:main=debug:db=debug:warning - Same as above\n\n\n\nGo chaincodes\n\n\nAs independently executed programs, user-provided chaincodes can use any appropriate technique to create their private logs - from simple print statements to fully-annotated and level-controlled logs. The chaincode \nshim\n package provides APIs that allow a chaincode to create and manage logging objects whose logs will be formatted and interleaved consistently with the \nshim\n logs.\n\n\nNewLogger(name string) *ChaincodeLogger\n - Create a logging object for use by a chaincode\n\n\n(c *ChaincodeLogger) SetLevel(level LoggingLevel)\n - Set the logging level of the logger\n\n\n(c *ChaincodeLogger) IsEnabledFor(level LoggingLevel) bool\n - Return true if logs will be generated at the given level\n\n\nLogLevel(levelString string) (LoggingLevel, error)\n - Convert a string to a \nLoggingLevel\n\n\nA \nLoggingLevel\n is a member of the enumeration\n\n\nLogDebug, LogInfo, LogNotice, LogWarning, LogError, LogCritical\n\n\n\n\nwhich can be used directly, or generated by passing a case-insensitive version of the strings\n\n\nDEBUG, INFO, NOTICE, WARNING, ERROR, CRITICAL\n\n\n\n\nto the \nLogLevel\n API.\n\n\nFormatted logging at various severity levels is provided by the functions\n\n\n(c *ChaincodeLogger) Debug(args ...interface{})\n(c *ChaincodeLogger) Info(args ...interface{})\n(c *ChaincodeLogger) Notice(args ...interface{})\n(c *ChaincodeLogger) Warning(args ...interface{})\n(c *ChaincodeLogger) Error(args ...interface{})\n(c *ChaincodeLogger) Critical(args ...interface{})\n\n(c *ChaincodeLogger) Debugf(format string, args ...interface{})\n(c *ChaincodeLogger) Infof(format string, args ...interface{})\n(c *ChaincodeLogger) Noticef(format string, args ...interface{})\n(c *ChaincodeLogger) Warningf(format string, args ...interface{})\n(c *ChaincodeLogger) Errorf(format string, args ...interface{})\n(c *ChaincodeLogger) Criticalf(format string, args ...interface{})\n\n\n\n\nThe \nf\n forms of the logging APIs provide for precise control over the formatting of the logs. The non-\nf\n forms of the APIs currently insert a space between the printed representations of the arguments, and arbitrarily choose the formats to use.\n\n\nIn the current implementation, the logs produced by the \nshim\n and a \nChaincodeLogger\n are timestamped, marked with the logger \nname\n and severity level, and written to \nstderr\n. Note that logging level control is currently based on the \nname\n provided when the \nChaincodeLogger\n is created. To avoid ambiguities, all \nChaincodeLogger\n should be given unique names other than \nshim\n. The logger \nname\n will appear in all log messages created by the logger. The \nshim\n logs as \nshim\n.\n\n\nGo language chaincodes can also control the logging level of the chaincode \nshim\n interface through the \nSetLoggingLevel\n API.\n\n\nSetLoggingLevel(LoggingLevel level)\n - Control the logging level of the shim\n\n\nThe default logging level for the shim is \nLogDebug\n.\n\n\nBelow is a simple example of how a chaincode might create a private logging object logging at the \nLogInfo\n level, and also control the amount of logging provided by the \nshim\n based on an environment variable.\n\n\nvar logger = shim.NewLogger(\nmyChaincode\n)\n\nfunc main() {\n\n    logger.SetLevel(shim.LogInfo)\n\n    logLevel, _ := shim.LogLevel(os.Getenv(\nSHIM_LOGGING_LEVEL\n))\n    shim.SetLoggingLevel(logLevel)\n    ...\n}",
            "title": "Logging"
        },
        {
            "location": "/Setup/logging-control/#logging-control",
            "text": "",
            "title": "Logging Control"
        },
        {
            "location": "/Setup/logging-control/#overview",
            "text": "Logging in the  peer  application and in the  shim  interface to chaincodes is programmed using facilities provided by the  github.com/op/go-logging  package. This package supports   Logging control based on the severity of the message  Logging control based on the software  module  generating the message  Different pretty-printing options based on the severity of the message   All logs are currently directed to  stderr , and the pretty-printing is currently fixed. However global and module-level control of logging by severity is provided for both users and developers. There are currently no formalized rules for the types of information provided at each severity level, however when submitting bug reports the developers may want to see full logs down to the DEBUG level.  In pretty-printed logs the logging level is indicated both by color and by a 4-character code, e.g,  ERRO  for ERROR,  DEBU  for DEBUG, etc. In the logging context a  module  is an arbitrary name (string) given by developers to groups of related messages. In the pretty-printed example below, the logging modules  peer ,  rest  and  main  are generating logs.  16:47:09.634 [peer] GetLocalAddress -  INFO 033 Auto detected peer address: 9.3.158.178:7051\n16:47:09.635 [rest] StartOpenchainRESTServer -  INFO 035 Initializing the REST service...\n16:47:09.635 [main] serve -  INFO 036 Starting peer with id=name:\"vp1\" , network id=dev, address=9.3.158.178:7051, discovery.rootnode=, validator=true  An arbitrary number of logging modules can be created at runtime, therefore\nthere is no  master list  of modules, and logging control constructs can not\ncheck whether logging modules actually do or will exist. Also note that the\nlogging module system does not understand hierarchy or wildcarding: You may\nsee module names like  foo/bar  in the code, but the logging system only sees\na flat string. It doesn t understand that  foo/bar  is related to  foo  in any\nway, or that  foo/*  might indicate all  submodules  of foo.",
            "title": "Overview"
        },
        {
            "location": "/Setup/logging-control/#peer",
            "text": "The logging level of the  peer  command can be controlled from the command line for each invocation using the  --logging-level  flag, for example  peer node start --logging-level=debug  The default logging level for each individual  peer  subcommand can also be\nset in the core.yaml \nfile. For example the key  logging.node  sets the default level for the  node \nsubcommmand. Comments in the file also explain how the logging level can be\noverridden in various ways by using environment varaibles.  Logging severity levels are specified using case-insensitive strings chosen from  CRITICAL | ERROR | WARNING | NOTICE | INFO | DEBUG  The full logging level specification for the  peer  is of the form  [ module [, module ...]=] level [:[ module [, module ...]=] level ...]  A logging level by itself is taken as the overall default. Otherwise, overrides for individual or groups of modules can be specified using the  module [, module ...]= level   syntax. Examples of   specifications (valid for all of --logging-level , environment variable and core.yaml \nsettings):  info                                       - Set default to INFO\nwarning:main,db=debug:chaincode=info       - Default WARNING; Override for main,db,chaincode\nchaincode=info:main=debug:db=debug:warning - Same as above",
            "title": "peer"
        },
        {
            "location": "/Setup/logging-control/#go-chaincodes",
            "text": "As independently executed programs, user-provided chaincodes can use any appropriate technique to create their private logs - from simple print statements to fully-annotated and level-controlled logs. The chaincode  shim  package provides APIs that allow a chaincode to create and manage logging objects whose logs will be formatted and interleaved consistently with the  shim  logs.  NewLogger(name string) *ChaincodeLogger  - Create a logging object for use by a chaincode  (c *ChaincodeLogger) SetLevel(level LoggingLevel)  - Set the logging level of the logger  (c *ChaincodeLogger) IsEnabledFor(level LoggingLevel) bool  - Return true if logs will be generated at the given level  LogLevel(levelString string) (LoggingLevel, error)  - Convert a string to a  LoggingLevel  A  LoggingLevel  is a member of the enumeration  LogDebug, LogInfo, LogNotice, LogWarning, LogError, LogCritical  which can be used directly, or generated by passing a case-insensitive version of the strings  DEBUG, INFO, NOTICE, WARNING, ERROR, CRITICAL  to the  LogLevel  API.  Formatted logging at various severity levels is provided by the functions  (c *ChaincodeLogger) Debug(args ...interface{})\n(c *ChaincodeLogger) Info(args ...interface{})\n(c *ChaincodeLogger) Notice(args ...interface{})\n(c *ChaincodeLogger) Warning(args ...interface{})\n(c *ChaincodeLogger) Error(args ...interface{})\n(c *ChaincodeLogger) Critical(args ...interface{})\n\n(c *ChaincodeLogger) Debugf(format string, args ...interface{})\n(c *ChaincodeLogger) Infof(format string, args ...interface{})\n(c *ChaincodeLogger) Noticef(format string, args ...interface{})\n(c *ChaincodeLogger) Warningf(format string, args ...interface{})\n(c *ChaincodeLogger) Errorf(format string, args ...interface{})\n(c *ChaincodeLogger) Criticalf(format string, args ...interface{})  The  f  forms of the logging APIs provide for precise control over the formatting of the logs. The non- f  forms of the APIs currently insert a space between the printed representations of the arguments, and arbitrarily choose the formats to use.  In the current implementation, the logs produced by the  shim  and a  ChaincodeLogger  are timestamped, marked with the logger  name  and severity level, and written to  stderr . Note that logging level control is currently based on the  name  provided when the  ChaincodeLogger  is created. To avoid ambiguities, all  ChaincodeLogger  should be given unique names other than  shim . The logger  name  will appear in all log messages created by the logger. The  shim  logs as  shim .  Go language chaincodes can also control the logging level of the chaincode  shim  interface through the  SetLoggingLevel  API.  SetLoggingLevel(LoggingLevel level)  - Control the logging level of the shim  The default logging level for the shim is  LogDebug .  Below is a simple example of how a chaincode might create a private logging object logging at the  LogInfo  level, and also control the amount of logging provided by the  shim  based on an environment variable.  var logger = shim.NewLogger( myChaincode )\n\nfunc main() {\n\n    logger.SetLevel(shim.LogInfo)\n\n    logLevel, _ := shim.LogLevel(os.Getenv( SHIM_LOGGING_LEVEL ))\n    shim.SetLoggingLevel(logLevel)\n    ...\n}",
            "title": "Go chaincodes"
        },
        {
            "location": "/API/ChaincodeAPI/",
            "text": "Chaincode APIs\n\n\nWhen the \nInit\n, \nInvoke\n or \nQuery\n function of a chaincode is called, the fabric passes the \nstub *shim.ChaincodeStub\n parameter. This \nstub\n can be used to call APIs to access to the ledger services, transaction context, or to invoke other chaincodes.\n\n\nThe current APIs are defined in the \nshim package\n, generated by \ngodoc\n. However, it includes functions from \nchaincode.pb.go\n such as \nfunc (*Column) XXX_OneofFuncs\n that are not intended as public API. The best is to look at the function definitions in \nchaincode.go\n and \nchaincode samples\n for usage.",
            "title": "Chaincode APIs"
        },
        {
            "location": "/API/ChaincodeAPI/#chaincode-apis",
            "text": "When the  Init ,  Invoke  or  Query  function of a chaincode is called, the fabric passes the  stub *shim.ChaincodeStub  parameter. This  stub  can be used to call APIs to access to the ledger services, transaction context, or to invoke other chaincodes.  The current APIs are defined in the  shim package , generated by  godoc . However, it includes functions from  chaincode.pb.go  such as  func (*Column) XXX_OneofFuncs  that are not intended as public API. The best is to look at the function definitions in  chaincode.go  and  chaincode samples  for usage.",
            "title": "Chaincode APIs"
        },
        {
            "location": "/API/CoreAPI/",
            "text": "APIs - CLI, REST, and Node.js\n\n\nOverview\n\n\nThis document covers the available APIs for interacting with a peer node. Three interface choices are provided:\n\n\n\n\nCLI\n\n\nREST API\n\n\nNode.js Application\n\n\nUsing Swagger JS Plugin\n\n\nMarbles Demo Application\n\n\nCommercial Paper Demo Application\n\n\n\n\nNote:\n If you are working with APIs with security enabled, please review the \nsecurity setup instructions\n before proceeding.\n\n\nCLI\n\n\nTo view the currently available CLI commands, execute the following:\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric\nbuild/bin/peer\n\n\n\nYou will see output similar to the example below (\nNOTE:\n rootcommand below is hardcoded in \nmain.go\n. Currently, the build will create a \npeer\n executable file).\n\n\n    Usage:\n      peer [flags]\n      peer [command]\n\n    Available Commands:\n      version     Print fabric peer version.\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level=\n: Default logging level and overrides, see core.yaml for full syntax\n          --test.coverprofile=\ncoverage.cov\n: Done\n      -v, --version[=false]: Show current version number of fabric peer server\n\n\n    Use \npeer [command] --help\n for more information about a command.\n\n\n\n\n\nThe \npeer\n command supports several subcommands and flags, as shown above. To\nfacilitate its use in scripted applications, the \npeer\n command always\nproduces a non-zero return code in the event of command failure. Upon success,\nmany of the subcommands produce a result on \nstdout\n as shown in the table\nbelow:\n\n\n\n\n\n\n\n\nCommand\n\n\nstdout\n result in the event of success\n\n\n\n\n\n\n\n\n\n\nversion\n\n\nString form of \npeer.version\n defined in \ncore.yaml\n\n\n\n\n\n\nnode start\n\n\nN/A\n\n\n\n\n\n\nnode status\n\n\nString form of \nStatusCode\n\n\n\n\n\n\nnode stop\n\n\nString form of \nStatusCode\n\n\n\n\n\n\nnetwork login\n\n\nN/A\n\n\n\n\n\n\nnetwork list\n\n\nThe list of network connections to the peer node.\n\n\n\n\n\n\nchaincode deploy\n\n\nThe chaincode container name (hash) required for subsequent \nchaincode invoke\n and \nchaincode query\n commands\n\n\n\n\n\n\nchaincode invoke\n\n\nThe transaction ID (UUID)\n\n\n\n\n\n\nchaincode query\n\n\nBy default, the query result is formatted as a printable string. Command line options support writing this value as raw bytes (-r, \nraw), or formatted as the hexadecimal representation of the raw bytes (-x, \nhex). If the query response is empty then nothing is output.\n\n\n\n\n\n\n\n\nDeploy a Chaincode\n\n\nDeploy creates the docker image for the chaincode and subsequently deploys the package to the validating peer. An example is below.\n\n\npeer chaincode deploy -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'\n\n\nThe response to the chaincode deploy command will contain the chaincode identifier (hash) which will be required on subsequent \nchaincode invoke\n and \nchaincode query\n commands in order to identify the deployed chaincode.\n\n\nWith security enabled, modify the command to include the -u parameter passing the username of a logged in user as follows:\n\n\npeer chaincode deploy -u jim -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'\n\n\nNote:\n If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.\n\n\nVerify Results\n\n\nTo verify that the block containing the latest transaction has been added to the blockchain, use the \n/chain\n REST endpoint from the command line. Target the IP address of either a validating or a non-validating node. In the example below, 172.17.0.2 is the IP address of a validating or a non-validating node and 7050 is the REST interface port defined in \ncore.yaml\n.\n\n\ncurl 172.17.0.2:7050/chain\n\n\nAn example of the response is below.\n\n\n{\n    \nheight\n:1,\n    \ncurrentBlockHash\n:\n4Yc4yCO95wcpWHW2NLFlf76OGURBBxYZMf3yUyvrEXs5TMai9qNKfy9Yn/==\n\n}\n\n\n\n\nThe returned BlockchainInfo message is defined inside \nfabric.proto\n.\n\n\nmessage BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}\n\n\n\n\nTo verify that a specific block is inside the blockchain, use the \n/chain/blocks/{Block}\n REST endpoint. Likewise, target the IP address of either a validating or a non-validating node on port 7050.\n\n\ncurl 172.17.0.2:7050/chain/blocks/0\n\n\nThe returned Block message structure is defined inside \nfabric.proto\n.\n\n\nmessage Block {\n    uint32 version = 1;\n    google.protobuf.Timestamp timestamp = 2;\n    repeated Transaction transactions = 3;\n    bytes stateHash = 4;\n    bytes previousBlockHash = 5;\n    bytes consensusMetadata = 6;\n    NonHashData nonHashData = 7;\n}\n\n\n\n\nAn example of a returned Block structure is below.\n\n\n{\n    \ntransactions\n:[{\n        \ntype\n:1,\n        \nchaincodeID\n: {\n            \npath\n:\ngithub.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n\n        },\n        \npayload\n:\nClwIARJYCk9naXRod...\n,\n        \nuuid\n:\nabdcec99-ae5e-415e-a8be-1fca8e38ba71\n\n    }],\n    \nstateHash\n:\nPY5YcQRu2g1vjiAqHHshoAhnq8CFP3MqzMslcEAJbnmXDtD+LopmkrUHrPMOGSF5UD7Kxqhbg1XUjmQAi84paw==\n\n}\n\n\n\n\nFor additional information on the available CLI commands, please see the \nprotocol specification\n section 6.3 on CLI.\n\n\nREST API\n\n\nYou can work with the REST API through any tool of your choice. For example, the curl command line utility or a browser based client such as the Firefox Rest Client or Chrome Postman. You can likewise trigger REST requests directly through \nSwagger\n. You can utilize the Swagger service directly or, if you prefer, you can set up Swagger locally by following the instructions \nhere\n.\n\n\nNote:\n The default REST interface port is \n7050\n. It can be configured in \ncore.yaml\n using the \nrest.address\n property. If using Vagrant, the REST port mapping is defined in \nVagrantfile\n.\n\n\nNote on constructing a test blockchain\n If you want to test the REST API locally, construct a test blockchain by running the TestServerOpenchain_API_GetBlockCount test implemented inside \napi_test.go\n. This test will create a test blockchain with 5 blocks. Subsequently restart the peer process.\n\n\n    cd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\n    go test -v -run TestServerOpenchain_API_GetBlockCount\n\n\n\n\nREST Endpoints\n\n\nTo learn about the REST API through Swagger, please take a look at the Swagger document \nhere\n. You can upload the service description file to the Swagger service directly or, if you prefer, you can set up Swagger locally by following the instructions \nhere\n.\n\n\n\n\nBlock\n\n\nGET /chain/blocks/{Block}\n\n\nBlockchain\n\n\nGET /chain\n\n\nChaincode\n\n\nPOST /chaincode\n\n\n\n\n\n\nNetwork\n\n\nGET /network/peers\n\n\nRegistrar\n\n\nPOST /registrar\n\n\nDELETE /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}/ecert\n\n\nGET /registrar/{enrollmentID}/tcert\n\n\nTransactions\n\n\nGET /transactions/{UUID}\n\n\n\n\n\n\n\n\nBlock\n\n\n\n\nGET /chain/blocks/{Block}\n\n\n\n\nUse the Block API to retrieve the contents of various blocks from the blockchain. The returned Block message structure is defined inside \nfabric.proto\n.\n\n\nmessage Block {\n    uint32 version = 1;\n    google.protobuf.Timestamp Timestamp = 2;\n    repeated Transaction transactions = 3;\n    bytes stateHash = 4;\n    bytes previousBlockHash = 5;\n}\n\n\n\n\nBlockchain\n\n\n\n\nGET /chain\n\n\n\n\nUse the Chain API to retrieve the current state of the blockchain. The returned BlockchainInfo message is defined inside \nfabric.proto\n.\n\n\nmessage BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}\n\n\n\n\nChaincode\n\n\n\n\nPOST /chaincode\n\n\n\n\nUse the /chaincode endpoint to deploy, invoke, and query a target chaincode. This service endpoint implements the \nJSON RPC 2.0 specification\n with the payload identifying the desired chaincode operation within the \nmethod\n field. The supported methods are \ndeploy\n, \ninvoke\n, and \nquery\n.\n\n\nThe /chaincode endpoint implements the \nJSON RPC 2.0 specification\n and as such, must have the required fields of \njsonrpc\n, \nmethod\n, and in our case \nparams\n supplied within the payload. The client should also add the \nid\n element within the payload if they wish to receive a response to the request. If the \nid\n element is missing from the request payload, the request is assumed to be a notification and the server will not produce a response.\n\n\nThe following sample payloads may be used to deploy, invoke, and query a sample chaincode. To deploy a chaincode, supply the \nChaincodeSpec\n identifying the chaincode to deploy within the request payload.\n\n\nChaincode Deployment Request without security enabled:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: 1,\n    \nchaincodeID\n:{\n        \npath\n:\ngithub.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n1000\n, \nb\n, \n2000\n]\n    }\n  },\n  \nid\n: 1\n}\n\n\n\n\nTo deploy a chaincode with security enabled, supply the \nsecureContext\n element containing the registrationID of a registered and logged in user together with the payload from above.\n\n\nChaincode Deployment Request with security enabled (add \nsecureContext\n element):\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: 1,\n    \nchaincodeID\n:{\n        \npath\n:\ngithub.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n1000\n, \nb\n, \n2000\n]\n    },\n    \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: 1\n}\n\n\n\n\nThe response to a chaincode deployment request will contain a \nstatus\n element confirming successful completion of the request. The response to a successful deployment request will likewise contain the generated chaincode hash which must be used in subsequent invocation and query requests sent to this chaincode.\n\n\nChaincode Deployment Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nid\n: 1\n}\n\n\n\n\nTo invoke a chaincode, supply the \nChaincodeSpec\n identifying the chaincode to invoke within the request payload. Note the chaincode \nname\n field, which is the hash returned from the deployment request.\n\n\nChaincode Invocation Request without security enabled:\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\ninvoke\n,\n         \nargs\n:[\na\n, \nb\n, \n100\n]\n      }\n  },\n  \nid\n: 3\n}\n\n\n\n\nTo invoke a chaincode with security enabled, supply the \nsecureContext\n element containing the registrationID of a registered and logged in user together with the payload from above.\n\n\nChaincode Invocation Request with security enabled (add \nsecureContext\n element):\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\ninvoke\n,\n         \nargs\n:[\na\n, \nb\n, \n100\n]\n      },\n      \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: 3\n}\n\n\n\n\nThe response to a chaincode invocation request will contain a \nstatus\n element confirming successful completion of the request. The response will likewise contain the transaction id number for that specific transaction. The client may use the returned transaction id number to check on the status of the transaction after it has been submitted to the system, as the transaction execution is asynchronous.\n\n\nChaincode Invocation Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n5a4540e5-902b-422d-a6ab-e70ab36a2e6d\n\n    },\n    \nid\n: 3\n}\n\n\n\n\nTo query a chaincode, supply the \nChaincodeSpec\n identifying the chaincode to query within the request payload. Note the chaincode \nname\n field, which is the hash returned from the deployment request.\n\n\nChaincode Query Request without security enabled:\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\nquery\n,\n         \nargs\n:[\na\n]\n      }\n  },\n  \nid\n: 5\n}\n\n\n\n\nTo query a chaincode with security enabled, supply the \nsecureContext\n element containing the registrationID of a registered and logged in user together with the payload from above.\n\n\nChaincode Query Request with security enabled (add \nsecureContext\n element):\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\nquery\n,\n         \nargs\n:[\na\n]\n      },\n      \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: 5\n}\n\n\n\n\nThe response to a chaincode query request will contain a \nstatus\n element confirming successful completion of the request. The response will likewise contain an appropriate \nmessage\n, as defined by the chaincode. The \nmessage\n received depends on the chaincode implementation and may be a string or number indicating the value of a specific chaincode variable.\n\n\nChaincode Query Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n-400\n\n    },\n    \nid\n: 5\n}\n\n\n\n\nNetwork\n\n\n\n\nGET /network/peers\n\n\n\n\nUse the Network APIs to retrieve information about the network of peer nodes comprising the blockchain network.\n\n\nThe /network/peers endpoint returns a list of all existing network connections for the target peer node. The list includes both validating and non-validating peers. The list of peers is returned as type \nPeersMessage\n, containing an array of \nPeerEndpoint\n.\n\n\nmessage PeersMessage {\n    repeated PeerEndpoint peers = 1;\n}\n\n\n\n\nmessage PeerEndpoint {\n    PeerID ID = 1;\n    string address = 2;\n    enum Type {\n      UNDEFINED = 0;\n      VALIDATOR = 1;\n      NON_VALIDATOR = 2;\n    }\n    Type type = 3;\n    bytes pkiID = 4;\n}\n\n\n\n\nmessage PeerID {\n    string name = 1;\n}\n\n\n\n\nRegistrar\n\n\n\n\nPOST /registrar\n\n\nDELETE /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}/ecert\n\n\nGET /registrar/{enrollmentID}/tcert\n\n\n\n\nUse the Registrar APIs to manage end user registration with the CA. These API endpoints are used to register a user with the CA, determine whether a given user is registered, and to remove any login tokens for a target user preventing them from executing any further transactions. The Registrar APIs are also used to retrieve user enrollment and transaction certificates from the system.\n\n\nThe /registrar endpoint is used to register a user with the CA. The required Secret payload is defined in \ndevops.proto\n.\n\n\nmessage Secret {\n    string enrollId = 1;\n    string enrollSecret = 2;\n}\n\n\n\n\nThe response to the registration request is either a confirmation of successful registration or an error, containing a reason for the failure. An example of a valid Secret message to register user \nlukas\n is shown below.\n\n\n{\n  \nenrollId\n: \nlukas\n,\n  \nenrollSecret\n: \nNPKYL39uKbkj\n\n}\n\n\n\n\nThe GET /registrar/{enrollmentID} endpoint is used to confirm whether a given user is registered with the CA. If so, a confirmation will be returned. Otherwise, an authorization error will result.\n\n\nThe DELETE /registrar/{enrollmentID} endpoint is used to delete login tokens for a target user. If the login tokens are deleted successfully, a confirmation will be returned. Otherwise, an authorization error will result. No payload is required for this endpoint. Note, that registration with the CA is a one time process for a given user, utilizing a single-use registrationID and registrationPW. If the user registration is deleted through this API, the user will not be able to register with the CA a second time.\n\n\nThe GET /registrar/{enrollmentID}/ecert endpoint is used to retrieve the enrollment certificate of a given user from local storage. If the target user has already registered with the CA, the response will include a URL-encoded version of the enrollment certificate. If the target user has not yet registered, an error will be returned. If the client wishes to use the returned enrollment certificate after retrieval, keep in mind that it must be URL-decoded. This can be accomplished with the QueryUnescape method in the \nnet/url\n package.\n\n\nThe /registrar/{enrollmentID}/tcert endpoint retrieves the transaction certificates for a given user that has registered with the certificate authority. If the user has registered, a confirmation message will be returned containing an array of URL-encoded transaction certificates. Otherwise, an error will result. The desired number of transaction certificates is specified with the optional \ncount\n query parameter. The default number of returned transaction certificates is 1; and 500 is the maximum number of certificates that can be retrieved with a single request. If the client wishes to use the returned transaction certificates after retrieval, keep in mind that they must be URL-decoded. This can be accomplished with the QueryUnescape method in the \nnet/url\n package.\n\n\nTransactions\n\n\n\n\nGET /transactions/{UUID}\n\n\n\n\nUse the /transactions/{UUID} endpoint to retrieve an individual transaction matching the UUID from the blockchain. The returned transaction message is defined inside \nfabric.proto\n.\n\n\nmessage Transaction {\n    enum Type {\n        UNDEFINED = 0;\n        CHAINCODE_DEPLOY = 1;\n        CHAINCODE_INVOKE = 2;\n        CHAINCODE_QUERY = 3;\n        CHAINCODE_TERMINATE = 4;\n    }\n    Type type = 1;\n    bytes chaincodeID = 2;\n    bytes payload = 3;\n    string uuid = 4;\n    google.protobuf.Timestamp timestamp = 5;\n\n    ConfidentialityLevel confidentialityLevel = 6;\n    bytes nonce = 7;\n\n    bytes cert = 8;\n    bytes signature = 9;\n}\n\n\n\n\nFor additional information on the REST endpoints and more detailed examples, please see the \nprotocol specification\n section 6.2 on the REST API.\n\n\nTo set up Swagger-UI\n\n\nSwagger\n is a convenient package that allows you to describe and document your REST API in a single file. The REST API is described in \nrest_api.json\n. To interact with the peer node directly through the Swagger-UI, you can upload the available Swagger definition to the \nSwagger service\n. Alternatively, you may set up a Swagger installation on your machine by following the instructions below.\n\n\n\n\n\n\nYou can use Node.js to serve up the rest_api.json locally. To do so, make sure you have Node.js installed on your local machine. If it is not installed, please download the \nNode.js\n package and install it.\n\n\n\n\n\n\nInstall the Node.js http-server package with the command below:\n\n\nnpm install http-server -g\n\n\n\n\n\n\nStart up an http-server on your local machine to serve up the rest_api.json.\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\nhttp-server -a 0.0.0.0 -p 5554 --cors\n\n\n\n\n\n\nMake sure that you are successfully able to access the API description document within your browser at this link:\n\n\nhttp://localhost:5554/rest_api.json\n\n\n\n\n\n\nDownload the Swagger-UI package with the following command:\n\n\ngit clone https://github.com/swagger-api/swagger-ui.git\n\n\n\n\n\n\nNavigate to the /swagger-ui/dist directory and click on the index.html file to bring up the Swagger-UI interface inside your browser.\n\n\n\n\n\n\nStart up the peer node with no connections to a leader or validator as follows.\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric\nbuild/bin/peer node start\n\n\n\n\n\n\nIf you need to construct a test blockchain on the local peer node, run the the TestServerOpenchain_API_GetBlockCount test implemented inside \napi_test.go\n. This test will create a blockchain with 5 blocks. Subsequently restart the peer process.\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\ngo test -v -run TestServerOpenchain_API_GetBlockCount\n\n\n\n\n\n\nGo back to the Swagger-UI interface inside your browser and load the API description. You should now be able to issue queries against the pre-built blockchain directly from Swagger.\n\n\n\n\n\n\nNode.js Application\n\n\nYou can interface with the peer process from a Node.js application. One way to accomplish that is by relying on the Swagger API description document, \nrest_api.json\n and the \nswagger-js plugin\n. Another way to accomplish that relies upon the IBM Blockchain \nJS SDK\n. Use the approach that you find the most convenient.\n\n\nUsing Swagger JS Plugin\n\n\n\n\nDemonstrates interfacing with a peer node from a Node.js application.\n\n\nUtilizes the Node.js swagger-js plugin: https://github.com/swagger-api/swagger-js\n\n\n\n\nTo run:\n\n\n\n\n\n\nBuild and install the \nfabric core\n.\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric\nmake peer\n\n\n\n\n\n\nRun a local peer node only (not a complete network) with:\n\n\nbuild/bin/peer node start\n\n\n\n\n\n\nSet up a test blockchain data structure (with 5 blocks only) by running a test from within Vagrant as follows. Subsequently restart the peer process.\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\ngo test -v -run TestServerOpenchain_API_GetBlockCount\n\n\n\n\n\n\nStart up an http-server on your local machine to serve up the rest_api.json.\n\n\nnpm install http-server -g\ncd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\nhttp-server -a 0.0.0.0 -p 5554 --cors\n\n\n\n\n\n\nDownload and unzip \nSample_1.zip\n\n\nunzip Sample_1.zip -d Sample_1\ncd Sample_1\n\n\n\n\n\n\nUpdate the api_url variable within \nopenchain.js\n to the appropriate URL if it is not already the default\n\n\nvar api_url = 'http://localhost:5554/rest_api.json';\n\n\n\n\n\n\nRun the Node.js app\n\n\nnode ./openchain.js\n\n\n\n\n\n\nYou will observe several responses on the console and the program will appear to hang for a few moments at the end. This is expected, as is it waiting for the invocation transaction to complete in order to then execute a query. You can take a look at the sample output of the program inside the \nopenchain_test\n file located in the Sample_1 directory.\n\n\nMarbles Demo Application\n\n\n\n\nDemonstrates an alternative way of interfacing with a peer node from a Node.js app.\n\n\nDemonstrates deploying a Blockchain application as a Bluemix service.\n\n\n\n\nHold on to your hats everyone, this application is going to demonstrate transferring marbles between two users leveraging IBM Blockchain. We are going to do this in Node.js and a bit of GoLang. The backend of this application will be the GoLang code running in our blockchain network. The chaincode itself will create a marble by storing it to the chaincode state. The chaincode itself is able to store data as a string in a key/value pair setup. Thus we will stringify JSON objects to store more complex structures.\n\n\nFor more inforation on the IBM Blockchain marbles demo, set-up, and instructions, please visit \nthis page\n.\n\n\nCommercial Paper Demo Application\n\n\n\n\nDemonstrates an alternative way of interfacing with a peer node from a Node.js app.\n\n\nDemonstrates deploying a Blockchain application as a Bluemix service.\n\n\n\n\nThis application is a demonstration of how a commercial paper trading network might be implemented on IBM Blockchain. The components of the demo are:\n\n\n\n\nAn interface for creating new users on the network.\n\n\nAn interface for creating new commercial papers to trade.\n\n\nA Trade Center for buying and selling existing trades.\n\n\nA special interface just for auditors of the network to examine trades.\n\n\n\n\nFor more inforation on the IBM Blockchain commercial paper demo, set-up, and instructions, please visit \nthis page\n.",
            "title": "Core API"
        },
        {
            "location": "/API/CoreAPI/#apis-cli-rest-and-nodejs",
            "text": "",
            "title": "APIs - CLI, REST, and Node.js"
        },
        {
            "location": "/API/CoreAPI/#overview",
            "text": "This document covers the available APIs for interacting with a peer node. Three interface choices are provided:   CLI  REST API  Node.js Application  Using Swagger JS Plugin  Marbles Demo Application  Commercial Paper Demo Application   Note:  If you are working with APIs with security enabled, please review the  security setup instructions  before proceeding.",
            "title": "Overview"
        },
        {
            "location": "/API/CoreAPI/#cli",
            "text": "To view the currently available CLI commands, execute the following:  cd /opt/gopath/src/github.com/hyperledger/fabric\nbuild/bin/peer  You will see output similar to the example below ( NOTE:  rootcommand below is hardcoded in  main.go . Currently, the build will create a  peer  executable file).      Usage:\n      peer [flags]\n      peer [command]\n\n    Available Commands:\n      version     Print fabric peer version.\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level= : Default logging level and overrides, see core.yaml for full syntax\n          --test.coverprofile= coverage.cov : Done\n      -v, --version[=false]: Show current version number of fabric peer server\n\n\n    Use  peer [command] --help  for more information about a command.  The  peer  command supports several subcommands and flags, as shown above. To\nfacilitate its use in scripted applications, the  peer  command always\nproduces a non-zero return code in the event of command failure. Upon success,\nmany of the subcommands produce a result on  stdout  as shown in the table\nbelow:     Command  stdout  result in the event of success      version  String form of  peer.version  defined in  core.yaml    node start  N/A    node status  String form of  StatusCode    node stop  String form of  StatusCode    network login  N/A    network list  The list of network connections to the peer node.    chaincode deploy  The chaincode container name (hash) required for subsequent  chaincode invoke  and  chaincode query  commands    chaincode invoke  The transaction ID (UUID)    chaincode query  By default, the query result is formatted as a printable string. Command line options support writing this value as raw bytes (-r,  raw), or formatted as the hexadecimal representation of the raw bytes (-x,  hex). If the query response is empty then nothing is output.",
            "title": "CLI"
        },
        {
            "location": "/API/CoreAPI/#deploy-a-chaincode",
            "text": "Deploy creates the docker image for the chaincode and subsequently deploys the package to the validating peer. An example is below.  peer chaincode deploy -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'  The response to the chaincode deploy command will contain the chaincode identifier (hash) which will be required on subsequent  chaincode invoke  and  chaincode query  commands in order to identify the deployed chaincode.  With security enabled, modify the command to include the -u parameter passing the username of a logged in user as follows:  peer chaincode deploy -u jim -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'  Note:  If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.",
            "title": "Deploy a Chaincode"
        },
        {
            "location": "/API/CoreAPI/#verify-results",
            "text": "To verify that the block containing the latest transaction has been added to the blockchain, use the  /chain  REST endpoint from the command line. Target the IP address of either a validating or a non-validating node. In the example below, 172.17.0.2 is the IP address of a validating or a non-validating node and 7050 is the REST interface port defined in  core.yaml .  curl 172.17.0.2:7050/chain  An example of the response is below.  {\n     height :1,\n     currentBlockHash : 4Yc4yCO95wcpWHW2NLFlf76OGURBBxYZMf3yUyvrEXs5TMai9qNKfy9Yn/== \n}  The returned BlockchainInfo message is defined inside  fabric.proto .  message BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}  To verify that a specific block is inside the blockchain, use the  /chain/blocks/{Block}  REST endpoint. Likewise, target the IP address of either a validating or a non-validating node on port 7050.  curl 172.17.0.2:7050/chain/blocks/0  The returned Block message structure is defined inside  fabric.proto .  message Block {\n    uint32 version = 1;\n    google.protobuf.Timestamp timestamp = 2;\n    repeated Transaction transactions = 3;\n    bytes stateHash = 4;\n    bytes previousBlockHash = 5;\n    bytes consensusMetadata = 6;\n    NonHashData nonHashData = 7;\n}  An example of a returned Block structure is below.  {\n     transactions :[{\n         type :1,\n         chaincodeID : {\n             path : github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 \n        },\n         payload : ClwIARJYCk9naXRod... ,\n         uuid : abdcec99-ae5e-415e-a8be-1fca8e38ba71 \n    }],\n     stateHash : PY5YcQRu2g1vjiAqHHshoAhnq8CFP3MqzMslcEAJbnmXDtD+LopmkrUHrPMOGSF5UD7Kxqhbg1XUjmQAi84paw== \n}  For additional information on the available CLI commands, please see the  protocol specification  section 6.3 on CLI.",
            "title": "Verify Results"
        },
        {
            "location": "/API/CoreAPI/#rest-api",
            "text": "You can work with the REST API through any tool of your choice. For example, the curl command line utility or a browser based client such as the Firefox Rest Client or Chrome Postman. You can likewise trigger REST requests directly through  Swagger . You can utilize the Swagger service directly or, if you prefer, you can set up Swagger locally by following the instructions  here .  Note:  The default REST interface port is  7050 . It can be configured in  core.yaml  using the  rest.address  property. If using Vagrant, the REST port mapping is defined in  Vagrantfile .  Note on constructing a test blockchain  If you want to test the REST API locally, construct a test blockchain by running the TestServerOpenchain_API_GetBlockCount test implemented inside  api_test.go . This test will create a test blockchain with 5 blocks. Subsequently restart the peer process.      cd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\n    go test -v -run TestServerOpenchain_API_GetBlockCount",
            "title": "REST API"
        },
        {
            "location": "/API/CoreAPI/#rest-endpoints",
            "text": "To learn about the REST API through Swagger, please take a look at the Swagger document  here . You can upload the service description file to the Swagger service directly or, if you prefer, you can set up Swagger locally by following the instructions  here .   Block  GET /chain/blocks/{Block}  Blockchain  GET /chain  Chaincode  POST /chaincode    Network  GET /network/peers  Registrar  POST /registrar  DELETE /registrar/{enrollmentID}  GET /registrar/{enrollmentID}  GET /registrar/{enrollmentID}/ecert  GET /registrar/{enrollmentID}/tcert  Transactions  GET /transactions/{UUID}",
            "title": "REST Endpoints"
        },
        {
            "location": "/API/CoreAPI/#block",
            "text": "GET /chain/blocks/{Block}   Use the Block API to retrieve the contents of various blocks from the blockchain. The returned Block message structure is defined inside  fabric.proto .  message Block {\n    uint32 version = 1;\n    google.protobuf.Timestamp Timestamp = 2;\n    repeated Transaction transactions = 3;\n    bytes stateHash = 4;\n    bytes previousBlockHash = 5;\n}",
            "title": "Block"
        },
        {
            "location": "/API/CoreAPI/#blockchain",
            "text": "GET /chain   Use the Chain API to retrieve the current state of the blockchain. The returned BlockchainInfo message is defined inside  fabric.proto .  message BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}",
            "title": "Blockchain"
        },
        {
            "location": "/API/CoreAPI/#chaincode",
            "text": "POST /chaincode   Use the /chaincode endpoint to deploy, invoke, and query a target chaincode. This service endpoint implements the  JSON RPC 2.0 specification  with the payload identifying the desired chaincode operation within the  method  field. The supported methods are  deploy ,  invoke , and  query .  The /chaincode endpoint implements the  JSON RPC 2.0 specification  and as such, must have the required fields of  jsonrpc ,  method , and in our case  params  supplied within the payload. The client should also add the  id  element within the payload if they wish to receive a response to the request. If the  id  element is missing from the request payload, the request is assumed to be a notification and the server will not produce a response.  The following sample payloads may be used to deploy, invoke, and query a sample chaincode. To deploy a chaincode, supply the  ChaincodeSpec  identifying the chaincode to deploy within the request payload.  Chaincode Deployment Request without security enabled:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type : 1,\n     chaincodeID :{\n         path : github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  1000 ,  b ,  2000 ]\n    }\n  },\n   id : 1\n}  To deploy a chaincode with security enabled, supply the  secureContext  element containing the registrationID of a registered and logged in user together with the payload from above.  Chaincode Deployment Request with security enabled (add  secureContext  element):  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type : 1,\n     chaincodeID :{\n         path : github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  1000 ,  b ,  2000 ]\n    },\n     secureContext :  lukas \n  },\n   id : 1\n}  The response to a chaincode deployment request will contain a  status  element confirming successful completion of the request. The response to a successful deployment request will likewise contain the generated chaincode hash which must be used in subsequent invocation and query requests sent to this chaincode.  Chaincode Deployment Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     id : 1\n}  To invoke a chaincode, supply the  ChaincodeSpec  identifying the chaincode to invoke within the request payload. Note the chaincode  name  field, which is the hash returned from the deployment request.  Chaincode Invocation Request without security enabled:  {\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n      },\n       ctorMsg : {\n          function : invoke ,\n          args :[ a ,  b ,  100 ]\n      }\n  },\n   id : 3\n}  To invoke a chaincode with security enabled, supply the  secureContext  element containing the registrationID of a registered and logged in user together with the payload from above.  Chaincode Invocation Request with security enabled (add  secureContext  element):  {\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n      },\n       ctorMsg : {\n          function : invoke ,\n          args :[ a ,  b ,  100 ]\n      },\n       secureContext :  lukas \n  },\n   id : 3\n}  The response to a chaincode invocation request will contain a  status  element confirming successful completion of the request. The response will likewise contain the transaction id number for that specific transaction. The client may use the returned transaction id number to check on the status of the transaction after it has been submitted to the system, as the transaction execution is asynchronous.  Chaincode Invocation Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  5a4540e5-902b-422d-a6ab-e70ab36a2e6d \n    },\n     id : 3\n}  To query a chaincode, supply the  ChaincodeSpec  identifying the chaincode to query within the request payload. Note the chaincode  name  field, which is the hash returned from the deployment request.  Chaincode Query Request without security enabled:  {\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n      },\n       ctorMsg : {\n          function : query ,\n          args :[ a ]\n      }\n  },\n   id : 5\n}  To query a chaincode with security enabled, supply the  secureContext  element containing the registrationID of a registered and logged in user together with the payload from above.  Chaincode Query Request with security enabled (add  secureContext  element):  {\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n      },\n       ctorMsg : {\n          function : query ,\n          args :[ a ]\n      },\n       secureContext :  lukas \n  },\n   id : 5\n}  The response to a chaincode query request will contain a  status  element confirming successful completion of the request. The response will likewise contain an appropriate  message , as defined by the chaincode. The  message  received depends on the chaincode implementation and may be a string or number indicating the value of a specific chaincode variable.  Chaincode Query Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  -400 \n    },\n     id : 5\n}",
            "title": "Chaincode"
        },
        {
            "location": "/API/CoreAPI/#network",
            "text": "GET /network/peers   Use the Network APIs to retrieve information about the network of peer nodes comprising the blockchain network.  The /network/peers endpoint returns a list of all existing network connections for the target peer node. The list includes both validating and non-validating peers. The list of peers is returned as type  PeersMessage , containing an array of  PeerEndpoint .  message PeersMessage {\n    repeated PeerEndpoint peers = 1;\n}  message PeerEndpoint {\n    PeerID ID = 1;\n    string address = 2;\n    enum Type {\n      UNDEFINED = 0;\n      VALIDATOR = 1;\n      NON_VALIDATOR = 2;\n    }\n    Type type = 3;\n    bytes pkiID = 4;\n}  message PeerID {\n    string name = 1;\n}",
            "title": "Network"
        },
        {
            "location": "/API/CoreAPI/#registrar",
            "text": "POST /registrar  DELETE /registrar/{enrollmentID}  GET /registrar/{enrollmentID}  GET /registrar/{enrollmentID}/ecert  GET /registrar/{enrollmentID}/tcert   Use the Registrar APIs to manage end user registration with the CA. These API endpoints are used to register a user with the CA, determine whether a given user is registered, and to remove any login tokens for a target user preventing them from executing any further transactions. The Registrar APIs are also used to retrieve user enrollment and transaction certificates from the system.  The /registrar endpoint is used to register a user with the CA. The required Secret payload is defined in  devops.proto .  message Secret {\n    string enrollId = 1;\n    string enrollSecret = 2;\n}  The response to the registration request is either a confirmation of successful registration or an error, containing a reason for the failure. An example of a valid Secret message to register user  lukas  is shown below.  {\n   enrollId :  lukas ,\n   enrollSecret :  NPKYL39uKbkj \n}  The GET /registrar/{enrollmentID} endpoint is used to confirm whether a given user is registered with the CA. If so, a confirmation will be returned. Otherwise, an authorization error will result.  The DELETE /registrar/{enrollmentID} endpoint is used to delete login tokens for a target user. If the login tokens are deleted successfully, a confirmation will be returned. Otherwise, an authorization error will result. No payload is required for this endpoint. Note, that registration with the CA is a one time process for a given user, utilizing a single-use registrationID and registrationPW. If the user registration is deleted through this API, the user will not be able to register with the CA a second time.  The GET /registrar/{enrollmentID}/ecert endpoint is used to retrieve the enrollment certificate of a given user from local storage. If the target user has already registered with the CA, the response will include a URL-encoded version of the enrollment certificate. If the target user has not yet registered, an error will be returned. If the client wishes to use the returned enrollment certificate after retrieval, keep in mind that it must be URL-decoded. This can be accomplished with the QueryUnescape method in the  net/url  package.  The /registrar/{enrollmentID}/tcert endpoint retrieves the transaction certificates for a given user that has registered with the certificate authority. If the user has registered, a confirmation message will be returned containing an array of URL-encoded transaction certificates. Otherwise, an error will result. The desired number of transaction certificates is specified with the optional  count  query parameter. The default number of returned transaction certificates is 1; and 500 is the maximum number of certificates that can be retrieved with a single request. If the client wishes to use the returned transaction certificates after retrieval, keep in mind that they must be URL-decoded. This can be accomplished with the QueryUnescape method in the  net/url  package.",
            "title": "Registrar"
        },
        {
            "location": "/API/CoreAPI/#transactions",
            "text": "GET /transactions/{UUID}   Use the /transactions/{UUID} endpoint to retrieve an individual transaction matching the UUID from the blockchain. The returned transaction message is defined inside  fabric.proto .  message Transaction {\n    enum Type {\n        UNDEFINED = 0;\n        CHAINCODE_DEPLOY = 1;\n        CHAINCODE_INVOKE = 2;\n        CHAINCODE_QUERY = 3;\n        CHAINCODE_TERMINATE = 4;\n    }\n    Type type = 1;\n    bytes chaincodeID = 2;\n    bytes payload = 3;\n    string uuid = 4;\n    google.protobuf.Timestamp timestamp = 5;\n\n    ConfidentialityLevel confidentialityLevel = 6;\n    bytes nonce = 7;\n\n    bytes cert = 8;\n    bytes signature = 9;\n}  For additional information on the REST endpoints and more detailed examples, please see the  protocol specification  section 6.2 on the REST API.",
            "title": "Transactions"
        },
        {
            "location": "/API/CoreAPI/#to-set-up-swagger-ui",
            "text": "Swagger  is a convenient package that allows you to describe and document your REST API in a single file. The REST API is described in  rest_api.json . To interact with the peer node directly through the Swagger-UI, you can upload the available Swagger definition to the  Swagger service . Alternatively, you may set up a Swagger installation on your machine by following the instructions below.    You can use Node.js to serve up the rest_api.json locally. To do so, make sure you have Node.js installed on your local machine. If it is not installed, please download the  Node.js  package and install it.    Install the Node.js http-server package with the command below:  npm install http-server -g    Start up an http-server on your local machine to serve up the rest_api.json.  cd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\nhttp-server -a 0.0.0.0 -p 5554 --cors    Make sure that you are successfully able to access the API description document within your browser at this link:  http://localhost:5554/rest_api.json    Download the Swagger-UI package with the following command:  git clone https://github.com/swagger-api/swagger-ui.git    Navigate to the /swagger-ui/dist directory and click on the index.html file to bring up the Swagger-UI interface inside your browser.    Start up the peer node with no connections to a leader or validator as follows.  cd /opt/gopath/src/github.com/hyperledger/fabric\nbuild/bin/peer node start    If you need to construct a test blockchain on the local peer node, run the the TestServerOpenchain_API_GetBlockCount test implemented inside  api_test.go . This test will create a blockchain with 5 blocks. Subsequently restart the peer process.  cd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\ngo test -v -run TestServerOpenchain_API_GetBlockCount    Go back to the Swagger-UI interface inside your browser and load the API description. You should now be able to issue queries against the pre-built blockchain directly from Swagger.",
            "title": "To set up Swagger-UI"
        },
        {
            "location": "/API/CoreAPI/#nodejs-application",
            "text": "You can interface with the peer process from a Node.js application. One way to accomplish that is by relying on the Swagger API description document,  rest_api.json  and the  swagger-js plugin . Another way to accomplish that relies upon the IBM Blockchain  JS SDK . Use the approach that you find the most convenient.",
            "title": "Node.js Application"
        },
        {
            "location": "/API/CoreAPI/#using-swagger-js-plugin",
            "text": "Demonstrates interfacing with a peer node from a Node.js application.  Utilizes the Node.js swagger-js plugin: https://github.com/swagger-api/swagger-js   To run:    Build and install the  fabric core .  cd /opt/gopath/src/github.com/hyperledger/fabric\nmake peer    Run a local peer node only (not a complete network) with:  build/bin/peer node start    Set up a test blockchain data structure (with 5 blocks only) by running a test from within Vagrant as follows. Subsequently restart the peer process.  cd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\ngo test -v -run TestServerOpenchain_API_GetBlockCount    Start up an http-server on your local machine to serve up the rest_api.json.  npm install http-server -g\ncd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\nhttp-server -a 0.0.0.0 -p 5554 --cors    Download and unzip  Sample_1.zip  unzip Sample_1.zip -d Sample_1\ncd Sample_1    Update the api_url variable within  openchain.js  to the appropriate URL if it is not already the default  var api_url = 'http://localhost:5554/rest_api.json';    Run the Node.js app  node ./openchain.js    You will observe several responses on the console and the program will appear to hang for a few moments at the end. This is expected, as is it waiting for the invocation transaction to complete in order to then execute a query. You can take a look at the sample output of the program inside the  openchain_test  file located in the Sample_1 directory.",
            "title": "Using Swagger JS Plugin"
        },
        {
            "location": "/API/CoreAPI/#marbles-demo-application",
            "text": "Demonstrates an alternative way of interfacing with a peer node from a Node.js app.  Demonstrates deploying a Blockchain application as a Bluemix service.   Hold on to your hats everyone, this application is going to demonstrate transferring marbles between two users leveraging IBM Blockchain. We are going to do this in Node.js and a bit of GoLang. The backend of this application will be the GoLang code running in our blockchain network. The chaincode itself will create a marble by storing it to the chaincode state. The chaincode itself is able to store data as a string in a key/value pair setup. Thus we will stringify JSON objects to store more complex structures.  For more inforation on the IBM Blockchain marbles demo, set-up, and instructions, please visit  this page .",
            "title": "Marbles Demo Application"
        },
        {
            "location": "/API/CoreAPI/#commercial-paper-demo-application",
            "text": "Demonstrates an alternative way of interfacing with a peer node from a Node.js app.  Demonstrates deploying a Blockchain application as a Bluemix service.   This application is a demonstration of how a commercial paper trading network might be implemented on IBM Blockchain. The components of the demo are:   An interface for creating new users on the network.  An interface for creating new commercial papers to trade.  A Trade Center for buying and selling existing trades.  A special interface just for auditors of the network to examine trades.   For more inforation on the IBM Blockchain commercial paper demo, set-up, and instructions, please visit  this page .",
            "title": "Commercial Paper Demo Application"
        },
        {
            "location": "/API/MemberServicesAPI/",
            "text": "Certificate Authority API\n\n\nEach of the CA services is split into two \nGRPC\n interfaces, namely a public one (indicated by a \nP\n suffix) and an administrator one (indicated by an \nA\n suffix).\n\n\nEnrollment Certificate Authority\n\n\nThe administrator interface of the ECA provides the following functions:\n\n\nservice ECAA { // admin\n    rpc RegisterUser(RegisterUserReq) returns (Token);\n    rpc ReadUserSet(ReadUserSetReq) returns (UserSet);\n    rpc RevokeCertificate(ECertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc PublishCRL(ECertCRLReq) returns (CAStatus); // not yet implemented\n}\n\n\n\nThe \nRegisterUser\n function allows you to register a new user by specifiying their name and roles in the \nRegisterUserReq\n structure. If the user has not been registered before, the ECA registers the new user and returns a unique one-time password, which can be used by the user to request their enrollment certificate pair via the public interface of the ECA. Otherwise an error is returned.\n\n\nThe \nReadUserSet\n function allows only auditors to retrieve the list of users registered with the blockchain.\n\n\nThe public interface of the ECA provides the following functions:\n\n\nservice ECAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificatePair(ECertCreateReq) returns (ECertCreateResp);\n    rpc ReadCertificatePair(ECertReadReq) returns (CertPair);\n    rpc ReadCertificateByHash(Hash) returns (Cert);\n    rpc RevokeCertificatePair(ECertRevokeReq) returns (CAStatus); // not yet implemented\n}\n\n\n\nThe \nReadCACertificate\n function returns the certificate of the ECA itself.\n\n\nThe \nCreateCertificatePair\n function allows a user to create and read their enrollment certificate pair. For this, the user has to do two successive invocations of this function. Firstly, both the signature and encryption public keys have to be handed to the ECA together with the one-time password previously returned by the \nRegisterUser\n function invocation. The request has to be signed by the user\ns private signature key to demonstrate that the user is in possession of the private signature key. The ECA in return gives the user a challenge encrypted with the user\ns public encryption key. The user has to decrypt the challenge, thereby demonstrating that they are in possession of the private encryption key, and then re-issue the certificate creation request - this time with the decrypted challenge instead of the one-time password passed in the invocation. If the challenge has been decrypted correctly, the ECA issues and returns the enrollment certificate pair for the user.\n\n\nThe \nReadCertificatePair\n function allows any user of the blockchain to read the certificate pair of any other user of the blockchain.\n\n\nThe \nReadCertificatePairByHash\n function allows any user of the blockchain to read a certificate from the ECA matching a given hash.\n\n\nTransaction Certificate Authority\n\n\nThe administrator interface of the TCA provides the following functions:\n\n\nservice TCAA { // admin\n    rpc RevokeCertificate(TCertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc RevokeCertificateSet(TCertRevokeSetReq) returns (CAStatus); // not yet implemented\n    rpc PublishCRL(TCertCRLReq) returns (CAStatus); // not yet implemented\n}\n\n\n\nThe public interface of the TCA provides the following functions:\n\n\nservice TCAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificate(TCertCreateReq) returns (TCertCreateResp);\n    rpc CreateCertificateSet(TCertCreateSetReq) returns (TCertCreateSetResp);\n    rpc RevokeCertificate(TCertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc RevokeCertificateSet(TCertRevokeSetReq) returns (CAStatus); // not yet implemented\n}\n\n\n\nThe \nReadCACertificate\n function returns the certificate of the TCA itself.\n\n\nThe \nCreateCertificate\n function allows a user to create and retrieve a new transaction certificate.\n\n\nThe \nCreateCertificateSet\n function allows a user to create and retrieve a set of transaction certificates in a single call.\n\n\nTLS Certificate Authority\n\n\nThe administrator interface of the TLSCA provides the following functions:\n\n\nservice TLSCAA { // admin\n    rpc RevokeCertificate(TLSCertRevokeReq) returns (CAStatus); not yet implemented\n}\n\n\n\nThe public interface of the TLSCA provides the following functions:\n\n\nservice TLSCAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificate(TLSCertCreateReq) returns (TLSCertCreateResp);\n    rpc ReadCertificate(TLSCertReadReq) returns (Cert);\n    rpc RevokeCertificate(TLSCertRevokeReq) returns (CAStatus); // not yet implemented\n}\n\n\n\nThe \nReadCACertificate\n function returns the certificate of the TLSCA itself.\n\n\nThe \nCreateCertificate\n function allows a user to create and retrieve a new TLS certificate.\n\n\nThe \nReadCertificate\n function allows a user to retrieve a previously created TLS certificate.",
            "title": "CA API"
        },
        {
            "location": "/API/MemberServicesAPI/#certificate-authority-api",
            "text": "Each of the CA services is split into two  GRPC  interfaces, namely a public one (indicated by a  P  suffix) and an administrator one (indicated by an  A  suffix).",
            "title": "Certificate Authority API"
        },
        {
            "location": "/API/MemberServicesAPI/#enrollment-certificate-authority",
            "text": "The administrator interface of the ECA provides the following functions:  service ECAA { // admin\n    rpc RegisterUser(RegisterUserReq) returns (Token);\n    rpc ReadUserSet(ReadUserSetReq) returns (UserSet);\n    rpc RevokeCertificate(ECertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc PublishCRL(ECertCRLReq) returns (CAStatus); // not yet implemented\n}  The  RegisterUser  function allows you to register a new user by specifiying their name and roles in the  RegisterUserReq  structure. If the user has not been registered before, the ECA registers the new user and returns a unique one-time password, which can be used by the user to request their enrollment certificate pair via the public interface of the ECA. Otherwise an error is returned.  The  ReadUserSet  function allows only auditors to retrieve the list of users registered with the blockchain.  The public interface of the ECA provides the following functions:  service ECAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificatePair(ECertCreateReq) returns (ECertCreateResp);\n    rpc ReadCertificatePair(ECertReadReq) returns (CertPair);\n    rpc ReadCertificateByHash(Hash) returns (Cert);\n    rpc RevokeCertificatePair(ECertRevokeReq) returns (CAStatus); // not yet implemented\n}  The  ReadCACertificate  function returns the certificate of the ECA itself.  The  CreateCertificatePair  function allows a user to create and read their enrollment certificate pair. For this, the user has to do two successive invocations of this function. Firstly, both the signature and encryption public keys have to be handed to the ECA together with the one-time password previously returned by the  RegisterUser  function invocation. The request has to be signed by the user s private signature key to demonstrate that the user is in possession of the private signature key. The ECA in return gives the user a challenge encrypted with the user s public encryption key. The user has to decrypt the challenge, thereby demonstrating that they are in possession of the private encryption key, and then re-issue the certificate creation request - this time with the decrypted challenge instead of the one-time password passed in the invocation. If the challenge has been decrypted correctly, the ECA issues and returns the enrollment certificate pair for the user.  The  ReadCertificatePair  function allows any user of the blockchain to read the certificate pair of any other user of the blockchain.  The  ReadCertificatePairByHash  function allows any user of the blockchain to read a certificate from the ECA matching a given hash.",
            "title": "Enrollment Certificate Authority"
        },
        {
            "location": "/API/MemberServicesAPI/#transaction-certificate-authority",
            "text": "The administrator interface of the TCA provides the following functions:  service TCAA { // admin\n    rpc RevokeCertificate(TCertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc RevokeCertificateSet(TCertRevokeSetReq) returns (CAStatus); // not yet implemented\n    rpc PublishCRL(TCertCRLReq) returns (CAStatus); // not yet implemented\n}  The public interface of the TCA provides the following functions:  service TCAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificate(TCertCreateReq) returns (TCertCreateResp);\n    rpc CreateCertificateSet(TCertCreateSetReq) returns (TCertCreateSetResp);\n    rpc RevokeCertificate(TCertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc RevokeCertificateSet(TCertRevokeSetReq) returns (CAStatus); // not yet implemented\n}  The  ReadCACertificate  function returns the certificate of the TCA itself.  The  CreateCertificate  function allows a user to create and retrieve a new transaction certificate.  The  CreateCertificateSet  function allows a user to create and retrieve a set of transaction certificates in a single call.",
            "title": "Transaction Certificate Authority"
        },
        {
            "location": "/API/MemberServicesAPI/#tls-certificate-authority",
            "text": "The administrator interface of the TLSCA provides the following functions:  service TLSCAA { // admin\n    rpc RevokeCertificate(TLSCertRevokeReq) returns (CAStatus); not yet implemented\n}  The public interface of the TLSCA provides the following functions:  service TLSCAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificate(TLSCertCreateReq) returns (TLSCertCreateResp);\n    rpc ReadCertificate(TLSCertReadReq) returns (Cert);\n    rpc RevokeCertificate(TLSCertRevokeReq) returns (CAStatus); // not yet implemented\n}  The  ReadCACertificate  function returns the certificate of the TLSCA itself.  The  CreateCertificate  function allows a user to create and retrieve a new TLS certificate.  The  ReadCertificate  function allows a user to retrieve a previously created TLS certificate.",
            "title": "TLS Certificate Authority"
        },
        {
            "location": "/SystemChaincodes/noop/",
            "text": "NO-OP system chaincode\n\n\nNO-OP is a system chaincode that does nothing when invoked. The parameters of the invoke transaction are stored on the ledger so it is possible to encode arbitrary data into them.\n\n\nFunctions and valid options\n\n\n\n\nInvoke transactions have to be called with \nexecute\n as function name and at least one argument. Only the \nfirst argument\n is used. Note that it should be \nencoded with BASE64\n.\n\n\nOnly one type of query is supported: \ngetTran\n (passed as a function name). GetTran has to get a transaction ID as argument in hexadecimal format. The function looks up the corresponding transaction\ns (if any) \nfirst argument\n and tries to \ndecode it as a BASE64 encoded string\n.\n\n\n\n\nTesting\n\n\nNO-OP has unit tests checking invocation and queries using proper/improper arguments. The chaincode implementation provides a facility for mocking the ledger under the chaincode (\nmockLedgerH\n in struct \nchaincode.SystemChaincode\n). This should only be used for testing as it is dangerous to rely on global variables in memory that can hold state across invokes.",
            "title": "System Chaincode"
        },
        {
            "location": "/SystemChaincodes/noop/#no-op-system-chaincode",
            "text": "NO-OP is a system chaincode that does nothing when invoked. The parameters of the invoke transaction are stored on the ledger so it is possible to encode arbitrary data into them.",
            "title": "NO-OP system chaincode"
        },
        {
            "location": "/SystemChaincodes/noop/#functions-and-valid-options",
            "text": "Invoke transactions have to be called with  execute  as function name and at least one argument. Only the  first argument  is used. Note that it should be  encoded with BASE64 .  Only one type of query is supported:  getTran  (passed as a function name). GetTran has to get a transaction ID as argument in hexadecimal format. The function looks up the corresponding transaction s (if any)  first argument  and tries to  decode it as a BASE64 encoded string .",
            "title": "Functions and valid options"
        },
        {
            "location": "/SystemChaincodes/noop/#testing",
            "text": "NO-OP has unit tests checking invocation and queries using proper/improper arguments. The chaincode implementation provides a facility for mocking the ledger under the chaincode ( mockLedgerH  in struct  chaincode.SystemChaincode ). This should only be used for testing as it is dangerous to rely on global variables in memory that can hold state across invokes.",
            "title": "Testing"
        },
        {
            "location": "/CONTRIBUTING/",
            "text": "Contributions Welcome!\n\n\nWe welcome contributions to the Hyperledger Project in many forms, and\nthere\ns always plenty to do!\n\n\nFirst things first, please review the Hyperledger Project\ns \nCode of\nConduct\n\nbefore participating. It is important that we keep things civil.\n\n\nGetting a Linux Foundation account\n\n\nIn order to participate in the development of the Hyperledger Fabric project,\nyou will need an \nLF account\n. This will give you single\nsign-on to all the community tools, including Gerrit and Jira (coming soon!).\n\n\nGetting help\n\n\nIf you are looking for something to work on, or need some expert assistance in\ndebugging a problem or working out a fix to an issue, our\n\ncommunity\n is always eager to help. We\nhang out on \nSlack\n, IRC (#hyperledger on\nfreenode.net) and the \nmailing lists\n. Most of us\ndon\nt bite ;-) and will be glad to help.\n\n\nRequirements and Use Cases\n\n\nWe have a \nRequirements\nWG\n that is\ndocumenting use cases and from those use cases deriving requirements. If you are\ninterested in contributing to this effort, please feel free to join the\ndiscussion in\n\nslack\n.\n\n\nReporting bugs\n\n\nIf you are a user and you find a bug, please submit an\n\nissue\n. Please try to provide\nsufficient information for someone else to reproduce the issue. One of the\nproject\ns maintainers should respond to your issue within 24 hours. If not,\nplease bump the issue and request that it be reviewed.\n\n\nFixing issues and working stories\n\n\nReview the \nissues list\n and find\nsomething that interests you. You could also check the \nhelp\nwanted\n\nand \ngood first\nbug\n\nlists. It is wise to start with something relatively straight forward and\nachievable. Usually there will be a comment in the issue that indicates whether\nsomeone has already self-assigned the issue. If no one has already taken it,\nthen add a comment assigning the issue to yourself, eg.: \nI'll work on this\nissue.\n. Please be considerate and rescind the offer in comments if you cannot\nfinish in a reasonable time, or add a comment saying that you are still actively\nworking the issue if you need a little more time.\n\n\nWorking with a local clone and Gerrit\n\n\nWe are using \nGerrit\n\nto manage code contributions. If you are unfamiliar, please review \nthis\ndocument\n before proceeding.\n\n\nAfter you have familiarized yourself with \nGerrit\n, and maybe played around with\nthe \nlf-sandbox\n project, you should be ready to set up your local \ndevelopment\nenvironment\n. We use a Vagrant-based approach to\ndevelopment that simplifies things greatly.\n\n\nCoding guidelines\n\n\nBe sure to check out the language-specific \nstyle\nguides\n before making any changes. This will ensure a\nsmoother review.\n\n\nBecoming a maintainer\n\n\nThis project is managed under open governance model as described in our\n\ncharter\n. Projects or sub-projects\nwill be lead by a set of maintainers. New projects can designate an initial set\nof maintainers that will be approved by the Technical Steering Committee when\nthe project is first approved. The project\ns maintainers will, from\ntime-to-time, consider adding or removing a maintainer. An existing maintainer\nwill post a patchset to the \nMAINTAINERS.md\n file. If a\nmajority of the maintainers concur in the comments, the pull request is then\nmerged and the individual becomes a (or is removed as a) maintainer. Note that\nremoving a maintainer should not be taken lightly, but occasionally, people do\nmove on - hence the bar should be some period of inactivity, an explicit\nresignation, some infraction of the code of conduct or consistently\ndemonstrating poor judgement.\n\n\nLegal stuff\n\n\nNote:\n Each source file must include a license header for the Apache Software\nLicense 2.0. A template of that header can be found \nhere\n.\n\n\nWe have tried to make it as easy as possible to make contributions. This\napplies to how we handle the legal aspects of contribution. We use the same\napproach\nthe \nDeveloper\ns Certificate of Origin 1.1 (DCO)\nthat\nthe Linux\n Kernel \ncommunity\n uses to manage code contributions.\n\n\nWe simply ask that when submitting a patch for review, the developer must include\na sign-off statement in the commit message.\n\n\nHere is an example Signed-off-by line, which indicates that the submitter\naccepts the DCO:\n\n\nSigned-off-by: John Doe \njohn.doe@hisdomain.com\n\n\n\n\n\nYou can include this automatically when you commit a change to your local git\nrepository using \ngit commit -s\n.",
            "title": "Contributing"
        },
        {
            "location": "/CONTRIBUTING/#contributions-welcome",
            "text": "We welcome contributions to the Hyperledger Project in many forms, and\nthere s always plenty to do!  First things first, please review the Hyperledger Project s  Code of\nConduct \nbefore participating. It is important that we keep things civil.",
            "title": "Contributions Welcome!"
        },
        {
            "location": "/CONTRIBUTING/#getting-a-linux-foundation-account",
            "text": "In order to participate in the development of the Hyperledger Fabric project,\nyou will need an  LF account . This will give you single\nsign-on to all the community tools, including Gerrit and Jira (coming soon!).",
            "title": "Getting a Linux Foundation account"
        },
        {
            "location": "/CONTRIBUTING/#getting-help",
            "text": "If you are looking for something to work on, or need some expert assistance in\ndebugging a problem or working out a fix to an issue, our community  is always eager to help. We\nhang out on  Slack , IRC (#hyperledger on\nfreenode.net) and the  mailing lists . Most of us\ndon t bite ;-) and will be glad to help.",
            "title": "Getting help"
        },
        {
            "location": "/CONTRIBUTING/#requirements-and-use-cases",
            "text": "We have a  Requirements\nWG  that is\ndocumenting use cases and from those use cases deriving requirements. If you are\ninterested in contributing to this effort, please feel free to join the\ndiscussion in slack .",
            "title": "Requirements and Use Cases"
        },
        {
            "location": "/CONTRIBUTING/#reporting-bugs",
            "text": "If you are a user and you find a bug, please submit an issue . Please try to provide\nsufficient information for someone else to reproduce the issue. One of the\nproject s maintainers should respond to your issue within 24 hours. If not,\nplease bump the issue and request that it be reviewed.",
            "title": "Reporting bugs"
        },
        {
            "location": "/CONTRIBUTING/#fixing-issues-and-working-stories",
            "text": "Review the  issues list  and find\nsomething that interests you. You could also check the  help\nwanted \nand  good first\nbug \nlists. It is wise to start with something relatively straight forward and\nachievable. Usually there will be a comment in the issue that indicates whether\nsomeone has already self-assigned the issue. If no one has already taken it,\nthen add a comment assigning the issue to yourself, eg.:  I'll work on this\nissue. . Please be considerate and rescind the offer in comments if you cannot\nfinish in a reasonable time, or add a comment saying that you are still actively\nworking the issue if you need a little more time.",
            "title": "Fixing issues and working stories"
        },
        {
            "location": "/CONTRIBUTING/#working-with-a-local-clone-and-gerrit",
            "text": "We are using  Gerrit \nto manage code contributions. If you are unfamiliar, please review  this\ndocument  before proceeding.  After you have familiarized yourself with  Gerrit , and maybe played around with\nthe  lf-sandbox  project, you should be ready to set up your local  development\nenvironment . We use a Vagrant-based approach to\ndevelopment that simplifies things greatly.",
            "title": "Working with a local clone and Gerrit"
        },
        {
            "location": "/CONTRIBUTING/#coding-guidelines",
            "text": "Be sure to check out the language-specific  style\nguides  before making any changes. This will ensure a\nsmoother review.",
            "title": "Coding guidelines"
        },
        {
            "location": "/CONTRIBUTING/#becoming-a-maintainer",
            "text": "This project is managed under open governance model as described in our charter . Projects or sub-projects\nwill be lead by a set of maintainers. New projects can designate an initial set\nof maintainers that will be approved by the Technical Steering Committee when\nthe project is first approved. The project s maintainers will, from\ntime-to-time, consider adding or removing a maintainer. An existing maintainer\nwill post a patchset to the  MAINTAINERS.md  file. If a\nmajority of the maintainers concur in the comments, the pull request is then\nmerged and the individual becomes a (or is removed as a) maintainer. Note that\nremoving a maintainer should not be taken lightly, but occasionally, people do\nmove on - hence the bar should be some period of inactivity, an explicit\nresignation, some infraction of the code of conduct or consistently\ndemonstrating poor judgement.",
            "title": "Becoming a maintainer"
        },
        {
            "location": "/CONTRIBUTING/#legal-stuff",
            "text": "Note:  Each source file must include a license header for the Apache Software\nLicense 2.0. A template of that header can be found  here .  We have tried to make it as easy as possible to make contributions. This\napplies to how we handle the legal aspects of contribution. We use the same\napproach the  Developer s Certificate of Origin 1.1 (DCO) that\nthe Linux  Kernel  community  uses to manage code contributions.  We simply ask that when submitting a patch for review, the developer must include\na sign-off statement in the commit message.  Here is an example Signed-off-by line, which indicates that the submitter\naccepts the DCO:  Signed-off-by: John Doe  john.doe@hisdomain.com   You can include this automatically when you commit a change to your local git\nrepository using  git commit -s .",
            "title": "Legal stuff"
        },
        {
            "location": "/Gerrit/lf-account/",
            "text": "Requesting a Linux Foundation Account\n\n\nContributions to the Fabric code base require a Linux Foundation account.\nFollow the steps below to create a Linux Foundation account.\n\n\nCreating a Linux Foundation ID\n\n\n\n\n\n\nGo to the \nLinux Foundation ID website\n.\n\n\n\n\n\n\nSelect the option \nI need to create a Linux Foundation ID\n.\n\n\n\n\n\n\nFill out the form that appears:\n\n\n\n\n\n\nOpen your email account and look for a message with the subject line:\n   \nValidate your Linux Foundation ID email\n.\n\n\n\n\n\n\nOpen the received URL to validate your email address.\n\n\n\n\n\n\nVerify the browser displays the message \nYou have successfully\n   validated your e-mail address\n.\n\n\n\n\n\n\nAccess \nGerrit\n by selecting \nSign In\n:\n\n\n\n\n\n\nUse your Linux Foundation ID to Sign In:\n\n\n\n\n\n\nConfiguring Gerrit to Use SSH\n\n\nGerrit uses SSH to interact with your Git client. A SSH private key\nneeds to be generated on the development machine with a matching public\nkey on the Gerrit server.\n\n\nIf you already have a SSH key-pair, skip this section.\n\n\nAs an example, we provide the steps to generate the SSH key-pair on a Linux\nenvironment. Follow the equivalent steps on your OS.\n\n\n\n\nCreate a key-pair, enter:\n\n\n\n\nssh-keygen -t rsa -C \nJohn Doe john.doe@example.com\n\n\n\n\n\nNote:\n This will ask you for a password to protect the private key as it\ngenerates a unique key. Please keep this password private, and DO NOT\nenter a blank password.\n\n\nThe generated key-pair is found in: \n~/.ssh/id_rsa\n and \n~/.ssh/id_rsa.pub\n.\n\n\n\n\nAdd the private key in the \nid_rsa\n file in your key ring, e.g.:\n\n\n\n\nssh-add ~/.ssh/id_rsa\n\n\n\n\nOnce the key-pair has been generated, the public key must be added to Gerrit.\n\n\nFollow these steps to add your public key \nid_rsa.pub\n to the Gerrit\naccount:\n\n\n\n\n\n\nGo to \nGerrit\n.\n\n\n\n\n\n\nClick on your account name in the upper right corner.\n\n\n\n\n\n\nFrom the pop-up menu, select \nSettings\n.\n\n\n\n\n\n\nOn the left side menu, click on \nSSH Public Keys\n.\n\n\n\n\n\n\nPaste the contents of your public key \n~/.ssh/id_rsa.pub\n and click\n   \nAdd key\n.\n\n\n\n\n\n\nNote:\n The \nid_rsa.pub\n file can be opened with any text editor. Ensure\n   that all the contents of the file are selected, copied and pasted into the\n   \nAdd SSH key\n window in Gerrit.\n\n\nNote:\n The ssh key generation instructions operate on the assumtion that\nyou are using the default naming. It is possible to generate multiple ssh Keys\nand to name the resulting files differently. See the \nssh-keygen\n\ndocumentation for details on how to do that. Once you have generated non-default\nkeys, you need to configure ssh to use the correct key for Gerrit. In that case,\nyou need to create a \n~/.ssh/config\n file modeled after the one below.\n\n\nhost gerrit.hyperledger.org\n HostName gerrit.hyperledger.org\n IdentityFile ~/.ssh/id_rsa_hyperledger_gerrit\n User \nLFID\n\n\n\n\n\nwhere \n is your Linux Foundation ID and the value of IdentityFile is the\nname of the public key file you generated.\n\n\nWarning:\n Potential Security Risk! Do not copy your private key\n   \n~/.ssh/id_rsa\n Use only the public \n~/.ssh/id_rsa.pub\n.\n\n\nChecking Out the Source Code\n\n\n\n\n\n\nEnsure that SSH has been set up properly. See\n   \nConfiguring Gerrit to Use SSH\n for details.\n\n\n\n\n\n\nClone the repository with your Linux Foundation ID (\n):\n\n\n\n\n\n\ngit clone ssh://\nLFID\n@gerrit.hyperledger.org:29418/fabric fabric\n\n\n\n\nYou have successfully checked out a copy of the source code to your local\nmachine.",
            "title": "Getting an Account"
        },
        {
            "location": "/Gerrit/lf-account/#requesting-a-linux-foundation-account",
            "text": "Contributions to the Fabric code base require a Linux Foundation account.\nFollow the steps below to create a Linux Foundation account.",
            "title": "Requesting a Linux Foundation Account"
        },
        {
            "location": "/Gerrit/lf-account/#creating-a-linux-foundation-id",
            "text": "Go to the  Linux Foundation ID website .    Select the option  I need to create a Linux Foundation ID .    Fill out the form that appears:    Open your email account and look for a message with the subject line:\n    Validate your Linux Foundation ID email .    Open the received URL to validate your email address.    Verify the browser displays the message  You have successfully\n   validated your e-mail address .    Access  Gerrit  by selecting  Sign In :    Use your Linux Foundation ID to Sign In:",
            "title": "Creating a Linux Foundation ID"
        },
        {
            "location": "/Gerrit/lf-account/#configuring-gerrit-to-use-ssh",
            "text": "Gerrit uses SSH to interact with your Git client. A SSH private key\nneeds to be generated on the development machine with a matching public\nkey on the Gerrit server.  If you already have a SSH key-pair, skip this section.  As an example, we provide the steps to generate the SSH key-pair on a Linux\nenvironment. Follow the equivalent steps on your OS.   Create a key-pair, enter:   ssh-keygen -t rsa -C  John Doe john.doe@example.com   Note:  This will ask you for a password to protect the private key as it\ngenerates a unique key. Please keep this password private, and DO NOT\nenter a blank password.  The generated key-pair is found in:  ~/.ssh/id_rsa  and  ~/.ssh/id_rsa.pub .   Add the private key in the  id_rsa  file in your key ring, e.g.:   ssh-add ~/.ssh/id_rsa  Once the key-pair has been generated, the public key must be added to Gerrit.  Follow these steps to add your public key  id_rsa.pub  to the Gerrit\naccount:    Go to  Gerrit .    Click on your account name in the upper right corner.    From the pop-up menu, select  Settings .    On the left side menu, click on  SSH Public Keys .    Paste the contents of your public key  ~/.ssh/id_rsa.pub  and click\n    Add key .    Note:  The  id_rsa.pub  file can be opened with any text editor. Ensure\n   that all the contents of the file are selected, copied and pasted into the\n    Add SSH key  window in Gerrit.  Note:  The ssh key generation instructions operate on the assumtion that\nyou are using the default naming. It is possible to generate multiple ssh Keys\nand to name the resulting files differently. See the  ssh-keygen \ndocumentation for details on how to do that. Once you have generated non-default\nkeys, you need to configure ssh to use the correct key for Gerrit. In that case,\nyou need to create a  ~/.ssh/config  file modeled after the one below.  host gerrit.hyperledger.org\n HostName gerrit.hyperledger.org\n IdentityFile ~/.ssh/id_rsa_hyperledger_gerrit\n User  LFID   where   is your Linux Foundation ID and the value of IdentityFile is the\nname of the public key file you generated.  Warning:  Potential Security Risk! Do not copy your private key\n    ~/.ssh/id_rsa  Use only the public  ~/.ssh/id_rsa.pub .",
            "title": "Configuring Gerrit to Use SSH"
        },
        {
            "location": "/Gerrit/lf-account/#checking-out-the-source-code",
            "text": "Ensure that SSH has been set up properly. See\n    Configuring Gerrit to Use SSH  for details.    Clone the repository with your Linux Foundation ID ( ):    git clone ssh:// LFID @gerrit.hyperledger.org:29418/fabric fabric  You have successfully checked out a copy of the source code to your local\nmachine.",
            "title": "Checking Out the Source Code"
        },
        {
            "location": "/Gerrit/gerrit/",
            "text": "Working with Gerrit\n\n\nFollow these instructions to collaborate on the Hyperledger Fabric Project\nthrough the Gerrit review system.\n\n\nPlease be sure that you are subscribed to the \nmailing\nlist\n and of\ncourse, you can reach out on \nSlack\n if\nyou need help.\n\n\nGerrit assigns the following roles to users:\n\n\n\n\nSubmitters\n: May submit changes for consideration, review other code\n  changes, and make recommendations for acceptance or rejection by voting\n  +1 or -1, respectively.\n\n\nMaintainers\n: May approve or reject changes based upon feedback from\n  reviewers voting +2 or -2, respectively.\n\n\nBuilders\n: (e.g. Jenkins) May use the build automation infrastructure to\n  verify the change.\n\n\n\n\nMaintainers should be familiar with the \nreview process\n. However,\nanyone is welcome to (and encouraged!) review changes, and hence may find that\ndocument of value.\n\n\nGit-review\n\n\nThere\ns a \nvery\n useful tool for working with Gerrit called\n\ngit-review\n. This\ncommand-line tool can automate most of the ensuing sections for you. Of course,\nreading the information below is also highly recommended so that you understand\nwhat\ns going on behind the scenes.\n\n\nSandbox project\n\n\nWe have created a \nsandbox\nproject\n to allow\ndevelopers to familiarize themselves with Gerrit and our workflows. Please do\nfeel free to use this project to experiment with the commands and tools, below.\n\n\nGetting deeper into Gerrit\n\n\nA comprehensive walk-through of Gerrit is beyond the scope of this document.\nThere are plenty of resources available on the Internet. A good summary can be\nfound \nhere\n. We have also\nprovided a set of \nBest Practices\n that you may find helpful.\n\n\nWorking with a local clone of the repository\n\n\nTo work on something, whether a new feature or a bugfix:\n\n\n\n\n\n\nOpen the Gerrit \nProjects page\n\n\n\n\n\n\nSelect the project you wish to work on.\n\n\n\n\n\n\nOpen a terminal window and clone the project locally using the \nClone with git\nhook\n URL. Be sure that \nssh\n is also selected, as this will make authentication\nmuch simpler:\n\n\n\n\n\n\ngit clone ssh://LFID@gerrit.hyperledger.org:29418/fabric \n scp -p -P 29418 LFID@gerrit.hyperledger.org:hooks/commit-msg fabric/.git/hooks/\n\n\n\n\nNote:\n if you are cloning the fabric project repository, you will want to\nclone it to the \n$GOPATH/src/github.com/hyperledger\n directory so that it will\nbuild, and so that you can use it with the Vagrant \ndevelopment\nenvironment\n.\n\n\n\n\nCreate a descriptively-named branch off of your cloned repository\n\n\n\n\ncd fabric\ngit checkout -b issue-nnnn\n\n\n\n\n\n\nCommit your code. For an in-depth discussion of creating an effective commit,\nplease read \nthis document\n.\n\n\n\n\ngit commit -s -a\n\n\n\n\nThen input precise and readable commit msg and submit.\n\n\n\n\nAny code changes that affect documentation should be accompanied by\ncorresponding changes (or additions) to the documentation and tests. This\nwill ensure that if the merged PR is reversed, all traces of the change will\nbe reversed as well.\n\n\n\n\nSubmitting a Change\n\n\nCurrently, Gerrit is the only method to submit a change for review. \nPlease review\nthe \nguidelines\n for making and submitting a change\n.\n\n\nUse git review\n\n\nNote:\n if you prefer, you can use the \ngit-review\n tool instead\nof the following. e.g.\n\n\nAdd the following section to \n.git/config\n, and replace \nUSERNAME\n with your \ngerrit id.\n\n\n[remote \ngerrit\n]\n    url = ssh://\nUSERNAME\n@gerrit.hyperledger.org:29418/fabric.git\n    fetch = +refs/heads/*:refs/remotes/gerrit/*\n\n\n\n\nThen submit your change with \ngit review\n.\n\n\n$ cd \nyour code dir\n\n$ git review\n\n\n\n\nWhen you update your patch, you can commit with \ngit commit --amend\n, and then \nrepeat the \ngit review\n command.\n\n\nNot Use git review\n\n\nDirections for building the source code can be found \nhere\n.\n\n\nWhen a change is ready for submission, Gerrit requires that the\nchange be pushed to a special branch. The name of this special branch\ncontains a reference to the final branch where the code should reside,\nonce accepted.\n\n\nFor the Hyperledger Fabric Project, the special branch is called \nrefs/for/master\n.\n\n\nTo push the current local development branch to the gerrit server, open a\nterminal window at the root of your cloned repository:\n\n\ncd \nyour clone dir\n\ngit push origin HEAD:refs/for/master\n\n\n\n\nIf the command executes correctly, the output should look similar to this:\n\n\nCounting objects: 3, done.\nWriting objects: 100% (3/3), 306 bytes | 0 bytes/s, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nremote: Processing changes: new: 1, refs: 1, done\nremote:\nremote: New Changes:\nremote:   https://gerrit.hyperledger.org/r/6 Test commit\nremote:\nTo ssh://LFID@gerrit.hyperledger.org:29418/fabric\n* [new branch]      HEAD -\n refs/for/master\n\n\n\n\nThe gerrit server generates a link where the change can be tracked.\n\n\nAdding reviewers\n\n\nOptionally, you can add reviewers to your change.\n\n\nTo specify a list of reviewers via the command line, add\n\n%r=reviewer@project.org\n to your push command. For example:\n\n\ngit push origin HEAD:refs/for/master%r=rev1@email.com,r=rev2@notemail.com\n\n\n\n\nAlternatively, you can auto-configure GIT to add a set of reviewers if your\n   commits will have the same reviewers all at the time.\n\n\nTo add a list of default reviewers, open the :file:\n.git/config\n file in the\n   project directory and add the following line in the \n[ branch \u201cmaster\u201d ]\n\n   section:\n\n\n[branch \nmaster\n] #.... push =\nHEAD:refs/for/master%r=rev1@email.com,r=rev2@notemail.com`\n\n\n\n\nMake sure to use actual email addresses instead of the \n@email.com and @notemail.com\n\naddressses. Don\nt forget to replace \norigin\n with your git remote name.\n\n\nReviewing Using Gerrit\n\n\n\n\n\n\nAdd\n: This button allows the change submitter to manually add names of\n  people who should review a change; start typing a name and the system\n  will auto-complete based on the list of people registered and with\n  access to the system. They will be notified by email that you are\n  requesting their input.\n\n\n\n\n\n\nAbandon\n: This button is available to the submitter only; it allows a\n  committer to abandon a change and remove it from the merge queue.\n\n\n\n\n\n\nChange-ID\n: This ID is generated by Gerrit (or system). It becomes\n  useful when the review process determines that your commit(s) have to\n  be amended. You may submit a new version; and if the same Change-ID\n  header (and value) are present, Gerrit will remember it and present\n  it as another version of the same change.\n\n\n\n\n\n\nStatus\n: Currently, the example change is in review status, as indicated\n  by \u201cNeeds Verified\u201d in the upper-left corner. The list of\n  Reviewers will all emit their opinion, voting +1 if they agree to the\n  merge, -1 if they disagree. Gerrit users with a Maintainer role can\n  agree to the merge or refuse it by voting +2 or -2 respectively.\n\n\n\n\n\n\nNotifications are sent to the email address in your commit message\ns\nSigned-off-by line. Visit your \nGerrit dashboard\n, to check the progress of your requests.\n\n\nThe history tab in Gerrit will show you the in-line comments and the author of\nthe review.\n\n\nViewing Pending Changes\n\n\nFind all pending changes by clicking on the \nAll --\n Changes\n link in the\nupper-left corner, or \nopen this link\n.\n\n\nIf you collaborate in multiple projects, you may wish to limit searching to\nthe specific branch through the search bar in the upper-right side.\n\n\nAdd the filter \nproject:fabric\n to limit the visible changes to\nonly those from the Hyperledger Fabric Project.\n\n\nList all current changes you submitted, or list just those changes in need\nof your input by clicking on \nMy --\n Changes\n or \nopen this link",
            "title": "Gerrit"
        },
        {
            "location": "/Gerrit/gerrit/#working-with-gerrit",
            "text": "Follow these instructions to collaborate on the Hyperledger Fabric Project\nthrough the Gerrit review system.  Please be sure that you are subscribed to the  mailing\nlist  and of\ncourse, you can reach out on  Slack  if\nyou need help.  Gerrit assigns the following roles to users:   Submitters : May submit changes for consideration, review other code\n  changes, and make recommendations for acceptance or rejection by voting\n  +1 or -1, respectively.  Maintainers : May approve or reject changes based upon feedback from\n  reviewers voting +2 or -2, respectively.  Builders : (e.g. Jenkins) May use the build automation infrastructure to\n  verify the change.   Maintainers should be familiar with the  review process . However,\nanyone is welcome to (and encouraged!) review changes, and hence may find that\ndocument of value.",
            "title": "Working with Gerrit"
        },
        {
            "location": "/Gerrit/gerrit/#git-review",
            "text": "There s a  very  useful tool for working with Gerrit called git-review . This\ncommand-line tool can automate most of the ensuing sections for you. Of course,\nreading the information below is also highly recommended so that you understand\nwhat s going on behind the scenes.",
            "title": "Git-review"
        },
        {
            "location": "/Gerrit/gerrit/#sandbox-project",
            "text": "We have created a  sandbox\nproject  to allow\ndevelopers to familiarize themselves with Gerrit and our workflows. Please do\nfeel free to use this project to experiment with the commands and tools, below.",
            "title": "Sandbox project"
        },
        {
            "location": "/Gerrit/gerrit/#getting-deeper-into-gerrit",
            "text": "A comprehensive walk-through of Gerrit is beyond the scope of this document.\nThere are plenty of resources available on the Internet. A good summary can be\nfound  here . We have also\nprovided a set of  Best Practices  that you may find helpful.",
            "title": "Getting deeper into Gerrit"
        },
        {
            "location": "/Gerrit/gerrit/#working-with-a-local-clone-of-the-repository",
            "text": "To work on something, whether a new feature or a bugfix:    Open the Gerrit  Projects page    Select the project you wish to work on.    Open a terminal window and clone the project locally using the  Clone with git\nhook  URL. Be sure that  ssh  is also selected, as this will make authentication\nmuch simpler:    git clone ssh://LFID@gerrit.hyperledger.org:29418/fabric   scp -p -P 29418 LFID@gerrit.hyperledger.org:hooks/commit-msg fabric/.git/hooks/  Note:  if you are cloning the fabric project repository, you will want to\nclone it to the  $GOPATH/src/github.com/hyperledger  directory so that it will\nbuild, and so that you can use it with the Vagrant  development\nenvironment .   Create a descriptively-named branch off of your cloned repository   cd fabric\ngit checkout -b issue-nnnn   Commit your code. For an in-depth discussion of creating an effective commit,\nplease read  this document .   git commit -s -a  Then input precise and readable commit msg and submit.   Any code changes that affect documentation should be accompanied by\ncorresponding changes (or additions) to the documentation and tests. This\nwill ensure that if the merged PR is reversed, all traces of the change will\nbe reversed as well.",
            "title": "Working with a local clone of the repository"
        },
        {
            "location": "/Gerrit/gerrit/#submitting-a-change",
            "text": "Currently, Gerrit is the only method to submit a change for review.  Please review\nthe  guidelines  for making and submitting a change .",
            "title": "Submitting a Change"
        },
        {
            "location": "/Gerrit/gerrit/#use-git-review",
            "text": "Note:  if you prefer, you can use the  git-review  tool instead\nof the following. e.g.  Add the following section to  .git/config , and replace  USERNAME  with your \ngerrit id.  [remote  gerrit ]\n    url = ssh:// USERNAME @gerrit.hyperledger.org:29418/fabric.git\n    fetch = +refs/heads/*:refs/remotes/gerrit/*  Then submit your change with  git review .  $ cd  your code dir \n$ git review  When you update your patch, you can commit with  git commit --amend , and then \nrepeat the  git review  command.",
            "title": "Use git review"
        },
        {
            "location": "/Gerrit/gerrit/#not-use-git-review",
            "text": "Directions for building the source code can be found  here .  When a change is ready for submission, Gerrit requires that the\nchange be pushed to a special branch. The name of this special branch\ncontains a reference to the final branch where the code should reside,\nonce accepted.  For the Hyperledger Fabric Project, the special branch is called  refs/for/master .  To push the current local development branch to the gerrit server, open a\nterminal window at the root of your cloned repository:  cd  your clone dir \ngit push origin HEAD:refs/for/master  If the command executes correctly, the output should look similar to this:  Counting objects: 3, done.\nWriting objects: 100% (3/3), 306 bytes | 0 bytes/s, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nremote: Processing changes: new: 1, refs: 1, done\nremote:\nremote: New Changes:\nremote:   https://gerrit.hyperledger.org/r/6 Test commit\nremote:\nTo ssh://LFID@gerrit.hyperledger.org:29418/fabric\n* [new branch]      HEAD -  refs/for/master  The gerrit server generates a link where the change can be tracked.",
            "title": "Not Use git review"
        },
        {
            "location": "/Gerrit/gerrit/#adding-reviewers",
            "text": "Optionally, you can add reviewers to your change.  To specify a list of reviewers via the command line, add %r=reviewer@project.org  to your push command. For example:  git push origin HEAD:refs/for/master%r=rev1@email.com,r=rev2@notemail.com  Alternatively, you can auto-configure GIT to add a set of reviewers if your\n   commits will have the same reviewers all at the time.  To add a list of default reviewers, open the :file: .git/config  file in the\n   project directory and add the following line in the  [ branch \u201cmaster\u201d ] \n   section:  [branch  master ] #.... push =\nHEAD:refs/for/master%r=rev1@email.com,r=rev2@notemail.com`  Make sure to use actual email addresses instead of the  @email.com and @notemail.com \naddressses. Don t forget to replace  origin  with your git remote name.",
            "title": "Adding reviewers"
        },
        {
            "location": "/Gerrit/gerrit/#reviewing-using-gerrit",
            "text": "Add : This button allows the change submitter to manually add names of\n  people who should review a change; start typing a name and the system\n  will auto-complete based on the list of people registered and with\n  access to the system. They will be notified by email that you are\n  requesting their input.    Abandon : This button is available to the submitter only; it allows a\n  committer to abandon a change and remove it from the merge queue.    Change-ID : This ID is generated by Gerrit (or system). It becomes\n  useful when the review process determines that your commit(s) have to\n  be amended. You may submit a new version; and if the same Change-ID\n  header (and value) are present, Gerrit will remember it and present\n  it as another version of the same change.    Status : Currently, the example change is in review status, as indicated\n  by \u201cNeeds Verified\u201d in the upper-left corner. The list of\n  Reviewers will all emit their opinion, voting +1 if they agree to the\n  merge, -1 if they disagree. Gerrit users with a Maintainer role can\n  agree to the merge or refuse it by voting +2 or -2 respectively.    Notifications are sent to the email address in your commit message s\nSigned-off-by line. Visit your  Gerrit dashboard , to check the progress of your requests.  The history tab in Gerrit will show you the in-line comments and the author of\nthe review.",
            "title": "Reviewing Using Gerrit"
        },
        {
            "location": "/Gerrit/gerrit/#viewing-pending-changes",
            "text": "Find all pending changes by clicking on the  All --  Changes  link in the\nupper-left corner, or  open this link .  If you collaborate in multiple projects, you may wish to limit searching to\nthe specific branch through the search bar in the upper-right side.  Add the filter  project:fabric  to limit the visible changes to\nonly those from the Hyperledger Fabric Project.  List all current changes you submitted, or list just those changes in need\nof your input by clicking on  My --  Changes  or  open this link",
            "title": "Viewing Pending Changes"
        },
        {
            "location": "/dev-setup/devenv/",
            "text": "Setting up the development environment\n\n\nOverview\n\n\nThe current development environment utilizes Vagrant running an Ubuntu image, which in turn launches Docker containers. Conceptually, the Host launches a VM, which in turn launches Docker containers.\n\n\nHost -\n VM -\n Docker\n\n\nThis model allows developers to leverage their favorite OS/editors and execute the system in a controlled environment that is consistent amongst the development team.\n\n\n\n\nNote that your Host should not run within a VM. If you attempt this, the VM within your Host may fail to boot with a message indicating that VT-x is not available.\n\n\n\n\nPrerequisites\n\n\n\n\nGit client\n\n\nGo\n - 1.6 or later\n\n\nVagrant\n - 1.7.4 or later\n\n\nVirtualBox\n - 5.0 or later\n\n\n\n\nBIOS Enabled Virtualization - Varies based on hardware\n\n\n\n\n\n\nNote: The BIOS Enabled Virtualization may be within the CPU or Security settings of the BIOS\n\n\n\n\n\n\nSteps\n\n\nSet your GOPATH\n\n\nMake sure you have properly setup your Host\ns \nGOPATH environment variable\n. This allows for both building within the Host and the VM.\n\n\nNote to Windows users\n\n\nIf you are running Windows, before running any \ngit clone\n commands, run the following command.\n\n\ngit config --get core.autocrlf\n\n\n\n\nIf \ncore.autocrlf\n is set to \ntrue\n, you must set it to \nfalse\n by running\n\n\ngit config --global core.autocrlf false\n\n\n\n\nIf you continue with \ncore.autocrlf\n set to \ntrue\n, the \nvagrant up\n command will fail with the error \n./setup.sh: /bin/bash^M: bad interpreter: No such file or directory\n\n\nCloning the Fabric project\n\n\nSince the Fabric project is a \nGo\n project, you\nll need to clone the Fabric repo to your $GOPATH/src directory. If your $GOPATH has multiple path components, then you will want to use the first one. There\ns a little bit of setup needed:\n\n\ncd $GOPATH/src\nmkdir -p github.com/hyperledger\ncd github.com/hyperledger\n\n\n\n\nRecall that we are using \nGerrit\n for source control, which has its own internal git repositories. Hence, we will need to \nclone from Gerrit\n. For brevity, the command is as follows:\n\n\ngit clone ssh://LFID@gerrit.hyperledger.org:29418/fabric \n scp -p -P 29418 LFID@gerrit.hyperledger.org:hooks/commit-msg fabric/.git/hooks/\n\n\n\n\nNote:\n of course, you would want to replace \nLFID\n with your \nLinux Foundation ID\n.\n\n\nBoostrapping the VM using Vagrant\n\n\nNow you\nre ready to launch Vagrant.\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant up\n\n\n\n\nGo get coffee\n this will take a few minutes. Once complete, you should be able to \nssh\n into the Vagrant VM just created.\n\n\nvagrant ssh\n\n\n\n\nBuilding the fabric\n\n\nOnce you have your vagrant development environment established, you can proceed to \nbuild and test\n the fabric. Once inside the VM, you can find the peer project under \n$GOPATH/src/github.com/hyperledger/fabric\n. It is also mounted as  \n/hyperledger\n.\n\n\nNotes\n\n\nNOTE:\n any time you change any of the files in your local fabric directory (under \n$GOPATH/src/github.com/hyperledger/fabric\n), the update will be instantly available within the VM fabric directory.\n\n\nNOTE:\n If you intend to run the development environment behind an HTTP Proxy, you need to configure the guest so that the provisioning process may complete. You can achieve this via the \nvagrant-proxyconf\n plugin. Install with \nvagrant plugin install vagrant-proxyconf\n and then set the VAGRANT_HTTP_PROXY and VAGRANT_HTTPS_PROXY environment variables \nbefore\n you execute \nvagrant up\n. More details are available here: https://github.com/tmatilai/vagrant-proxyconf/\n\n\nNOTE:\n The first time you run this command it may take quite a while to complete (it could take 30 minutes or more depending on your environment) and at times it may look like it\ns not doing anything. As long you don\nt get any error messages just leave it alone, it\ns all good, it\ns just cranking.\n\n\nNOTE to Windows 10 Users:\n There is a known problem with vagrant on Windows 10 (see \nmitchellh/vagrant#6754\n). If the \nvagrant up\n command fails it may be because you do not have Microsoft Visual C++ Redistributable installed. You can download the missing package at the following address: http://www.microsoft.com/en-us/download/details.aspx?id=8328",
            "title": "Fabric Developer Setup"
        },
        {
            "location": "/dev-setup/devenv/#setting-up-the-development-environment",
            "text": "",
            "title": "Setting up the development environment"
        },
        {
            "location": "/dev-setup/devenv/#overview",
            "text": "The current development environment utilizes Vagrant running an Ubuntu image, which in turn launches Docker containers. Conceptually, the Host launches a VM, which in turn launches Docker containers.  Host -  VM -  Docker  This model allows developers to leverage their favorite OS/editors and execute the system in a controlled environment that is consistent amongst the development team.   Note that your Host should not run within a VM. If you attempt this, the VM within your Host may fail to boot with a message indicating that VT-x is not available.",
            "title": "Overview"
        },
        {
            "location": "/dev-setup/devenv/#prerequisites",
            "text": "Git client  Go  - 1.6 or later  Vagrant  - 1.7.4 or later  VirtualBox  - 5.0 or later   BIOS Enabled Virtualization - Varies based on hardware    Note: The BIOS Enabled Virtualization may be within the CPU or Security settings of the BIOS",
            "title": "Prerequisites"
        },
        {
            "location": "/dev-setup/devenv/#steps",
            "text": "",
            "title": "Steps"
        },
        {
            "location": "/dev-setup/devenv/#set-your-gopath",
            "text": "Make sure you have properly setup your Host s  GOPATH environment variable . This allows for both building within the Host and the VM.",
            "title": "Set your GOPATH"
        },
        {
            "location": "/dev-setup/devenv/#note-to-windows-users",
            "text": "If you are running Windows, before running any  git clone  commands, run the following command.  git config --get core.autocrlf  If  core.autocrlf  is set to  true , you must set it to  false  by running  git config --global core.autocrlf false  If you continue with  core.autocrlf  set to  true , the  vagrant up  command will fail with the error  ./setup.sh: /bin/bash^M: bad interpreter: No such file or directory",
            "title": "Note to Windows users"
        },
        {
            "location": "/dev-setup/devenv/#cloning-the-fabric-project",
            "text": "Since the Fabric project is a  Go  project, you ll need to clone the Fabric repo to your $GOPATH/src directory. If your $GOPATH has multiple path components, then you will want to use the first one. There s a little bit of setup needed:  cd $GOPATH/src\nmkdir -p github.com/hyperledger\ncd github.com/hyperledger  Recall that we are using  Gerrit  for source control, which has its own internal git repositories. Hence, we will need to  clone from Gerrit . For brevity, the command is as follows:  git clone ssh://LFID@gerrit.hyperledger.org:29418/fabric   scp -p -P 29418 LFID@gerrit.hyperledger.org:hooks/commit-msg fabric/.git/hooks/  Note:  of course, you would want to replace  LFID  with your  Linux Foundation ID .",
            "title": "Cloning the Fabric project"
        },
        {
            "location": "/dev-setup/devenv/#boostrapping-the-vm-using-vagrant",
            "text": "Now you re ready to launch Vagrant.  cd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant up  Go get coffee  this will take a few minutes. Once complete, you should be able to  ssh  into the Vagrant VM just created.  vagrant ssh",
            "title": "Boostrapping the VM using Vagrant"
        },
        {
            "location": "/dev-setup/devenv/#building-the-fabric",
            "text": "Once you have your vagrant development environment established, you can proceed to  build and test  the fabric. Once inside the VM, you can find the peer project under  $GOPATH/src/github.com/hyperledger/fabric . It is also mounted as   /hyperledger .",
            "title": "Building the fabric"
        },
        {
            "location": "/dev-setup/devenv/#notes",
            "text": "NOTE:  any time you change any of the files in your local fabric directory (under  $GOPATH/src/github.com/hyperledger/fabric ), the update will be instantly available within the VM fabric directory.  NOTE:  If you intend to run the development environment behind an HTTP Proxy, you need to configure the guest so that the provisioning process may complete. You can achieve this via the  vagrant-proxyconf  plugin. Install with  vagrant plugin install vagrant-proxyconf  and then set the VAGRANT_HTTP_PROXY and VAGRANT_HTTPS_PROXY environment variables  before  you execute  vagrant up . More details are available here: https://github.com/tmatilai/vagrant-proxyconf/  NOTE:  The first time you run this command it may take quite a while to complete (it could take 30 minutes or more depending on your environment) and at times it may look like it s not doing anything. As long you don t get any error messages just leave it alone, it s all good, it s just cranking.  NOTE to Windows 10 Users:  There is a known problem with vagrant on Windows 10 (see  mitchellh/vagrant#6754 ). If the  vagrant up  command fails it may be because you do not have Microsoft Visual C++ Redistributable installed. You can download the missing package at the following address: http://www.microsoft.com/en-us/download/details.aspx?id=8328",
            "title": "Notes"
        },
        {
            "location": "/dev-setup/build/",
            "text": "Building the fabric\n\n\nThe following instructions assume that you have already set up your \ndevelopment environment\n.\n\n\nTo access your VM, run \nvagrant ssh\n from within the devenv directory of your locally cloned fabric repository.\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant ssh\n\n\n\n\nFrom within the VM, you can build, run, and test your environment.\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer\n\n\n\n\nTo see what commands are available, simply execute the following commands:\n\n\npeer help\n\n\n\n\nYou should see the following output:\n\n\n    Usage:\n      peer [command]\n\n    Available Commands:\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level=\n: Default logging level and overrides, see core.yaml for full syntax\n\n\n    Use \npeer [command] --help\n for more information about a command.\n\n\n\n\nThe \npeer node start\n command will initiate a peer process, with which one can interact by executing other commands. For example, the \npeer node status\n command will return the status of the running peer. The full list of commands is the following:\n\n\n      node\n        start       Starts the node.\n        status      Returns status of the node.\n        stop        Stops the running node.\n      network\n        login       Logs in user to CLI.\n        list        Lists all network peers.\n      chaincode\n        deploy      Deploy the specified chaincode to the network.\n        invoke      Invoke the specified chaincode.\n        query       Query using the specified chaincode.\n      help        Help about any command\n\n\n\n\nNote:\n If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.\n\n\nRunning the unit tests\n\n\nUse the following sequence to run all unit tests\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake unit-test\n\n\n\n\nTo run a specific test use the \n-run RE\n flag where RE is a regular expression that matches the test case name. To run tests with verbose output use the \n-v\n flag. For example, to run the \nTestGetFoo\n test case, change to the directory containing the \nfoo_test.go\n and call/excecute\n\n\ngo test -v -run=TestGetFoo\n\n\n\n\nRunning Node.js Unit Tests\n\n\nYou must also run the Node.js unit tests to insure that the Node.js client SDK is not broken by your changes. To run the Node.js unit tests, follow the instructions \nhere\n.\n\n\nRunning Behave BDD Tests\n\n\nBehave\n tests will setup networks of peers with different security and consensus configurations and verify that transactions run properly. To run these tests\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake behave\n\n\n\n\nSome of the Behave tests run inside Docker containers. If a test fails and you want to have the logs from the Docker containers, run the tests with this option\n\n\nbehave -D logs=Y\n\n\n\n\nNote, in order to run behave directly, you must run \nmake images\n first to build the necessary \npeer\n and \nmember services\n docker images. These images can also be individually built when \ngo test\n is called with the following parameters:\n\n\ngo test github.com/hyperledger/fabric/core/container -run=BuildImage_Peer\ngo test github.com/hyperledger/fabric/core/container -run=BuildImage_Obcca\n\n\n\n\nBuilding outside of Vagrant\n\n\nIt is possible to build the project and run peers outside of Vagrant. Generally speaking, one has to \ntranslate\n the vagrant \nsetup file\n to the platform of your choice.\n\n\nPrerequisites\n\n\n\n\nGit client\n\n\nGo\n - 1.6 or later\n\n\nRocksDB\n version 4.1 and its dependencies\n\n\nDocker\n\n\nPip\n\n\nSet the maximum number of open files to 10000 or greater for your OS\n\n\n\n\nDocker\n\n\nMake sure that the Docker daemon initialization includes the options\n\n\n-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock\n\n\n\n\nTypically, docker runs as a \nservice\n task, with configuration file at \n/etc/default/docker\n.\n\n\nBe aware that the Docker bridge (the \nCORE_VM_ENDPOINT\n) may not come\nup at the IP address currently assumed by the test environment\n(\n172.17.0.1\n). Use \nifconfig\n or \nip addr\n to find the docker bridge.\n\n\nBuilding RocksDB\n\n\napt-get install -y libsnappy-dev zlib1g-dev libbz2-dev\ncd /tmp\ngit clone https://github.com/facebook/rocksdb.git\ncd rocksdb\ngit checkout v4.1\nPORTABLE=1 make shared_lib\nINSTALL_PATH=/usr/local make install-shared\n\n\n\n\npip\n, \nbehave\n and \ndocker-compose\n\n\npip install --upgrade pip\npip install behave nose docker-compose\npip install -I flask==0.10.1 python-dateutil==2.2 pytz==2014.3 pyyaml==3.10 couchdb==1.0 flask-cors==2.0.1 requests==2.4.3\n\n\n\n\nBuilding on Z\n\n\nTo make building on Z easier and faster, \nthis script\n is provided (which is similar to the \nsetup file\n provided for vagrant). This script has been tested only on RHEL 7.2 and has some assumptions one might want to re-visit (firewall settings, development as root user, etc.). It is however sufficient for development in a personally-assigned VM instance.\n\n\nTo get started, from a freshly installed OS:\n\n\nsudo su\nyum install git\nmkdir -p $HOME/git/src/github.com/hyperledger\ncd $HOME/git/src/github.com/hyperledger\ngit clone http://gerrit.hyperledger.org/r/fabric\nsource fabric/devenv/setupRHELonZ.sh\n\n\n\n\nFrom this point, you can proceed as described above for the Vagrant development environment.\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer unit-test behave\n\n\n\n\nBuilding on Power Platform\n\n\nDevelopment and build on Power (ppc64le) systems is done outside of vagrant as outlined \nhere\n. For ease of setting up the dev environment on Ubuntu, invoke \nthis script\n as root. This script has been validated on Ubuntu 16.04 and assumes certain things (like, development system has OS repositories in place, firewall setting etc) and in general can be improvised further.\n\n\nTo get started on Power server installed with Ubuntu, first ensure you have properly setup your Host\ns \nGOPATH environment variable\n. Then, execute the following commands to build the fabric code:\n\n\nmkdir -p $GOPATH/src/github.com/hyperledger\ncd $GOPATH/src/github.com/hyperledger\ngit clone http://gerrit.hyperledger.org/r/fabric\nsudo ./fabric/devenv/setupUbuntuOnPPC64le.sh\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake dist-clean all\n\n\n\n\nBuilding natively on OSX\n\n\nFirst, install Docker, as described \nhere\n.\nThe database by default writes to /var/hyperledger. You can override this in the \ncore.yaml\n configuration file, under \npeer.fileSystemPath\n.\n\n\nbrew install go rocksdb snappy gnu-tar     # For RocksDB version 4.1, you can compile your own, as described earlier\n\n# You will need the following two for every shell you want to use\neval $(docker-machine env)\nexport PATH=\n/usr/local/opt/gnu-tar/libexec/gnubin:$PATH\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer\n\n\n\n\nConfiguration\n\n\nConfiguration utilizes the \nviper\n and \ncobra\n libraries.\n\n\nThere is a \ncore.yaml\n file that contains the configuration for the peer process. Many of the configuration settings can be overridden on the command line by setting ENV variables that match the configuration setting, but by prefixing with \nCORE_\n. For example, logging level manipulation through the environment is shown below:\n\n\nCORE_PEER_LOGGING_LEVEL=CRITICAL peer\n\n\n\nLogging\n\n\nLogging utilizes the \ngo-logging\n library. \n\n\nThe available log levels in order of increasing verbosity are: \nCRITICAL | ERROR | WARNING | NOTICE | INFO | DEBUG\n\n\nSee \nspecific logging control\n instructions when running the peer process.",
            "title": "Building Fabric"
        },
        {
            "location": "/dev-setup/build/#building-the-fabric",
            "text": "The following instructions assume that you have already set up your  development environment .  To access your VM, run  vagrant ssh  from within the devenv directory of your locally cloned fabric repository.  cd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant ssh  From within the VM, you can build, run, and test your environment.  cd $GOPATH/src/github.com/hyperledger/fabric\nmake peer  To see what commands are available, simply execute the following commands:  peer help  You should see the following output:      Usage:\n      peer [command]\n\n    Available Commands:\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level= : Default logging level and overrides, see core.yaml for full syntax\n\n\n    Use  peer [command] --help  for more information about a command.  The  peer node start  command will initiate a peer process, with which one can interact by executing other commands. For example, the  peer node status  command will return the status of the running peer. The full list of commands is the following:        node\n        start       Starts the node.\n        status      Returns status of the node.\n        stop        Stops the running node.\n      network\n        login       Logs in user to CLI.\n        list        Lists all network peers.\n      chaincode\n        deploy      Deploy the specified chaincode to the network.\n        invoke      Invoke the specified chaincode.\n        query       Query using the specified chaincode.\n      help        Help about any command  Note:  If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.",
            "title": "Building the fabric"
        },
        {
            "location": "/dev-setup/build/#running-the-unit-tests",
            "text": "Use the following sequence to run all unit tests  cd $GOPATH/src/github.com/hyperledger/fabric\nmake unit-test  To run a specific test use the  -run RE  flag where RE is a regular expression that matches the test case name. To run tests with verbose output use the  -v  flag. For example, to run the  TestGetFoo  test case, change to the directory containing the  foo_test.go  and call/excecute  go test -v -run=TestGetFoo",
            "title": "Running the unit tests"
        },
        {
            "location": "/dev-setup/build/#running-nodejs-unit-tests",
            "text": "You must also run the Node.js unit tests to insure that the Node.js client SDK is not broken by your changes. To run the Node.js unit tests, follow the instructions  here .",
            "title": "Running Node.js Unit Tests"
        },
        {
            "location": "/dev-setup/build/#running-behave-bdd-tests",
            "text": "Behave  tests will setup networks of peers with different security and consensus configurations and verify that transactions run properly. To run these tests  cd $GOPATH/src/github.com/hyperledger/fabric\nmake behave  Some of the Behave tests run inside Docker containers. If a test fails and you want to have the logs from the Docker containers, run the tests with this option  behave -D logs=Y  Note, in order to run behave directly, you must run  make images  first to build the necessary  peer  and  member services  docker images. These images can also be individually built when  go test  is called with the following parameters:  go test github.com/hyperledger/fabric/core/container -run=BuildImage_Peer\ngo test github.com/hyperledger/fabric/core/container -run=BuildImage_Obcca",
            "title": "Running Behave BDD Tests"
        },
        {
            "location": "/dev-setup/build/#building-outside-of-vagrant",
            "text": "It is possible to build the project and run peers outside of Vagrant. Generally speaking, one has to  translate  the vagrant  setup file  to the platform of your choice.",
            "title": "Building outside of Vagrant"
        },
        {
            "location": "/dev-setup/build/#prerequisites",
            "text": "Git client  Go  - 1.6 or later  RocksDB  version 4.1 and its dependencies  Docker  Pip  Set the maximum number of open files to 10000 or greater for your OS",
            "title": "Prerequisites"
        },
        {
            "location": "/dev-setup/build/#docker",
            "text": "Make sure that the Docker daemon initialization includes the options  -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock  Typically, docker runs as a  service  task, with configuration file at  /etc/default/docker .  Be aware that the Docker bridge (the  CORE_VM_ENDPOINT ) may not come\nup at the IP address currently assumed by the test environment\n( 172.17.0.1 ). Use  ifconfig  or  ip addr  to find the docker bridge.",
            "title": "Docker"
        },
        {
            "location": "/dev-setup/build/#building-rocksdb",
            "text": "apt-get install -y libsnappy-dev zlib1g-dev libbz2-dev\ncd /tmp\ngit clone https://github.com/facebook/rocksdb.git\ncd rocksdb\ngit checkout v4.1\nPORTABLE=1 make shared_lib\nINSTALL_PATH=/usr/local make install-shared",
            "title": "Building RocksDB"
        },
        {
            "location": "/dev-setup/build/#pip-behave-and-docker-compose",
            "text": "pip install --upgrade pip\npip install behave nose docker-compose\npip install -I flask==0.10.1 python-dateutil==2.2 pytz==2014.3 pyyaml==3.10 couchdb==1.0 flask-cors==2.0.1 requests==2.4.3",
            "title": "pip, behave and docker-compose"
        },
        {
            "location": "/dev-setup/build/#building-on-z",
            "text": "To make building on Z easier and faster,  this script  is provided (which is similar to the  setup file  provided for vagrant). This script has been tested only on RHEL 7.2 and has some assumptions one might want to re-visit (firewall settings, development as root user, etc.). It is however sufficient for development in a personally-assigned VM instance.  To get started, from a freshly installed OS:  sudo su\nyum install git\nmkdir -p $HOME/git/src/github.com/hyperledger\ncd $HOME/git/src/github.com/hyperledger\ngit clone http://gerrit.hyperledger.org/r/fabric\nsource fabric/devenv/setupRHELonZ.sh  From this point, you can proceed as described above for the Vagrant development environment.  cd $GOPATH/src/github.com/hyperledger/fabric\nmake peer unit-test behave",
            "title": "Building on Z"
        },
        {
            "location": "/dev-setup/build/#building-on-power-platform",
            "text": "Development and build on Power (ppc64le) systems is done outside of vagrant as outlined  here . For ease of setting up the dev environment on Ubuntu, invoke  this script  as root. This script has been validated on Ubuntu 16.04 and assumes certain things (like, development system has OS repositories in place, firewall setting etc) and in general can be improvised further.  To get started on Power server installed with Ubuntu, first ensure you have properly setup your Host s  GOPATH environment variable . Then, execute the following commands to build the fabric code:  mkdir -p $GOPATH/src/github.com/hyperledger\ncd $GOPATH/src/github.com/hyperledger\ngit clone http://gerrit.hyperledger.org/r/fabric\nsudo ./fabric/devenv/setupUbuntuOnPPC64le.sh\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake dist-clean all",
            "title": "Building on Power Platform"
        },
        {
            "location": "/dev-setup/build/#building-natively-on-osx",
            "text": "First, install Docker, as described  here .\nThe database by default writes to /var/hyperledger. You can override this in the  core.yaml  configuration file, under  peer.fileSystemPath .  brew install go rocksdb snappy gnu-tar     # For RocksDB version 4.1, you can compile your own, as described earlier\n\n# You will need the following two for every shell you want to use\neval $(docker-machine env)\nexport PATH= /usr/local/opt/gnu-tar/libexec/gnubin:$PATH \n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer",
            "title": "Building natively on OSX"
        },
        {
            "location": "/dev-setup/build/#configuration",
            "text": "Configuration utilizes the  viper  and  cobra  libraries.  There is a  core.yaml  file that contains the configuration for the peer process. Many of the configuration settings can be overridden on the command line by setting ENV variables that match the configuration setting, but by prefixing with  CORE_ . For example, logging level manipulation through the environment is shown below:  CORE_PEER_LOGGING_LEVEL=CRITICAL peer",
            "title": "Configuration"
        },
        {
            "location": "/dev-setup/build/#logging",
            "text": "Logging utilizes the  go-logging  library.   The available log levels in order of increasing verbosity are:  CRITICAL | ERROR | WARNING | NOTICE | INFO | DEBUG  See  specific logging control  instructions when running the peer process.",
            "title": "Logging"
        },
        {
            "location": "/Gerrit/best-practices/",
            "text": "Gerrit Recommended Practices\n\n\nThis document presents some best practices to help you use Gerrit more\neffectively.  The intent is to show how content can be submitted easily. Use the\nrecommended practices to reduce your troubleshooting time and improve\nparticipation in the community.\n\n\nBrowsing the Git Tree\n\n\nVisit \nGerrit\n then\nselect \nProjects --\n List --\n SELECT-PROJECT --\n Branches\n.  Select the branch\nthat interests you, click on \ngitweb\n located on the right-hand side.  Now,\n\ngitweb\n loads your selection on the Git web interface and redirects\nappropriately.\n\n\nWatching a Project\n\n\nVisit \nGerrit\n, then\nselect \nSettings\n, located on the top right corner. Select \nWatched Projects\n\nand then add any projects that interest you.\n\n\nCommit Messages\n\n\nGerrit follows the Git commit message format. Ensure the headers are at the\nbottom and don\nt contain blank lines between one another. The following example\nshows the format and content expected in a commit message:\n\n\nBrief (no more than 50 chars) one line description.\n\n\nElaborate summary of the changes made referencing why (motivation), what was\nchanged and how it was tested. Note also any changes to documentation made to\nremain consistent with the code changes, wrapping text at 72 chars/line.\n\n\nJira: FAB-100\n\n   Change-Id: LONGHEXHASH\n\n   Signed-off-by: Your Name your.email@example.org\n\n   AnotherExampleHeader: An Example of another Value\n\n\nThe Gerrit server provides a precommit hook to autogenerate the Change-Id which\nis one time use.\n\n\nRecommended reading:\n \nHow to Write a Git Commit Message\n\n\nAvoid Pushing Untested Work to a Gerrit Server\n\n\nTo avoid pushing untested work to Gerrit.\n\n\nCheck your work at least three times before pushing your change to Gerrit.\nBe mindful of what information you are publishing.\n\n\nKeeping Track of Changes\n\n\n\n\n\n\nSet Gerrit to send you emails:\n\n\n\n\n\n\nGerrit will add you to the email distribution list for a change if a\n    developer adds you as a reviewer, or if you comment on a specific Patch\n    Set.\n\n\n\n\n\n\nOpening a change in Gerrit\ns review interface is a quick way to follow that\n  change.\n\n\n\n\n\n\nWatch projects in the Gerrit projects section at \nGerrit\n, select at least\n   \nNew Changes, New Patch Sets, All Comments\n and \nSubmitted Changes\n.\n\n\n\n\n\n\nAlways track the projects you are working on; also see the feedback/comments\nmailing list to learn and help others ramp up.\n\n\nTopic branches\n\n\nTopic branches are temporary branches that you push to commit a set of\nlogically-grouped dependent commits:\n\n\nTo push changes from \nREMOTE/master\n tree to Gerrit for being reviewed as\na topic in  \nTopicName\n use the following command as an example:\n\n\n$ git push REMOTE HEAD:refs/for/master/TopicName\n\n\nThe topic will show up in the review :abbr:\nUI\n and in the\n\nOpen Changes List\n.  Topic branches will disappear from the master\ntree when its content is merged.\n\n\nCreating a Cover Letter for a Topic\n\n\nYou may decide whether or not you\nd like the cover letter to appear in the\nhistory.\n\n\n\n\nTo make a cover letter that appears in the history, use this command:\n\n\n\n\ngit commit --allow-empty\n\n\n\n\nEdit the commit message, this message then becomes the cover letter.\nThe command used doesn\nt change any files in the source tree.\n\n\n\n\n\n\nTo make a cover letter that doesn\nt appear in the history follow these steps:\n\n\n\n\n\n\nPut the empty commit at the end of your commits list so it can be ignored\n\n   without having to rebase.\n\n\n\n\n\n\nNow add your commits\n\n\n\n\n\n\ngit commit ...\ngit commit ...\ngit commit ...\n\n\n\n\n\n\nFinally, push the commits to a topic branch.  The following command is an\n     example:\n\n\n\n\ngit push REMOTE HEAD:refs/for/master/TopicName\n\n\n\n\nIf you already have commits but you want to set a cover letter, create an empty\ncommit for the cover letter and move the commit so it becomes the last commit\non the list. Use the following command as an example:\n\n\ngit rebase -i HEAD~#Commits\n\n\n\n\nBe careful to uncomment the commit before moving it.\n\n#Commits\n is the sum of the commits plus your new cover letter.\n\n\nFinding Available Topics\n\n\n   $ ssh -p 29418 gerrit.hyperledger.org gerrit query \\ status:open project:fabric branch:master \\\n   | grep topic: | sort -u\n\n\n\n\n\n\ngerrit.hyperledger.org\n Is the current URL where the project is hosted.\n\n\nstatus\n Indicates the topic\ns current status: open , merged, abandoned, draft,\nmerge conflict.\n\n\nproject\n Refers to the current name of the project, in this case fabric.\n\n\nbranch\n The topic is searched at this branch.\n\n\ntopic\n The name of an specific topic, leave it blank to include them all.\n\n\nsort\n Sorts the found topics, in this case by update (-u).\n\n\n\n\nDownloading or Checking Out a Change\n\n\nIn the review UI, on the top right corner, the \nDownload\n link provides a\nlist of commands and hyperlinks to checkout or download diffs or files.\n\n\nWe recommend the use of the \ngit review\n plugin.\nThe steps to install git review are beyond the scope of this document.\nRefer to the \ngit review documentation\n for the installation process.\n\n\nTo check out a specific change using Git, the following command usually works:\n\n\ngit review -d CHANGEID\n\n\n\n\nIf you don\nt have Git-review installed, the following commands will do the same\nthing:\n\n\ngit fetch REMOTE refs/changes/NN/CHANGEIDNN/VERSION \\ \n git checkout FETCH_HEAD\n\n\n\n\nFor example, for the 4th version of change 2464, NN is the first two digits\n(24):\n\n\ngit fetch REMOTE refs/changes/24/2464/4 \\ \n git checkout FETCH_HEAD\n\n\n\n\nUsing Draft Branches\n\n\nYou can use draft branches to add specific reviewers before you publishing your\nchange.  The Draft Branches are pushed to \nrefs/drafts/master/TopicName\n\n\nThe next command ensures a local branch is created:\n\n\ngit checkout -b BRANCHNAME\n\n\n\n\nThe next command pushes your change to the drafts branch under \nTopicName\n:\n\n\ngit push REMOTE HEAD:refs/drafts/master/TopicName\n\n\n\n\nUsing Sandbox Branches\n\n\nYou can create your own branches to develop features. The branches are pushed to\nthe \nrefs/sandbox/USERNAME/BRANCHNAME\n location.\n\n\nThese commands ensure the branch is created in Gerrit\ns server.\n\n\ngit checkout -b sandbox/USERNAME/BRANCHNAME\ngit push --set-upstream REMOTE HEAD:refs/heads/sandbox/USERNAME/BRANCHNAME\n\n\n\n\nUsually, the process to create content is:\n\n\n\n\ndevelop the code,\n\n\nbreak the information into small commits,\n\n\nsubmit changes,\n\n\napply feedback,\n\n\nrebase.\n\n\n\n\nThe next command pushes forcibly without review:\n\n\ngit push REMOTE sandbox/USERNAME/BRANCHNAME\n\n\n\n\nYou can also push forcibly with review:\n\n\ngit push REMOTE HEAD:ref/for/sandbox/USERNAME/BRANCHNAME\n\n\n\n\nUpdating the Version of a Change\n\n\nDuring the review process, you might be asked to update your change. It is\npossible to submit multiple versions of the same change. Each version of the\nchange is called a patch set.\n\n\nAlways maintain the \nChange-Id\n that was assigned.\nFor example, there is a list of commits, \nc0\nc7\n, which were submitted as a\ntopic branch:\n\n\ngit log REMOTE/master..master\n\nc0\n...\nc7\n\ngit push REMOTE HEAD:refs/for/master/SOMETOPIC\n\n\n\n\nAfter you get reviewers\n feedback, there are changes in \nc3\n and \nc4\n that\nmust be fixed.  If the fix requires rebasing, rebasing changes the commit Ids,\nsee the \nrebasing\n section\nfor more information. However, you must keep the same Change-Id and push the\nchanges again:\n\n\ngit push REMOTE HEAD:refs/for/master/SOMETOPIC\n\n\n\n\nThis new push creates a patches revision, your local history is then cleared.\nHowever you can still access the history of your changes in Gerrit on the\n\nreview UI\n section, for each change.\n\n\nIt is also permitted to add more commits when pushing new versions.\n\n\nRebasing\n\n\nRebasing is usually the last step before pushing changes to Gerrit; this allows\nyou to make the necessary \nChange-Ids\n.  The \nChange-Ids\n must be kept the same.\n\n\n\n\nsquash:\n mixes two or more commits into a single one.\n\n\nreword:\n changes the commit message.\n\n\nedit:\n changes the commit content.\n\n\nreorder:\n allows you to interchange the order of the commits.\n\n\nrebase:\n stacks the commits on top of the master.\n\n\n\n\nRebasing During a Pull\n\n\nBefore pushing a rebase to your master, ensure that the history has a\nconsecutive order.\n\n\nFor example, your \nREMOTE/master\n has the list of commits from \na0\n to\n\na4\n; Then, your changes \nc0\nc7\n are on top of \na4\n; thus:\n\n\ngit log --oneline REMOTE/master..master\n\na0\na1\na2\na3\na4\nc0\nc1\n...\nc7\n\n\n\n\nIf \nREMOTE/master\n receives commits \na5\n, \na6\n and \na7\n. Pull with a\nrebase as follows:\n\n\ngit pull --rebase REMOTE master\n\n\n\n\nThis pulls \na5-a7\n and re-apply \nc0-c7\n on top of them:\n\n\n   $ git log --oneline REMOTE/master..master\n   a0\n   ...\n   a7\n   c0\n   c1\n   ...\n   c7\n\n\n\n\nGetting Better Logs from Git\n\n\nUse these commands to change the configuration of Git in order to produce better\nlogs:\n\n\ngit config log.abbrevCommit true\n\n\n\n\nThe command above sets the log to abbreviate the commits\n hash.\n\n\ngit config log.abbrev 5\n\n\n\n\nThe command above sets the abbreviation length to the last 5 characters of the\nhash.\n\n\ngit config format.pretty oneline\n\n\n\n\nThe command above avoids the insertion of an unnecessary line before the Author\nline.\n\n\nTo make these configuration changes specifically for the current Git user,\nyou must add the path option \n--global\n to \nconfig\n as follows:",
            "title": "Best Practices"
        },
        {
            "location": "/Gerrit/best-practices/#gerrit-recommended-practices",
            "text": "This document presents some best practices to help you use Gerrit more\neffectively.  The intent is to show how content can be submitted easily. Use the\nrecommended practices to reduce your troubleshooting time and improve\nparticipation in the community.",
            "title": "Gerrit Recommended Practices"
        },
        {
            "location": "/Gerrit/best-practices/#browsing-the-git-tree",
            "text": "Visit  Gerrit  then\nselect  Projects --  List --  SELECT-PROJECT --  Branches .  Select the branch\nthat interests you, click on  gitweb  located on the right-hand side.  Now, gitweb  loads your selection on the Git web interface and redirects\nappropriately.",
            "title": "Browsing the Git Tree"
        },
        {
            "location": "/Gerrit/best-practices/#watching-a-project",
            "text": "Visit  Gerrit , then\nselect  Settings , located on the top right corner. Select  Watched Projects \nand then add any projects that interest you.",
            "title": "Watching a Project"
        },
        {
            "location": "/Gerrit/best-practices/#commit-messages",
            "text": "Gerrit follows the Git commit message format. Ensure the headers are at the\nbottom and don t contain blank lines between one another. The following example\nshows the format and content expected in a commit message:  Brief (no more than 50 chars) one line description.  Elaborate summary of the changes made referencing why (motivation), what was\nchanged and how it was tested. Note also any changes to documentation made to\nremain consistent with the code changes, wrapping text at 72 chars/line.  Jira: FAB-100 \n   Change-Id: LONGHEXHASH \n   Signed-off-by: Your Name your.email@example.org \n   AnotherExampleHeader: An Example of another Value  The Gerrit server provides a precommit hook to autogenerate the Change-Id which\nis one time use.  Recommended reading:   How to Write a Git Commit Message",
            "title": "Commit Messages"
        },
        {
            "location": "/Gerrit/best-practices/#avoid-pushing-untested-work-to-a-gerrit-server",
            "text": "To avoid pushing untested work to Gerrit.  Check your work at least three times before pushing your change to Gerrit.\nBe mindful of what information you are publishing.",
            "title": "Avoid Pushing Untested Work to a Gerrit Server"
        },
        {
            "location": "/Gerrit/best-practices/#keeping-track-of-changes",
            "text": "Set Gerrit to send you emails:    Gerrit will add you to the email distribution list for a change if a\n    developer adds you as a reviewer, or if you comment on a specific Patch\n    Set.    Opening a change in Gerrit s review interface is a quick way to follow that\n  change.    Watch projects in the Gerrit projects section at  Gerrit , select at least\n    New Changes, New Patch Sets, All Comments  and  Submitted Changes .    Always track the projects you are working on; also see the feedback/comments\nmailing list to learn and help others ramp up.",
            "title": "Keeping Track of Changes"
        },
        {
            "location": "/Gerrit/best-practices/#topic-branches",
            "text": "Topic branches are temporary branches that you push to commit a set of\nlogically-grouped dependent commits:  To push changes from  REMOTE/master  tree to Gerrit for being reviewed as\na topic in   TopicName  use the following command as an example:  $ git push REMOTE HEAD:refs/for/master/TopicName  The topic will show up in the review :abbr: UI  and in the Open Changes List .  Topic branches will disappear from the master\ntree when its content is merged.",
            "title": "Topic branches"
        },
        {
            "location": "/Gerrit/best-practices/#creating-a-cover-letter-for-a-topic",
            "text": "You may decide whether or not you d like the cover letter to appear in the\nhistory.   To make a cover letter that appears in the history, use this command:   git commit --allow-empty  Edit the commit message, this message then becomes the cover letter.\nThe command used doesn t change any files in the source tree.    To make a cover letter that doesn t appear in the history follow these steps:    Put the empty commit at the end of your commits list so it can be ignored \n   without having to rebase.    Now add your commits    git commit ...\ngit commit ...\ngit commit ...   Finally, push the commits to a topic branch.  The following command is an\n     example:   git push REMOTE HEAD:refs/for/master/TopicName  If you already have commits but you want to set a cover letter, create an empty\ncommit for the cover letter and move the commit so it becomes the last commit\non the list. Use the following command as an example:  git rebase -i HEAD~#Commits  Be careful to uncomment the commit before moving it. #Commits  is the sum of the commits plus your new cover letter.",
            "title": "Creating a Cover Letter for a Topic"
        },
        {
            "location": "/Gerrit/best-practices/#finding-available-topics",
            "text": "$ ssh -p 29418 gerrit.hyperledger.org gerrit query \\ status:open project:fabric branch:master \\\n   | grep topic: | sort -u   gerrit.hyperledger.org  Is the current URL where the project is hosted.  status  Indicates the topic s current status: open , merged, abandoned, draft,\nmerge conflict.  project  Refers to the current name of the project, in this case fabric.  branch  The topic is searched at this branch.  topic  The name of an specific topic, leave it blank to include them all.  sort  Sorts the found topics, in this case by update (-u).",
            "title": "Finding Available Topics"
        },
        {
            "location": "/Gerrit/best-practices/#downloading-or-checking-out-a-change",
            "text": "In the review UI, on the top right corner, the  Download  link provides a\nlist of commands and hyperlinks to checkout or download diffs or files.  We recommend the use of the  git review  plugin.\nThe steps to install git review are beyond the scope of this document.\nRefer to the  git review documentation  for the installation process.  To check out a specific change using Git, the following command usually works:  git review -d CHANGEID  If you don t have Git-review installed, the following commands will do the same\nthing:  git fetch REMOTE refs/changes/NN/CHANGEIDNN/VERSION \\   git checkout FETCH_HEAD  For example, for the 4th version of change 2464, NN is the first two digits\n(24):  git fetch REMOTE refs/changes/24/2464/4 \\   git checkout FETCH_HEAD",
            "title": "Downloading or Checking Out a Change"
        },
        {
            "location": "/Gerrit/best-practices/#using-draft-branches",
            "text": "You can use draft branches to add specific reviewers before you publishing your\nchange.  The Draft Branches are pushed to  refs/drafts/master/TopicName  The next command ensures a local branch is created:  git checkout -b BRANCHNAME  The next command pushes your change to the drafts branch under  TopicName :  git push REMOTE HEAD:refs/drafts/master/TopicName",
            "title": "Using Draft Branches"
        },
        {
            "location": "/Gerrit/best-practices/#using-sandbox-branches",
            "text": "You can create your own branches to develop features. The branches are pushed to\nthe  refs/sandbox/USERNAME/BRANCHNAME  location.  These commands ensure the branch is created in Gerrit s server.  git checkout -b sandbox/USERNAME/BRANCHNAME\ngit push --set-upstream REMOTE HEAD:refs/heads/sandbox/USERNAME/BRANCHNAME  Usually, the process to create content is:   develop the code,  break the information into small commits,  submit changes,  apply feedback,  rebase.   The next command pushes forcibly without review:  git push REMOTE sandbox/USERNAME/BRANCHNAME  You can also push forcibly with review:  git push REMOTE HEAD:ref/for/sandbox/USERNAME/BRANCHNAME",
            "title": "Using Sandbox Branches"
        },
        {
            "location": "/Gerrit/best-practices/#updating-the-version-of-a-change",
            "text": "During the review process, you might be asked to update your change. It is\npossible to submit multiple versions of the same change. Each version of the\nchange is called a patch set.  Always maintain the  Change-Id  that was assigned.\nFor example, there is a list of commits,  c0 c7 , which were submitted as a\ntopic branch:  git log REMOTE/master..master\n\nc0\n...\nc7\n\ngit push REMOTE HEAD:refs/for/master/SOMETOPIC  After you get reviewers  feedback, there are changes in  c3  and  c4  that\nmust be fixed.  If the fix requires rebasing, rebasing changes the commit Ids,\nsee the  rebasing  section\nfor more information. However, you must keep the same Change-Id and push the\nchanges again:  git push REMOTE HEAD:refs/for/master/SOMETOPIC  This new push creates a patches revision, your local history is then cleared.\nHowever you can still access the history of your changes in Gerrit on the review UI  section, for each change.  It is also permitted to add more commits when pushing new versions.",
            "title": "Updating the Version of a Change"
        },
        {
            "location": "/Gerrit/best-practices/#rebasing",
            "text": "Rebasing is usually the last step before pushing changes to Gerrit; this allows\nyou to make the necessary  Change-Ids .  The  Change-Ids  must be kept the same.   squash:  mixes two or more commits into a single one.  reword:  changes the commit message.  edit:  changes the commit content.  reorder:  allows you to interchange the order of the commits.  rebase:  stacks the commits on top of the master.",
            "title": "Rebasing"
        },
        {
            "location": "/Gerrit/best-practices/#rebasing-during-a-pull",
            "text": "Before pushing a rebase to your master, ensure that the history has a\nconsecutive order.  For example, your  REMOTE/master  has the list of commits from  a0  to a4 ; Then, your changes  c0 c7  are on top of  a4 ; thus:  git log --oneline REMOTE/master..master\n\na0\na1\na2\na3\na4\nc0\nc1\n...\nc7  If  REMOTE/master  receives commits  a5 ,  a6  and  a7 . Pull with a\nrebase as follows:  git pull --rebase REMOTE master  This pulls  a5-a7  and re-apply  c0-c7  on top of them:     $ git log --oneline REMOTE/master..master\n   a0\n   ...\n   a7\n   c0\n   c1\n   ...\n   c7",
            "title": "Rebasing During a Pull"
        },
        {
            "location": "/Gerrit/best-practices/#getting-better-logs-from-git",
            "text": "Use these commands to change the configuration of Git in order to produce better\nlogs:  git config log.abbrevCommit true  The command above sets the log to abbreviate the commits  hash.  git config log.abbrev 5  The command above sets the abbreviation length to the last 5 characters of the\nhash.  git config format.pretty oneline  The command above avoids the insertion of an unnecessary line before the Author\nline.  To make these configuration changes specifically for the current Git user,\nyou must add the path option  --global  to  config  as follows:",
            "title": "Getting Better Logs from Git"
        },
        {
            "location": "/MAINTAINERS/",
            "text": "Maintainers\n\n\n\n\n\n\n\n\nName\n\n\nGitHub\n\n\nGerrit\n\n\nemail\n\n\n\n\n\n\n\n\n\n\nBinh Nguyen\n\n\nbinhn\n\n\n\n\nbinhn@us.ibm.com\n\n\n\n\n\n\nSheehan Anderson\n\n\nsrderson\n\n\nsheehan\n\n\nsranderson@gmail.com\n\n\n\n\n\n\nTamas Blummer\n\n\ntamasblummer\n\n\ntamas@digitalasset.com\n\n\n\n\n\n\n\n\nRobert Fajta\n\n\nrfajta\n\n\nrobert@digitalasset.com\n\n\n\n\n\n\n\n\nGreg Haskins\n\n\nghaskins\n\n\nghaskins@lseg.com\n\n\n\n\n\n\n\n\nJonathan Levi\n\n\nJonathanLevi\n\n\njonathan@levi.name\n\n\n\n\n\n\n\n\nGabor Hosszu\n\n\ngabre\n\n\ngabor@digitalasset.com\n\n\n\n\n\n\n\n\nSimon Schubert\n\n\ncorecode\n\n\nsis@zurich.ibm.com\n\n\n\n\n\n\n\n\nChris Ferris\n\n\nchristo4ferris\n\n\nChristopherFerris\n\n\nchrisfer@us.ibm.com\n\n\n\n\n\n\nSrinivasan Muralidharan\n\n\nmuralisrini\n\n\nmuralisr\n\n\nmuralisr@us.ibm.com\n\n\n\n\n\n\nGari Singh\n\n\nmastersingh24\n\n\nmastersingh24\n\n\ngari.r.singh@gmail.com",
            "title": "Maintainers"
        },
        {
            "location": "/MAINTAINERS/#maintainers",
            "text": "Name  GitHub  Gerrit  email      Binh Nguyen  binhn   binhn@us.ibm.com    Sheehan Anderson  srderson  sheehan  sranderson@gmail.com    Tamas Blummer  tamasblummer  tamas@digitalasset.com     Robert Fajta  rfajta  robert@digitalasset.com     Greg Haskins  ghaskins  ghaskins@lseg.com     Jonathan Levi  JonathanLevi  jonathan@levi.name     Gabor Hosszu  gabre  gabor@digitalasset.com     Simon Schubert  corecode  sis@zurich.ibm.com     Chris Ferris  christo4ferris  ChristopherFerris  chrisfer@us.ibm.com    Srinivasan Muralidharan  muralisrini  muralisr  muralisr@us.ibm.com    Gari Singh  mastersingh24  mastersingh24  gari.r.singh@gmail.com",
            "title": "Maintainers"
        },
        {
            "location": "/Gerrit/reviewing/",
            "text": "Reviewing a Change\n\n\n\n\n\n\nClick on a link for incoming or outgoing review.\n\n\n\n\n\n\nThe details of the change and its current status are loaded:\n\n\n\n\n\n\nStatus:\n Displays the current status of the change. In the\n     example below, the status reads: Needs Verified.\n\n\n\n\n\n\nReply:\n Click on this button after reviewing to add a final\n     review message and a score, -1, 0 or +1.\n\n\n\n\n\n\nPatch Sets:\n If multiple revisions of a patch exist, this button\n     enables navigation among revisions to see the changes. By default,\n     the most recent revision is presented.\n\n\n\n\n\n\nDownload:\n This button brings up another window with multiple\n     options to download or checkout the current changeset. The button on\n     the right copies the line to your clipboard. You can easily paste it\n     into your git interface to work with the patch as you prefer.\n\n\n\n\n\n\nUnderneath the commit information, the files that have been changed by\n   this patch are displayed.\n\n\n\n\n\n\nClick on a filename to review it. Select the code base to differentiate\n   against. The default is \nBase\n and it will generally be\n   what is needed.\n\n\n\n\n\n\nThe review page presents the changes made to the file. At the top of\n   the review, the presentation shows some general navigation options.\n   Navigate through the patch set using the arrows on the top\n   right corner. It is possible to go to the previous or next file in the\n   set or to return to the main change screen. Click on the yellow sticky\n   pad to add comments to the whole file.\n\n\n\n\n\n\nThe focus of the page is on the comparison window. The changes made\n   are presented in green on the right versus the base version on the left.\n   Double click to highlight the text within the actual change to provide\n   feedback on a specific section of the code. Press \nc\n once the code is\n   highlighted to add comments to that section.\n\n\n\n\n\n\nAfter adding the comment, it is saved as a \nDraft\n.\n\n\n\n\n\n\nOnce you have reviewed all files and provided feedback, click the\n   \ngreen up arrow\n at the top right to return to the main change page. Click\n   the \nReply\n button, write some final comments, and submit your score for\n   the patch set. Click \nPost\n to submit the review of each reviewed file, as\n   well as your final comment and score. Gerrit sends an email to the\n   change-submitter and all listed reviewers. Finally, it logs the review\n   for future reference. All individual comments are saved as \nDraft\n until\n   the \nPost\n button is clicked.",
            "title": "Reviewing"
        },
        {
            "location": "/Gerrit/reviewing/#reviewing-a-change",
            "text": "Click on a link for incoming or outgoing review.    The details of the change and its current status are loaded:    Status:  Displays the current status of the change. In the\n     example below, the status reads: Needs Verified.    Reply:  Click on this button after reviewing to add a final\n     review message and a score, -1, 0 or +1.    Patch Sets:  If multiple revisions of a patch exist, this button\n     enables navigation among revisions to see the changes. By default,\n     the most recent revision is presented.    Download:  This button brings up another window with multiple\n     options to download or checkout the current changeset. The button on\n     the right copies the line to your clipboard. You can easily paste it\n     into your git interface to work with the patch as you prefer.    Underneath the commit information, the files that have been changed by\n   this patch are displayed.    Click on a filename to review it. Select the code base to differentiate\n   against. The default is  Base  and it will generally be\n   what is needed.    The review page presents the changes made to the file. At the top of\n   the review, the presentation shows some general navigation options.\n   Navigate through the patch set using the arrows on the top\n   right corner. It is possible to go to the previous or next file in the\n   set or to return to the main change screen. Click on the yellow sticky\n   pad to add comments to the whole file.    The focus of the page is on the comparison window. The changes made\n   are presented in green on the right versus the base version on the left.\n   Double click to highlight the text within the actual change to provide\n   feedback on a specific section of the code. Press  c  once the code is\n   highlighted to add comments to that section.    After adding the comment, it is saved as a  Draft .    Once you have reviewed all files and provided feedback, click the\n    green up arrow  at the top right to return to the main change page. Click\n   the  Reply  button, write some final comments, and submit your score for\n   the patch set. Click  Post  to submit the review of each reviewed file, as\n   well as your final comment and score. Gerrit sends an email to the\n   change-submitter and all listed reviewers. Finally, it logs the review\n   for future reference. All individual comments are saved as  Draft  until\n   the  Post  button is clicked.",
            "title": "Reviewing a Change"
        },
        {
            "location": "/Gerrit/changes/",
            "text": "Submitting a Change to Gerrit\n\n\nCarefully review the following before submitting a change. These\nguidelines apply to developers that are new to open source, as well as\nto experienced open source developers.\n\n\nChange Requirements\n\n\nThis section contains guidelines for submitting code changes for review.\nFor more information on how to submit a change using Gerrit, please\nsee \nGerrit\n.\n\n\nChanges are submitted as Git commits. Each commit must contain:\n\n\n\n\na short and descriptive subject line that is 72 characters or fewer,\n  followed by a blank line.\n\n\na change description with your logic or reasoning for the changes,\n  followed by a blank line\n\n\na Signed-off-by line, followed by a colon (Signed-off-by:)\n\n\na Change-Id identifier line, followed by a colon (Change-Id:). Gerrit won\nt\n  accept patches without this identifier.\n\n\n\n\nA commit with the above details is considered well-formed.\n\n\nAll changes and topics sent to Gerrit must be well-formed. Informationally,\n\ncommit messages\n must include:\n\n\n\n\nwhat\n the change does,\n\n\nwhy\n you chose that approach, and\n\n\nhow\n you know it works \n for example, which tests you ran.\n\n\n\n\nCommits must \nbuild cleanly\n when applied in top of each\nother, thus avoiding breaking bisectability. Each commit must address a single\nidentifiable issue and must be logically self-contained.\n\n\nFor example: One commit fixes whitespace issues, another renames a\nfunction and a third one changes the code\ns functionality.  An example commit\nfile is illustrated below in detail:\n\n\nA short description of your change with no period at the end\n\nYou can add more details here in several paragraphs, but please keep each line\nwidth less than 80 characters. A bug fix should include the issue number.\n\nFix Issue # 7050.\n\nChange-Id: IF7b6ac513b2eca5f2bab9728ebd8b7e504d3cebe1\nSigned-off-by: Your Name \ncommit-sender@email.address\n\n\n\n\n\nEach commit must contain the following line at the bottom of the commit\nmessage:\n\n\nSigned-off-by: Your Name \nyour@email.address\n\n\n\n\n\nThe name in the Signed-off-by line and your email must match the change\nauthorship information. Make sure your :file:\n.git/config\n is set up\ncorrectly. Always submit the full set of changes via Gerrit.\n\n\nWhen a change is included in the set to enable other changes, but it\nwill not be part of the final set, please let the reviewers know this.",
            "title": "Changes"
        },
        {
            "location": "/Gerrit/changes/#submitting-a-change-to-gerrit",
            "text": "Carefully review the following before submitting a change. These\nguidelines apply to developers that are new to open source, as well as\nto experienced open source developers.",
            "title": "Submitting a Change to Gerrit"
        },
        {
            "location": "/Gerrit/changes/#change-requirements",
            "text": "This section contains guidelines for submitting code changes for review.\nFor more information on how to submit a change using Gerrit, please\nsee  Gerrit .  Changes are submitted as Git commits. Each commit must contain:   a short and descriptive subject line that is 72 characters or fewer,\n  followed by a blank line.  a change description with your logic or reasoning for the changes,\n  followed by a blank line  a Signed-off-by line, followed by a colon (Signed-off-by:)  a Change-Id identifier line, followed by a colon (Change-Id:). Gerrit won t\n  accept patches without this identifier.   A commit with the above details is considered well-formed.  All changes and topics sent to Gerrit must be well-formed. Informationally, commit messages  must include:   what  the change does,  why  you chose that approach, and  how  you know it works   for example, which tests you ran.   Commits must  build cleanly  when applied in top of each\nother, thus avoiding breaking bisectability. Each commit must address a single\nidentifiable issue and must be logically self-contained.  For example: One commit fixes whitespace issues, another renames a\nfunction and a third one changes the code s functionality.  An example commit\nfile is illustrated below in detail:  A short description of your change with no period at the end\n\nYou can add more details here in several paragraphs, but please keep each line\nwidth less than 80 characters. A bug fix should include the issue number.\n\nFix Issue # 7050.\n\nChange-Id: IF7b6ac513b2eca5f2bab9728ebd8b7e504d3cebe1\nSigned-off-by: Your Name  commit-sender@email.address   Each commit must contain the following line at the bottom of the commit\nmessage:  Signed-off-by: Your Name  your@email.address   The name in the Signed-off-by line and your email must match the change\nauthorship information. Make sure your :file: .git/config  is set up\ncorrectly. Always submit the full set of changes via Gerrit.  When a change is included in the set to enable other changes, but it\nwill not be part of the final set, please let the reviewers know this.",
            "title": "Change Requirements"
        },
        {
            "location": "/Style-guides/go-style/",
            "text": "Coding guidelines\n\n\nCoding Golang \n\n\nWe code in Go\n and strictly follow the \nbest\npractices\n and will not accept any\ndeviations. You must run the following tools against your Go code and fix all\nerrors and warnings:\n  - \ngolint\n\n  - \ngo vet\n\n  - \ngoimports\n\n\nGenerating gRPC code \n\n\nIf you modify any \n.proto\n files, run the following command to generate/update\nthe respective \n.pb.go\n files.\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake protos\n\n\n\n\nAdding or updating Go packages\n\n\nThe Hyperledger Fabric Project uses Go 1.6 vendoring for package management.\nThis means that all required packages reside in the \nvendor\n folder within the\nfabric project. Go will use packages in this folder instead of the GOPATH when\nthe \ngo install\n or \ngo build\n commands are executed. To manage the packages in\nthe \nvendor\n folder, we use \nGovendor\n,\nwhich is installed in the Vagrant environment. The following commands can be\nused for package management:\n\n\n  # Add external packages.\n  govendor add +external\n\n  # Add a specific package.\n  govendor add github.com/kardianos/osext\n\n  # Update vendor packages.\n  govendor update +vendor\n\n  # Revert back to normal GOPATH packages.\n  govendor remove +vendor\n\n  # List package.\n  govendor list",
            "title": "Golang"
        },
        {
            "location": "/Style-guides/go-style/#coding-guidelines",
            "text": "",
            "title": "Coding guidelines"
        },
        {
            "location": "/Style-guides/go-style/#coding-golang",
            "text": "We code in Go  and strictly follow the  best\npractices  and will not accept any\ndeviations. You must run the following tools against your Go code and fix all\nerrors and warnings:\n  -  golint \n  -  go vet \n  -  goimports",
            "title": "Coding Golang "
        },
        {
            "location": "/Style-guides/go-style/#generating-grpc-code",
            "text": "If you modify any  .proto  files, run the following command to generate/update\nthe respective  .pb.go  files.  cd $GOPATH/src/github.com/hyperledger/fabric\nmake protos",
            "title": "Generating gRPC code "
        },
        {
            "location": "/Style-guides/go-style/#adding-or-updating-go-packages",
            "text": "The Hyperledger Fabric Project uses Go 1.6 vendoring for package management.\nThis means that all required packages reside in the  vendor  folder within the\nfabric project. Go will use packages in this folder instead of the GOPATH when\nthe  go install  or  go build  commands are executed. To manage the packages in\nthe  vendor  folder, we use  Govendor ,\nwhich is installed in the Vagrant environment. The following commands can be\nused for package management:    # Add external packages.\n  govendor add +external\n\n  # Add a specific package.\n  govendor add github.com/kardianos/osext\n\n  # Update vendor packages.\n  govendor update +vendor\n\n  # Revert back to normal GOPATH packages.\n  govendor remove +vendor\n\n  # List package.\n  govendor list",
            "title": "Adding or updating Go packages"
        },
        {
            "location": "/FAQ/chaincode_FAQ/",
            "text": "Chaincode (Smart Contracts and Digital Assets)\n\n\n\n\nDoes the fabric implementation support smart contract logic?\n\n\nYes. Chaincode is the fabric\u2019s interpretation of the smart contract method/algorithm, with additional features.\n\n\nA chaincode is programmatic code deployed on the network, where it is executed and validated by chain validators together during the consensus process. Developers can use chaincodes to develop business contracts, asset definitions, and collectively-managed decentralized applications.\n\n\n\n\nHow do I create a business contract using the fabric?\n\n\nThere are generally two ways to develop business contracts: the first way is to code individual contracts into standalone instances of chaincode; the second way, and probably the more efficient way, is to use chaincode to create decentralized applications that manage the life cycle of one or multiple types of business contracts, and let end users instantiate instances of contracts within these applications.\n\n\n\n\nHow do I create assets using the fabric?\n\n\nUsers can use chaincode (for business rules) and membership service (for digital tokens) to design assets, as well as the logic that manages them.\n\n\nThere are two popular approaches to defining assets in most blockchain solutions: the stateless UTXO model, where account balances are encoded into past transaction records; and the account model, where account balances are kept in state storage space on the ledger.\n\n\nEach approach carries its own benefits and drawbacks. This blockchain fabric does not advocate either one over the other. Instead, one of our first requirements was to ensure that both approaches can be easily implemented with tools available in the fabric.\n\n\n\n\nWhich languages are supported for writing chaincode?\n\n\nChaincode can be written in any programming language and executed in containers inside the fabric context layer. We are also looking into developing a templating language (such as Apache Velocity) that can either get compiled into chaincode or have its interpreter embedded into a chaincode container.\n\n\nThe fabric\ns first fully supported chaincode language is Golang, and support for JavaScript and Java is planned for 2016. Support for additional languages and the development of a fabric-specific templating language have been discussed, and more details will be released in the near future.\n\n\n\n\nDoes the fabric have native currency?\n\n\nNo. However, if you really need a native currency for your chain network, you can develop your own native currency with chaincode. One common attribute of native currency is that some amount will get transacted (the chaincode defining that currency will get called) every time a transaction is processed on its chain.",
            "title": "ChainCodeFAQ"
        },
        {
            "location": "/FAQ/chaincode_FAQ/#chaincode-smart-contracts-and-digital-assets",
            "text": "",
            "title": "Chaincode (Smart Contracts and Digital Assets)"
        },
        {
            "location": "/FAQ/chaincode_FAQ/#does-the-fabric-implementation-support-smart-contract-logic",
            "text": "Yes. Chaincode is the fabric\u2019s interpretation of the smart contract method/algorithm, with additional features.  A chaincode is programmatic code deployed on the network, where it is executed and validated by chain validators together during the consensus process. Developers can use chaincodes to develop business contracts, asset definitions, and collectively-managed decentralized applications.",
            "title": "Does the fabric implementation support smart contract logic?"
        },
        {
            "location": "/FAQ/chaincode_FAQ/#how-do-i-create-a-business-contract-using-the-fabric",
            "text": "There are generally two ways to develop business contracts: the first way is to code individual contracts into standalone instances of chaincode; the second way, and probably the more efficient way, is to use chaincode to create decentralized applications that manage the life cycle of one or multiple types of business contracts, and let end users instantiate instances of contracts within these applications.",
            "title": "How do I create a business contract using the fabric?"
        },
        {
            "location": "/FAQ/chaincode_FAQ/#how-do-i-create-assets-using-the-fabric",
            "text": "Users can use chaincode (for business rules) and membership service (for digital tokens) to design assets, as well as the logic that manages them.  There are two popular approaches to defining assets in most blockchain solutions: the stateless UTXO model, where account balances are encoded into past transaction records; and the account model, where account balances are kept in state storage space on the ledger.  Each approach carries its own benefits and drawbacks. This blockchain fabric does not advocate either one over the other. Instead, one of our first requirements was to ensure that both approaches can be easily implemented with tools available in the fabric.",
            "title": "How do I create assets using the fabric?"
        },
        {
            "location": "/FAQ/chaincode_FAQ/#which-languages-are-supported-for-writing-chaincode",
            "text": "Chaincode can be written in any programming language and executed in containers inside the fabric context layer. We are also looking into developing a templating language (such as Apache Velocity) that can either get compiled into chaincode or have its interpreter embedded into a chaincode container.  The fabric s first fully supported chaincode language is Golang, and support for JavaScript and Java is planned for 2016. Support for additional languages and the development of a fabric-specific templating language have been discussed, and more details will be released in the near future.",
            "title": "Which languages are supported for writing chaincode?"
        },
        {
            "location": "/FAQ/chaincode_FAQ/#does-the-fabric-have-native-currency",
            "text": "No. However, if you really need a native currency for your chain network, you can develop your own native currency with chaincode. One common attribute of native currency is that some amount will get transacted (the chaincode defining that currency will get called) every time a transaction is processed on its chain.",
            "title": "Does the fabric have native currency?"
        },
        {
            "location": "/FAQ/confidentiality_FAQ/",
            "text": "Confidentiality\n\n\n\n\nHow is the confidentiality of transactions and business logic achieved?\n\n\nThe security module works in conjunction with the membership service module to provide access control service to any data recorded and business logic deployed on a chain network.\n\n\nWhen a code is deployed on a chain network, whether it is used to define a business contract or an asset, its creator can put access control on it so that only transactions issued by authorized entities will be processed and validated by chain validators.\n\n\nRaw transaction records are permanently stored in the ledger. While the contents of non-confidential transactions are open to all participants, the contents of confidential transactions are encrypted with secret keys known only to their originators, validators, and authorized auditors. Only holders of the secret keys can interpret transaction contents.\n\n\n\n\nWhat if none of the stakeholders of a business contract are validators?\n\n\nIn some business scenarios, full confidentiality of contract logic may be required \u2013 such that only contract counterparties and auditors can access and interpret their chaincode. Under these scenarios, counter parties would need to spin off a new child chain with only themselves as validators.",
            "title": "ConfidentialityFAQ"
        },
        {
            "location": "/FAQ/confidentiality_FAQ/#confidentiality",
            "text": "",
            "title": "Confidentiality"
        },
        {
            "location": "/FAQ/confidentiality_FAQ/#how-is-the-confidentiality-of-transactions-and-business-logic-achieved",
            "text": "The security module works in conjunction with the membership service module to provide access control service to any data recorded and business logic deployed on a chain network.  When a code is deployed on a chain network, whether it is used to define a business contract or an asset, its creator can put access control on it so that only transactions issued by authorized entities will be processed and validated by chain validators.  Raw transaction records are permanently stored in the ledger. While the contents of non-confidential transactions are open to all participants, the contents of confidential transactions are encrypted with secret keys known only to their originators, validators, and authorized auditors. Only holders of the secret keys can interpret transaction contents.",
            "title": "How is the confidentiality of transactions and business logic achieved?"
        },
        {
            "location": "/FAQ/confidentiality_FAQ/#what-if-none-of-the-stakeholders-of-a-business-contract-are-validators",
            "text": "In some business scenarios, full confidentiality of contract logic may be required \u2013 such that only contract counterparties and auditors can access and interpret their chaincode. Under these scenarios, counter parties would need to spin off a new child chain with only themselves as validators.",
            "title": "What if none of the stakeholders of a business contract are validators?"
        },
        {
            "location": "/FAQ/consensus_FAQ/",
            "text": "Consensus Algorithm\n\n\n\n\nWhich Consensus Algorithm is used in the fabric?\n\n\nThe fabric is built on a pluggable architecture such that developers can configure their deployment with the consensus module that best suits their needs. The initial release package will offer three consensus implementations for users to select from: 1) No-op (consensus ignored); and 2) Batch PBFT.",
            "title": "ConsensusFAQ"
        },
        {
            "location": "/FAQ/consensus_FAQ/#consensus-algorithm",
            "text": "",
            "title": "Consensus Algorithm"
        },
        {
            "location": "/FAQ/consensus_FAQ/#which-consensus-algorithm-is-used-in-the-fabric",
            "text": "The fabric is built on a pluggable architecture such that developers can configure their deployment with the consensus module that best suits their needs. The initial release package will offer three consensus implementations for users to select from: 1) No-op (consensus ignored); and 2) Batch PBFT.",
            "title": "Which Consensus Algorithm is used in the fabric?"
        },
        {
            "location": "/FAQ/identity_management_FAQ/",
            "text": "Identity Management (Membership Service)\n\n\n\n\nWhat is unique about the fabric\ns Membership Service module?\n\n\nOne of the things that makes the Membership Service module stand out from the pack is our implementation of the latest advances in cryptography.\n\n\nIn addition to ensuring private, auditable transactions, our Membership Service module introduces the concept of enrollment and transaction certificates. This innovation ensures that only verified owners can create asset tokens, allowing an infinite number of transaction certificates to be issued through parent enrollment certificates while guaranteeing the private keys of asset tokens can be regenerated if lost. \n\n\nIssuers also have the ability revoke transaction certificates or designate them to expire within a certain timeframe, allowing greater control over the asset tokens they have issued. \n\n\nLike most other modules on the fabric, you can always replace the default module with another membership service option should the need arise.\n\n\n\n\nDoes its Membership Service make the fabric a centralized solution?\n\n\nNo. The only role of the Membership Service module is to issue digital certificates to validated entities that want to participate in the network. It does not execute transactions nor is it aware of how or when these certificates are used in any particular network.\n\n\nHowever, because certificates are the way networks regulate and manage their users, the module serves a central regulatory and organizational role.",
            "title": "Identity ManagementFAQ"
        },
        {
            "location": "/FAQ/identity_management_FAQ/#identity-management-membership-service",
            "text": "",
            "title": "Identity Management (Membership Service)"
        },
        {
            "location": "/FAQ/identity_management_FAQ/#what-is-unique-about-the-fabrics-membership-service-module",
            "text": "One of the things that makes the Membership Service module stand out from the pack is our implementation of the latest advances in cryptography.  In addition to ensuring private, auditable transactions, our Membership Service module introduces the concept of enrollment and transaction certificates. This innovation ensures that only verified owners can create asset tokens, allowing an infinite number of transaction certificates to be issued through parent enrollment certificates while guaranteeing the private keys of asset tokens can be regenerated if lost.   Issuers also have the ability revoke transaction certificates or designate them to expire within a certain timeframe, allowing greater control over the asset tokens they have issued.   Like most other modules on the fabric, you can always replace the default module with another membership service option should the need arise.",
            "title": "What is unique about the fabric's Membership Service module?"
        },
        {
            "location": "/FAQ/identity_management_FAQ/#does-its-membership-service-make-the-fabric-a-centralized-solution",
            "text": "No. The only role of the Membership Service module is to issue digital certificates to validated entities that want to participate in the network. It does not execute transactions nor is it aware of how or when these certificates are used in any particular network.  However, because certificates are the way networks regulate and manage their users, the module serves a central regulatory and organizational role.",
            "title": "Does its Membership Service make the fabric a centralized solution?"
        },
        {
            "location": "/FAQ/usage_FAQ/",
            "text": "Usage\n\n\n\n\nWhat are the expected performance figures for the fabric?\n\n\nThe performance of any chain network depends on several factors: proximity of the validating nodes, number of validators, encryption method, transaction message size, security level set, business logic running, and the consensus algorithm deployed, among others.\n\n\nThe current performance goal for the fabric is to achieve 100,000 transactions per second in a standard production environment of about 15 validating nodes running in close proximity. The team is committed to continuously improving the performance and the scalability of the system.\n\n\n\n\nDo I have to own a validating node to transact on a chain network?\n\n\nNo. You can still transact on a chain network by owning a non-validating node (NV-node).\n\n\nAlthough transactions initiated by NV-nodes will eventually be forwarded to their validating peers for consensus processing, NV-nodes establish their own connections to the membership service module and can therefore package transactions independently. This allows NV-node owners to independently register and manage certificates, a powerful feature that empowers NV-node owners to create custom-built applications for their clients while managing their client certificates.\n\n\nIn addition, NV-nodes retain full copies of the ledger, enabling local queries of the ledger data.\n\n\n\n\nWhat does the error string \nstate may be inconsistent, cannot query\n as a query result mean?\n\n\nSometimes, a validating peer will be out of sync with the rest of the network. Although determining this condition is not always possible, validating peers make a best effort determination to detect it, and internally mark themselves as out of date.\n\n\nWhen under this condition, rather than reply with out of date or potentially incorrect data, the peer will reply to chaincode queries with the error string \nstate may be inconsistent, cannot query\n.\n\n\nIn the future, more sophisticated reporting mechanisms may be introduced such as returning the stale value and a flag that the value is stale.",
            "title": "UsageFAQ"
        },
        {
            "location": "/FAQ/usage_FAQ/#usage",
            "text": "",
            "title": "Usage"
        },
        {
            "location": "/FAQ/usage_FAQ/#what-are-the-expected-performance-figures-for-the-fabric",
            "text": "The performance of any chain network depends on several factors: proximity of the validating nodes, number of validators, encryption method, transaction message size, security level set, business logic running, and the consensus algorithm deployed, among others.  The current performance goal for the fabric is to achieve 100,000 transactions per second in a standard production environment of about 15 validating nodes running in close proximity. The team is committed to continuously improving the performance and the scalability of the system.",
            "title": "What are the expected performance figures for the fabric?"
        },
        {
            "location": "/FAQ/usage_FAQ/#do-i-have-to-own-a-validating-node-to-transact-on-a-chain-network",
            "text": "No. You can still transact on a chain network by owning a non-validating node (NV-node).  Although transactions initiated by NV-nodes will eventually be forwarded to their validating peers for consensus processing, NV-nodes establish their own connections to the membership service module and can therefore package transactions independently. This allows NV-node owners to independently register and manage certificates, a powerful feature that empowers NV-node owners to create custom-built applications for their clients while managing their client certificates.  In addition, NV-nodes retain full copies of the ledger, enabling local queries of the ledger data.",
            "title": "Do I have to own a validating node to transact on a chain network?"
        },
        {
            "location": "/FAQ/usage_FAQ/#what-does-the-error-string-state-may-be-inconsistent-cannot-query-as-a-query-result-mean",
            "text": "Sometimes, a validating peer will be out of sync with the rest of the network. Although determining this condition is not always possible, validating peers make a best effort determination to detect it, and internally mark themselves as out of date.  When under this condition, rather than reply with out of date or potentially incorrect data, the peer will reply to chaincode queries with the error string  state may be inconsistent, cannot query .  In the future, more sophisticated reporting mechanisms may be introduced such as returning the stale value and a flag that the value is stale.",
            "title": "What does the error string \"state may be inconsistent, cannot query\" as a query result mean?"
        },
        {
            "location": "/tech/application-ACL/",
            "text": "Hyperledger Fabric - Application Access Control Lists\n\n\nOverview\n\n\nWe consider the following entities:\n\n\n\n\nHelloWorld\n: is a chaincode that contains a single function called \nhello\n;\n\n\nAlice\n: is the \nHelloWorld\n deployer;\n\n\nBob\n: is the \nHelloWorld\ns functions invoker.\n\n\n\n\nAlice wants to ensure that only Bob can invoke the function \nhello\n.\n\n\nFabric Support\n\n\nTo allow Alice to specify her own access control lists and Bob to gain access, the fabric layer gives access to following capabilities:\n\n\n\n\nAlice and Bob can sign and verify any message with specific transaction certificates or enrollment certificate they own;\n\n\nThe fabric allows to \nname\n each transaction by means of a unique \nbinding\n to be used to bind application data\nto the underlying transaction transporting it;\n\n\nExtended transaction format.\n\n\n\n\nThe fabric layer exposes the following interfaces and functions to allow the application layer to define its own ACLS.\n\n\nCertificate Handler\n\n\nThe following interface allows to sign and verify any message using signing key-pair underlying the associated certificate.\nThe certificate can be a TCert or an ECert.\n\n\n// CertificateHandler exposes methods to deal with an ECert/TCert\ntype CertificateHandler interface {\n\n    // GetCertificate returns the certificate's DER\n    GetCertificate() []byte\n\n    // Sign signs msg using the signing key corresponding to the certificate\n    Sign(msg []byte) ([]byte, error)\n\n    // Verify verifies msg using the verifying key corresponding to the certificate\n    Verify(signature []byte, msg []byte) error\n\n    // GetTransactionHandler returns a new transaction handler relative to this certificate\n    GetTransactionHandler() (TransactionHandler, error)\n}\n\n\n\n\nTransaction Handler\n\n\nThe following interface allows to create transactions and give access to the underlying \nbinding\n that can be leveraged to link\napplication data to the underlying transaction.\n\n\n// TransactionHandler represents a single transaction that can be named by the output of the GetBinding method.\n// This transaction is linked to a single Certificate (TCert or ECert).\ntype TransactionHandler interface {\n\n    // GetCertificateHandler returns the certificate handler relative to the certificate mapped to this transaction\n    GetCertificateHandler() (CertificateHandler, error)\n\n    // GetBinding returns a binding to the underlying transaction\n    GetBinding() ([]byte, error)\n\n    // NewChaincodeDeployTransaction is used to deploy chaincode\n    NewChaincodeDeployTransaction(chaincodeDeploymentSpec *obc.ChaincodeDeploymentSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeExecute is used to execute chaincode's functions\n    NewChaincodeExecute(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeQuery is used to query chaincode's functions\n    NewChaincodeQuery(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n}\n\n\n\n\nClient\n\n\nThe following interface offers a mean to get instances of the previous interfaces.\n\n\ntype Client interface {\n\n    ...\n\n    // GetEnrollmentCertHandler returns a CertificateHandler whose certificate is the enrollment certificate\n    GetEnrollmentCertificateHandler() (CertificateHandler, error)\n\n    // GetTCertHandlerNext returns a CertificateHandler whose certificate is the next available TCert\n    GetTCertificateHandlerNext() (CertificateHandler, error)\n\n    // GetTCertHandlerFromDER returns a CertificateHandler whose certificate is the one passed\n    GetTCertificateHandlerFromDER(der []byte) (CertificateHandler, error)\n\n}\n\n\n\n\nTransaction Format\n\n\nTo support application-level ACLs, the fabric\ns transaction and chaincode specification format have an additional field to store application-specific metadata.\nThe content of this field is decided by the application. The fabric layer treats it as an unstructured stream of bytes.\n\n\n\nmessage ChaincodeSpec {\n\n    ...\n\n    ConfidentialityLevel confidentialityLevel;\n    bytes metadata;\n\n    ...\n}\n\n\nmessage Transaction {\n    ...\n\n    bytes payload;\n    bytes metadata;\n\n    ...\n}\n\n\n\n\nAnother way to achieve this is to have the payload contain the metadata itself.\n\n\nValidators\n\n\nTo assist chaincode execution, the validators provide the chaincode additional information, such as the metadata and the binding.\n\n\nApplication-level access control\n\n\nDeploy Transaction\n\n\nAlice has full control over the deployment transaction\ns metadata.\nIn particular, the metadata can be used to store a list of ACLs (one per function), or a list of roles.\nTo define each of these lists/roles, Alice can use any TCerts/ECerts of the users who have been\ngranted that (access control) privilege or have been assigned that role. The latter is done offline.\n\n\nNow, Alice requires that in order to invoke the \nhello\n function, a certain message \nM\n has to be authenticated by an authorized invoker (Bob, in our case).\nWe distinguish the following two cases:\n\n\n\n\nM\n is one of the chaincode\ns function arguments;\n\n\nM\n is the invocation message itself, i.e., function-name, arguments.\n\n\n\n\nExecute Transaction\n\n\nTo invoke \nhello\n, Bob needs to sign \nM\n using the TCert/ECert Alice has used to name him in the deployment transaction\ns metadata.\nLet\ns call this certificate CertBob. At this point Bob does the following:   \n\n\n\n\nBob obtains a \nCertificateHandler\n for CertBob, \ncHandlerBob\n;\n\n\nBob obtains a new \nTransactionHandler\n to issue the execute transaction, \ntxHandler\n relative to his next available TCert or his ECert;\n\n\nBob obtains \ntxHandler\ns \nbinding\n by invoking \ntxHandler.getBinding()\n;\n\n\nBob signs \nM || txBinding\n by invoking \ncHandlerBob.Sign(\nM || txBinding\n)\n, let \nsignature\n be the output of the signing function;\n\n\nBob issues a new execute transaction by invoking, \ntxHandler.NewChaincodeExecute(\n)\n. Now, \nsignature\n can be included\n  in the transaction as one of the argument to be passed to the function or as transaction metadata.\n\n\n\n\nChaincode Execution\n\n\nThe validators, who receive the execute transaction issued by Bob, will provide to \nhello\n the following information:\n\n\n\n\nThe \nbinding\n of the execute transaction;\n\n\nThe \nmetadata\n of the execute transaction;\n\n\nThe \nmetadata\n of the deploy transaction.\n\n\n\n\nThen, \nhello\n is responsible for checking that \nsignature\n is indeed a valid signature issued by Bob.",
            "title": "Application ACL"
        },
        {
            "location": "/tech/application-ACL/#hyperledger-fabric-application-access-control-lists",
            "text": "",
            "title": "Hyperledger Fabric - Application Access Control Lists"
        },
        {
            "location": "/tech/application-ACL/#overview",
            "text": "We consider the following entities:   HelloWorld : is a chaincode that contains a single function called  hello ;  Alice : is the  HelloWorld  deployer;  Bob : is the  HelloWorld s functions invoker.   Alice wants to ensure that only Bob can invoke the function  hello .",
            "title": "Overview"
        },
        {
            "location": "/tech/application-ACL/#fabric-support",
            "text": "To allow Alice to specify her own access control lists and Bob to gain access, the fabric layer gives access to following capabilities:   Alice and Bob can sign and verify any message with specific transaction certificates or enrollment certificate they own;  The fabric allows to  name  each transaction by means of a unique  binding  to be used to bind application data\nto the underlying transaction transporting it;  Extended transaction format.   The fabric layer exposes the following interfaces and functions to allow the application layer to define its own ACLS.",
            "title": "Fabric Support"
        },
        {
            "location": "/tech/application-ACL/#certificate-handler",
            "text": "The following interface allows to sign and verify any message using signing key-pair underlying the associated certificate.\nThe certificate can be a TCert or an ECert.  // CertificateHandler exposes methods to deal with an ECert/TCert\ntype CertificateHandler interface {\n\n    // GetCertificate returns the certificate's DER\n    GetCertificate() []byte\n\n    // Sign signs msg using the signing key corresponding to the certificate\n    Sign(msg []byte) ([]byte, error)\n\n    // Verify verifies msg using the verifying key corresponding to the certificate\n    Verify(signature []byte, msg []byte) error\n\n    // GetTransactionHandler returns a new transaction handler relative to this certificate\n    GetTransactionHandler() (TransactionHandler, error)\n}",
            "title": "Certificate Handler"
        },
        {
            "location": "/tech/application-ACL/#transaction-handler",
            "text": "The following interface allows to create transactions and give access to the underlying  binding  that can be leveraged to link\napplication data to the underlying transaction.  // TransactionHandler represents a single transaction that can be named by the output of the GetBinding method.\n// This transaction is linked to a single Certificate (TCert or ECert).\ntype TransactionHandler interface {\n\n    // GetCertificateHandler returns the certificate handler relative to the certificate mapped to this transaction\n    GetCertificateHandler() (CertificateHandler, error)\n\n    // GetBinding returns a binding to the underlying transaction\n    GetBinding() ([]byte, error)\n\n    // NewChaincodeDeployTransaction is used to deploy chaincode\n    NewChaincodeDeployTransaction(chaincodeDeploymentSpec *obc.ChaincodeDeploymentSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeExecute is used to execute chaincode's functions\n    NewChaincodeExecute(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeQuery is used to query chaincode's functions\n    NewChaincodeQuery(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n}",
            "title": "Transaction Handler"
        },
        {
            "location": "/tech/application-ACL/#client",
            "text": "The following interface offers a mean to get instances of the previous interfaces.  type Client interface {\n\n    ...\n\n    // GetEnrollmentCertHandler returns a CertificateHandler whose certificate is the enrollment certificate\n    GetEnrollmentCertificateHandler() (CertificateHandler, error)\n\n    // GetTCertHandlerNext returns a CertificateHandler whose certificate is the next available TCert\n    GetTCertificateHandlerNext() (CertificateHandler, error)\n\n    // GetTCertHandlerFromDER returns a CertificateHandler whose certificate is the one passed\n    GetTCertificateHandlerFromDER(der []byte) (CertificateHandler, error)\n\n}",
            "title": "Client"
        },
        {
            "location": "/tech/application-ACL/#transaction-format",
            "text": "To support application-level ACLs, the fabric s transaction and chaincode specification format have an additional field to store application-specific metadata.\nThe content of this field is decided by the application. The fabric layer treats it as an unstructured stream of bytes.  \nmessage ChaincodeSpec {\n\n    ...\n\n    ConfidentialityLevel confidentialityLevel;\n    bytes metadata;\n\n    ...\n}\n\n\nmessage Transaction {\n    ...\n\n    bytes payload;\n    bytes metadata;\n\n    ...\n}  Another way to achieve this is to have the payload contain the metadata itself.",
            "title": "Transaction Format"
        },
        {
            "location": "/tech/application-ACL/#validators",
            "text": "To assist chaincode execution, the validators provide the chaincode additional information, such as the metadata and the binding.",
            "title": "Validators"
        },
        {
            "location": "/tech/application-ACL/#application-level-access-control",
            "text": "",
            "title": "Application-level access control"
        },
        {
            "location": "/tech/application-ACL/#deploy-transaction",
            "text": "Alice has full control over the deployment transaction s metadata.\nIn particular, the metadata can be used to store a list of ACLs (one per function), or a list of roles.\nTo define each of these lists/roles, Alice can use any TCerts/ECerts of the users who have been\ngranted that (access control) privilege or have been assigned that role. The latter is done offline.  Now, Alice requires that in order to invoke the  hello  function, a certain message  M  has to be authenticated by an authorized invoker (Bob, in our case).\nWe distinguish the following two cases:   M  is one of the chaincode s function arguments;  M  is the invocation message itself, i.e., function-name, arguments.",
            "title": "Deploy Transaction"
        },
        {
            "location": "/tech/application-ACL/#execute-transaction",
            "text": "To invoke  hello , Bob needs to sign  M  using the TCert/ECert Alice has used to name him in the deployment transaction s metadata.\nLet s call this certificate CertBob. At this point Bob does the following:      Bob obtains a  CertificateHandler  for CertBob,  cHandlerBob ;  Bob obtains a new  TransactionHandler  to issue the execute transaction,  txHandler  relative to his next available TCert or his ECert;  Bob obtains  txHandler s  binding  by invoking  txHandler.getBinding() ;  Bob signs  M || txBinding  by invoking  cHandlerBob.Sign( M || txBinding ) , let  signature  be the output of the signing function;  Bob issues a new execute transaction by invoking,  txHandler.NewChaincodeExecute( ) . Now,  signature  can be included\n  in the transaction as one of the argument to be passed to the function or as transaction metadata.",
            "title": "Execute Transaction"
        },
        {
            "location": "/tech/application-ACL/#chaincode-execution",
            "text": "The validators, who receive the execute transaction issued by Bob, will provide to  hello  the following information:   The  binding  of the execute transaction;  The  metadata  of the execute transaction;  The  metadata  of the deploy transaction.   Then,  hello  is responsible for checking that  signature  is indeed a valid signature issued by Bob.",
            "title": "Chaincode Execution"
        },
        {
            "location": "/tech/attributes/",
            "text": "Attributes support\n\n\nTo support attributes the user has to pass them during TCert creation, these attributes can be used  during transaction deployment, execution or query for Attribute Based Access Control (ABAC) to determine whether the user can or cannot execute a specific chaincode  or used attributes\n values for other purposes. A mechanism to validate the ownership of attributes is required in order to prove if the attributes passed by the user are correct. The Attribute Certificate Authority (ACA) has the responsibility of validate attributes and to return an Attribute Certificate (ACert) with the valid attribute values.\nAttributes values are encrypted using the keys defined below (section Attributes keys).\n\n\nAttribute Keys\n\n\nThe attributes are encrypted using a key derived from a hierarchy called PreKey tree. This approach consists in deriving keys from a parent key, allowing the parent key owner, get access to derived keys. This way keys used to encrypt attributes are different among attributes and TCerts avoiding linkability while allowing an authorized auditor who owns a parent key to derive the keys in the lower levels.\n\n\nExample of prekey tree\n\n\nPre3K_BI\n        |_Pre2K_B = HMAC(Pre3K_BI, \u201cbanks\u201d)\n        |   |_Pre1K_BankA = HMAC(Pre2K_B, \u201cBank A\u201d)\n        |   |   |_Pre0K_BankA = HMAC(Pre1K_BankA, TCertID)\n        |   |       |_PositionKey_BankA_TIdx = HMAC(Pre0K_BankA, \"position\")\n        |   |       |_CompanyKey_BankA_TIdx = HMAC(Pre0K_BankA, \"company\")\n        |   |\n        |   |_Pre1K_BankB = HMAC(Pre2K_B, \u201cBanKB\u201d)\n        |       |_Pre0K_BankB = HMAC(Pre1K_BankB, TCertID)\n        |            |_PositionKey_BankB_TIdx = HMAC(Pre0K_BankB, \"position\")\n        |            |_CompanyKey_BankB_TIdx = HMAC(Pre0K_BankB, \"company\")\n        |\n        |_Pre2K_I = HMAC(Pre3K_BI, \"institutions\")\n            |_Pre1K_InstitutionA= HMAC(Pre2K_I, \"Institution A\u201d)\n               |_Pre0K_InstitutionA = HMAC(_Pre1K_InstitutionA, TCertID)\n                    |_PositionKey_InstA_TIdx = HMAC(Pre0K_InstitutionA, \"position\")\n                    |_CompanyKey_InstA_TIdx = HMAC(Pre0K_InstitutionA, \"company\")\n\n\n\n\n\nPre3K_BI: is available to TCA and auditors for banks and institutions.\n\n\nPre2K_B: is available to auditors for banks\n\n\nPre1K_BankA: is available to auditors for Bank A.\n\n\nPre1K_BankB: is available to auditors for Bank B.\n\n\nPre2K_I: is available to auditors for institutions.\n\n\nPre1K_InstitutionA: is available to auditors for Institution A.\n\n\n\n\nEach TCert has a different PreK0 (for example Pre0K_BankA) and each TCert attribute has a different attribute key (for example PositionKey_BankA_TIdx).\n\n\nAttribute Certificate Authority\n\n\nAttribute Certificate Authority (ACA) has the responsibility of certify the ownership of the attributes. ACA has a database to hold attributes for each user and affiliation.\n\n\n\n\nid: The id passed by the user during enrollment\n\n\naffiliation: The entity which the user is affiliated to\n\n\nattributeName: The name used to look for the attribute, e.g. \nposition\n\n\nattributeValue: The value of the attribute, e.g. \nsoftware engineer\n\n\nvalidFrom: The start of the attribute\ns validity period\n\n\nvalidTo: The end of the attribute\ns validity period\n\n\n\n\ngRPC ACA API\n\n\n\n\nFetchAttributes\n\n\n\n\n    rpc FetchAttributes(ACAFetchAttrReq) returns (ACAFetchAttrResp);\n\n    message ACAFetchAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Cert eCert = 2;                  // ECert of involved user.\n        Signature signature = 3;         // Signed using the ECA private key.\n    }\n\n    message ACAFetchAttrResp {\n        enum StatusCode {\n            SUCCESS = 000;\n            FAILURE = 100;\n        }\n        StatusCode status = 1;\n    }\n\n\n\n\n\n\nRequestAttributes\n\n\n\n\n    rpc RequestAttributes(ACAAttrReq) returns (ACAAttrResp);\n\n    message ACAAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Identity id = 2;\n        Cert eCert = 3;                                // ECert of involved user.\n        repeated TCertAttributeHash attributes = 4;    // Pairs attribute-key, attribute-value-hash\n        Signature signature = 5;                       // Signed using the TCA private key.\n    }\n\n    message ACAAttrResp {\n        enum StatusCode {\n            FULL_SUCCESSFUL     = 000;\n            PARTIAL_SUCCESSFUL  = 001;\n            NO_ATTRIBUTES_FOUND = 010;\n            FAILURE             = 100;\n        }\n        StatusCode status = 1;\n        Cert cert = 2;                  // ACert with the owned attributes.\n        Signature signature = 3;        // Signed using the ACA private key.\n    }\n\n\n\n\n\n\nRefreshAttributes\n\n\n\n\n    rpc RefreshAttributes(ACARefreshReq) returns (ACARefreshResp);\n\n    message ACARefreshAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Cert eCert = 2;                              // ECert of the involved user.\n        Signature signature = 3;                     // Signed using enrollPrivKey\n    }\n\n    message ACARefreshAttrResp {\n        enum StatusCode {\n            SUCCESS = 000;\n            FAILURE = 100;\n        }\n        StatusCode status = 1;\n    }\n\n\n\n\nFLOW\n\n\n\n\nDuring enrollment\n\n\n\n\nThe user requests an Enrollment Certificate (ECert) to ECA\n\n\nECA creates the ECert and responds to the user with it.\n\n\nECA issues a fetch request under TLS to the ACA passing the newly generated ECert as a parameter. This request is signed with the ECA\ns private key.\n\n\nThe request triggers ACA asynchronous mechanism that fetches attributes\n values from external sources and populates the attributes database (in the current implementation attributes are loaded from an internal configuration file).\n\n\n\n\nDuring TCert generation\n\n\n\n\nWhen the user needs TCerts to create a new transaction it requests a batch of TCerts to the TCA, and provides the following:\n\n\nThe batch size (i.e. how many TCerts the user is expecting)\n\n\nIts ECert\n\n\nA list of attributes (e.g. Company, Position)\n\n\nUnder TLS TCA sends a RequestAttributes() to ACA to verify if the user is in possession of those attributes. This request is signed with TCA\ns private key and it contains:\n\n\nUser\ns ECert\n\n\nA list of attribute names \ncompany, position, \n\n\nThe ACA performs a query to the internal attributes database and there are three possible scenarios***:\n     a. The user does not have any of the specified attributes \u2013 An error is returned.\n     b. The user has all the specified attributes \u2013 An X.509 certificate (ACert) with all the specified attributes and the ECert public key is returned.\n     c. The user has a subset of the requested attributes \u2013 An X.509 certificate (ACert) with just the subset of the specified attributes and the ECert public key is returned.\n\n\nThe TCA checks the validity period of the ACert\ns attributes and updates the list by eliminating those that are expired. Then for scenarios b and c from the previous item it checks how many (and which ones) of the attributes the user will actually receive inside each TCert. This information needs to be returned to the user in order to decide whether the TCerts are useful or if further actions needs to be performed (i.e. issue a RefreshAttributes command and request a new batch, throw an error or make use of the TCerts as they are).\n\n\nThe TCA could have other criteria to update the valid list of attributes.\n\n\nThe TCA creates the batch of TCerts. Each TCert contains the valid attributes encrypted with keys derived from the Prekey tree (each key is unique per attribute, per TCert and per user).\n\n\nThe TCA returns the batch of TCerts to the user along with a root key (Prek0) from which each attribute encryption key was derived. There is a Prek0 per TCert. All the TCerts in the batch have the same attributes and the validity period of the TCerts is the same for the entire batch.\n\n\n\n\n*** \nIn the current implementation an attributes refresh is executed automatically before this step, but once the refresh service is implemented the user will have the responsibility of keeping his/her attributes updated by invoking this method.\n\n\nAssumptions\n\n\n\n\nAn Attribute Certificate Authority (ACA) has been incorporated to the Membership Services internally to provide a trusted source for attribute values.\n\n\nIn the current implementation attributes are loaded from a configuration file (membersrvc.yml).\n\n\nRefresh attributes service is not implemented yet, instead, attributes are refreshed in each RequestAttribute invocation.",
            "title": "Attributes"
        },
        {
            "location": "/tech/attributes/#attributes-support",
            "text": "To support attributes the user has to pass them during TCert creation, these attributes can be used  during transaction deployment, execution or query for Attribute Based Access Control (ABAC) to determine whether the user can or cannot execute a specific chaincode  or used attributes  values for other purposes. A mechanism to validate the ownership of attributes is required in order to prove if the attributes passed by the user are correct. The Attribute Certificate Authority (ACA) has the responsibility of validate attributes and to return an Attribute Certificate (ACert) with the valid attribute values.\nAttributes values are encrypted using the keys defined below (section Attributes keys).",
            "title": "Attributes support"
        },
        {
            "location": "/tech/attributes/#attribute-keys",
            "text": "The attributes are encrypted using a key derived from a hierarchy called PreKey tree. This approach consists in deriving keys from a parent key, allowing the parent key owner, get access to derived keys. This way keys used to encrypt attributes are different among attributes and TCerts avoiding linkability while allowing an authorized auditor who owns a parent key to derive the keys in the lower levels.",
            "title": "Attribute Keys"
        },
        {
            "location": "/tech/attributes/#example-of-prekey-tree",
            "text": "Pre3K_BI\n        |_Pre2K_B = HMAC(Pre3K_BI, \u201cbanks\u201d)\n        |   |_Pre1K_BankA = HMAC(Pre2K_B, \u201cBank A\u201d)\n        |   |   |_Pre0K_BankA = HMAC(Pre1K_BankA, TCertID)\n        |   |       |_PositionKey_BankA_TIdx = HMAC(Pre0K_BankA, \"position\")\n        |   |       |_CompanyKey_BankA_TIdx = HMAC(Pre0K_BankA, \"company\")\n        |   |\n        |   |_Pre1K_BankB = HMAC(Pre2K_B, \u201cBanKB\u201d)\n        |       |_Pre0K_BankB = HMAC(Pre1K_BankB, TCertID)\n        |            |_PositionKey_BankB_TIdx = HMAC(Pre0K_BankB, \"position\")\n        |            |_CompanyKey_BankB_TIdx = HMAC(Pre0K_BankB, \"company\")\n        |\n        |_Pre2K_I = HMAC(Pre3K_BI, \"institutions\")\n            |_Pre1K_InstitutionA= HMAC(Pre2K_I, \"Institution A\u201d)\n               |_Pre0K_InstitutionA = HMAC(_Pre1K_InstitutionA, TCertID)\n                    |_PositionKey_InstA_TIdx = HMAC(Pre0K_InstitutionA, \"position\")\n                    |_CompanyKey_InstA_TIdx = HMAC(Pre0K_InstitutionA, \"company\")   Pre3K_BI: is available to TCA and auditors for banks and institutions.  Pre2K_B: is available to auditors for banks  Pre1K_BankA: is available to auditors for Bank A.  Pre1K_BankB: is available to auditors for Bank B.  Pre2K_I: is available to auditors for institutions.  Pre1K_InstitutionA: is available to auditors for Institution A.   Each TCert has a different PreK0 (for example Pre0K_BankA) and each TCert attribute has a different attribute key (for example PositionKey_BankA_TIdx).",
            "title": "Example of prekey tree"
        },
        {
            "location": "/tech/attributes/#attribute-certificate-authority",
            "text": "Attribute Certificate Authority (ACA) has the responsibility of certify the ownership of the attributes. ACA has a database to hold attributes for each user and affiliation.   id: The id passed by the user during enrollment  affiliation: The entity which the user is affiliated to  attributeName: The name used to look for the attribute, e.g.  position  attributeValue: The value of the attribute, e.g.  software engineer  validFrom: The start of the attribute s validity period  validTo: The end of the attribute s validity period",
            "title": "Attribute Certificate Authority"
        },
        {
            "location": "/tech/attributes/#grpc-aca-api",
            "text": "FetchAttributes       rpc FetchAttributes(ACAFetchAttrReq) returns (ACAFetchAttrResp);\n\n    message ACAFetchAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Cert eCert = 2;                  // ECert of involved user.\n        Signature signature = 3;         // Signed using the ECA private key.\n    }\n\n    message ACAFetchAttrResp {\n        enum StatusCode {\n            SUCCESS = 000;\n            FAILURE = 100;\n        }\n        StatusCode status = 1;\n    }   RequestAttributes       rpc RequestAttributes(ACAAttrReq) returns (ACAAttrResp);\n\n    message ACAAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Identity id = 2;\n        Cert eCert = 3;                                // ECert of involved user.\n        repeated TCertAttributeHash attributes = 4;    // Pairs attribute-key, attribute-value-hash\n        Signature signature = 5;                       // Signed using the TCA private key.\n    }\n\n    message ACAAttrResp {\n        enum StatusCode {\n            FULL_SUCCESSFUL     = 000;\n            PARTIAL_SUCCESSFUL  = 001;\n            NO_ATTRIBUTES_FOUND = 010;\n            FAILURE             = 100;\n        }\n        StatusCode status = 1;\n        Cert cert = 2;                  // ACert with the owned attributes.\n        Signature signature = 3;        // Signed using the ACA private key.\n    }   RefreshAttributes       rpc RefreshAttributes(ACARefreshReq) returns (ACARefreshResp);\n\n    message ACARefreshAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Cert eCert = 2;                              // ECert of the involved user.\n        Signature signature = 3;                     // Signed using enrollPrivKey\n    }\n\n    message ACARefreshAttrResp {\n        enum StatusCode {\n            SUCCESS = 000;\n            FAILURE = 100;\n        }\n        StatusCode status = 1;\n    }",
            "title": "gRPC ACA API"
        },
        {
            "location": "/tech/attributes/#flow",
            "text": "",
            "title": "FLOW"
        },
        {
            "location": "/tech/attributes/#during-enrollment",
            "text": "The user requests an Enrollment Certificate (ECert) to ECA  ECA creates the ECert and responds to the user with it.  ECA issues a fetch request under TLS to the ACA passing the newly generated ECert as a parameter. This request is signed with the ECA s private key.  The request triggers ACA asynchronous mechanism that fetches attributes  values from external sources and populates the attributes database (in the current implementation attributes are loaded from an internal configuration file).",
            "title": "During enrollment"
        },
        {
            "location": "/tech/attributes/#during-tcert-generation",
            "text": "When the user needs TCerts to create a new transaction it requests a batch of TCerts to the TCA, and provides the following:  The batch size (i.e. how many TCerts the user is expecting)  Its ECert  A list of attributes (e.g. Company, Position)  Under TLS TCA sends a RequestAttributes() to ACA to verify if the user is in possession of those attributes. This request is signed with TCA s private key and it contains:  User s ECert  A list of attribute names  company, position,   The ACA performs a query to the internal attributes database and there are three possible scenarios***:\n     a. The user does not have any of the specified attributes \u2013 An error is returned.\n     b. The user has all the specified attributes \u2013 An X.509 certificate (ACert) with all the specified attributes and the ECert public key is returned.\n     c. The user has a subset of the requested attributes \u2013 An X.509 certificate (ACert) with just the subset of the specified attributes and the ECert public key is returned.  The TCA checks the validity period of the ACert s attributes and updates the list by eliminating those that are expired. Then for scenarios b and c from the previous item it checks how many (and which ones) of the attributes the user will actually receive inside each TCert. This information needs to be returned to the user in order to decide whether the TCerts are useful or if further actions needs to be performed (i.e. issue a RefreshAttributes command and request a new batch, throw an error or make use of the TCerts as they are).  The TCA could have other criteria to update the valid list of attributes.  The TCA creates the batch of TCerts. Each TCert contains the valid attributes encrypted with keys derived from the Prekey tree (each key is unique per attribute, per TCert and per user).  The TCA returns the batch of TCerts to the user along with a root key (Prek0) from which each attribute encryption key was derived. There is a Prek0 per TCert. All the TCerts in the batch have the same attributes and the validity period of the TCerts is the same for the entire batch.   ***  In the current implementation an attributes refresh is executed automatically before this step, but once the refresh service is implemented the user will have the responsibility of keeping his/her attributes updated by invoking this method.",
            "title": "During TCert generation"
        },
        {
            "location": "/tech/attributes/#assumptions",
            "text": "An Attribute Certificate Authority (ACA) has been incorporated to the Membership Services internally to provide a trusted source for attribute values.  In the current implementation attributes are loaded from a configuration file (membersrvc.yml).  Refresh attributes service is not implemented yet, instead, attributes are refreshed in each RequestAttribute invocation.",
            "title": "Assumptions"
        },
        {
            "location": "/tech/best-practices/",
            "text": "Hyperledger Fabric Development Best Practices\n\n\n(This page is under construction.)",
            "title": "Best Practices"
        },
        {
            "location": "/tech/best-practices/#hyperledger-fabric-development-best-practices",
            "text": "(This page is under construction.)",
            "title": "Hyperledger Fabric Development Best Practices"
        }
    ]
}