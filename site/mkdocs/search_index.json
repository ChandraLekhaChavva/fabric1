{
    "docs": [
        {
            "location": "/", 
            "text": "site_nam", 
            "title": "HOME"
        }, 
        {
            "location": "/#site_nam", 
            "text": "", 
            "title": "site_nam"
        }, 
        {
            "location": "/CONTRIBUTING/", 
            "text": "../CONTRIBUTING.md", 
            "title": "CONTRIBUTING"
        }, 
        {
            "location": "/README/", 
            "text": "Getting started\n\n\nWelcome to the Linux Foundation Hyperledger Project documentation README. This page contains: \n- Getting started doc links \n- Quickstart doc links\n- Table of Contents links to the complete library\n\n\nIf you are new to the project, you can begin by reviewing the following documents:\n- \nWhitepaper WG\n\n- \nRequirements WG\n\n- \nGlossary\n: to understand the terminology that we use throughout the website and project.\n\n\nWhen you are ready to start building applications or to otherwise contribute to the project, we strongly recommend that you read our \nprotocol specification\n for the technical details. Procedurally, we use the agile methodology with a weekly sprint, organized by \nissues\n, so take a look to familiarize yourself with the current work.\n\n\nQuickstart documentation\n\n\nIn addition to the \nGetting started\n documentation, the following quickstart topics are available:\n- \nFabric FAQs\n\n- \nCanonical use cases\n\n- \nDevelopment environment set-up\n\n- \nChaincode development environment\n\n- \nAPIs\n\n- \nNetwork setup\n\n\nTable of Contents\n\n\nThis table of contents provides links to the complete documentation library: \n\nOverview docs; Reference docs; API and chaincode developer docs; Network operations docs; Security administration docs; Use cases and demos\n\n\nOverview docs:\n\n\n\n\nHyperledger project\n\n\nWhitepaper\n\n\nFabric README\n\n\nGlossary\n \n\n\nFigures \n Diagrams\n \n\n\nProtocol specification\n:\n\n\nIntroduction (fabric, terminology)\n\n\nFabric: \n\n\nArchitecture (Membership Services, Blockchain Services, Chaincode Services, Events, API, CLI)\n\n\nTopology (SVP, MVP, Multichain)\n\n\nProtocol (Messages, Ledger, Chaincode, Consensus, Events)\n\n\nSecurity (Business Security, User Security, Transaction Security, App. ACL, Wallet, Network Security (TLS))\n\n\nPBFT (Core PBFT, PI, Sieve)\n\n\nAPI (REST service, REST API, CLI)\n\n\nApplication Model (Composition, Sample)\n\n\nFuture (Systems Integration, Performance \n Scalability, Consensus Plugins, Additional Languages)\n\n\n\n\n\n\n\n\n\n\n\n\nReference docs:\n\n\n\n\nContributing\n\n\nCommunicating\n\n\nProject Lifecycle\n\n\nLicense\n\n\nMaintainers\n\n\n\n\nAPI and chaincode developer docs:\n\n\n\n\nSetting up the development environment\n: \n\n\nOverview (Vagrant/Docker) \n\n\nPrerequisites (Git, Go, Vagrant, VirtualBox, BIOS)\n\n\nSteps (GOPATH, Windows, Clone Peer, VM Vagrant\n\n\n\n\n\n\nBuilding the fabric core\n\n\nBuilding outside of Vagrant\n\n\nCode contributions\n\n\nCoding Golang\n\n\nHeaders\n\n\nWriting Chaincode\n\n\nWriting, Building, and Running Chaincode in a Development Environment\n\n\nChaincode FAQ\n\n\nSetting Up a Network\n\n\nSetting Up a Network For Development\n:\n\n\nDocker\n\n\nValidating Peers\n\n\nRun chaincode\n\n\nConsensus Plugin\n\n\n\n\n\n\nWorking with CLI, REST, and Node.js\n\n\nAPIs - CLI, REST, and Node.js\n: \n\n\nCLI\n\n\nREST\n\n\nNode.js Application\n\n\n\n\n\n\nConfiguration\n\n\nLogging\n\n\nLogging control\n: \n\n\nOverview \n\n\nPeer\n\n\nGo \n\n\n\n\n\n\nGenerating grpc code\n\n\nAdding or updating Go packages\n\n\nSDK\n\n\n\n\nNetwork operations docs:\n\n\n\n\nSetting Up a Network\n\n\nConsensus Algorithms\n\n\n\n\nSecurity administration docs:\n\n\n\n\nCertificate Authority (CA) Setup\n:\n\n\nEnrollment CA\n\n\nTransaction CA\n\n\nTLS CA\n\n\nConfiguration\n\n\nBuild and Run \n \n\n\n\n\n\n\nApplication ACL\n:\n\n\nFabric Support\n\n\nCertificate Handler\n\n\nTransaction Handler\n\n\nClient\n\n\nTransaction Format\n\n\nValidators\n\n\nDeploy Transaction\n\n\nExecute Transaction\n\n\nChaincode Execution", 
            "title": "Getting started"
        }, 
        {
            "location": "/README/#getting-started", 
            "text": "Welcome to the Linux Foundation Hyperledger Project documentation README. This page contains: \n- Getting started doc links \n- Quickstart doc links\n- Table of Contents links to the complete library  If you are new to the project, you can begin by reviewing the following documents:\n-  Whitepaper WG \n-  Requirements WG \n-  Glossary : to understand the terminology that we use throughout the website and project.  When you are ready to start building applications or to otherwise contribute to the project, we strongly recommend that you read our  protocol specification  for the technical details. Procedurally, we use the agile methodology with a weekly sprint, organized by  issues , so take a look to familiarize yourself with the current work.", 
            "title": "Getting started"
        }, 
        {
            "location": "/README/#quickstart-documentation", 
            "text": "In addition to the  Getting started  documentation, the following quickstart topics are available:\n-  Fabric FAQs \n-  Canonical use cases \n-  Development environment set-up \n-  Chaincode development environment \n-  APIs \n-  Network setup", 
            "title": "Quickstart documentation"
        }, 
        {
            "location": "/README/#table-of-contents", 
            "text": "This table of contents provides links to the complete documentation library:  \nOverview docs; Reference docs; API and chaincode developer docs; Network operations docs; Security administration docs; Use cases and demos", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/README/#overview-docs", 
            "text": "Hyperledger project  Whitepaper  Fabric README  Glossary    Figures   Diagrams    Protocol specification :  Introduction (fabric, terminology)  Fabric:   Architecture (Membership Services, Blockchain Services, Chaincode Services, Events, API, CLI)  Topology (SVP, MVP, Multichain)  Protocol (Messages, Ledger, Chaincode, Consensus, Events)  Security (Business Security, User Security, Transaction Security, App. ACL, Wallet, Network Security (TLS))  PBFT (Core PBFT, PI, Sieve)  API (REST service, REST API, CLI)  Application Model (Composition, Sample)  Future (Systems Integration, Performance   Scalability, Consensus Plugins, Additional Languages)", 
            "title": "Overview docs:"
        }, 
        {
            "location": "/README/#reference-docs", 
            "text": "Contributing  Communicating  Project Lifecycle  License  Maintainers", 
            "title": "Reference docs:"
        }, 
        {
            "location": "/README/#api-and-chaincode-developer-docs", 
            "text": "Setting up the development environment :   Overview (Vagrant/Docker)   Prerequisites (Git, Go, Vagrant, VirtualBox, BIOS)  Steps (GOPATH, Windows, Clone Peer, VM Vagrant    Building the fabric core  Building outside of Vagrant  Code contributions  Coding Golang  Headers  Writing Chaincode  Writing, Building, and Running Chaincode in a Development Environment  Chaincode FAQ  Setting Up a Network  Setting Up a Network For Development :  Docker  Validating Peers  Run chaincode  Consensus Plugin    Working with CLI, REST, and Node.js  APIs - CLI, REST, and Node.js :   CLI  REST  Node.js Application    Configuration  Logging  Logging control :   Overview   Peer  Go     Generating grpc code  Adding or updating Go packages  SDK", 
            "title": "API and chaincode developer docs:"
        }, 
        {
            "location": "/README/#network-operations-docs", 
            "text": "Setting Up a Network  Consensus Algorithms", 
            "title": "Network operations docs:"
        }, 
        {
            "location": "/README/#security-administration-docs", 
            "text": "Certificate Authority (CA) Setup :  Enrollment CA  Transaction CA  TLS CA  Configuration  Build and Run       Application ACL :  Fabric Support  Certificate Handler  Transaction Handler  Client  Transaction Format  Validators  Deploy Transaction  Execute Transaction  Chaincode Execution", 
            "title": "Security administration docs:"
        }, 
        {
            "location": "/TravisCI_Readme/", 
            "text": "Continuous Integration Process:\n\n\nContinuous Integration is a development practice that requires developers to integrate code into a shared repository. Each time developer checks in code into the repository, it is then verified by an automated build process. This process gives flexibility for the developer to detect any build issues early in the build life cycle.\n\n\nhyperledger\n build process is fully automated using \nTravis CI\n Continuous Integration tool, which helps in building a real time solution for all the code check-ins, perform Unit and Functional Tests. Once the build execution completes, developer will get build result notifications on slack, GitHub and email (Depending on configuration settings provided in .travis.yml file)\n\n\nMaster Repository\n can be found at [\nhyperledger\n] (https://github.com/hyperledger/fabric.git).\n\n\nSetting up Continuous Integration Process:\n\n\n\n\nLogin to [GitHub] (https://github.com) --\n Fork and clone the  \nhyperledger\n project into your \nGitHub\n account, if you weren't already. If you have a forked repository in your GitHub account, please pull \nhyperledger/fabric master repository\n. So that, updated .travis.yml (\nConfiguration file for Travis CI\n) file will be copied into your repository.\n\n\n\n\nPerform \nTravis CI\n integration in \nGitHub\n:\n\n\n\n\n\n\nClick on \nSettings\n tab in forked \nfabric\n GitHub repository and click on \nWebhooks \n Services\n option. Click on \nAdd Service\n and click on \nTravis CI\n link in services panel. Provide below details\n\n\n\n\n\n\nUser (GitHub User Name)\n\n\n\n\nToken (Generate token from profile - settings - Personal access token - click on Generate New Token) - Check on \"public_repo\" scope and click on generate token button. Copy and paste it in Token field\n\n\n\n\nDomain (Enter \"notify.travis-ci.org\")\n\n\n\n\n\n\nClick on Add Service button\n\n\n\n\n\n\nThis will enable integration between Travis CI and GitHub for the selected repository. After successful integration, \nTravis CI\n service will appear in Services menu.\n\n\n\n\nSync and Enable fabric repository in Travis:\n\n\n\n\n\n\nBrowse \nTravis CI\n and click on \nSign in with GitHub\n button and provide GitHub credentials.\n\n\n\n\n\n\nhttp://travis-ci.org - for Public Repositories. http://travis-ci.com - for Private repositories.\n\n\n\n\n\n\nAfter login to Travis CI --\n Click on \nAccounts\n link under Username (Available at the top of right corner) and click on \nSync account\n button. This will sync and display all the repositories available for the logged in user. As a next step user has to flick ON for the required repositories. After successful flick, refresh the Travis home page and you see all the selected repositories available in \nMy Repositories\n section in Travis home page. \n\n\n\n\n\n\nIn more options menu, click on \nSettings\n and enable general settings (\nBuild only if .travis.yml is present\n ,  \nBuild Pushes\n ,  \nLimit Current jobs\n  , \nBuild pull requests\n) for the selected repository. \n\n\n\n\n\n\n \n\n\n\n\nDisable \nBuild Pull Requests\n option if you don't want to trigger automation build deployment for any \nPull Requests\n.\n\n\n\n\nAdd Build status markdown link in Readme.md file\n\n\n\n\nCopy markdown link from Travis CI home page and place it in Readme.md file of your working branch. Follow \nEmbedding Status Images\n that helps you to setup the build status in Readme.md file.\n\n\n\n\nNote: Please make sure \n.travis.yml\n , \nfoldercopy.sh\n and \ncontainerlogs.sh\n are present with below modifications in the master branch or the working branch in GitHub before performing any \ngit push\n operations.\n\n\n\n\nChange notifications section as per user preferences:\n\n\n\n\nFollow \nTravis Notification Settings\n to setup notifications in .travis.yml file.\n\n\nRepository Owner has to provide slack token. Please get in touch with him/her for your Slack Token.\n\n\nnotifications:\nslack:\nSlack account name\n:\nUser Slack Token\n ex: slack:openchain:\nuser slack token\n\n on_success: always\n on_failure: always\n email:\n    recipients:\n      - one@example.com\n      - other@example.com\n    on_success: [always|never|change] # default: change\n    on_failure: [always|never|change] # default: always\n  ```\n\nNow you have completed with Travis CI setup process. If you make any changes in your code and push code to remote repository, Travis CI automatically starts the build process and shows you the build results on your notification settings (Slack, email and on GitHub Readme.md).\n\n![Build Results](images/BuildStatus.png)\n\n**Build Process includes below steps:**\n\n1. git clone on updated git repository into Travis cloud environment from GitHub.\n2. Install all dependency software's and libraries\n3. Perform go build\n4. Start Peer process\n5. Perform unit tests (go tests)\n6. Perform Behave test suite (behave tests)\n7. Provides failed container log files in travis raw log file.\n8. Update slack channel (#fabric-ci-status) with build results.\n\n## More Information/Troubleshooting:\n\n- Developer can skip the Travis CI build process by providing ` [ci skip] ` in the git commit message.\n\n\n\n\ngit commit -m \"Ignore build process [ci skip]\"\n\n\n```\n- How to skip Travis Build execution for PR's:?\n\n\n\n\nTravis CI checks latest commit of PR and if the commit message is tagged with [ci skip], Travis CI ignores build process.\n\n\nThis will be useful, when you want to open a pull request early for review but you are not necessarily ready to run the tests right away. Also, you can skip Travis build process for document changes.\n\n\n\n\nRight now, Travis only supports above method to skip build process.\n\n\n\n\n\n\nWhat is the slack channel to view build results?\n\n\n\n\n\n\nWe are sending build notifications to hyperledger \n#fabric-ci-status\n slack channel. (User must join in #fabric-ci-status slack channel to receive build notifications)\n\n\n\n\n\n\nWhat is build status \nerrored\n mean?\n\n\n\n\n\n\nWhen \"go build\" and \"Unit tests\" fails, Travis stops the build process and exits and mark the build status as \nerrored\n. When unit tests fail, Travis CI will not execute behave test scripts. \nFailed\n: If Behave test cases fail, Travis continues executing remaining test cases and exits with build status as \nfailed\n.\n\n\n\n\n\n\nHow to restart build without committing any changes to remote GitHub?\n\n\n\n\n\n\nApply \ngit commit --allow-empty -m \"Empty commit\"\n and do a git push or click on \nRestart Job\n (only users with push access to repository can do this) button on Travis CI home page.\n\n\n\n\n\n\nWhere can I find Build log files?\n\n\n\n\n\n\nClick on \nRAW log\n link on Travis CI home page.\n\n\n\n\n\n\nWhere can I find Behave Container log files?\n\n\n\n\nClick on each container log file link displays bottom of the RAW log file.", 
            "title": "TravisCI Readme"
        }, 
        {
            "location": "/TravisCI_Readme/#continuous-integration-process", 
            "text": "Continuous Integration is a development practice that requires developers to integrate code into a shared repository. Each time developer checks in code into the repository, it is then verified by an automated build process. This process gives flexibility for the developer to detect any build issues early in the build life cycle.  hyperledger  build process is fully automated using  Travis CI  Continuous Integration tool, which helps in building a real time solution for all the code check-ins, perform Unit and Functional Tests. Once the build execution completes, developer will get build result notifications on slack, GitHub and email (Depending on configuration settings provided in .travis.yml file)  Master Repository  can be found at [ hyperledger ] (https://github.com/hyperledger/fabric.git).", 
            "title": "Continuous Integration Process:"
        }, 
        {
            "location": "/TravisCI_Readme/#setting-up-continuous-integration-process", 
            "text": "Login to [GitHub] (https://github.com) --  Fork and clone the   hyperledger  project into your  GitHub  account, if you weren't already. If you have a forked repository in your GitHub account, please pull  hyperledger/fabric master repository . So that, updated .travis.yml ( Configuration file for Travis CI ) file will be copied into your repository.", 
            "title": "Setting up Continuous Integration Process:"
        }, 
        {
            "location": "/TravisCI_Readme/#perform-travis-ci-integration-in-github", 
            "text": "Click on  Settings  tab in forked  fabric  GitHub repository and click on  Webhooks   Services  option. Click on  Add Service  and click on  Travis CI  link in services panel. Provide below details    User (GitHub User Name)   Token (Generate token from profile - settings - Personal access token - click on Generate New Token) - Check on \"public_repo\" scope and click on generate token button. Copy and paste it in Token field   Domain (Enter \"notify.travis-ci.org\")    Click on Add Service button    This will enable integration between Travis CI and GitHub for the selected repository. After successful integration,  Travis CI  service will appear in Services menu.", 
            "title": "Perform Travis CI integration in GitHub:"
        }, 
        {
            "location": "/TravisCI_Readme/#sync-and-enable-fabric-repository-in-travis", 
            "text": "Browse  Travis CI  and click on  Sign in with GitHub  button and provide GitHub credentials.    http://travis-ci.org - for Public Repositories. http://travis-ci.com - for Private repositories.    After login to Travis CI --  Click on  Accounts  link under Username (Available at the top of right corner) and click on  Sync account  button. This will sync and display all the repositories available for the logged in user. As a next step user has to flick ON for the required repositories. After successful flick, refresh the Travis home page and you see all the selected repositories available in  My Repositories  section in Travis home page.     In more options menu, click on  Settings  and enable general settings ( Build only if .travis.yml is present  ,   Build Pushes  ,   Limit Current jobs   ,  Build pull requests ) for the selected repository.         Disable  Build Pull Requests  option if you don't want to trigger automation build deployment for any  Pull Requests .   Add Build status markdown link in Readme.md file   Copy markdown link from Travis CI home page and place it in Readme.md file of your working branch. Follow  Embedding Status Images  that helps you to setup the build status in Readme.md file.   Note: Please make sure  .travis.yml  ,  foldercopy.sh  and  containerlogs.sh  are present with below modifications in the master branch or the working branch in GitHub before performing any  git push  operations.   Change notifications section as per user preferences:   Follow  Travis Notification Settings  to setup notifications in .travis.yml file.  Repository Owner has to provide slack token. Please get in touch with him/her for your Slack Token.  notifications:\nslack: Slack account name : User Slack Token  ex: slack:openchain: user slack token \n on_success: always\n on_failure: always\n email:\n    recipients:\n      - one@example.com\n      - other@example.com\n    on_success: [always|never|change] # default: change\n    on_failure: [always|never|change] # default: always\n  ```\n\nNow you have completed with Travis CI setup process. If you make any changes in your code and push code to remote repository, Travis CI automatically starts the build process and shows you the build results on your notification settings (Slack, email and on GitHub Readme.md).\n\n![Build Results](images/BuildStatus.png)\n\n**Build Process includes below steps:**\n\n1. git clone on updated git repository into Travis cloud environment from GitHub.\n2. Install all dependency software's and libraries\n3. Perform go build\n4. Start Peer process\n5. Perform unit tests (go tests)\n6. Perform Behave test suite (behave tests)\n7. Provides failed container log files in travis raw log file.\n8. Update slack channel (#fabric-ci-status) with build results.\n\n## More Information/Troubleshooting:\n\n- Developer can skip the Travis CI build process by providing ` [ci skip] ` in the git commit message.  git commit -m \"Ignore build process [ci skip]\"  ```\n- How to skip Travis Build execution for PR's:?   Travis CI checks latest commit of PR and if the commit message is tagged with [ci skip], Travis CI ignores build process.  This will be useful, when you want to open a pull request early for review but you are not necessarily ready to run the tests right away. Also, you can skip Travis build process for document changes.   Right now, Travis only supports above method to skip build process.    What is the slack channel to view build results?    We are sending build notifications to hyperledger  #fabric-ci-status  slack channel. (User must join in #fabric-ci-status slack channel to receive build notifications)    What is build status  errored  mean?    When \"go build\" and \"Unit tests\" fails, Travis stops the build process and exits and mark the build status as  errored . When unit tests fail, Travis CI will not execute behave test scripts.  Failed : If Behave test cases fail, Travis continues executing remaining test cases and exits with build status as  failed .    How to restart build without committing any changes to remote GitHub?    Apply  git commit --allow-empty -m \"Empty commit\"  and do a git push or click on  Restart Job  (only users with push access to repository can do this) button on Travis CI home page.    Where can I find Build log files?    Click on  RAW log  link on Travis CI home page.    Where can I find Behave Container log files?   Click on each container log file link displays bottom of the RAW log file.", 
            "title": "Sync and Enable fabric repository in Travis:"
        }, 
        {
            "location": "/glossary/", 
            "text": "Roles \n Personas\n\n\nRoles\n\n\n\n\n\n\n\n\n\n\n\n\nChain Member\n\n\n\nEntities that do not participate in the validation process of a blockchain network, but help to maintain the integrity of a network. Unlike Chain transactors, chain members maintain a local copy of the ledger.\n\n\n\n\n\n\n\nChain Transactor\n\n\n\nEntities that have permission to create transactions and query network data.\n\n\n\n\n\n\n\nChain Validator\n\n\n\nEntities that own a stake of a chain network. Each chain validator has a voice in deciding whether a transaction is valid, therefore chain validators can interrogate all transactions sent to their chain.\n\n\n\n\n\n\n\nChain Auditor\n\n\n\nEntities with the permission to interrogate transactions.\n\n\n\n\n\n\n\nParticipants\n\n\n\n\n\n\n\n\n\n\n\n\nSolution User\n\n\n\nEnd users are agnostic about the details of chain networks, they typically initiate transactions on a chain network through applications made available by solutions providers.\n\n\n\nRoles:\n None\n\n\n\n\n\n\n\nSolution Provider\n\n\n\nOrganizations that develop mobile and/or browser based applications for end (solution) users to access chain networks. Some application owners may also be network owners.\n\n\nRoles: Chain Transactor\n\n\n\n\n\n\n\nNetwork Proprietor\n\n\n\nProprietor(s) setup and define the purpose of a chain network. They are the stakeholders of a network.\n\n\nRoles: Chain Transactor, Chain Validator\n\n\n\n\n\n\n\nNetwork Owner\n\n\n\nOwners are stakeholders of a network that can validate transactions. After a network is first launched, its proprietor (who then becomes an owner) will invite business partners to co-own the network (by assigning them validating nodes). Any new owner added to a network must be approved by its existing owners.\n\n\nRoles: Chain Transactor, Chain Validator\n\n\n\n\n\n\n\nNetwork Member\n\n\n\nMembers are participants of a blockchain network that cannot validate transactions but has the right to add users to the network.\n\n\nRoles: Chain Transactor, Chain Member\n\n\n\n\n\n\n\nNetwork Users\n\n\n\nEnd users of a network are also solution users. Unlike network owners and members, users do not own nodes. They transact with the network through an entry point offered by a member or an owner node.\n\n\nRoles: Chain Transactor\n\n\n\n\n\n\n\nNetwork Auditors\n\n\n\nIndividuals or organizations with the permission to interrogate transactions.\n\n\nRoles: Chain Auditor\n\n\n\n\n\n\n\n\n\nBusiness Network\n\n\nTypes of Networks (Business View)\n\n\n\n\n\n\n\n\n\n\n\n\nIndustry Network\n\n\n\nA chain network that services solutions built for a particular industry.\n\n\n\n\n\n\n\nRegional Industry Network\n\n\n\nA chain network that services applications built for a particular industry and region.\n\n\n\n\n\n\n\nApplication Network\n\n\n\nA chain network that only services a single solution.\n\n\n\n\n\n\n\nTypes of Chains (Conceptual View)\n\n\n\n\n\n\n\n\n\n\n\n\nMain Chain\n\n\n\nA business network; each main chain operates one or multiple applications/solutions validated by the same group of organizations.\n\n\n\n\n\n\n\nConfidential Chain\n\n\n\nA special purpose chain created to run confidential business logic that is only accessible by contract stakeholders.\n\n\n\n\n\n\n\n\n\nNetwork Management\n\n\nMember management\n\n\n\n\n\n\n\n\n\n\n\n\nOwner Registration\n\n\n\nThe process of registering and inviting new owner(s) to a blockchain network. Approval from existing network owners is required when adding or deleting a participant with ownership right\n\n\n\n\n\n\n\nMember Registration\n\n\n\nThe process of registering and inviting new network members to a blockchain network.\n\n\n\n\n\n\n\n\nUser Registration\n\n\n\nThe process of registering new users to a blockchain network. Both members and owners can register users on their own behalf as long as they follow the policy of their network.\n\n\n\n\n\n\n\n\n\nTransactions\n\n\nTypes of Transactions\n\n\n\n\n\n\n\n\n\n\n\n\nDeployment Transaction\n\n\n\nTransactions that deploy a new chaincode to a chain.\n\n\n\n\n\n\n\nInvocation Transaction\n\n\n\nTransactions that invoke a function on a chaincode.\n\n\n\n\n\n\n\nConfidentiality of Transactions\n\n\n\n\n\n\n\n\n\n\n\n\nPublic Transaction\n\n\n\nA transaction with its payload in the open. Anyone with access to a chain network can interrogate the details of public transactions.\n\n\n\n\n\n\n\nConfidential Transaction\n\n\n\nA transaction with its payload cryptographically hidden such that no one besides the stakeholders of a transaction can interrogate its content.\n\n\n\n\n\n\n\nConfidential Chaincode Transaction\n\n\n\nA transaction with its payload encrypted such that only validators can decrypt them. Chaincode confidentiality is determined during deploy time. If a chaincode is deployed as a confidential chaincode, then the payload of all subsequent invocation transactions to that chaincode will be encrypted.\n\n\n\n\n\n\n\nInter-chain Transactions\n\n\n\n\n\n\n\n\n\n\n\n\nInter-Network Transaction\n\n\n\nTransactions between two business networks (main chains).\n\n\n\n\n\n\n\nInter-Chain Transaction\n\n\n\nTransactions between confidential chains and main chains. Chaincodes in a confidential chain can trigger transactions on one or multiple main chain(s).\n\n\n\n\n\n\n\n\n\nNetwork Entities\n\n\nSystems\n\n\n\n\n\n\n\n\n\n\n\n\nApplication Backend\n\n\n\n  Purpose: Backend application service that supports associated mobile and/or browser based applications.\n  \n\n  Key Roles:\n\n  1)    Manages end users and registers them with the membership service\n  \n\n  2)    Initiates transactions requests, and sends the requests to a node\n  \n\n  Owned by: Solution Provider, Network Proprietor\n\n\n\n\n\n\n\nNon Validating Node (Peer)\n\n\n\n  Purpose: Constructs transactions and forwards them to validating nodes. Peer nodes keep a copy of all transaction records so that solution providers can query them locally. \n  \n\n  Key Roles:\n\n  1)    Manages and maintains user certificates issued by the membership service\n\n  2)    Constructs transactions and forwards them to validating nodes \n\n  3)    Maintains a local copy of the ledger, and allows application owners to query information locally.\n  \n\n    Owned by: Solution Provider, Network Auditor\n\n\n\n\n\n\n\nValidating Node (Peer)\n\n\n\n  Purpose: Creates and validates transactions, and maintains the state of chaincodes\n\n  Key Roles:\n\n  1)    Manages and maintains user certificates issued by membership service\n\n  2)    Creates transactions\n\n  3)    Executes and validates transactions with other validating nodes on the network\n\n  4)    Maintains a local copy of ledger\n\n  5)    Participates in consensus and updates ledger\n  \n\n  Owned by: Network Proprietor, Solution Provider (if they belong to the same entity)\n\n\n\n\n\n\n\nMembership Service\n\n\n\n  Purpose: Issues and manages the identity of end users and organizations\n\n  Key Roles:\n\n  1)    Issues enrollment certificate to each end user and organization\n\n  2)    Issues transaction certificates associated to each end user and organization\n\n  3)    Issues TLS certificates for secured communication between Hyperledger fabric entities\n\n  4)    Issues chain specific keys\n  \n\n  Owned by: Third party service provider\n\n\n\n\n\n\n\nMembership Service Components\n\n\n\n\n\n\n\n\n\n\n\n\nRegistration Authority\n\n\n\nAssigns registration username \n registration password pairs to network participants. This username/password pair will be used to acquire enrollment certificate from ECA.\n\n\n\n\n\n\n\nEnrollment Certificate Authority (ECA)\n\n\n\nIssues enrollment certificates (ECert) to network participants that have already registered with a membership service.  ECerts are long term certificates used to identify individual entities participating in one or more networks.\n\n\n\n\n\n\n\nTransaction Certificate Authority (TCA)\n\n\n\nIssues transaction certificates (TCerts) to ECert owners.  An infinite number of TCerts can be derived from each ECert. TCerts are used by network participants to send transactions. Depending on the level of security requirements, network participants may choose to use a new TCert for every transaction.\n\n\n\n\n\n\n\nTLS-Certificate Authority (TLS-CA)\n\n\n\nIssues TLS certificates to systems that transmit messages in a chain network. TLS certificates are used to secure the communication channel between systems.\n\n\n\n\n\n\n\n\n\nHyperledger Fabric Entities\n\n\nChaincode\n\n\n\n\n\n\n\n\n\n\n\n\nPublic Chaincode\n\n\n\nChaincodes deployed by public transactions, these chaincodes can be invoked by any member of the network.\n\n\n\n\n\n\n\nConfidential Chaincode\n\n\n\nChaincodes deployed by confidential transactions, these chaincodes can only be invoked by validating members (Chain validators) of the network.\n\n\n\n\n\n\n\nAccess Controlled Chaincode\n\n\n\nChaincodes deployed by confidential transactions that also embed the tokens of approved invokers. These invokers are also allowed to invoke confidential chaincodes even though they are not validators.\n\n\n\n\n\n\n\nLedger\n\n\n\n\n\n\n\n\n\n\n\n\nChaincode-State\n\n\n\nHPL provides state support; Chaincodes access internal state storage through state APIs. States are created and updated by transactions calling chaincode functions with state accessing logic.\n\n\n\n\n\n\n\nTransaction List\n\n\n\nAll processed transactions are kept in the ledger in their original form (with payload encrypted for confidential transactions), so that network participants can interrogate past transactions to which they have access permissions.\n\n\n\n\n\n\n\nLedger Hash\n\n\n\nA hash that captures the present snapshot of the ledger. It is a product of all validated transactions processed by the network since the genesis transaction.\n\n\n\n\n\n\n\nNode\n\n\n\n\n\n\n\n\n\n\n\n\nDevOps Service\n\n\n\nThe frontal module on a node that provides APIs for clients to interact with their node and chain network. This module is also responsible to construct transactions, and work with the membership service component to receive and store all types of certificates and encryption keys in its storage.\n\n\n\n\n\n\n\nNode Service\n\n\n\nThe main module on a node that is responsible to process transactions, deploy and execute chaincodes, maintain ledger data, and trigger the consensus process.\n\n\n\n\n\n\n\nConsensus\n\n\n\nThe default consensus algorithm of Hyperledger fabric is called Sieve. It is a new algorithm, enhancing the \u201cclassic\u201d PBFT mechanism in that it allows validating nodes to do a best effort in identifying non-deterministic transactions.", 
            "title": "Glossary"
        }, 
        {
            "location": "/glossary/#roles-personas", 
            "text": "", 
            "title": "Roles &amp; Personas"
        }, 
        {
            "location": "/glossary/#roles", 
            "text": "Chain Member  \nEntities that do not participate in the validation process of a blockchain network, but help to maintain the integrity of a network. Unlike Chain transactors, chain members maintain a local copy of the ledger.    Chain Transactor  \nEntities that have permission to create transactions and query network data.    Chain Validator  \nEntities that own a stake of a chain network. Each chain validator has a voice in deciding whether a transaction is valid, therefore chain validators can interrogate all transactions sent to their chain.    Chain Auditor  \nEntities with the permission to interrogate transactions.", 
            "title": "Roles"
        }, 
        {
            "location": "/glossary/#participants", 
            "text": "Solution User  \nEnd users are agnostic about the details of chain networks, they typically initiate transactions on a chain network through applications made available by solutions providers.  Roles:  None    Solution Provider  \nOrganizations that develop mobile and/or browser based applications for end (solution) users to access chain networks. Some application owners may also be network owners. \nRoles: Chain Transactor    Network Proprietor  \nProprietor(s) setup and define the purpose of a chain network. They are the stakeholders of a network. \nRoles: Chain Transactor, Chain Validator    Network Owner  \nOwners are stakeholders of a network that can validate transactions. After a network is first launched, its proprietor (who then becomes an owner) will invite business partners to co-own the network (by assigning them validating nodes). Any new owner added to a network must be approved by its existing owners. \nRoles: Chain Transactor, Chain Validator    Network Member  \nMembers are participants of a blockchain network that cannot validate transactions but has the right to add users to the network. \nRoles: Chain Transactor, Chain Member    Network Users  \nEnd users of a network are also solution users. Unlike network owners and members, users do not own nodes. They transact with the network through an entry point offered by a member or an owner node. \nRoles: Chain Transactor    Network Auditors  \nIndividuals or organizations with the permission to interrogate transactions. \nRoles: Chain Auditor", 
            "title": "Participants"
        }, 
        {
            "location": "/glossary/#business-network", 
            "text": "", 
            "title": "Business Network"
        }, 
        {
            "location": "/glossary/#types-of-networks-business-view", 
            "text": "Industry Network  \nA chain network that services solutions built for a particular industry.    Regional Industry Network  \nA chain network that services applications built for a particular industry and region.    Application Network  \nA chain network that only services a single solution.", 
            "title": "Types of Networks (Business View)"
        }, 
        {
            "location": "/glossary/#types-of-chains-conceptual-view", 
            "text": "Main Chain  \nA business network; each main chain operates one or multiple applications/solutions validated by the same group of organizations.    Confidential Chain  \nA special purpose chain created to run confidential business logic that is only accessible by contract stakeholders.", 
            "title": "Types of Chains (Conceptual View)"
        }, 
        {
            "location": "/glossary/#network-management", 
            "text": "", 
            "title": "Network Management"
        }, 
        {
            "location": "/glossary/#member-management", 
            "text": "Owner Registration  \nThe process of registering and inviting new owner(s) to a blockchain network. Approval from existing network owners is required when adding or deleting a participant with ownership right    Member Registration  \nThe process of registering and inviting new network members to a blockchain network.     User Registration  \nThe process of registering new users to a blockchain network. Both members and owners can register users on their own behalf as long as they follow the policy of their network.", 
            "title": "Member management"
        }, 
        {
            "location": "/glossary/#transactions", 
            "text": "", 
            "title": "Transactions"
        }, 
        {
            "location": "/glossary/#types-of-transactions", 
            "text": "Deployment Transaction  \nTransactions that deploy a new chaincode to a chain.    Invocation Transaction  \nTransactions that invoke a function on a chaincode.", 
            "title": "Types of Transactions"
        }, 
        {
            "location": "/glossary/#confidentiality-of-transactions", 
            "text": "Public Transaction  \nA transaction with its payload in the open. Anyone with access to a chain network can interrogate the details of public transactions.    Confidential Transaction  \nA transaction with its payload cryptographically hidden such that no one besides the stakeholders of a transaction can interrogate its content.    Confidential Chaincode Transaction  \nA transaction with its payload encrypted such that only validators can decrypt them. Chaincode confidentiality is determined during deploy time. If a chaincode is deployed as a confidential chaincode, then the payload of all subsequent invocation transactions to that chaincode will be encrypted.", 
            "title": "Confidentiality of Transactions"
        }, 
        {
            "location": "/glossary/#inter-chain-transactions", 
            "text": "Inter-Network Transaction  \nTransactions between two business networks (main chains).    Inter-Chain Transaction  \nTransactions between confidential chains and main chains. Chaincodes in a confidential chain can trigger transactions on one or multiple main chain(s).", 
            "title": "Inter-chain Transactions"
        }, 
        {
            "location": "/glossary/#network-entities", 
            "text": "", 
            "title": "Network Entities"
        }, 
        {
            "location": "/glossary/#systems", 
            "text": "Application Backend  \n  Purpose: Backend application service that supports associated mobile and/or browser based applications.\n   \n  Key Roles: \n  1)    Manages end users and registers them with the membership service\n   \n  2)    Initiates transactions requests, and sends the requests to a node\n   \n  Owned by: Solution Provider, Network Proprietor    Non Validating Node (Peer)  \n  Purpose: Constructs transactions and forwards them to validating nodes. Peer nodes keep a copy of all transaction records so that solution providers can query them locally. \n   \n  Key Roles: \n  1)    Manages and maintains user certificates issued by the membership service \n  2)    Constructs transactions and forwards them to validating nodes  \n  3)    Maintains a local copy of the ledger, and allows application owners to query information locally.\n   \n    Owned by: Solution Provider, Network Auditor    Validating Node (Peer)  \n  Purpose: Creates and validates transactions, and maintains the state of chaincodes \n  Key Roles: \n  1)    Manages and maintains user certificates issued by membership service \n  2)    Creates transactions \n  3)    Executes and validates transactions with other validating nodes on the network \n  4)    Maintains a local copy of ledger \n  5)    Participates in consensus and updates ledger\n   \n  Owned by: Network Proprietor, Solution Provider (if they belong to the same entity)    Membership Service  \n  Purpose: Issues and manages the identity of end users and organizations \n  Key Roles: \n  1)    Issues enrollment certificate to each end user and organization \n  2)    Issues transaction certificates associated to each end user and organization \n  3)    Issues TLS certificates for secured communication between Hyperledger fabric entities \n  4)    Issues chain specific keys\n   \n  Owned by: Third party service provider", 
            "title": "Systems"
        }, 
        {
            "location": "/glossary/#membership-service-components", 
            "text": "Registration Authority  \nAssigns registration username   registration password pairs to network participants. This username/password pair will be used to acquire enrollment certificate from ECA.    Enrollment Certificate Authority (ECA)  \nIssues enrollment certificates (ECert) to network participants that have already registered with a membership service.  ECerts are long term certificates used to identify individual entities participating in one or more networks.    Transaction Certificate Authority (TCA)  \nIssues transaction certificates (TCerts) to ECert owners.  An infinite number of TCerts can be derived from each ECert. TCerts are used by network participants to send transactions. Depending on the level of security requirements, network participants may choose to use a new TCert for every transaction.    TLS-Certificate Authority (TLS-CA)  \nIssues TLS certificates to systems that transmit messages in a chain network. TLS certificates are used to secure the communication channel between systems.", 
            "title": "Membership Service Components"
        }, 
        {
            "location": "/glossary/#hyperledger-fabric-entities", 
            "text": "", 
            "title": "Hyperledger Fabric Entities"
        }, 
        {
            "location": "/glossary/#chaincode", 
            "text": "Public Chaincode  \nChaincodes deployed by public transactions, these chaincodes can be invoked by any member of the network.    Confidential Chaincode  \nChaincodes deployed by confidential transactions, these chaincodes can only be invoked by validating members (Chain validators) of the network.    Access Controlled Chaincode  \nChaincodes deployed by confidential transactions that also embed the tokens of approved invokers. These invokers are also allowed to invoke confidential chaincodes even though they are not validators.", 
            "title": "Chaincode"
        }, 
        {
            "location": "/glossary/#ledger", 
            "text": "Chaincode-State  \nHPL provides state support; Chaincodes access internal state storage through state APIs. States are created and updated by transactions calling chaincode functions with state accessing logic.    Transaction List  \nAll processed transactions are kept in the ledger in their original form (with payload encrypted for confidential transactions), so that network participants can interrogate past transactions to which they have access permissions.    Ledger Hash  \nA hash that captures the present snapshot of the ledger. It is a product of all validated transactions processed by the network since the genesis transaction.", 
            "title": "Ledger"
        }, 
        {
            "location": "/glossary/#node", 
            "text": "DevOps Service  \nThe frontal module on a node that provides APIs for clients to interact with their node and chain network. This module is also responsible to construct transactions, and work with the membership service component to receive and store all types of certificates and encryption keys in its storage.    Node Service  \nThe main module on a node that is responsible to process transactions, deploy and execute chaincodes, maintain ledger data, and trigger the consensus process.    Consensus  \nThe default consensus algorithm of Hyperledger fabric is called Sieve. It is a new algorithm, enhancing the \u201cclassic\u201d PBFT mechanism in that it allows validating nodes to do a best effort in identifying non-deterministic transactions.", 
            "title": "Node"
        }, 
        {
            "location": "/protocol-spec/", 
            "text": "\ufeff# Protocol Specification\n\n\nPreface\n\n\nThis document is the protocol specification for a permissioned blockchain implementation for industry use-cases. It is not intended to be a complete explanation of the implementation, but rather a description of the interfaces and relationships between components in the system and the application.\n\n\nIntended Audience\n\n\nThe intended audience for this specification includes the following groups:\n\n\n\n\nBlockchain vendors who want to implement blockchain systems that conform to this specification\n\n\nTool developers who want to extend the capabilities of the fabric\n\n\nApplication developers who want to leverage blockchain technologies to enrich their applications\n\n\n\n\nAuthors\n\n\nThe following authors have written sections of this document:  Binh Q Nguyen, Elli Androulaki, Angelo De Caro, Sheehan Anderson, Manish Sethi, Thorsten Kramp, Alessandro Sorniotti, Marko Vukolic, Florian Simon Schubert, Jason K Yellick, Konstantinos Christidis, Srinivasan Muralidharan, Anna D Derbakova, Dulce Ponceleon, David Kravitz, Diego Masini.\n\n\nReviewers\n\n\nThe following reviewers have contributed to this document:  Frank Lu, John Wolpert, Bishop Brock, Nitin Gaur, Sharon Weed, Konrad Pabjan.\n\n\nAcknowledgements\n\n\nThe following contributors have provided invaluable technical input to this specification:\nGennaro Cuomo, Joseph A Latone, Christian Cachin\n\n\n\n\nTable of Contents\n\n\n1. Introduction\n\n\n\n\n1.1 What is the fabric?\n\n\n1.2 Why the fabric?\n\n\n1.3 Terminology\n\n\n\n\n2. Fabric\n\n\n\n\n2.1 Architecture\n\n\n2.1.1 Membership Services\n\n\n2.1.2 Blockchain Services\n\n\n2.1.3 Chaincode Services\n\n\n2.1.4 Events\n\n\n2.1.5 Application Programming Interface\n\n\n2.1.6 Command Line Interface\n\n\n2.2 Topology\n\n\n2.2.1 Single Validating Peer\n\n\n2.2.2 Multiple Validating Peers\n\n\n2.2.3 Multichain\n\n\n\n\n3. Protocol\n\n\n\n\n3.1 Message\n\n\n3.1.1 Discovery Messages\n\n\n3.1.2 Transaction Messages\n\n\n3.1.2.1 Transaction Data Structure\n\n\n3.1.2.2 Transaction Specification\n\n\n3.1.2.3 Deploy Transaction\n\n\n3.1.2.4 Invoke Transaction\n\n\n3.1.2.5 Query Transaction\n\n\n3.1.3 Synchronization Messages\n\n\n3.1.4 Consensus Messages\n\n\n3.2 Ledger\n\n\n3.2.1 Blockchain\n\n\n3.2.1.1 Block\n\n\n3.2.1.2 Block Hashing\n\n\n3.2.1.3 NonHashData\n\n\n3.2.1.4 Transaction\n\n\n3.2.2 World State\n\n\n3.2.2.1 Hashing the world state\n\n\n3.2.2.1.1 Bucket-tree\n\n\n3.3 Chaincode\n\n\n3.3.1 Virtual Machine Instantiation\n\n\n3.3.2 Chaincode Protocol\n\n\n3.3.2.1 Chaincode Deploy\n\n\n3.3.2.2 Chaincode Invoke\n\n\n3.3.2.3 Chaincode Query\n\n\n3.3.2.4 Chaincode State\n\n\n3.4 Pluggable Consensus Framework\n\n\n3.4.1 Consenter interface\n\n\n3.4.2 Consensus Programming Interface\n\n\n3.4.3 Inquirer interface\n\n\n3.4.4 Communicator interface\n\n\n3.4.5 SecurityUtils interface\n\n\n3.4.6 LedgerStack interface\n\n\n3.4.7 Executor interface\n\n\n3.4.7.1 Beginning a transaction batch\n\n\n3.4.7.2 Executing transactions\n\n\n3.4.7.3 Committing and rolling-back transactions\n\n\n3.4.8 Ledger interface\n\n\n3.4.8.1 ReadOnlyLedger interface\n\n\n3.4.8.2 UtilLedger interface\n\n\n3.4.8.3 WritableLedger interface\n\n\n3.4.9 RemoteLedgers interface\n\n\n3.4.10 Controller package\n\n\n3.4.11 Helper package\n\n\n3.5 Events\n\n\n3.4.1 Event Stream\n\n\n3.4.2 Event Structure\n\n\n3.4.3 Event Adapters\n\n\n\n\n4. Security\n\n\n\n\n\n\n\n\nSecurity\n\n\n\n\n\n\n4.1 Business security requirements\n\n\n4.2 User Privacy through Membership Services\n\n\n4.2.1 User/Client Enrollment Process\n\n\n4.2.2 Expiration and revocation of certificates\n\n\n4.2.3 Online wallet service\n\n\n4.3 Transaction security offerings at the infrastructure level\n\n\n4.3.1 Security lifecycle of transactions\n\n\n4.3.2 Transaction confidentiality\n\n\n4.3.2.1 Confidentiality against users\n\n\n4.3.2.2 Confidentiality against validators\n\n\n4.3.3 Invocation access control\n\n\n4.3.4 Replay attack resistance\n\n\n4.4 Access control features on the application\n\n\n4.4.1 Invocation access control\n\n\n4.4.2 Read access control\n\n\n4.5 Online wallet service\n\n\n4.6 Network security (TLS)\n\n\n4.7 Restrictions in the current release\n\n\n4.7.1 Simplified client\n\n\n4.7.1 Simplified transaction confidentiality\n\n\n\n\n5. Byzantine Consensus\n\n\n\n\n5.1 Overview\n\n\n5.2 Core PBFT\n\n\n5.3 Inner Consensus Programming Interface\n\n\n5.4 Sieve Consensus\n\n\n\n\n6. Application Programming Interface\n\n\n\n\n6.1 REST Service\n\n\n6.2 REST API\n\n\n6.3 CLI\n\n\n\n\n7. Application Model\n\n\n\n\n7.1 Composition of an Application\n\n\n7.2 Sample Application\n\n\n\n\n8. Future Directions\n\n\n\n\n8.1 Enterprise Integration\n\n\n8.2 Performance and Scalability\n\n\n8.3 Additional Consensus Plugins\n\n\n8.4 Additional Languages\n\n\n\n\n9. References\n\n\n\n\n1. Introduction\n\n\nThis document specifies the principles, architecture, and protocol of a blockchain implementation suitable for industrial use-cases.\n\n\n1.1 What is the fabric?\n\n\nThe fabric is a ledger of digital events, called transactions, shared among  different participants, each having a stake in the system. The ledger can only be updated by consensus of the participants, and, once recorded, information can never be altered. Each recorded event is cryptographically verifiable with proof of agreement from the participants.\n\n\nTransactions are secured, private, and confidential. Each participant registers with proof of identity to the network membership services to gain access to the system. Transactions are issued with derived certificates unlinkable to the individual participant, offering a complete anonymity on the network. Transaction content is encrypted with sophisticated key derivation functions to ensure only intended participants may see the content, protecting the confidentiality of the business transactions.\n\n\nThe ledger allows compliance with regulations as ledger entries are auditable in whole or in part. In collaboration with participants, auditors may obtain time-based certificates to allow viewing the ledger and linking transactions to provide an accurate assessment of the operations.\n\n\nThe fabric is an implementation of blockchain technology, where Bitcoin could be a simple application built on the fabric. It is a modular architecture allowing components to be plug-and-play by implementing this protocol specification. It features powerful container technology to host any main stream language for smart contracts development. Leveraging familiar and proven technologies is the motto of the fabric architecture.\n\n\n1.2 Why the fabric?\n\n\nEarly blockchain technology serves a set of purposes but is often not well-suited for the needs of specific industries. To meet the demands of modern markets, the fabric is based on an industry-focused design that addresses the multiple and varied requirements of specific industry use cases, extending the learning of the pioneers in this field while also addressing issues such as scalability. The fabric provides a new approach to enable permissioned networks, privacy, and confidentially on multiple blockchain networks.\n\n\n1.3 Terminology\n\n\nThe following terminology is defined within the limited scope of this specification to help readers understand clearly and precisely the concepts described here.\n\n\nTransaction\n is a request to the blockchain to execute a function on the ledger. The function is implemented by a \nchaincode\n.\n\n\nTransactor\n is an entity that issues transactions such as a client application.\n\n\nLedger\n is a sequence of cryptographically linked blocks, containing transactions and current \nworld state\n.\n\n\nWorld State\n is the collection of variables containing the results of executed transactions.\n\n\nChaincode\n is an application-level code (a.k.a. \nsmart contract\n) stored on the ledger as a part of a transaction. Chaincode runs transactions that may modify the world state.\n\n\nValidating Peer\n is a computer node on the network responsible for running consensus, validating transactions, and maintaining the ledger.\n\n\nNon-validating Peer\n is a computer node on the network which functions as a proxy connecting transactors to the neighboring validating peers. A non-validating peer doesn't execute transactions but does verify them. It also hosts the event stream server and the REST service.\n\n\nPermissioned Ledger\n is a blockchain network where each entity or node is required to be a member of the network. Anonymous nodes are not allowed to connect.\n\n\nPrivacy\n is required by the chain transactors to conceal their identities on the network. While members of the network may examine the transactions, the transactions can't be linked to the transactor without special privilege.\n\n\nConfidentiality\n is the ability to render the transaction content inaccessible to anyone other than the stakeholders of the transaction.\n\n\nAuditability\n of the blockchain is required, as business usage of blockchain needs to comply with regulations to make it easy for regulators to investigate transaction records.\n\n\n2. Fabric\n\n\nThe fabric is made up of the core components described in the subsections below.\n\n\n2.1 Architecture\n\n\nThe reference architecture is aligned in 3 categories: Membership, Blockchain, and Chaincode services. These categories are logical structures, not a physical depiction of partitioning of components into separate processes, address spaces or (virtual) machines.\n\n\n\n\n2.1.1 Membership Services\n\n\nMembership provides services for managing identity, privacy, confidentiality and auditability on the network. In a non-permissioned blockchain, participation does not require authorization and all nodes can equally submit transactions and/or attempt to accumulate them into acceptable blocks, i.e. there are no distinctions of roles. Membership services combine elements of Public Key Infrastructure (PKI) and decentralization/consensus to transform a non-permissioned blockchain into a permissioned blockchain. In the latter, entities register in order to acquire long-term identity credentials (enrollment certificates), and may be distinguished according to entity type. In the case of users, such credentials enable the Transaction Certificate Authority (TCA) to issue pseudonymous credentials. Such credentials, i.e., transaction certificates, are used to authorize submitted transactions. Transaction certificates persist on the blockchain, and enable authorized auditors to cluster otherwise unlinkable transactions.  \n\n\n2.1.2 Blockchain Services\n\n\nBlockchain services manage the distributed ledger through a peer-to-peer protocol, built on HTTP/2. The data structures are highly optimized to provide the most efficient hash algorithm for maintaining the world state replication. Different consensus (PBFT, Raft, PoW, PoS) may be plugged in and configured per deployment.\n\n\n2.1.3 Chaincode Services\n\n\nChaincode services provides a secured and lightweight way to sandbox the chaincode execution on the validating nodes. The environment is a \u201clocked down\u201d and secured container along with a set of signed base images containing secure OS and chaincode language, runtime and SDK layers for Go, Java, and Node.js. Other languages can be enabled if required.\n\n\n2.1.4 Events\n\n\nValidating peers and chaincodes can emit events on the network that applications may listen for and take actions on. There is a set of pre-defined events, and chaincodes can generate custom events. Events are consumed by 1 or more event adapters. Adapters may further deliver events using other vehicles such as Web hooks or Kafka.\n\n\n2.1.5 Application Programming Interface (API)\n\n\nThe primary interface to the fabric is a REST API and its variations over Swagger 2.0. The API allows applications to register users, query the blockchain, and to issue transactions. There is a set of APIs specifically for chaincode to interact with the stack to execute transactions and query transaction results.\n\n\n2.1.6 Command Line Interface (CLI)\n\n\nCLI includes a subset of the REST API to enable developers to quickly test chaincodes or query for status of transactions. CLI is implemented in Golang and operable on multiple OS platforms.\n\n\n2.2 Topology\n\n\nA deployment of the fabric can consist of a membership service, many validating peers, non-validating peers, and 1 or more applications. All of these components make up a chain. There can be multiple chains; each one having its own operating parameters and security requirements.\n\n\n2.2.1 Single Validating Peer\n\n\nFunctionally, a non-validating peer is a subset of a validating peer; that is, every capability on a non-validating peer may be enabled on a validating peer, so the simplest network may consist of a single validating peer node. This configuration is most appropriate for a development environment, where a single validating peer may be started up during the edit-compile-debug cycle.\n\n\n\n\nA single validating peer doesn't require consensus, and by default uses the \nnoops\n plugin, which executes transactions as they arrive. This gives the developer an immediate feedback during development.\n\n\n2.2.2 Multiple Validating Peers\n\n\nProduction or test networks should be made up of multiple validating and non-validating peers as necessary. Non-validating peers can take workload off the validating peers, such as handling API requests and processing events.\n\n\n\n\nThe validating peers form a mesh-network (every validating peer connects to every other validating peer) to disseminate information. A non-validating peer connects to a neighboring validating peer that it is allowed to connect to. Non-validating peers are optional since applications may communicate directly with validating peers.\n\n\n2.2.3 Multichain\n\n\nEach network of validating and non-validating peers makes up a chain. Many chains may be created to address different needs, similar to having multiple Web sites, each serving a different purpose.\n\n\n3. Protocol\n\n\nThe fabric's peer-to-peer communication is built on \ngRPC\n, which allows bi-directional stream-based messaging. It uses \nProtocol Buffers\n to serialize data structures for data transfer between peers. Protocol buffers are a language-neutral, platform-neutral and extensible mechanism for serializing structured data. Data structures, messages, and services are described using \nproto3 language\n notation.\n\n\n3.1 Message\n\n\nMessages passed between nodes are encapsulated by \nMessage\n proto structure, which consists of 4 types: Discovery, Transaction, Synchronization, and Consensus. Each type may define more subtypes embedded in the \npayload\n.\n\n\nmessage Message {\n   enum Type {\n        UNDEFINED = 0;\n\n        DISC_HELLO = 1;\n        DISC_DISCONNECT = 2;\n        DISC_GET_PEERS = 3;\n        DISC_PEERS = 4;\n        DISC_NEWMSG = 5;\n\n        CHAIN_STATUS = 6;\n        CHAIN_TRANSACTION = 7;\n        CHAIN_GET_TRANSACTIONS = 8;\n        CHAIN_QUERY = 9;\n\n        SYNC_GET_BLOCKS = 11;\n        SYNC_BLOCKS = 12;\n        SYNC_BLOCK_ADDED = 13;\n\n        SYNC_STATE_GET_SNAPSHOT = 14;\n        SYNC_STATE_SNAPSHOT = 15;\n        SYNC_STATE_GET_DELTAS = 16;\n        SYNC_STATE_DELTAS = 17;\n\n        RESPONSE = 20;\n        CONSENSUS = 21;\n    }\n    Type type = 1;\n    bytes payload = 2;\n    google.protobuf.Timestamp timestamp = 3;\n}\n\n\n\n\nThe \npayload\n is an opaque byte array containing other objects such as \nTransaction\n or \nResponse\n depending on the type of the message. For example, if the \ntype\n is \nCHAIN_TRANSACTION\n, the \npayload\n is a \nTransaction\n object.\n\n\n3.1.1 Discovery Messages\n\n\nUpon start up, a peer runs discovery protocol if \nCORE_PEER_DISCOVERY_ROOTNODE\n is specified. \nCORE_PEER_DISCOVERY_ROOTNODE\n is the IP address of another peer on the network (any peer) that serves as the starting point for discovering all the peers on the network. The protocol sequence begins with \nDISC_HELLO\n, whose \npayload\n is a \nHelloMessage\n object, containing its endpoint:\n\n\nmessage HelloMessage {\n  PeerEndpoint peerEndpoint = 1;\n  uint64 blockNumber = 2;\n}\nmessage PeerEndpoint {\n    PeerID ID = 1;\n    string address = 2;\n    enum Type {\n      UNDEFINED = 0;\n      VALIDATOR = 1;\n      NON_VALIDATOR = 2;\n    }\n    Type type = 3;\n    bytes pkiID = 4;\n}\n\nmessage PeerID {\n    string name = 1;\n}\n\n\n\n\nDefinition of fields:\n\n\n\n\nPeerID\n is any name given to the peer at start up or defined in the config file\n\n\nPeerEndpoint\n describes the endpoint and whether it's a validating or a non-validating peer\n\n\npkiID\n is the cryptographic ID of the peer\n\n\naddress\n is host or IP address and port of the peer in the format \nip:port\n\n\nblockNumber\n is the height of the blockchain the peer currently has\n\n\n\n\nIf the block height received upon \nDISC_HELLO\n is higher than the current block height of the peer, it immediately initiates the synchronization protocol to catch up with the network.\n\n\nAfter \nDISC_HELLO\n, peer sends \nDISC_GET_PEERS\n periodically to discover any additional peers joining the network. In response to \nDISC_GET_PEERS\n, a peer sends \nDISC_PEERS\n with \npayload\n containing an array of \nPeerEndpoint\n. Other discovery message types are not used at this point.\n\n\n3.1.2 Transaction Messages\n\n\nThere are 3 types of transactions: Deploy, Invoke and Query. A deploy transaction installs the specified chaincode on the chain, while invoke and query transactions call a function of a deployed chaincode. Another type in consideration is Create transaction, where a deployed chaincode may be instantiated on the chain and is addressable. This type has not been implemented as of this writing.\n\n\n3.1.2.1 Transaction Data Structure\n\n\nMessages with type \nCHAIN_TRANSACTION\n or \nCHAIN_QUERY\n carry a \nTransaction\n object in the \npayload\n:\n\n\nmessage Transaction {\n    enum Type {\n        UNDEFINED = 0;\n        CHAINCODE_DEPLOY = 1;\n        CHAINCODE_INVOKE = 2;\n        CHAINCODE_QUERY = 3;\n        CHAINCODE_TERMINATE = 4;\n    }\n    Type type = 1;\n    string uuid = 5;\n    bytes chaincodeID = 2;\n    bytes payloadHash = 3;\n\n    ConfidentialityLevel confidentialityLevel = 7;\n    bytes nonce = 8;\n    bytes cert = 9;\n    bytes signature = 10;\n\n    bytes metadata = 4;\n    google.protobuf.Timestamp timestamp = 6;\n}\n\nmessage TransactionPayload {\n    bytes payload = 1;\n}\n\nenum ConfidentialityLevel {\n    PUBLIC = 0;\n    CONFIDENTIAL = 1;\n}\n\n\n\n\n\nDefinition of fields:\n\n- \ntype\n - The type of the transaction, which is 1 of the following:\n    - \nUNDEFINED\n - Reserved for future use.\n  - \nCHAINCODE_DEPLOY\n - Represents the deployment of a new chaincode.\n    - \nCHAINCODE_INVOKE\n - Represents a chaincode function execution that may read and modify the world state.\n    - \nCHAINCODE_QUERY\n - Represents a chaincode function execution that may only read the world state.\n    - \nCHAINCODE_TERMINATE\n - Marks a chaincode as inactive so that future functions of the chaincode can no longer be invoked.\n- \nchaincodeID\n - The ID of a chaincode which is a hash of the chaincode source, path to the source code, constructor function, and parameters.\n- \npayloadHash\n - Bytes defining the hash of \nTransactionPayload.payload\n.\n- \nmetadata\n - Bytes defining any associated transaction metadata that the application may use.\n- \nuuid\n - A unique ID for the transaction.\n- \ntimestamp\n - A timestamp of when the transaction request was received by the peer.\n- \nconfidentialityLevel\n - Level of data confidentiality. There are currently 2 levels. Future releases may define more levels.\n- \nnonce\n - Used for security.\n- \ncert\n - Certificate of the transactor.\n- \nsignature\n - Signature of the transactor.\n- \nTransactionPayload.payload\n - Bytes defining the payload of the transaction. As the payload can be large, only the payload hash is included directly in the transaction message.\n\n\nMore detail on transaction security can be found in section 4.\n\n\n3.1.2.2 Transaction Specification\n\n\nA transaction is always associated with a chaincode specification which defines the chaincode and the execution environment such as language and security context. Currently there is an implementation that uses Golang for writing chaincode. Other languages may be added in the future.\n\n\nmessage ChaincodeSpec {\n    enum Type {\n        UNDEFINED = 0;\n        GOLANG = 1;\n        NODE = 2;\n    }\n    Type type = 1;\n    ChaincodeID chaincodeID = 2;\n    ChaincodeInput ctorMsg = 3;\n    int32 timeout = 4;\n    string secureContext = 5;\n    ConfidentialityLevel confidentialityLevel = 6;\n    bytes metadata = 7;\n}\n\nmessage ChaincodeID {\n    string path = 1;\n    string name = 2;\n}\n\nmessage ChaincodeInput {\n    string function = 1;\n    repeated string args  = 2;\n}\n\n\n\n\nDefinition of fields:\n\n- \nchaincodeID\n - The chaincode source code path and name.\n- \nctorMsg\n - Function name and argument parameters to call.\n- \ntimeout\n - Time in milliseconds to execute the transaction.\n- \nconfidentialityLevel\n - Confidentiality level of this transaction.\n- \nsecureContext\n - Security context of the transactor.\n- \nmetadata\n - Any data the application wants to pass along.\n\n\nThe peer, receiving the \nchaincodeSpec\n, wraps it in an appropriate transaction message and broadcasts to the network.\n\n\n3.1.2.3 Deploy Transaction\n\n\nTransaction \ntype\n of a deploy transaction is \nCHAINCODE_DEPLOY\n and the payload contains an object of \nChaincodeDeploymentSpec\n.\n\n\nmessage ChaincodeDeploymentSpec {\n    ChaincodeSpec chaincodeSpec = 1;\n    google.protobuf.Timestamp effectiveDate = 2;\n    bytes codePackage = 3;\n}\n\n\n\n\nDefinition of fields:\n\n- \nchaincodeSpec\n - See section 3.1.2.2, above.\n- \neffectiveDate\n - Time when the chaincode is ready to accept invocations.\n- \ncodePackage\n - gzip of the chaincode source.\n\n\nThe validating peers always verify the hash of the \ncodePackage\n when they deploy the chaincode to make sure the package has not been tampered with since the deploy transaction entered the network.\n\n\n3.1.2.4 Invoke Transaction\n\n\nTransaction \ntype\n of an invoke transaction is \nCHAINCODE_INVOKE\n and the \npayload\n contains an object of \nChaincodeInvocationSpec\n.\n\n\nmessage ChaincodeInvocationSpec {\n    ChaincodeSpec chaincodeSpec = 1;\n}\n\n\n\n\n3.1.2.5 Query Transaction\n\n\nA query transaction is similar to an invoke transaction, but the message \ntype\n is \nCHAINCODE_QUERY\n.\n\n\n3.1.3 Synchronization Messages\n\n\nSynchronization protocol starts with discovery, described above in section 3.1.1, when a peer realizes that it's behind or its current block is not the same with others. A peer broadcasts either \nSYNC_GET_BLOCKS\n, \nSYNC_STATE_GET_SNAPSHOT\n, or \nSYNC_STATE_GET_DELTAS\n and receives \nSYNC_BLOCKS\n, \nSYNC_STATE_SNAPSHOT\n, or \nSYNC_STATE_DELTAS\n respectively.\n\n\nThe installed consensus plugin (e.g. pbft) dictates how synchronization protocol is being applied. Each message is designed for a specific situation:\n\n\nSYNC_GET_BLOCKS\n requests for a range of contiguous blocks expressed in the message \npayload\n, which is an object of \nSyncBlockRange\n.  The correlationId specified is included in the \nSyncBlockRange\n of any replies to this message.\n\n\nmessage SyncBlockRange {\n    uint64 correlationId = 1;\n    uint64 start = 2;\n    uint64 end = 3;\n}\n\n\n\n\nA receiving peer responds with a \nSYNC_BLOCKS\n message whose \npayload\n contains an object of \nSyncBlocks\n\n\nmessage SyncBlocks {\n    SyncBlockRange range = 1;\n    repeated Block blocks = 2;\n}\n\n\n\n\nThe \nstart\n and \nend\n indicate the starting and ending blocks inclusively. The order in which blocks are returned is defined by the \nstart\n and \nend\n values. For example, if \nstart\n=3 and \nend\n=5, the order of blocks will be 3, 4, 5. If \nstart\n=5 and \nend\n=3, the order will be 5, 4, 3.\n\n\nSYNC_STATE_GET_SNAPSHOT\n requests for the snapshot of the current world state. The \npayload\n is an object of \nSyncStateSnapshotRequest\n\n\nmessage SyncStateSnapshotRequest {\n  uint64 correlationId = 1;\n}\n\n\n\n\nThe \ncorrelationId\n is used by the requesting peer to keep track of the response messages. A receiving peer replies with \nSYNC_STATE_SNAPSHOT\n message whose \npayload\n is an instance of \nSyncStateSnapshot\n\n\nmessage SyncStateSnapshot {\n    bytes delta = 1;\n    uint64 sequence = 2;\n    uint64 blockNumber = 3;\n    SyncStateSnapshotRequest request = 4;\n}\n\n\n\n\nThis message contains the snapshot or a chunk of the snapshot on the stream, and in which case, the sequence indicate the order starting at 0.  The terminating message will have len(delta) == 0.\n\n\nSYNC_STATE_GET_DELTAS\n requests for the state deltas of a range of contiguous blocks. By default, the Ledger maintains 500 transition deltas. A delta(j) is a state transition between block(i) and block(j) where i = j-1. The message \npayload\n contains an instance of \nSyncStateDeltasRequest\n\n\nmessage SyncStateDeltasRequest {\n    SyncBlockRange range = 1;\n}\n\n\n\n\nA receiving peer responds with \nSYNC_STATE_DELTAS\n, whose \npayload\n is an instance of \nSyncStateDeltas\n\n\nmessage SyncStateDeltas {\n    SyncBlockRange range = 1;\n    repeated bytes deltas = 2;\n}\n\n\n\n\nA delta may be applied forward (from i to j) or backward (from j to i) in the state transition.\n\n\n3.1.4 Consensus Messages\n\n\nConsensus deals with transactions, so a \nCONSENSUS\n message is initiated internally by the consensus framework when it receives a \nCHAIN_TRANSACTION\n message. The framework converts \nCHAIN_TRANSACTION\n into \nCONSENSUS\n then broadcasts to the validating nodes with the same \npayload\n. The consensus plugin receives this message and process according to its internal algorithm. The plugin may create custom subtypes to manage consensus finite state machine. See section 3.4 for more details.\n\n\n3.2 Ledger\n\n\nThe ledger consists of two primary pieces, the blockchain and the world state. The blockchain is a series of linked blocks that is used to record transactions within the ledger. The world state is a key-value database that chaincodes may use to store state when executed by a transaction.\n\n\n3.2.1 Blockchain\n\n\n3.2.1.1 Block\n\n\nThe blockchain is defined as a linked list of blocks as each block contains the hash of the previous block in the chain. The two other important pieces of information that a block contains are the list of transactions contained within the block and the hash of the world state after executing all transactions in the block.\n\n\nmessage Block {\n  version = 1;\n  google.protobuf.Timestamp timestamp = 2;\n  bytes transactionsHash = 3;\n  bytes stateHash = 4;\n  bytes previousBlockHash = 5;\n  bytes consensusMetadata = 6;\n  NonHashData nonHashData = 7;\n}\n\nmessage BlockTransactions {\n  repeated Transaction transactions = 1;\n}\n\n\n\n\n\n\nversion\n - Version used to track any protocol changes.\n\n\ntimestamp\n - The timestamp to be filled in by the block proposer.\n\n\ntransactionsHash\n - The merkle root hash of the block's transactions.\n\n\nstateHash\n - The merkle root hash of the world state.\n\n\npreviousBlockHash\n - The hash of the previous block.\n\n\nconsensusMetadata\n - Optional metadata that the consensus may include in a block.\n\n\nnonHashData\n - A \nNonHashData\n message that is set to nil before computing the hash of the block, but stored as part of the block in the database.\n\n\nBlockTransactions.transactions\n - An array of Transaction messages. Transactions are not included in the block directly due to their size.\n\n\n\n\n3.2.1.2 Block Hashing\n\n\n\n\nThe \npreviousBlockHash\n hash is calculated using the following algorithm.\n\n\n\n\nSerialize the Block message to bytes using the protocol buffer library.\n\n\n\n\n\n\nHash the serialized block message to 512 bits of output using the SHA3 SHAKE256 algorithm as described in \nFIPS 202\n.\n\n\n\n\n\n\nThe \ntransactionHash\n is the root of the transaction merkle tree. Defining the merkle tree implementation is a TODO.\n\n\n\n\n\n\nThe \nstateHash\n is defined in section 3.2.2.1.\n\n\n\n\n\n\n3.2.1.3 NonHashData\n\n\nThe NonHashData message is used to store block metadata that is not required to be the same value on all peers. These are suggested values.\n\n\nmessage NonHashData {\n  google.protobuf.Timestamp localLedgerCommitTimestamp = 1;\n  repeated TransactionResult transactionResults = 2;\n}\n\nmessage TransactionResult {\n  string uuid = 1;\n  bytes result = 2;\n  uint32 errorCode = 3;\n  string error = 4;\n}\n\n\n\n\n\n\n\n\nlocalLedgerCommitTimestamp\n - A timestamp indicating when the block was commited to the local ledger.\n\n\n\n\n\n\nTransactionResult\n - An array of transaction results.\n\n\n\n\n\n\nTransactionResult.uuid\n - The ID of the transaction.\n\n\n\n\n\n\nTransactionResult.result\n - The return value of the transaction.\n\n\n\n\n\n\nTransactionResult.errorCode\n - A code that can be used to log errors associated with the transaction.\n\n\n\n\n\n\nTransactionResult.error\n - A string that can be used to log errors associated with the transaction.\n\n\n\n\n\n\n3.2.1.4 Transaction Execution\n\n\nA transaction defines either the deployment of a chaincode or the execution of a chaincode. All transactions within a block are run before recording a block in the ledger. When chaincodes execute, they may modify the world state. The hash of the world state is then recorded in the block.\n\n\n3.2.2 World State\n\n\nThe \nworld state\n of a peer refers to the collection of the \nstates\n of all the deployed chaincodes. Further, the state of a chaincode is represented as a collection of key-value pairs. Thus, logically, the world state of a peer is also a collection of key-value pairs where key consists of a tuple \n{chaincodeID, ckey}\n. Here, we use the term \nkey\n to represent a key in the world state i.e., a tuple \n{chaincodeID, ckey}\n and we use the term \ncKey\n to represent a unique key within a chaincode.\n\n\nFor the purpose of the description below, \nchaincodeID\n is assumed to be a valid utf8 string and \nckey\n and the \nvalue\n can be a sequence of one or more arbitrary bytes.\n\n\n3.2.2.1 Hashing the world state\n\n\nDuring the functioning of a network, many occasions such as committing transactions and synchronizing peers may require computing a crypto-hash of the world state observed by a peer. For instance, the consensus protocol may require to ensure that a \nminimum\n number of peers in the network observe the same world state.\n\n\nSince, computing the crypto-hash of the world state could be an expensive operation, this is highly desirable to organize the world state such that it enables an efficient crypto-hash computation of the world state when a change occurs in the world state. Further, different organization designs may be suitable under different workloads conditions.\n\n\nBecause the fabric is expected to function under a variety of scenarios leading to different workloads conditions, a pluggable mechanism is supported for organizing the world state.\n\n\n3.2.2.1.1 Bucket-tree\n\n\nBucket-tree\n is one of the implementations for organizing the world state. For the purpose of the description below, a key in the world state is represented as a concatenation of the two components (\nchaincodeID\n and \nckey\n)  separated by a \nnil\n byte i.e., \nkey\n = \nchaincodeID\n+\nnil\n+\ncKey\n.\n\n\nThis method models a \nmerkle-tree\n on top of buckets of a \nhash table\n in order to compute the crypto-hash of the \nworld state\n.\n\n\nAt the core of this method, the \nkey-values\n of the world state are assumed to be stored in a hash-table that consists of a pre-decided number of buckets (\nnumBuckets\n). A hash function (\nhashFunction\n) is employed to determine the bucket number that should contain a given key. Please note that the \nhashFunction\n does not represent a crypto-hash method such as SHA3, rather this is a regular programming language hash function that decides the bucket number for a given key.\n\n\nFor modeling the merkle-tree, the ordered buckets act as leaf nodes of the tree - lowest numbered bucket being the left most leaf node in the tree. For constructing the second-last level of the tree, a pre-decided number of leaf nodes (\nmaxGroupingAtEachLevel\n), starting from left, are grouped together and for each such group, a node is inserted at the second-last level that acts as a common parent for all the leaf nodes in the group. Note that the number of children for the last parent node may be less than \nmaxGroupingAtEachLevel\n. This grouping method of constructing the next higher level is repeated until the root node of the tree is constructed.\n\n\nAn example setup with configuration \n{numBuckets=10009 and maxGroupingAtEachLevel=10}\n will result in a tree with number of nodes at different level as depicted in the following table.\n\n\n\n\n\n\n\n\nLevel\n\n\nNumber of nodes\n\n\n\n\n\n\n\n\n\n\n0\n\n\n1\n\n\n\n\n\n\n1\n\n\n2\n\n\n\n\n\n\n2\n\n\n11\n\n\n\n\n\n\n3\n\n\n101\n\n\n\n\n\n\n4\n\n\n1001\n\n\n\n\n\n\n5\n\n\n10009\n\n\n\n\n\n\n\n\nFor computing the crypto-hash of the world state, the crypto-hash of each bucket is computed and is assumed to be the crypto-hash of leaf-nodes of the merkle-tree. In order to compute crypto-hash of a bucket, the key-values present in the bucket are first serialized and crypto-hash function is applied on the serialized bytes. For serializing the key-values of a bucket, all the key-values with a common chaincodeID prefix are serialized separately and then appending together, in the ascending order of chaincodeIDs. For serializing the key-values of a chaincodeID, the following information is concatenated:\n   1. Length of chaincodeID (number of bytes in the chaincodeID)\n   - The utf8 bytes of the chaincodeID\n   - Number of key-values for the chaincodeID\n   - For each key-value (in sorted order of the ckey)\n      - Length of the ckey\n      - ckey bytes\n      - Length of the value\n      - value bytes\n\n\nFor all the numeric types in the above list of items (e.g., Length of chaincodeID), protobuf's varint encoding is assumed to be used. The purpose of the above encoding is to achieve a byte representation of the key-values within a bucket that can not be arrived at by any other combination of key-values and also to reduce the overall size of the serialized bytes.\n\n\nFor example, consider a bucket that contains three key-values namely, \nchaincodeID1_key1:value1, chaincodeID1_key2:value2, and chaincodeID2_key1:value1\n. The serialized bytes for the bucket would logically look as - \n12 + chaincodeID1 + 2 + 4 + key1 + 6 + value1 + 4 + key2 + 6 + value2 + 12 + chaincodeID2 + 1 + 4 + key1 + 6 + value1\n\n\nIf a bucket has no key-value present, the crypto-hash is considered as \nnil\n.\n\n\nThe crypto-hash of an intermediate node and root node are computed just like in a standard merkle-tree i.e., applying a crypto-hash function on the bytes obtained by concatenating the crypto-hash of all the children nodes, from left to right. Further, if a child has a crypto-hash as \nnil\n, the crypto-hash of the child is omitted when concatenating the children crypto-hashes. If the node has a single child, the crypto-hash of the child is assumed to be the crypto-hash of the node. Finally, the crypto-hash of the root node is considered as the crypto-hash of the world state.\n\n\nThe above method offers performance benefits for computing crypto-hash when a few key-values change in the state. The major benefits include\n  - Computation of crypto-hashes of the unchanged buckets can be skipped\n  - The depth and breadth of the merkle-tree can be controlled by configuring the parameters \nnumBuckets\n and \nmaxGroupingAtEachLevel\n. Both depth and breadth of the tree has different implication on the performance cost incurred by and resource demand of different resources (namely - disk I/O, storage, and memory)\n\n\nIn a particular deployment, all the peer nodes are expected to use same values for the configurations \nnumBuckets, maxGroupingAtEachLevel, and hashFunction\n. Further, if any of these configurations are to be changed at a later stage, the configurations should be changed on all the peer nodes so that the comparison of crypto-hashes across peer nodes is meaningful. Also, this may require to migrate the existing data based on the implementation. For example, an implementation is expected to store the last computed crypto-hashes for all the nodes in the tree which would need to be recalculated.\n\n\n3.3 Chaincode\n\n\nChaincode is an application-level code deployed as a transaction (see section 3.1.2) to be distributed to the network and managed by each validating peer as isolated sandbox. Though any virtualization technology can support the sandbox, currently Docker container is utilized to run the chaincode. The protocol described in this section enables different virtualization support implementation to plug and play.\n\n\n3.3.1 Virtual Machine Instantiation\n\n\nA virtual machine implements the VM interface:  \n\n\ntype VM interface {\n    build(ctxt context.Context, id string, args []string, env []string, attachstdin bool, attachstdout bool, reader io.Reader) error\n    start(ctxt context.Context, id string, args []string, env []string, attachstdin bool, attachstdout bool) error\n    stop(ctxt context.Context, id string, timeout uint, dontkill bool, dontremove bool) error\n}\n\n\n\n\nThe fabric instantiates the VM when it processes a Deploy transaction or other transactions on the chaincode while the VM for that chaincode is not running (either crashed or previously brought down due to inactivity). Each chaincode image is built by the \nbuild\n function, started by \nstart\n and stopped by \nstop\n function.\n\n\nOnce the chaincode container is up, it makes a gRPC connection back to the validating peer that started the chaincode, and that establishes the channel for Invoke and Query transactions on the chaincode.\n\n\n3.3.2 Chaincode Protocol\n\n\nCommunication between a validating peer and its chaincodes is based on a bidirectional gRPC stream. There is a shim layer on the chaincode container to handle the message protocol between the chaincode and the validating peer using protobuf message.\n\n\nmessage ChaincodeMessage {\n\n    enum Type {\n        UNDEFINED = 0;\n        REGISTER = 1;\n        REGISTERED = 2;\n        INIT = 3;\n        READY = 4;\n        TRANSACTION = 5;\n        COMPLETED = 6;\n        ERROR = 7;\n        GET_STATE = 8;\n        PUT_STATE = 9;\n        DEL_STATE = 10;\n        INVOKE_CHAINCODE = 11;\n        INVOKE_QUERY = 12;\n        RESPONSE = 13;\n        QUERY = 14;\n        QUERY_COMPLETED = 15;\n        QUERY_ERROR = 16;\n        RANGE_QUERY_STATE = 17;\n    }\n\n    Type type = 1;\n    google.protobuf.Timestamp timestamp = 2;\n    bytes payload = 3;\n    string uuid = 4;\n}\n\n\n\n\nDefinition of fields:\n\n- \nType\n is the type of the message.\n- \npayload\n is the payload of the message. Each payload depends on the \nType\n.\n- \nuuid\n is a unique identifier of the message.\n\n\nThe message types are described in the following sub-sections.\n\n\nA chaincode implements the \nChaincode\n interface, which is called by the validating peer when it processes Deploy, Invoke or Query transactions.\n\n\ntype Chaincode interface {\ni   Init(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n    Invoke(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n    Query(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n}\n\n\n\n\nInit\n, \nInvoke\n and \nQuery\n functions take \nfunction\n and \nargs\n as parameters to be used by those methods to support a variety of transactions. \nInit\n is a constructor function, which will only be invoked by the Deploy transaction. The \nQuery\n function is not allowed to modify the state of the chaincode; it can only read and calculate the return value as a byte array.\n\n\n3.3.2.1 Chaincode Deploy\n\n\nUpon deploy (chaincode container is started), the shim layer sends a one time \nREGISTER\n message to the validating peer with the \npayload\n containing the \nChaincodeID\n. The validating peer responds with \nREGISTERED\n or \nERROR\n on success or failure respectively. The shim closes the connection and exits if it receives an \nERROR\n.\n\n\nAfter registration, the validating peer sends \nINIT\n with the \npayload\n containing a \nChaincodeInput\n object. The shim calls the \nInit\n function with the parameters from the \nChaincodeInput\n, enabling the chaincode to perform any initialization, such as setting up the persistent state.\n\n\nThe shim responds with \nRESPONSE\n or \nERROR\n message depending on the returned value from the chaincode \nInit\n function. If there are no errors, the chaincode initialization is complete and is ready to receive Invoke and Query transactions.\n\n\n3.3.2.2 Chaincode Invoke\n\n\nWhen processing an invoke transaction, the validating peer sends a \nTRANSACTION\n message to the chaincode container shim, which in turn calls the chaincode \nInvoke\n function, passing the parameters from the \nChaincodeInput\n object. The shim responds to the validating peer with \nRESPONSE\n or \nERROR\n message, indicating the completion of the function. If \nERROR\n is received, the \npayload\n contains the error message generated by the chaincode.\n\n\n3.3.2.3 Chaincode Query\n\n\nSimilar to an invoke transaction, when processing a query, the validating peer sends a \nQUERY\n message to the chaincode container shim, which in turn calls the chaincode \nQuery\n function, passing the parameters from the \nChaincodeInput\n object. The \nQuery\n function may return a state value or an error, which the shim forwards to the validating peer using \nRESPONSE\n or \nERROR\n messages respectively.\n\n\n3.3.2.4 Chaincode State\n\n\nEach chaincode may define its own persistent state variables. For example, a chaincode may create assets such as TVs, cars, or stocks using state variables to hold the assets attributes. During \nInvoke\n function processing, the chaincode may update the state variables, for example, changing an asset owner. A chaincode manipulates the state variables by using the following message types:\n\n\nPUT_STATE\n\n\nChaincode sends a \nPUT_STATE\n message to persist a key-value pair, with the \npayload\n containing \nPutStateInfo\n object.\n\n\nmessage PutStateInfo {\n    string key = 1;\n    bytes value = 2;\n}\n\n\n\n\nGET_STATE\n\n\nChaincode sends a \nGET_STATE\n message to retrieve the value whose key is specified in the \npayload\n.\n\n\nDEL_STATE\n\n\nChaincode sends a \nDEL_STATE\n message to delete the value whose key is specified in the \npayload\n.\n\n\nRANGE_QUERY_STATE\n\n\nChaincode sends a \nRANGE_QUERY_STATE\n message to get a range of values. The message \npayload\n contains a \nRangeQueryStateInfo\n object.\n\n\nmessage RangeQueryState {\n    string startKey = 1;\n    string endKey = 2;\n}\n\n\n\n\nThe \nstartKey\n and \nendKey\n are inclusive and assumed to be in lexical order. The validating peer responds with \nRESPONSE\n message whose \npayload\n is a \nRangeQueryStateResponse\n object.\n\n\nmessage RangeQueryStateResponse {\n    repeated RangeQueryStateKeyValue keysAndValues = 1;\n    bool hasMore = 2;\n    string ID = 3;\n}\nmessage RangeQueryStateKeyValue {\n    string key = 1;\n    bytes value = 2;\n}\n\n\n\n\nIf \nhasMore=true\n in the response, this indicates that additional keys are available in the requested range. The chaincode can request the next set of keys and values by sending a \nRangeQueryStateNext\n message with an ID that matches the ID returned in the response.\n\n\nmessage RangeQueryStateNext {\n    string ID = 1;\n}\n\n\n\n\nWhen the chaincode is finished reading from the range, it should send a \nRangeQueryStateClose\n message with the ID it wishes to close.\n\n\nmessage RangeQueryStateClose {\n  string ID = 1;\n}\n\n\n\n\nINVOKE_CHAINCODE\n\n\nChaincode may call another chaincode in the same transaction context by sending an \nINVOKE_CHAINCODE\n message to the validating peer with the \npayload\n containing a \nChaincodeSpec\n object.\n\n\nQUERY_CHAINCODE\n\n\nChaincode may query another chaincode in the same transaction context by sending a \nQUERY_CHAINCODE\n message with the \npayload\n containing a \nChaincodeSpec\n object.\n\n\n3.4 Pluggable Consensus Framework\n\n\nThe consensus framework defines the interfaces that every consensus \nplugin\n implements:\n\n\n\n\nconsensus.Consenter\n: interface that  allows consensus plugin to receive messages from the network.\n\n\nconsensus.CPI\n:  \nConsensus Programming Interface\n (\nCPI\n) is used by consensus plugin to interact with rest of the stack. This interface is split in two parts:\n\n\nconsensus.Communicator\n: used to send (broadcast and unicast) messages to other validating peers.\n\n\nconsensus.LedgerStack\n: which is used as an interface to the execution framework as well as the ledger.\n\n\n\n\n\n\n\n\nAs described below in more details, \nconsensus.LedgerStack\n encapsulates, among other interfaces, the \nconsensus.Executor\n interface, which is the key part of the consensus framework. Namely, \nconsensus.Executor\n interface allows for a (batch of) transaction to be started, executed, rolled back if necessary, previewed, and potentially committed. A particular property that every consensus plugin needs to satisfy is that batches (blocks)  of transactions are committed to the ledger (via \nconsensus.Executor.CommitTxBatch\n) in total order across all validating peers (see \nconsensus.Executor\n interface description below for more details).\n\n\nCurrently, consensus framework consists of 3 packages \nconsensus\n, \ncontroller\n, and \nhelper\n. The primary reason for \ncontroller\n and \nhelper\n packages is to avoid \"import cycle\" in Go (golang) and minimize code changes for plugin to update.\n\n\n\n\ncontroller\n package specifies the consensus plugin used by a validating peer.\n\n\nhelper\n package is a shim around a consensus plugin that helps it interact with the rest of the stack, such as maintaining message handlers to other peers.  \n\n\n\n\nThere are 2 consensus plugins provided: \npbft\n and \nnoops\n:\n\n\n\n\nobcpbft\n package contains consensus plugin that implements \nPBFT\n [1] and \nSieve\n consensus protocols. See section 5 for more detail.\n\n\nnoops\n is a ''dummy'' consensus plugin for development and test purposes. It doesn't perform consensus but processes all consensus messages. It also serves as a good simple sample to start learning how to code a consensus plugin.\n\n\n\n\n3.4.1 \nConsenter\n interface\n\n\nDefinition:\n\n\ntype Consenter interface {\n    RecvMsg(msg *pb.Message) error\n}\n\n\n\n\nThe plugin's entry point for (external) client requests, and consensus messages generated internally (i.e. from the consensus module) during the consensus process. The \ncontroller.NewConsenter\n creates the plugin \nConsenter\n. \nRecvMsg\n processes the incoming transactions in order to reach consensus.\n\n\nSee \nhelper.HandleMessage\n below to understand how the peer interacts with this interface.\n\n\n3.4.2 \nCPI\n interface\n\n\nDefinition:\n\n\ntype CPI interface {\n    Inquirer\n    Communicator\n    SecurityUtils\n    LedgerStack\n}\n\n\n\n\nCPI\n allows the plugin to interact with the stack. It is implemented by the \nhelper.Helper\n object. Recall that this object:\n\n\n\n\nIs instantiated when the \nhelper.NewConsensusHandler\n is called.\n\n\nIs accessible to the plugin author when they construct their plugin's \nconsensus.Consenter\n object.\n\n\n\n\n3.4.3 \nInquirer\n interface\n\n\nDefinition:\n\n\ntype Inquirer interface {\n        GetNetworkInfo() (self *pb.PeerEndpoint, network []*pb.PeerEndpoint, err error)\n        GetNetworkHandles() (self *pb.PeerID, network []*pb.PeerID, err error)\n}\n\n\n\n\nThis interface is a part of the \nconsensus.CPI\n interface. It is used to get the handles of the validating peers in the network (\nGetNetworkHandles\n) as well as details about the those validating peers (\nGetNetworkInfo\n):\n\n\nNote that the peers are identified by a \npb.PeerID\n object. This is a protobuf message (in the \nprotos\n package), currently defined as (notice that this definition will likely be modified):\n\n\nmessage PeerID {\n    string name = 1;\n}\n\n\n\n\n3.4.4 \nCommunicator\n interface\n\n\nDefinition:\n\n\ntype Communicator interface {\n    Broadcast(msg *pb.Message) error\n    Unicast(msg *pb.Message, receiverHandle *pb.PeerID) error\n}\n\n\n\n\nThis interface is a part of the \nconsensus.CPI\n interface. It is used to communicate with other peers on the network (\nhelper.Broadcast\n, \nhelper.Unicast\n):\n\n\n3.4.5 \nSecurityUtils\n interface\n\n\nDefinition:\n\n\ntype SecurityUtils interface {\n        Sign(msg []byte) ([]byte, error)\n        Verify(peerID *pb.PeerID, signature []byte, message []byte) error\n}\n\n\n\n\nThis interface is a part of the \nconsensus.CPI\n interface. It is used to handle the cryptographic operations of message signing (\nSign\n) and verifying signatures (\nVerify\n)\n\n\n3.4.6 \nLedgerStack\n interface\n\n\nDefinition:\n\n\ntype LedgerStack interface {\n    Executor\n    Ledger\n    RemoteLedgers\n}\n\n\n\n\nA key member of the \nCPI\n interface, \nLedgerStack\n groups interaction of consensus with the rest of the fabric, such as the execution of transactions, querying, and updating the ledger.  This interface supports querying the local blockchain and state, updating the local blockchain and state, and querying the blockchain and state of other nodes in the consensus network. It consists of three parts: \nExecutor\n, \nLedger\n and \nRemoteLedgers\n interfaces. These are described in the following.\n\n\n3.4.7 \nExecutor\n interface\n\n\nDefinition:\n\n\ntype Executor interface {\n    BeginTxBatch(id interface{}) error\n    ExecTXs(id interface{}, txs []*pb.Transaction) ([]byte, []error)  \n    CommitTxBatch(id interface{}, transactions []*pb.Transaction, transactionsResults []*pb.TransactionResult, metadata []byte) error  \n    RollbackTxBatch(id interface{}) error  \n    PreviewCommitTxBatchBlock(id interface{}, transactions []*pb.Transaction, metadata []byte) (*pb.Block, error)  \n}\n\n\n\n\nThe executor interface is the most frequently utilized portion of the \nLedgerStack\n interface, and is the only piece which is strictly necessary for a consensus network to make progress.  The interface allows for a transaction to be started, executed, rolled back if necessary, previewed, and potentially committed.  This interface is comprised of the following methods.\n\n\n3.4.7.1 Beginning a transaction batch\n\n\nBeginTxBatch(id interface{}) error\n\n\n\n\nThis call accepts an arbitrary \nid\n, deliberately opaque, as a way for the consensus plugin to ensure only the transactions associated with this particular batch are executed. For instance, in the pbft implementation, this \nid\n is the an encoded hash of the transactions to be executed.\n\n\n3.4.7.2 Executing transactions\n\n\nExecTXs(id interface{}, txs []*pb.Transaction) ([]byte, []error)\n\n\n\n\nThis call accepts an array of transactions to execute against the current state of the ledger and returns the current state hash in addition to an array of errors corresponding to the array of transactions.  Note that a transaction resulting in an error has no effect on whether a transaction batch is safe to commit.  It is up to the consensus plugin to determine the behavior which should occur when failing transactions are encountered.  This call is safe to invoke multiple times.\n\n\n3.4.7.3 Committing and rolling-back transactions\n\n\nRollbackTxBatch(id interface{}) error\n\n\n\n\nThis call aborts an execution batch.  This will undo the changes to the current state, and restore the ledger to its previous state.  It concludes the batch begun with \nBeginBatchTx\n and a new one must be created before executing any transactions.\n\n\nPreviewCommitTxBatchBlock(id interface{}, transactions []*pb.Transaction, metadata []byte) (*pb.Block, error)\n\n\n\n\nThis call is most useful for consensus plugins which wish to test for non-deterministic transaction execution.  The hashable portions of the block returned are guaranteed to be identical to the block which would be committed if \nCommitTxBatch\n were immediately invoked.  This guarantee is violated if any new transactions are executed.\n\n\nCommitTxBatch(id interface{}, transactions []*pb.Transaction, transactionsResults []*pb.TransactionResult, metadata []byte) error\n\n\n\n\nThis call commits a block to the blockchain.  Blocks must be committed to a blockchain in total order. \nCommitTxBatch\n concludes the transaction batch, and a new call to \nBeginTxBatch\n must be made before any new transactions are executed and committed.\n\n\n3.4.8 \nLedger\n interface\n\n\nDefinition:\n\n\ntype Ledger interface {\n    ReadOnlyLedger\n    UtilLedger\n    WritableLedger\n}\n\n\n\n\nLedger\n interface is intended to allow the consensus plugin to interrogate and possibly update the current state and blockchain. It is comprised of the three interfaces described below.\n\n\n3.4.8.1 \nReadOnlyLedger\n interface\n\n\nDefinition:\n\n\ntype ReadOnlyLedger interface {\n    GetBlock(id uint64) (block *pb.Block, err error)\n    GetCurrentStateHash() (stateHash []byte, err error)\n    GetBlockchainSize() (uint64, error)\n}\n\n\n\n\nReadOnlyLedger\n interface is intended to query the local copy of the ledger without the possibility of modifying it.  It is comprised of the following functions.\n\n\nGetBlockchainSize() (uint64, error)\n\n\n\n\nThis call returns the current length of the blockchain ledger.  In general, this function should never fail, though in the unlikely event that this occurs, the error is passed to the caller to decide what if any recovery is necessary.  The block with the highest number will have block number \nGetBlockchainSize()-1\n.  \n\n\nNote that in the event that the local copy of the blockchain ledger is corrupt or incomplete, this call will return the highest block number in the chain, plus one.  This allows for a node to continue operating from the current state/block even when older blocks are corrupt or missing.\n\n\nGetBlock(id uint64) (block *pb.Block, err error)\n\n\n\n\nThis call returns the block from the blockchain with block number \nid\n.  In general, this call should not fail, except when the block queried exceeds the current blocklength, or when the underlying blockchain has somehow become corrupt.  A failure of \nGetBlock\n has a possible resolution of using the state transfer mechanism to retrieve it.\n\n\nGetCurrentStateHash() (stateHash []byte, err error)\n\n\n\n\nThis call returns the current state hash for the ledger.  In general, this function should never fail, though in the unlikely event that this occurs, the error is passed to the caller to decide what if any recovery is necessary.\n\n\n3.4.8.2 \nUtilLedger\n interface\n\n\nDefinition:\n\n\ntype UtilLedger interface {\n    HashBlock(block *pb.Block) ([]byte, error)\n    VerifyBlockchain(start, finish uint64) (uint64, error)\n}\n\n\n\n\nUtilLedger\n  interface defines some useful utility functions which are provided by the local ledger.  Overriding these functions in a mock interface can be useful for testing purposes.  This interface is comprised of two functions.\n\n\nHashBlock(block *pb.Block) ([]byte, error)\n\n\n\n\nAlthough \n*pb.Block\n has a \nGetHash\n method defined, for mock testing, overriding this method can be very useful.  Therefore, it is recommended that the \nGetHash\n method never be directly invoked, but instead invoked via this \nUtilLedger.HashBlock\n interface.  In general, this method should never fail, but the error is still passed to the caller to decide what if any recovery is appropriate.\n\n\nVerifyBlockchain(start, finish uint64) (uint64, error)\n\n\n\n\nThis utility method is intended for verifying large sections of the blockchain.  It proceeds from a high block \nstart\n to a lower block \nfinish\n, returning the block number of the first block whose \nPreviousBlockHash\n does not match the block hash of the previous block as well as an error.  Note, this generally indicates the last good block number, not the first bad block number.\n\n\n3.4.8.3 \nWritableLedger\n interface\n\n\nDefinition:\n\n\ntype WritableLedger interface {\n    PutBlock(blockNumber uint64, block *pb.Block) error\n    ApplyStateDelta(id interface{}, delta *statemgmt.StateDelta) error\n    CommitStateDelta(id interface{}) error\n    RollbackStateDelta(id interface{}) error\n    EmptyState() error\n}\n\n\n\n\nWritableLedger\n  interface allows for the caller to update the blockchain.  Note that this is \nNOT\n intended for use in normal operation of a consensus plugin.  The current state should be modified by executing transactions using the \nExecutor\n interface, and new blocks will be generated when transactions are committed.  This interface is instead intended primarily for state transfer or corruption recovery.  In particular, functions in this interface should \nNEVER\n be exposed directly via consensus messages, as this could result in violating the immutability promises of the blockchain concept.  This interface is comprised of the following functions.\n\n\n-\n    \nPutBlock(blockNumber uint64, block *pb.Block) error\n\n\nThis function takes a provided, raw block, and inserts it into the blockchain at the given blockNumber.  Note that this intended to be an unsafe interface, so no error or sanity checking is performed.  Inserting a block with a number higher than the current block height is permitted, similarly overwriting existing already committed blocks is also permitted.  Remember, this does not affect the auditability or immutability of the chain, as the hashing techniques make it computationally infeasible to forge a block earlier in the chain.  Any attempt to rewrite the blockchain history is therefore easily detectable.  This is generally only useful to the state transfer API.\n\n\n\n-\n    \nApplyStateDelta(id interface{}, delta *statemgmt.StateDelta) error\n\n\nThis function takes a state delta, and applies it to the current state.  The delta will be applied to transition a state forward or backwards depending on the construction of the state delta.  Like the `Executor` methods, `ApplyStateDelta` accepts an opaque interface `id` which should also be passed into `CommitStateDelta` or `RollbackStateDelta` as appropriate.\n\n\n\n-\n    \nCommitStateDelta(id interface{}) error\n\n\nThis function commits the state delta which was applied in `ApplyStateDelta`.  This is intended to be invoked after the caller to `ApplyStateDelta` has verified the state via the state hash obtained via `GetCurrentStateHash()`.  This call takes the same `id` which was passed into `ApplyStateDelta`.\n\n\n\n-\n    \nRollbackStateDelta(id interface{}) error\n\n\nThis function unapplies a state delta which was applied in `ApplyStateDelta`.  This is intended to be invoked after the caller to `ApplyStateDelta` has detected the state hash obtained via `GetCurrentStateHash()` is incorrect.  This call takes the same `id` which was passed into `ApplyStateDelta`.\n\n\n\n-\n    \nEmptyState() error\n\n\nThis function will delete the entire current state, resulting in a pristine empty state.  It is intended to be called before loading an entirely new state via deltas.  This is generally only useful to the state transfer API.\n\n\n\n3.4.9 \nRemoteLedgers\n interface\n\n\nDefinition:\n\n\ntype RemoteLedgers interface {\n    GetRemoteBlocks(peerID uint64, start, finish uint64) (\n-chan *pb.SyncBlocks, error)\n    GetRemoteStateSnapshot(peerID uint64) (\n-chan *pb.SyncStateSnapshot, error)\n    GetRemoteStateDeltas(peerID uint64, start, finish uint64) (\n-chan *pb.SyncStateDeltas, error)\n}\n\n\n\n\nThe \nRemoteLedgers\n interface exists primarily to enable state transfer and to interrogate the blockchain state at  other replicas.  Just like the \nWritableLedger\n interface, it is not intended to be used in normal operation and is designed to be used for catchup, error recovery, etc.  For all functions in this interface it is the caller's responsibility to enforce timeouts.  This interface contains the following functions.\n\n\n\n\n\n\nGetRemoteBlocks(peerID uint64, start, finish uint64) (\n-chan *pb.SyncBlocks, error)\n\n\nThis function attempts to retrieve a stream of \n*pb.SyncBlocks\n from the peer designated by \npeerID\n for the range from \nstart\n to \nfinish\n.  In general, \nstart\n should be specified with a higher block number than \nfinish\n, as the blockchain must be validated from end to beginning.  The caller must validate that the desired block is being returned, as it is possible that slow results from another request could appear on this channel.  Invoking this call for the same \npeerID\n a second time will cause the first channel to close.\n\n\n\n\n\n\n```\nGetRemoteStateSnapshot(peerID uint64) (\n-chan *pb.SyncStateSnapshot, error)\n```\n\n\n\nThis function attempts to retrieve a stream of \n*pb.SyncStateSnapshot\n from the peer designated by \npeerID\n.  To apply the result, the existing state should first be emptied via the \nWritableLedger\n \nEmptyState\n call, then the contained deltas in the stream should be applied sequentially.\n\n\n\n\n\n\n-\n    \nGetRemoteStateDeltas(peerID uint64, start, finish uint64) (\n-chan *pb.SyncStateDeltas, error)\n\n\nThis function attempts to retrieve a stream of `*pb.SyncStateDeltas` from the peer designated by `peerID` for the range from `start` to `finish`.  The caller must validated that the desired block delta is being returned, as it is possible that slow results from another request could appear on this channel.  Invoking this call for the same `peerID` a second time will cause the first channel to close.\n\n\n\n3.4.10 \ncontroller\n package\n\n\n3.4.10.1 controller.NewConsenter\n\n\nSignature:\n\n\nfunc NewConsenter(cpi consensus.CPI) (consenter consensus.Consenter)\n\n\n\n\nThis function reads the \npeer.validator.consensus\n value in \ncore.yaml\n configuration file, which is the  configuration file for the \npeer\n process. The value of the \npeer.validator.consensus\n key defines whether the validating peer will run with the \nnoops\n consensus plugin or the \nobcpbft\n one. (Notice that this should eventually be changed to either \nnoops\n or \ncustom\n. In case of \ncustom\n, the validating peer will run with the consensus plugin defined in \nconsensus/config.yaml\n.)\n\n\nThe plugin author needs to edit the function's body so that it routes to the right constructor for their package. For example, for \nobcpbft\n we point to the \nobcpft.GetPlugin\n constructor.\n\n\nThis function is called by \nhelper.NewConsensusHandler\n when setting the \nconsenter\n field of the returned message handler. The input argument \ncpi\n is the output of the \nhelper.NewHelper\n constructor and implements the \nconsensus.CPI\n interface.\n\n\n3.4.11 \nhelper\n package\n\n\n3.4.11.1 High-level overview\n\n\nA validating peer establishes a message handler (\nhelper.ConsensusHandler\n) for every connected peer, via the \nhelper.NewConsesusHandler\n function (a handler factory). Every incoming message is inspected on its type (\nhelper.HandleMessage\n); if it's a message for which consensus needs to be reached, it's passed on to the peer's consenter object (\nconsensus.Consenter\n). Otherwise it's passed on to the next message handler in the stack.\n\n\n3.4.11.2 helper.ConsensusHandler\n\n\nDefinition:\n\n\ntype ConsensusHandler struct {\n    chatStream  peer.ChatStream\n    consenter   consensus.Consenter\n    coordinator peer.MessageHandlerCoordinator\n    done        chan struct{}\n    peerHandler peer.MessageHandler\n}\n\n\n\n\nWithin the context of consensus, we focus only on the \ncoordinator\n and \nconsenter\n fields. The \ncoordinator\n, as the name implies, is used to coordinate between the peer's message handlers. This is, for instance, the object that is accessed when the peer wishes to \nBroadcast\n. The \nconsenter\n receives the messages for which consensus needs to be reached and processes them.\n\n\nNotice that \nfabric/peer/peer.go\n defines the \npeer.MessageHandler\n (interface), and \npeer.MessageHandlerCoordinator\n (interface) types.\n\n\n3.4.11.3 helper.NewConsensusHandler\n\n\nSignature:\n\n\nfunc NewConsensusHandler(coord peer.MessageHandlerCoordinator, stream peer.ChatStream, initiatedStream bool, next peer.MessageHandler) (peer.MessageHandler, error)\n\n\n\n\nCreates a \nhelper.ConsensusHandler\n object. Sets the same \ncoordinator\n for every message handler. Also sets the \nconsenter\n equal to: \ncontroller.NewConsenter(NewHelper(coord))\n\n\n3.4.11.4 helper.Helper\n\n\nDefinition:\n\n\ntype Helper struct {\n    coordinator peer.MessageHandlerCoordinator\n}\n\n\n\n\nContains the reference to the validating peer's \ncoordinator\n. Is the object that implements the \nconsensus.CPI\n interface for the peer.\n\n\n3.4.11.5 helper.NewHelper\n\n\nSignature:\n\n\nfunc NewHelper(mhc peer.MessageHandlerCoordinator) consensus.CPI\n\n\n\n\nReturns a \nhelper.Helper\n object whose \ncoordinator\n is set to the input argument \nmhc\n (the \ncoordinator\n field of the \nhelper.ConsensusHandler\n message handler). This object implements the \nconsensus.CPI\n interface, thus allowing the plugin to interact with the stack.\n\n\n3.4.11.6 helper.HandleMessage\n\n\nRecall that the \nhelper.ConsesusHandler\n object returned by \nhelper.NewConsensusHandler\n implements the \npeer.MessageHandler\n interface:\n\n\ntype MessageHandler interface {\n    RemoteLedger\n    HandleMessage(msg *pb.Message) error\n    SendMessage(msg *pb.Message) error\n    To() (pb.PeerEndpoint, error)\n    Stop() error\n}\n\n\n\n\nWithin the context of consensus, we focus only on the \nHandleMessage\n method. Signature:\n\n\nfunc (handler *ConsensusHandler) HandleMessage(msg *pb.Message) error\n\n\n\n\nThe function inspects the \nType\n of the incoming \nMessage\n. There are four cases:\n\n\n\n\nEqual to \npb.Message_CONSENSUS\n: passed to the handler's \nconsenter.RecvMsg\n function.\n\n\nEqual to \npb.Message_CHAIN_TRANSACTION\n (i.e. an external deployment request): a response message is sent to the user first, then the message is passed to the \nconsenter.RecvMsg\n function.\n\n\nEqual to \npb.Message_CHAIN_QUERY\n (i.e. a query): passed to the \nhelper.doChainQuery\n method so as to get executed locally.\n\n\nOtherwise: passed to the \nHandleMessage\n method of the next handler down the stack.\n\n\n\n\n3.5 Events\n\n\nThe event framework provides the ability to generate and consume predefined and custom events. There are 3 basic components:\n  - Event stream\n  - Event adapters\n  - Event structures\n\n\n3.5.1 Event Stream\n\n\nAn event stream is a gRPC channel capable of sending and receiving events. Each consumer establishes an event stream to the event framework and expresses the events that it is interested in. the event producer only sends appropriate events to the consumers who have connected to the producer over the event stream.\n\n\nThe event stream initializes the buffer and timeout parameters. The buffer holds the number of events waiting for delivery, and the timeout has 3 options when the buffer is full:\n\n\n\n\nIf timeout is less than 0, drop the newly arriving events\n\n\nIf timeout is 0, block on the event until the buffer becomes available\n\n\nIf timeout is greater than 0, wait for the specified timeout and drop the event if the buffer remains full after the timeout\n\n\n\n\n3.5.1.1 Event Producer\n\n\nThe event producer exposes a function to send an event, \nSend(e *pb.Event)\n, where \nEvent\n is either a pre-defined \nBlock\n or a \nGeneric\n event. More events will be defined in the future to include other elements of the fabric.\n\n\nmessage Generic {\n    string eventType = 1;\n    bytes payload = 2;\n}\n\n\n\n\nThe \neventType\n and \npayload\n are freely defined by the event producer. For example, JSON data may be used in the \npayload\n. The \nGeneric\n event may also be emitted by the chaincode or plugins to communicate with consumers.\n\n\n3.5.1.2 Event Consumer\n\n\nThe event consumer enables external applications to listen to events. Each event consumer registers an event adapter with the event stream. The consumer framework can be viewed as a bridge between the event stream and the adapter. A typical use of the event consumer framework is:\n\n\nadapter = \nadapter supplied by the client application to register and receive events\n\nconsumerClient = NewEventsClient(\nevent consumer address\n, adapter)\nconsumerClient.Start()\n...\n...\nconsumerClient.Stop()\n\n\n\n\n3.5.2 Event Adapters\n\n\nThe event adapter encapsulates three facets of event stream interaction:\n  - an interface that returns the list of all events of interest\n  - an interface called by the event consumer framework on receipt of an event\n  - an interface called by the event consumer framework when the event bus terminates\n\n\nThe reference implementation provides Golang specific language binding.\n\n\n      EventAdapter interface {\n         GetInterestedEvents() ([]*ehpb.Interest, error)\n         Recv(msg *ehpb.Event) (bool,error)\n         Disconnected(err error)\n      }\n\n\n\n\nUsing gRPC as the event bus protocol allows the event consumer framework to be ported to different language bindings without affecting the event producer framework.\n\n\n3.5.3 Event Structure\n\n\nThis section details the message structures of the event system. Messages are described directly in Golang for simplicity.\n\n\nThe core message used for communication between the event consumer and producer is the Event.\n\n\n    message Event {\n        oneof Event {\n            //consumer events\n            Register register = 1;\n\n            //producer events\n            Block block = 2;\n            Generic generic = 3;\n       }\n    }\n\n\n\n\nPer the above definition, an event has to be one of \nRegister\n, \nBlock\n or \nGeneric\n.\n\n\nAs mentioned in the previous sections, a consumer creates an event bus by establishing a connection with the producer and sending a \nRegister\n event. The \nRegister\n event is essentially an array of \nInterest\n messages declaring the events of interest to the consumer.\n\n\n    message Interest {\n        enum ResponseType {\n            //don't send events (used to cancel interest)\n            DONTSEND = 0;\n            //send protobuf objects\n            PROTOBUF = 1;\n            //marshall into JSON structure\n            JSON = 2;\n        }\n        string eventType = 1;\n        ResponseType responseType = 2;\n    }\n\n\n\n\nEvents can be sent directly as protobuf structures or can be sent as JSON structures by specifying the \nresponseType\n appropriately.\n\n\nCurrently, the producer framework can generate a \nBlock\n or a \nGeneric\n event. A \nBlock\n is a message used for encapsulating properties of a block in the blockchain.\n\n\n4. Security\n\n\nThis section discusses the setting depicted in the figure below.\nIn particular, the system consists of the following entities:\nmembership management infrastructure, i.e., a set of entities that are\nresponsible for identifying an individual user (using any form of identification\nconsidered in the system, e.g., credit cards, id-cards), open an account for\nthat user to be able to register, and issue the necessary credentials to\nsuccessfully create transactions and deploy or invoke chaincode successfully\nthrough the fabric.\n\n\n * Peers, that are classified as validating peers, and non-validating peers.\n   Validating peers (also known as validators) order and process (check validity, execute,\n   and add to the blockchain) user-messages (transactions) submitted to the network.\n   Non validating peers (also known as peers) receive user transactions on behalf of users,\n   and after some fundamental validity checks, they forward the transactions to their\n   neighboring validating peers. Peers maintain an up-to-date copy of the blockchain,\n   but in contradiction to validators, they do not execute transactions\n   (a process also known as \ntransaction validation\n).\n * End users of the system, that have registered to our membership service administration,\n   after having demonstrated ownership of what is considered \nidentity\n in the system,\n   and have obtained credentials to install the client-software and submit transactions\n   to the system.\n * Client-software, the software that needs to be installed at the client side for the\n   latter to be able to complete his registration to our membership service and submit\n   transactions to the system.\n * Online wallets, entities that are trusted by a user to maintain that user's credentials,\n   and submit transactions solely upon user request to the network. Online wallets come\n   with their own software at the client-side, that is usually light-weight, as the\n   client only needs to authenticate himself and his requests to the wallet.\n   While it can be the case that peers can play the role of \nonline wallet\n for a set of\n   users, in the following sessions the security of online wallets is detailed separately.\n\n\nUsers who wish to make use of the fabric, open an account at the membership management\nadministration, by proving ownership of identity as discussed in previous sections, new chaincodes\nare announced to the blockchain network by the chaincode creator (developer) through the means\nof a deployment transaction that the client-software would construct on behalf of the developer.\nSuch transaction is first received by a peer or validator, and afterwards circulated\nin the entire network of validators, this transaction is executed and finds its place to\nthe blockchain network. Users can also invoke a function of an already deployed chain-code\nthrough an invocation transaction.\n\n\nThe next section provides a summary of the business goals of the system that drive the security requirements. We then overview the security components and their operation and show how this design fulfills the security requirements.  \n\n\n4.1 Business security requirements\n\n\nThis section presents business security requirements that are relevant to the context of the fabric.\n\nIncorporation of identity and role management.\n\n\nIn order to adequately support real business applications it is necessary to progress beyond ensuring cryptographic continuity. A workable B2B system must consequently move towards addressing proven/demonstrated identities or other attributes relevant to conducting business. Business transactions and consumer interactions with financial institutions need to be unambiguously mapped to account holders. Business contracts typically require demonstrable affiliation with specific institutions and/or possession of other specific properties of transacting parties. Accountability and non-frameability are two reasons that identity management is a critical component of such systems.\n\n\nAccountability means that users of the system, individuals, or corporations, who misbehave can be traced back and be set accountable for their actions. In many cases, members of a B2B system are required to use their identities (in some form) to participate in the system, in a way such that accountability is guaranteed. Accountability and non-frameability are both essential security requirements in B2B systems and they are closely related. That is, a B2B system should guarantee that an honest user of such system cannot be framed to be accused as responsible for transactions originated by other users.\n\n\nIn addition a B2B system should be renewable and flexible in order to accommodate changes of participants\u2019s roles and/or affiliations.\n\n\nTransactional privacy.\n\n\nIn B2B relationships there is a strong need for transactional privacy, i.e., allowing the end-user of a system to control the degree to which it interacts and shares information with its environment. For example, a corporation doing business through a transactional B2B system requires that its transactions are not visible to other corporations or industrial partners that are not authorized to share classified information with.\n\n\nTransactional privacy in the fabric is offered by the mechanisms to achieve two properties with respect to non authorized users:\n\n\n\n\n\n\nTransaction anonymity, where the owner of a transaction is hidden among the so called \nanonymity set\n, which in the fabric, is the set of users.\n\n\n\n\n\n\nTransaction unlinkability, where two or more transactions of the same user should not be linked as such.\n\n\n\n\n\n\nClearly depending on the context, non-authorized users can be anyone outside the system, or a subset of users.\n\n\nTransactional privacy is strongly associated to the confidentiality of the content of a contractual agreement between two or more members of a B2B system, as well as to the anonymity and unlinkability of any authentication mechanism that should be in place within transactions.\n\n\nReconciling transactional privacy with identity management.\n\n\nAs described later in this document, the approach taken here to reconcile identity management with user privacy and to enable competitive institutions to transact effectively on a common blockchain (for both intra- and inter-institutional transactions) is as follows:\n\n\n\n\n\n\nadd certificates to transactions to implement a \u201cpermissioned\u201d blockchain\n\n\n\n\n\n\nutilize a two-level system:\n\n\n\n\n\n\n(relatively) static enrollment certificates (ECerts), acquired via registration with an enrollment certificate authority (CA).\n\n\n\n\n\n\ntransaction certificates (TCerts) that faithfully but pseudonymously represent enrolled users, acquired via a transaction CA.\n\n\n\n\n\n\noffer mechanisms to conceal the content of transactions to unauthorized members of the system.\n\n\n\n\n\n\nAudit support.\n Commercial systems are occasionally subjected to audits. Auditors in such cases should be given the means to check a certain transaction, or a certain group of transactions, the activity of a particular user of the system, or the operation of the system itself. Thus, such capabilities should be offered by any system featuring transactions containing contractual agreements between business partners.\n\n\n4.2 User Privacy through Membership Services\n\n\nMembership Services consists of an infrastructure of several entities that together manage the identity and privacy of users on the network. These services validate user\u2019s identity, register the user in the system, and provide all the credentials needed for him/her to be an active and compliant participant able to create and/or invoke transactions. A Public Key Infrastructure (PKI) is a framework based on public key cryptography that ensures not only the secure exchange of data over public networks but also affirms the identity of the other party. A PKI manages the generation, distribution and revocation of keys and digital certificates. Digital certificates are used to establish user credentials and to sign messages. Signing messages with a certificate ensures that the message has not been altered. Typically a PKI has a Certificate Authority (CA), a Registration Authority (RA), a certificate database, and a certificate storage. The RA is a trusted party that authenticates users and vets the legitimacy of data, certificates or other evidence submitted to support the user\u2019s request for one or more certificates that reflect that user\u2019s identity or other properties. A CA, upon advice from an RA, issues digital certificates for specific uses and is certified directly or hierarchically by a root CA. Alternatively, the user-facing communications and due diligence responsibilities of the RA can be subsumed as part of the CA. Membership Services is composed of the entities shown in the following figure. Introduction of such full PKI reinforces the strength of this system for B2B (over, e.g. Bitcoin).\n\n\n\n\nRoot Certificate Authority (Root CA):\n entity that represents the trust anchor for the PKI scheme. Digital certificates verification follows a chain of trust. The Root CA is the top-most CA in the PKI hierarchy.\n\n\nRegistration Authority (RA):\n a trusted entity that can ascertain the validity and identity of users who want to participate in the permissioned blockchain. It is responsible for out-of-band communication with the user to validate his/her identity and role.  It creates registration credentials needed for enrollment and information on root of trust.\n\n\nEnrollment Certificate Authority (ECA):\n  responsible for issuing Enrollment Certificates (ECerts) after validating the registration credentials provided by the user.\n\n\nTransaction Certificate Authority (TCA):\n responsible for issuing Transaction Certificates (TCerts) after validating the enrollment credentials provided by the user.  \n\n\nTLS Certificate Authority (TLS-CA):\n responsible for issuing TLS certificates and credentials that allow the user to make use of its network. It validates the credential(s) or evidence provided by the user that justifies issuance of a TLS certificate that includes specific information pertaining to the user.\n\n\nIn this specification, membership services is expressed through the following associated certificates issued by the PKI:\n\n\nEnrollment Certificates (ECerts)\n\nECerts are long-term certificates. They are issued for all roles, i.e. users, non-validating peers, and validating peers. In the case of users, who submit transactions for candidate incorporation into the blockchain and who also own TCerts (discussed below), there are two possible structure and usage models for ECerts:\n\n\n\n\n\n\nModel A:  ECerts contain the identity/enrollmentID of their owner and can be used to offer only nominal entity-authentication for TCert requests and/or within transactions. They contain the public part of two key pairs \u2013 a signature key-pair and an encryption/key agreement key-pair. ECerts are accessible to everyone.\n\n\n\n\n\n\nModel B: ECerts contain the identity/enrollmentID of their owner and can be used to offer only nominal entity-authentication for TCert requests. They contain the public part of a signature key-pair, i.e., a signature verification public key. ECerts are preferably accessible to only TCA and auditors, as relying parties. They are invisible to transactions, and thus (unlike TCerts) their signature key pairs do not play a non-repudiation role at that level.\n\n\n\n\n\n\nTransaction Certificates (TCerts)\n\nTCerts are short-term certificates for each transaction. They are issued by the TCA upon authenticated user-request. They securely authorize a transaction and may be configured to not reveal the identities of who is involved in the transaction or to selectively reveal such identity/enrollmentID information. They include the public part of a signature key-pair, and may be configured to also include the public part of a key agreement key pair. They are issued only to users. They are uniquely associated to the owner \u2013 they may be configured so that this association is known only by the TCA (and to authorized auditors). TCerts may be configured to not carry information of the identity of the user. They enable the user not only to anonymously participate in the system but also prevent linkability of transactions.\n\n\nHowever, auditability and accountability requirements assume that the TCA is able to retrieve TCerts of a given identity, or retrieve the owner of a specific TCert. For details on how TCerts are used in deployment and invocation transactions see Section 4.3, Transaction Security offerings at the infrastructure level.  \n\n\nTCerts can accommodate encryption or key agreement public keys (as well as digital signature verification public keys).\nIf TCerts are thus equipped, then enrollment certificates need not also contain encryption or key agreement public keys.\n\n\nSuch a key agreement public key, Key_Agreement_TCertPub_Key, can be generated by the transaction certificate authority (TCA) using a method that is the same as that used to generate the Signature_Verification_TCertPub_Key, but using an index value of TCertIndex + 1 rather than TCertIndex, where TCertIndex is hidden within the TCert by the TCA for recovery by the TCert owner.\n\n\nThe structure of a Transaction Certificate (TCert) is as follows:\n\n TCertID \u2013 transaction certificate ID (preferably generated by TCA randomly in order to avoid unintended linkability via the Hidden Enrollment ID field).\n\n Hidden Enrollment ID: AES_Encrypt\nK\n(enrollmentID), where key K = [HMAC(Pre-K, TCertID)]\n256-bit truncation\n and where three distinct key distribution scenarios for Pre-K are defined below as (a), (b) and (c).\n\n Hidden Private Keys Extraction: AES_Encrypt\nTCertOwner_EncryptKey\n(TCertIndex || known padding/parity check vector) where || denotes concatenation, and where each batch has a unique (per batch) time-stamp/random offset that is added to a counter (initialized at 1 in this implementation) in order to generate TCertIndex. The counter can be incremented by 2 each time in order to accommodate generation by the TCA of the public keys and recovery by the TCert owner of the private keys of both types, i.e., signature key pairs and key agreement key pairs.\n\n Sign Verification Public Key \u2013 TCert signature verification public key.\n\n Key Agreement Public Key \u2013 TCert key agreement public key.\n\n Validity period \u2013 the time window during which the transaction certificate can be used for the outer/external signature of a transaction.\n\n\nThere are at least three useful ways to consider configuring the key distribution scenario for the Hidden Enrollment ID field:\n\n(a)\n Pre-K is distributed during enrollment to user clients, peers and auditors, and is available to the TCA and authorized auditors. It may, for example, be derived from K\nchain\n (described subsequently in this specification) or be independent of key(s) used for chaincode confidentiality.\n\n\n(b)\n Pre-K is available to validators, the TCA and authorized auditors. K is made available by a validator to a user (under TLS) in response to a successful query transaction. The query transaction can have the same format as the invocation transaction. Corresponding to Example 1 below, the querying user would learn the enrollmentID of the user who created the Deployment Transaction if the querying user owns one of the TCerts in the ACL of the Deployment Transaction. Corresponding to Example 2 below, the querying user would learn the enrollmentID of the user who created the Deployment Transaction if the enrollmentID of the TCert used to query matches one of the affiliations/roles in the Access Control field of the Deployment Transaction.\n\n\nExample 1:\n\n\n\n\nExample 2:\n\n\n\n\n(c)\n Pre-K is available to the TCA and authorized auditors. The TCert-specific K can be distributed the TCert owner (under TLS) along with the TCert, for each TCert in the batch. This enables targeted release by the TCert owner of K (and thus trusted notification of the TCert owner\u2019s enrollmentID). Such targeted release can use key agreement public keys of the intended recipients and/or PK\nchain\n where SK\nchain\n is available to validators as described subsequently in this specification. Such targeted release to other contract participants can be incorporated into a transaction or done out-of-band.\n\n\nIf the TCerts are used in conjunction with ECert Model A above, then using (c) where K is not distributed to the TCert owner may suffice.\nIf the TCerts are used in conjunction with ECert Model A above, then the Key Agreement Public Key field of the TCert may not be necessary.\n\n\nThe Transaction Certificate Authority (TCA) returns TCerts in batches, each batch contains the KeyDF_Key (Key-Derivation-Function Key) which is not included within every TCert but delivered to the client with the batch of TCerts (using TLS). The KeyDF_Key allows the TCert owner to derive TCertOwner_EncryptKey which in turn enables recovery of TCertIndex from AES_Encrypt\nTCertOwner_EncryptKey\n(TCertIndex || known padding/parity check vector).\n\n\nTLS-Certificates (TLS-Certs)\n\nTLS-Certs are certificates used for system/component-to-system/component communications. They carry the identity of their owner and are used for network level security.\n\n\nThis implementation of membership services provides the following basic functionality: there is no expiration/revocation of ECerts; expiration of TCerts is provided via the validity period time window; there is no revocation of TCerts. The ECA, TCA, and TLS CA certificates are self-signed, where the TLS CA is provisioned as a trust anchor.\n\n\n4.2.1 User/Client Enrollment Process\n\n\nThe next figure has a high-level description of the user enrollment process. It has an offline and an online phase.\n\n\n\n\nOffline Process:\n in Step 1, each user/non-validating peer/validating peer has to present strong identification credentials (proof of ID) to a Registration Authority (RA) offline. This has to be done out-of-band to provide the evidence needed by the RA to create (and store) an account for the user. In Step 2, the RA returns the associated username/password and trust anchor (TLS-CA Cert in this implementation) to the user. If the user has access to a local client then this is one way the client can be securely provisioned with the TLS-CA certificate as trust anchor.\n\n\nOnline Phase:\n In Step 3, the user connects to the client to request to be enrolled in the system. The user sends his username and password to the client. On behalf of the user, the client sends the request to the PKI framework, Step 4, and receives a package, Step 5, containing several certificates, some of which should correspond to private/secret keys held by the client. Once the client verifies that the all the crypto material in the package is correct/valid, it stores the certificates in local storage and notifies the user. At this point the user enrollment has been completed.\n\n\n\n\nFigure 4 shows a detailed description of the enrollment process. The PKI framework has the following entities \u2013 RA, ECA, TCA and TLS-CA. After Step 1, the RA calls the function \u201cAddEntry\u201d to enter the (username/password) in its database. At this point the user has been formally registered into the system database. The client needs the TLS-CA certificate (as trust anchor) to verify that the TLS handshake is set up appropriately with the server. In Step 4, the client sends the registration request to the ECA along with its enrollment public key and additional identity information such as username and password (under the TLS record layer protocol). The ECA verifies that such user really exists in the database. Once it establishes this assurance the user has the right to submit his/her enrollment public key and the ECA will certify it. This enrollment information is of a one-time use. The ECA updates the database marking that this registration request information (username/password) cannot be used again. The ECA constructs, signs and sends back to the client an enrollment certificate (ECert) that contains the user\u2019s enrollment public key (Step 5). It also sends the ECA Certificate (ECA-Cert) needed in future steps (client will need to prove to the TCA that his/her ECert was created by the proper ECA). (Although the ECA-Cert is self-signed in the initial implementation, the TCA and TLS-CA and ECA are co-located.) The client verifies, in Step 6, that the public key inside the ECert is the one originally submitted by the client (i.e. that the ECA is not cheating). It also verifies that all the expected information within the ECert is present and properly formed.\n\n\nSimilarly, In Step 7, the client sends a registration request to the TLS-CA along with its public key and identity information. The TLS-CA verifies that such user is in the database. The TLS-CA generates, and signs a TLS-Cert that contains the user\u2019s TLS public key (Step 8). TLS-CA sends the TLS-Cert and its certificate (TLS-CA Cert). Step 9 is analogous to Step 6, the client verifies that the public key inside the TLS Cert is the one originally submitted by the client and that the information in the TLS Cert is complete and properly formed. In Step 10, the client saves all certificates in local storage for both certificates. At this point the user enrollment has been completed.\n\n\nIn this implementation the enrollment process for validators is the same as that for peers. However, it is possible that a different implementation would have validators enroll directly through an on-line process.\n\n\n\n\n\n\nClient:\n Request for TCerts batch needs to include (in addition to count), ECert and signature of request using ECert private key (where Ecert private key is pulled from Local Storage).\n\n\nTCA generates TCerts for batch:\n Generates key derivation function key, KeyDF_Key, as HMAC(TCA_KDF_Key, EnrollPub_Key). Generates each TCert public key (using TCertPub_Key = EnrollPub_Key + ExpansionValue G, where 384-bit ExpansionValue = HMAC(Expansion_Key, TCertIndex) and 384-bit Expansion_Key = HMAC(KeyDF_Key, \u201c2\u201d)). Generates each AES_Encrypt\nTCertOwner_EncryptKey\n(TCertIndex || known padding/parity check vector), where || denotes concatenation and where TCertOwner_EncryptKey is derived as [HMAC(KeyDF_Key, \u201c1\u201d)]\n256-bit truncation\n.\n\n\nClient:\n Deriving TCert private key from a TCert in order to be able to deploy or invoke or query: KeyDF_Key and ECert private key need to be pulled from Local Storage. KeyDF_Key is used to derive TCertOwner_EncryptKey as [HMAC(KeyDF_Key, \u201c1\u201d)]\n256-bit truncation\n; then TCertOwner_EncryptKey is used to decrypt the TCert field AES_Encrypt\nTCertOwner_EncryptKey\n(TCertIndex || known padding/parity check vector); then TCertIndex is used to derive TCert private key: TCertPriv_Key = (EnrollPriv_Key + ExpansionValue) modulo n, where 384-bit ExpansionValue = HMAC(Expansion_Key, TCertIndex) and 384-bit Expansion_Key = HMAC(KeyDF_Key, \u201c2\u201d).\n\n\n4.2.2 Expiration and revocation of certificates\n\n\nIt is practical to support expiration of transaction certificates. The time window during which a transaction certificate can be used is expressed by a \u2018validity period\u2019 field. The challenge regarding support of expiration lies in the distributed nature of the system. That is, all validating entities must share the same information; i.e. be consistent with respect to the expiration of the validity period associated with the transactions to be executed and validated. To guarantee that the expiration of validity periods is done in a consistent manner across all validators, the concept of validity period identifier is introduced. This identifier acts as a logical clock enabling the system to uniquely identify a validity period. At genesis time the \u201ccurrent validity period\u201d of the chain gets initialized by the TCA. It is essential that this validity period identifier is given monotonically increasing values over time, such that it imposes a total order among validity periods.\n\n\nA special type of transactions, system transactions, and the validity period identified are used together to announce the expiration of a validity period to the Blockchain. System transactions refer to contracts that have been defined in the genesis block and are part of the infrastructure. The validity period identified is updated periodically by the TCA invoking a system chaincode. Note that only the TCA should be allowed to update the validity period. The TCA sets the validity period for each transaction certificate by setting the appropriate integer values in the following two fields that define a range: \u2018not-before\u2019 and \u2018not-after\u2019 fields.\n\n\nTCert Expiration:\nAt the time of processing a TCert, validators read from the state table associated with the ledger the value of \u2018current validity period\u2019 to check if the outer certificate associated with the transaction being evaluated is currently valid. That is, the current value in the state table has to be within the range defined by TCert sub-fields \u2018not-before\u2019 and \u2018not-after\u2019. If this is the case, the validator continues processing the transaction. In the case that the current value is not within range, the TCert has expired or is not yet valid and the validator should stop processing the transaction.\n\n\nECert Expiration:\nEnrollment certificates have different validity period length(s) than those in transaction certificates.\n\n\nRevocation is supported in the form of Certificate Revocation Lists (CRLs). CRLs identify revoked certificates. Changes to the CRLs, incremental differences, are announced through the Blockchain.\n\n\n4.3 Transaction security offerings at the infrastructure level\n\n\nTransactions in the fabric are user-messages submitted to be included\nin the ledger. As discussed in previous sections, these messages have a\nspecific structure, and enable users to deploy new chaincodes, invoke existing\nchaincodes, or query the state of existing chaincodes.\nTherefore, the way transactions are formed, announced and processed plays\nan important role to the privacy and security offerings of the entire system.\n\n\nOn one hand our membership service provides the means to authenticate transactions as\nhaving originated by valid users of the system, to disassociate transactions with user identities,\nbut while efficiently tracing the transactions a particular individual under certain conditions\n(law enforcement, auditing). In other words, membership services offer to transactions authentication\nmechanisms that marry user-privacy with accountability and non-repudiation.\n\n\nOn the other hand, membership services alone cannot offer full privacy of user-activities within\nthe fabric. First of all, for privacy provisions offered by the fabric to be complete,\nprivacy-preserving authentication mechanisms need to be accompanied by transaction confidentiality.\nThis becomes clear if one considers that the content of a chaincode, may leak information on who may have\ncreated it, and thus break the privacy of that chaincode's creator. The first subsection\ndiscusses transaction confidentiality.\n\n\n\n\n\n\n\n\nEnforcing access control for the invocation of chaincode is an important security requirement.\nThe fabric exposes to the application (e.g., chaincode creator) the means for the application\nto perform its own invocation access control, while leveraging the fabric's membership services.\nSection 4.4 elaborates on this.\n\n\n\n\n\nReplay attacks is another crucial aspect of the security of the chaincode,\nas a malicious user may copy a transaction that was added to the Blockchain\nin the past, and replay it in the network to distort its operation.\nThis is the topic of Section 4.3.3.\n\n\nThe rest of this Section presents an overview of how security mechanisms in the\ninfrastructure are incorporated in the transactions' lifecycle,\nand details each security mechanism separately.\n\n\n4.3.1 Security Lifecycle of Transactions\n\n\nTransactions are created on the client side. The client can be either plain\nclient, or a more specialized application, i.e., piece of\nsoftware that handles (server) or invokes (client) specific chaincodes\nthrough the blockchain. Such applications are built on top of the\nplatform (client) and are detailed in Section 4.4.\n\n\nDevelopers of new chaincodes create a new deploy transaction by passing to\nthe fabric infrastructure:\n\n the confidentiality/security version or type they want the transaction to conform with,\n\n the set of users who wish to be given access to parts of the chaincode and\n  a proper representation of their (read) access rights\n\n\n\n the chaincode specification,\n\n code metadata, containing information that should be passed to the chaincode\n  at the time of its execution\n  (e.g., configuration parameters), and\n* transaction metadata, that is attached to the transaction structure,\n  and is only used by the application that deployed the chaincode.\n\n\nInvoke and query transactions corresponding to chaincodes with confidentiality\nrestrictions are created using a similar approach. The transactor provides the\nidentifier of the chaincode to be executed, the name of the function to be\ninvoked and its arguments. Optionally, the invoker can pass to the\ntransaction creation function, code invocation metadata, that will be provided\nto the chaincode at the time of its execution. Transaction metadata is another\nfield that the application of the invoker or the invoker himself can leverage\nfor their own purposes.\n\n\nFinally transactions at the client side, are signed by a certificate of their\ncreator and released to the network of validators.\nValidators receive the confidential transactions, and pass them through the following phases:\n\n \npre-validation\n phase, where validators validate the transaction certificate against the accepted root certificate authority,\n  verify transaction certificate signature included in the transaction (statically), and check whether the transaction is a replay (see, later section for details on replay attack protection).\n\n \nconsensus\n phase, where the validators add this transaction to the total order of transactions (ultimately included in the ledger)\n\n \npre-execution\n phase, where validators verify the validity of the transaction / enrollment certificate against the current validity period,\n  decrypt the transaction (if the transaction is encrypted), and check that the transaction's plaintext is correctly formed(e.g., invocation access control is respected, included TCerts are correctly formed);\n  mini replay-attack check is also performed here within the transactions of the currently processed block.\n\n \nexecution\n phase, where the (decrypted) chaincode is passed to a container, along with the associated code metadata, and is executed\n\n \ncommit* phase, where (encrypted) updates of that chaincodes state is committed to the ledger with the transaction itself.\n\n\n4.3.2 Transaction confidentiality\n\n\nTransaction confidentiality requires that under the request of the developer, the plain-text\nof a chaincode, i.e., code, description, is not accessible or inferable (assuming a computational\nattacker) by any unauthorized entities(i.e., user or peer not authorized by the developer).\nFor the latter, it is important that for chaincodes with confidentiality requirements the\ncontent of both \ndeploy\n and \ninvoke\n transactions remains concealed. In the same spirit,\nnon-authorized parties, should not be able to associate invocations (invoke transactions) of a\nchaincode to the chaincode itself (deploy transaction) or these invocations to each other.\n\n\nAdditional requirements for any candidate solution is that it respects and supports the privacy\nand security provisions of the underlying membership service. In addition, it should not prevent\nthe enforcement of any invocation access control of the chain-code functions in the fabric, or\nthe implementation of enforcement of access-control mechanisms on the application (See Subsection 4.4).\n\n\nIn the following is provided the specification of transaction confidentiality\nmechanisms at the granularity of users. The last subsection provides some guidelines\non how to extend this functionality at the level of validators.\nInformation on the features supported in current release and its security\nprovisions, you can find in Section 4.7.\n\n\nThe goal is to achieve a design that will allow for granting or restricting\naccess to an entity to any subset of the following parts of a chain-code:\n1. chaincode content, i.e., complete (source) code of the\n   chaincode,\n\n\n2. chaincode function headers, i.e., the prototypes of the functions included in a chaincode,\n\n\n\n\n3. chaincode [invocations \n] state, i.e., successive updates to the state of a specific chaincode,\n   when one or more functions of its are invoked\n4. all the above\n\n\nNotice, that this design offers the application the capability to leverage the fabric's\nmembership service infrastructure and its public key infrastructure to build their own access\ncontrol policies and enforcement mechanisms.\n\n\n4.3.2.1 Confidentiality against users\n\n\nTo support fine-grained confidentiality control, i.e., restrict read-access to the\nplain-text of a chaincode to a subset of users that the chaincode creator\ndefines, a chain is bound to a single long-term encryption key-pair\n(PK\nchain\n, SK\nchain\n).\nThough initially this key-pair is to be stored and maintained by each chain's\nPKI, in later releases, however, this restriction will be moved away,\nas chains (and the associated key-pairs) can be triggered through the Blockchain\nby any user with \nspecial\n (admin) privileges (See, Section 4.3.2.2).\n\n\nSetup\n. At enrollment phase, users obtain (as before) an enrollment certificate,\ndenoted by Cert\nu\ni\n for user u\ni\n, while each\nvalidator v\nj\n obtain its enrollment certificate denoted by\nCert\nv\nj\n. Enrollment would grant users and validators the\nfollowing credentials:\n\n\n\n\nUsers:\n\n\n\n\na. claim and grant themselves signing key-pair (spk\nu\n, ssk\nu\n),\n\n\nb. claim and grant themselves encryption key-pair (epk\nu\n, esk\nu\n),\n\n\nc. obtain the encryption (public) key of the chain PK\nchain\n\n\n\n\nValidators:\n\n\n\n\na. claim and grant themselves signing key-pair (spk\nv\n, ssk\nv\n),\n\n\nb. claim and grant themselves an encryption key-pair (epk\nv\n, esk\nv\n),\n\n\nc. obtain the decryption (secret) key of the chain SK\nchain\n\n\nThus, enrollment certificates contain the public part of two key-pairs:\n\n one signature key-pair [denoted by (spk\nv\nj\n,ssk\nv\nj\n)\n  for validators and by (spk\nu\ni\n, ssk\nu\ni\n) for users], and\n\n an encryption key-pair [denoted by (epk\nv\nj\n,esk\nv\nj\n)\n  for validators and (epk\nu\ni\n, esk\nu\ni\n) for users]\n\n\nChain, validator and user enrollment public keys are accessible to everyone.\n\n\nIn addition to enrollment certificates, users who wish to anonymously\nparticipate in transactions issue transaction certificates. For simplicity\ntransaction certificates of a user u\ni\n are denoted by\nTCert\nu\ni\n. Transaction certificates include the public part\nof a signature key-pair denoted by\n\n(tpk\nu\ni\n,tsk\nu\ni\n).\n\n\nThe following section provides a high level description of how transaction\nformat accommodates read-access restrictions at the granularity of users.\n\n\nStructure of deploy transaction.\n\nThe following figure depicts the structure of a typical deploy\ntransaction with confidentiality enabled.\n\n\n\n\nOne can notice that a deployment transaction consists of several sections:\n\n Section \ngeneral-info\n: contains the administration details of the\n  transaction, i.e., which chain this transaction corresponds to (chained),\n  the type of transaction (that is set to ''deplTrans''), the version number of\n  confidentiality policy implemented, its creator identifier (expressed by means\n  of transaction certificate TCert of enrollment certificate Cert), and a Nonce,\n  that facilitates primarily replay-attack resistance techniques.\n\n Section \ncode-info\n: contains information on the chain-code source code,\n  and function headers. As shown in the figure below, there is a symmetric key\n  used for the source-code of the chaincode (K\nC\n), and another\n  symmetric key used for the function prototypes (K\nH\n). A signature of\n  the creator of the chaincode is included on the plain-text code such that\n  the latter cannot be detached from the transaction and replayed by another\n  party.\n\n Section \nchain-validators\n: where appropriate key material is passed to the\n  validators for the latter to be able to (i) decrypt the chain-code source\n  (K\nC\n), (ii) decrypt the headers,  and\n  (iii) encrypt the state when the chain-code has been\n  invoked accordingly(K\nS\n). In particular, the chain-code creator\n  generates an encryption key-pair for the chain-code it deploys\n  (PK\nC\n, SK\nC\n). It then uses PK\nC\n\n  to encrypt all the keys associated to the chain-code:\n  \n [(''code'',K\nC\n) ,(''headr'',K\nH\n),(''code-state'',K\nS\n), Sig\nTCert\nu\nc\n(*)]\nPK\nc\n, \n\n  and passes the secret key SK\nC\n to the validators using the\n  chain-specific public key:\n  \n[(''chaincode'',SK\nC\n), Sig\nTCert\nu\nc\n(\n)]\nPK\nchain\n.\n\n\n Section \ncontract-users*: where the public encryption keys of the contract users,\n  i.e., users who are given read-access to parts of the chaincode, are used to encrypt\n  the keys  associated to their access rights:\n\n\n\n\n\n\nSK\nc\n for the users to be able to read any message associated to\n     that chain-code (invocation, state, etc),\n\n\n\n\n\n\nK\nC\n for the user to be able to read only the contract code,\n\n\n\n\n\n\nK\nH\n for the user to only be able to read the headers,\n\n\n\n\n\n\nK\nS\n for the user to be able to read the state associated to that contract.\n\n\n\n\n\n\nFinally users are given the contract's public key PK\nc\n,\n  for them to be able to encrypt information related to that contract for the validators\n  (or any in possession of SK\nc\n) to be able to read it. Transaction certificate\n  of each contract user is appended to the transaction and follows that user's message.\n  This is done for users to be able to easily search the blockchain\n  for transactions they have been part of. Notice that the deployment transaction also\n  appends a message to the creator u\nc\n of the chain-code, for the\n  latter to be able to retrieve this transaction through parsing the ledger and without\n  keeping any state locally.\n\n\nThe entire transaction is signed by a certificate of the chaincode creator, i.e., enrollment\nor transaction certificate as decided by the latter.\nTwo noteworthy points:\n\n Messages that are included in a transaction in an encrypted format, i.e., code-functions, code-hdrs,\n  are signed before they are encrypted using the same TCert the entire transaction is signed with, or\n  even with a different TCert or the ECert of the user (if the transaction deployment should carry the identity\n  of its owner. A binding to the underlying transaction carrier should be included in the signed message, e.g.,\n  the hash of the TCert the transaction is signed, such that mix\\\nmatch attacks are not possible.\n  Though we detail such attacks in Section 4.4, in these cases an attacker who sees a transaction should not be able\n  to isolate the ciphertext corresponding to, e.g., code-info, and use it for another transaction of her own.\n  Clearly, such an ability would disrupt the operation of the system, as a chaincode that was first created by user A,\n  will now also belong to malicious user B (who is not even able to read it).\n\n To offer the ability to the users to cross-verify they are given access to the\n  correct key, i.e., to the same key as the other contract users, transaction\n  ciphertexts that are encrypted with a key K are accompanied by a commitment\n  to K, while the opening of this commitment value is passed to all users who\n  are entitled access to K in contract-users, and chain-validator sections.\n  \n\n  In this way, anyone who is entitled access to that key can verify that the key\n  has been properly passed to it. This part is omitted in the figure above to\n  avoid confusion.\n\n\nStructure of invoke transaction.\n\nA transaction invoking the chain-code triggering the execution of a function of the chain-code with\nuser-specified arguments is structured as depicted in the figure below.\n\n\n\n\nInvocation transaction as in the case of deployment transaction consists of a\n\ngeneral-info\n section, a \ncode-info\n section, a section for the \nchain-validators\n,\nand one for the \ncontract users\n, signed altogether with one of the invoker's\ntransaction certificates.\n\n\n\n\n\n\nGeneral-info follows the same structure as the corresponding section of the\ndeployment transaction.\nThe only difference relates to the transaction type that is now set to ''InvocTx'',\nand the chain-code identifier or name that is now encrypted under the\nchain-specific encryption (public) key.\n\n\n\n\n\n\nCode-info exhibits the same structure as the one of the deployment transaction.\nCode payload, as in the case of deployment transaction, consists of function\ninvocation details (the name of the function invoked, and associated arguments),\ncode-metadata provided by the application and the transaction's creator\n(invoker's u) certificate, TCert\nu\n. Code payload is signed by the\ntransaction certificate TCert\nu\n of the invoker u, as in the case\nof deploy transactions. As in the case of\ndeploy transactions, code-metadata, and tx-metadata, are fields that are\nprovided by the application and can be used (as described in Section 4.4),\nfor the latter to implement their own access control mechanisms and roles.\n\n\n\n\n\n\nFinally, contract-users and chain-validator sections provide the key the payload\nis encrypted with, the invoker's key, and the chain encryption key respectively.\nUpon receiving such transactions, the validators decrypt [code-name]\nPK\nchain\n using the\nchain-specific secret key SK\nchain\n and obtain the invoked chain-code identifier.\nGiven the latter, validators retrieve from their local storage the chaincode's\ndecryption key SK\nc\n, and use it to decrypt chain-validators' message,\nthat would equip them with the symmetric key K\nI\n the invocation\ntransaction's payload was encrypted with.\nGiven the latter, validators decrypt code-info, and execute the chain-code\nfunction with the specified arguments,\nand the code-metadata attached(See, Section 4.4 for more details on the use of\ncode-metadata). While the chain-code is executed, updates of the state of that\nchain-code are possible.\nThese are encrypted using the state-specific key K\ns\n that was defined\nduring that chain-code's deployment. In particular, K\ns\n is used the\nsame way K\niTx\n is used in the design of our current release\n(See, Section 4.7).  \n\n\n\n\n\n\nStructure of query transaction.\n\nQuery transactions have the same format as invoke transactions.\nThe only difference is that Query transactions do not affect the state\nof the chaincode, and thus there is no need for the state to be retrieved\n(decrypted) and/or updated (encrypted) after the execution of the chaincode\ncompletes.\n\n\n4.3.2.2 Confidentiality against validators\n\n\nThis section deals with ways of how to support execution of certain transactions\nunder a different (or subset) sets of validators in the current chain. This\nsection inhibits IP restrictions and will be expanded in the following few weeks.\n\n\n4.3.3 Replay attack resistance\n\n\nIn replay attacks the attacker \"replays\" a message it \"eavesdropped\" on the network or ''saw'' on the Blockchain.\nReplay attacks are a big problem here, as they can incur into the validating entities re-doing a computationally intensive\nprocess (chaincode invocation) and/or affect the state of the corresponding chaincode, while it requires minimal or no\npower from the attacker side.  To make matters worse, if a transaction was a payment transaction, replays could\npotentially incur into the payment being performed more than once, without this being the original intention of the payer.\nExisting systems resist replay attacks as follows:\n\n Record hashes of transactions in the system. This solution would require that validators maintain a log of the hash of\n  each transaction that has ever been announced through the network, and compare a new transaction against their locally\n  stored transaction record. Clearly such approach cannot scale for large networks, and could easily result into validators\n  spending a lot of time to do the check of whether a transaction has been replayed, than executing the actual transaction.\n\n Leverage state that is maintained per user identity (Ethereum). Ethereum keeps some state, e.g., counter (initially set to 1)\n  for each identity/pseudonym in the system. Users also maintain their own counter (initially set to 0) for each\n  identity/pseudonym of theirs. Each time a user sends a transaction using an identity/pseudonym of his, he increases\n  his local counter by one and adds the resulting value to the transaction. The transaction is subsequently signed by that\n  user identity and released to the network. When picking up this transaction, validators check the counter value included\n  within and compare it with the one they have stored locally; if the value is the same, they increase the local value of\n  that identity's counter and accept the transaction. Otherwise, they reject the transaction as invalid or replay.\n\n  Although this would work well in cases where we have limited number of user identities/pseudonyms (e.g., not too large),\n  it would ultimately not scale in a system where users use a different identifier (transaction certificate) per transaction,\n  and thus have a number of user pseudonyms proportional to the number of transactions.\n\n\nOther asset management systems, e.g., Bitcoin, though not directly dealing with replay attacks, they resist them. In systems\nthat manage (digital) assets, state is maintained on a per asset basis, i.e., validators only keep a record of who owns what.\nResistance to replay attacks come as a direct result from this, as replays of transactions would be immediately be\ndeemed as invalid by the protocol (since can only be shown to be derived from older owners of an asset/coin). While this would\nbe appropriate for asset management systems, this does not abide with the needs of a Blockchain systems with more generic\nuse than asset management.\n\n\nIn the fabric, replay attack protection uses a hybrid approach.\nThat is, users add in the transaction a nonce that is generated in a different manner\ndepending on whether the transaction is anonymous (followed and signed by a transaction certificate) or not\n(followed and signed by a long term enrollment certificate). More specifically:\n\n\n\n\nUsers submitting a transaction with their enrollment certificate should include in that\n  transaction a nonce that is a function of the nonce they used in the previous transaction\n  they issued with the same certificate (e.g., a counter function or a hash). The nonce included\n  in the first transaction of each enrollment certificate can be either pre-fixed by the system\n  (e.g., included in the genesis block) or chosen by the user. In the first case, the genesis block\n  would need to include nonceall , i.e., a fixed number and the nonce used by user with identity\n  IDA for his first enrollment certificate signed transaction would be\n  \nnonce\nround\n0\nIDA\n \n- hash(IDA, nonce\nall\n),\n\n  where IDA appears in the enrollment certificate. From that point onward successive transactions of\n  that user with enrollment certificate would include a nonce as follows\n  \nnonce\nround\ni\nIDA\n \n- hash(nonce\nround\n{i-1}\nIDA\n),\n\n  that is the nonce of the ith transaction would be using the hash of the nonce used in the {i-1}th transaction of that certificate.\n  Validators here continue to process a transaction they receive, as long as it satisfies the condition mentioned above.\n  Upon successful validation of transaction's format, the validators update their database with that nonce.\n\n\n\n\nStorage overhead\n:\n\n\n\n\n\n\non the user side: only the most recently used nonce,\n\n\n\n\n\n\non validator side: O(n), where n is the number of users.\n\n\n\n\nUsers submitting a transaction with a transaction certificate\n  should include in the transaction a random nonce, that would guarantee that\n  two transactions do not result into the same hash. Validators add the hash of\n  this transaction in their local database if the transaction certificate used within\n  it has not expired. To avoid storing large amounts of hashes, validity periods of transaction certificates\n  are leveraged. In particular validators maintain an updated record of received\n  transactions' hashes within the current or future validity period.\n\n\n\n\nStorage overhead\n (only makes sense for validators here):  O(m), where m is the approximate number of\n  transactions within a validity period and corresponding validity period identifier (see below).\n\n\n4.4 Access control features on the application\n\n\nAn application, is a piece of software that runs on top of a Blockchain client software, and,\nperforms a special task over the Blockchain, i.e., restaurant table reservation.\nApplication software have a version of\ndeveloper, enabling the latter to generate and manage a couple of chaincodes that are necessary for\nthe business this application serves, and a client-version that would allow the application's end-users\nto make use of the application, by invoking these chain-codes.\nThe use of the Blockchain can be transparent to the application end-users or not.\n\n\nThis section describes how an application leveraging chaincodes can implement its own access control policies,\nand guidelines on how our Membership services PKI can be leveraged for the same purpose.\n\n\nThe presentation is divided into enforcement of invocation access control,\nand enforcement of read-access control by the application.\n\n\n4.4.1 Invocation access control\n\n\nTo allow the application to implement its own invocation access control at the\napplication layer securely, special support by the fabric must be provided.\nIn the following we elaborate on the tools exposed by the fabric to the\napplication for this purpose, and provide guidelines on how these should be used\nby the application for the latter to enforce access control securely.\n\n\nSupport from the infrastructure.\n\nFor the chaincode creator, let it be, \nu\nc\n,\nto be able to implement its own invocation access control at\nthe application layer securely, special support by the fabric must be provided.\nMore specifically fabric layer gives access to following capabilities:\n\n\n\n\n\n\nThe client-application can request the fabric to sign and verify any message with specific transaction certificates or enrollment certificate the client owns; this is expressed via the Certificate Handler interface\n\n\n\n\n\n\nThe client-application can request the fabric a unique \nbinding\n to be used to bind authentication data of the application to the underlying transaction transporting it; this is expressed via the Transaction Handler interface\n\n\n\n\n\n\nSupport for a transaction format, that allows for the application to specify metadata, that are passed to the chain-code at deployment, and invocation time; the latter denoted by code-metadata.\n\n\n\n\n\n\nThe \nCertificate Handler\n interface allows to sign and verify any message using signing key-pair underlying the associated certificate.\nThe certificate can be a TCert or an ECert.\n\n\n// CertificateHandler exposes methods to deal with an ECert/TCert\ntype CertificateHandler interface {\n\n    // GetCertificate returns the certificate's DER\n    GetCertificate() []byte\n\n    // Sign signs msg using the signing key corresponding to the certificate\n    Sign(msg []byte) ([]byte, error)\n\n    // Verify verifies msg using the verifying key corresponding to the certificate\n    Verify(signature []byte, msg []byte) error\n\n    // GetTransactionHandler returns a new transaction handler relative to this certificate\n    GetTransactionHandler() (TransactionHandler, error)\n}\n\n\n\n\nThe \nTransaction Handler\n interface allows to create transactions and give access to the underlying \nbinding\n that can be leveraged to link\napplication data to the underlying transaction. Bindings are a concept that have been introduced in network transport protocols (See, https://tools.ietf.org/html/rfc5056),\nknown as \nchannel bindings\n, that \nallows applications to establish that the two end-points of a secure channel at one network layer are the same as at a higher layer\nby binding authentication at the higher layer to the channel at the lower layer.\nThis allows applications to delegate session protection to lower layers, which has various performance benefits.\n\nTransaction bindings offer the ability to uniquely identify the fabric layer of the transaction that serves as the container that\napplication data uses to be added to the ledger.\n\n\n// TransactionHandler represents a single transaction that can be uniquely determined or identified by the output of the GetBinding method.\n// This transaction is linked to a single Certificate (TCert or ECert).\ntype TransactionHandler interface {\n\n    // GetCertificateHandler returns the certificate handler relative to the certificate mapped to this transaction\n    GetCertificateHandler() (CertificateHandler, error)\n\n    // GetBinding returns a binding to the underlying transaction (container)\n    GetBinding() ([]byte, error)\n\n    // NewChaincodeDeployTransaction is used to deploy chaincode\n    NewChaincodeDeployTransaction(chaincodeDeploymentSpec *obc.ChaincodeDeploymentSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeExecute is used to execute chaincode's functions\n    NewChaincodeExecute(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeQuery is used to query chaincode's functions\n    NewChaincodeQuery(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n}\n\n\n\n\nFor version 1, \nbinding\n consists of the \nhash\n(TCert, Nonce), where TCert, is the transaction certificate\nused to sign the entire transaction, while Nonce, is the nonce number used within.\n\n\nThe \nClient\n interface is more generic, and offers a mean to get instances of the previous interfaces.\n\n\ntype Client interface {\n\n    ...\n\n    // GetEnrollmentCertHandler returns a CertificateHandler whose certificate is the enrollment certificate\n    GetEnrollmentCertificateHandler() (CertificateHandler, error)\n\n    // GetTCertHandlerNext returns a CertificateHandler whose certificate is the next available TCert\n    GetTCertificateHandlerNext() (CertificateHandler, error)\n\n    // GetTCertHandlerFromDER returns a CertificateHandler whose certificate is the one passed\n    GetTCertificateHandlerFromDER(der []byte) (CertificateHandler, error)\n\n}\n\n\n\n\nTo support application-level access control lists for controlling chaincode\ninvocation, the fabric's transaction and chaincode specification format\nhave an additional field to store application-specific metadata.\nThis field is depicted in both figures 1, by code-metadata. The content of this field is decided\nby the application, at the transaction creation time.\nThe fabric layer treats it as an unstructured stream of bytes.\n\n\n\nmessage ChaincodeSpec {\n\n    ...\n\n    ConfidentialityLevel confidentialityLevel;\n    bytes metadata;\n\n    ...\n}\n\n\nmessage Transaction {\n    ...\n\n    bytes payload;\n    bytes metadata;\n\n    ...\n}\n\n\n\n\nTo assist chaincode execution, at the chain-code invocation time, the validators provide the\nchaincode with additional information, like the metadata and the binding.  \n\n\nApplication invocation access control.\n\nThis section describes how the application can leverage the means provided by the fabric\nto implement its own access control on its chain-code functions.\nIn the scenario considered here, the following entities are identified:\n\n\n\n\n\n\nC\n: is a chaincode that contains a single function, e.g., called \nhello\n;\n\n\n\n\n\n\nu\nc\n: is the \nC\n deployer;\n\n\n\n\n\n\nu\ni\n: is a user who is authorized to invoke \nC\n's functions. User u\nc\n wants to ensure that only u\ni\n can invoke the function \nhello\n.\n\n\n\n\n\n\nDeployment of a Chaincode:\n At deployment time, u\nc\n has full control on the deployment transaction's metadata,\n and can be used to store a list of ACLs (one per function), or a list of roles that are needed by the application. The format which is used to store these ACLs is up to the deployer's application, as the chain-code is the one\nwho would need to parse the metadata at execution time.\nTo define each of these lists/roles, u\nc\n can use any TCerts/Certs of the u\ni\n (or, if applicable, or other users who have been assigned that privilege or role). Let this be TCert\nu\ni\n.\nThe exchange of TCerts or Certs among the developer and authorized users is done through an out-of-band channel.\n\n\nAssume that the application of u\nc\n's requires that to invoke the \nhello\n function, a certain message \nM\n has to be authenticated by an authorized invoker (u\ni\n, in our example).\nOne can distinguish the following two cases:\n\n\n\n\n\n\nM\n is one of the chaincode's function arguments;\n\n\n\n\n\n\nM\n is the invocation message itself, i.e., function-name, function-arguments.\n\n\n\n\n\n\nChaincode invocation:\n\nTo invoke C, u\ni\n's application needs to sign \nM\n using the TCert/ECert, that was used to identify u\ni\n's participation in the chain-code at the associated\ndeployment transaction's metadata, i.e., TCert\nu\ni\n. More specifically, u\ni\n's client application does the following:\n\n\n\n\n\n\nRetrieves a CertificateHandler for Cert\nu\ni\n, \ncHandler\n;\n\n\n\n\n\n\nobtains a new TransactionHandler to issue the execute transaction, \ntxHandler\n relative to his next available TCert or his ECert;\n\n\n\n\n\n\ngets \ntxHandler\n's \nbinding\n by invoking \ntxHandler.getBinding()\n;\n\n\n\n\n\n\nsigns \n'\nM\n || txBinding'\n by invoking \ncHandler.Sign('\nM\n || txBinding')\n, let \nsigma\n be the output of the signing function;\n\n\n\n\n\n\nissues a new execute transaction by invoking, \ntxHandler.NewChaincodeExecute(...)\n. Now, \nsigma\n can be included in the transaction as one of the arguments that are passed to the function (case 1) or as part of the code-metadata section of the payload(case 2).\n\n\n\n\n\n\nChaincode processing:\n\nThe validators, who receive the execute transaction issued u\ni\n, will provide to \nhello\n the following information:\n\n\n\n\n\n\nThe \nbinding\n of the execute transaction, that can be independently computed at the validator side;\n\n\n\n\n\n\nThe \nmetadata\n of the execute transaction (code-metadata section of the transaction);\n\n\n\n\n\n\nThe \nmetadata\n of the deploy transaction (code-metadata component of the corresponding deployment transaction).\n\n\n\n\n\n\nNotice that \nsigma\n is either part of the arguments of the invoked function, or stored inside the code-metadata of the invocation transaction (properly formatted by the client-application).\nApplication ACLs are included in the code-metadata section, that is also passed to the chain-code at execution time.\nFunction \nhello\n is responsible for checking that \nsigma\n is indeed a valid signature issued by TCert\nu\ni\n, on '\nM\n || \ntxBinding'\n.\n\n\n4.4.2 Read access control\n\n\nThis section describes how the fabric's infrastructure offers support to the application to\nenforce its own read-access control policies at the level of users. As in the case of invocation access\ncontrol, the first part describes the infrastructure features that can be leveraged by the application for this\npurpose, and the last part details on the way applications should use these tools.\n\n\nFor the purpose of this discussion, we leverage a similar example as before, i.e.,\n\n\n\n\n\n\nC\n: is a chaincode that contains a single function, e.g., called \nhello\n;\n\n\n\n\n\n\nu\nA\n: is the \nC\n's deployer, also known as application;\n\n\n\n\n\n\nu\nr\n: is a user who is authorized to read \nC\n's functions. User u\nA\n wants to ensure that only u\nr\n can read the function \nhello\n.\n\n\n\n\n\n\nSupport from the infrastructure.\n\nFor \nu\nA\n to be able to implement its own read access control at the application layer securely, our infrastructure is required to\nsupport the transaction format for code deployment and invocation, as depicted in the two figures below.\n\n\n\n\n\n\nMore specifically fabric layer is required to provide the following functionality:\n\n\n\n\n\n\nProvide minimal encryption capability such that data is only decryptable by a validator's (infrastructure) side; this means that the infrastructure should move closer to our future version, where an asymmetric encryption scheme is used for encrypting transactions. More specifically, an asymmetric key-pair is used for the chain, denoted by K\nchain\n in the Figures above, but detailed in Section \nTransaction Confidentiality\n.\n\n\n\n\n\n\nThe client-application can request the infrastructure sitting on the client-side to encrypt/decrypt information using a specific public encryption key, or that client's long-term decryption key.\n\n\n\n\n\n\nThe transaction format offers the ability to the application to store additional transaction metadata, that can be passed to the client-application after the latter's request. Transaction metadata, as opposed to code-metadata, is not encrypted or provided to the chain-code at execution time. Validators treat these metadata as a list of bytes they are not responsible for checking validity of.\n\n\n\n\n\n\nApplication read-access control.\n\nFor this reason the application may request and obtain access to the public encryption key of the user \nu\nr\n; let that be \nPK\nu\nr\n. Optionally,\n\nu\nr\n may be providing \nu\nA\n with a certificate of its, that would be leveraged by the application, say, TCert\nu\nr\n; given the latter,\nthe application would, e.g., be able to trace that user's transactions w.r.t. the application's chain-codes. TCert\nu\nr\n, and PK\nu\nr\n, are\nexchanged in an out-of-band channel.\n\n\nAt deployment time, application \nu\nA\n performs the following steps:\n\n\n\n\n\n\nUses the underlying infrastructure to encrypt the information of \nC\n, the application would like to make accessible to \nu\nr\n, using PK\nu\nr\n.\n   Let C\nu\nr\n be the resulting ciphertext.\n\n\n\n\n\n\n(optional) C\nu\nr\n can be concatenated with TCert\nu\nr\n\n\n\n\n\n\nPasses the overall string as ''Tx-metadata'' of the confidential transaction to be constructed.\n\n\n\n\n\n\nAt invocation time, the client-application on u\nr\n's node, would be able, by obtaining the deployment transaction to retrieve the content of \nC\n.\nIt just needs to retrieve the \ntx-metadata\n field of the associated deployment transaction, and trigger the decryption functionality offered by our Blockchain\ninfrastrucure's client, for C\nu\nr\n. Notice that it is the application's responsibility to encrypt the correct \nC\n for u\nr\n.\nAlso, the use of \ntx-metadata\n field can be generalized to accommodate application-needs. E.g., it can be that invokers leverage the same field of invocation transactions\nto pass information to the developer of the application, etc.\n\n\nImportant Note:\n \n It is essential to note that validators \ndo not provide\n any decryption oracle to the chain-code\nthroughout its execution. Its infrastructure is though responsible for decrypting the payload of the chain-code itself (as well as\nthe code-metadata fields near it), and provide those to containers for deployment/execution.\n\n\n4.5 Online wallet service\n\n\nThis section describes the security design of a wallet service, which in this case is a node where end-users can register, move their key material to, and perform transactions through.\nBecause the wallet service is in possession of the user's key material, it is clear that without a secure authorization\nmechanism in place a malicious wallet service could successfully impersonate the user.\nWe thus emphasize that this design corresponds to a wallet service that is \ntrusted\n to only perform transactions\non behalf of its clients, with the consent of the latter.\nThere are two cases for the registration of an end-user to an online wallet service:\n\n\n\n\nWhen the user has registered with the registration authority and acquired his/her \nenrollID, enrollPWD\n,\n   but has not installed the client to trigger and complete the enrollment process;\n\n\nWhen the user has already installed the client, and completed the enrollment phase.\n\n\n\n\nInitially, the user interacts with the online wallet service to issue credentials that would allow him to authenticate\nto the wallet service. That is, the user is given a username, and password, where username identifies the user in the\nmembership service, denoted by AccPub, and password is the associated secret, denoted by AccSec, that is \nshared\n by\nboth user and service.\n\n\nTo enroll through the online wallet service, a user must provide the following request\nobject to the wallet service:\n\n\nAccountRequest /* account request of u \\*/\n{\n    OBCSecCtx ,           /* credentials associated to network \\*/\n    AccPub\nsub\nu\n/sub\n,   /* account identifier of u \\*/\n    AccSecProof\nsub\nu\n/sub\n  /* proof of AccSec\nsub\nu\n/sub\n\\*/\n }\n\n\n\nOBCSecCtx refers to user credentials, which depending on the stage of his enrollment process, can be either his enrollment ID and password, \nenrollID, enrollPWD\n or his enrollment certificate and associated secret key(s)\n(ECert\nu\n, sk\nu\n),  where  sk\nu\n denotes for simplicity signing and decryption secret of the user.\nThe content of AccSecProof\nu\n is an HMAC on the rest fields of request using the shared secret. Nonce-based methods\nsimilar to what we have in the fabric can be used to protect against replays.\nOBCSecCtx would give the online wallet service the necessary information to enroll the user or issue required TCerts.\n\n\nFor subsequent requests, the user u should provide to the wallet service a request of similar format.\n\n\n TransactionRequest /* account request of u \\*/\n {\n      TxDetails,            /* specifications for the new transaction \\*/\n      AccPub\nsub\nu\n/sub\n,       /* account identifier of u \\*/\n      AccSecProof\nsub\nu\n/sub\n   /* proof of AccSec\nsub\nu\n/sub\n \\*/\n }\n\n\n\nHere, TxDetails refer to the information needed by the online service to construct a transaction on behalf of the user, i.e.,\nthe type, and user-specified content of the transaction.\n\n\nAccSecProof\nu\n is again an HMAC on the rest fields of request using the shared secret.\nNonce-based methods similar to what we have in the fabric can be used to protect against replays.\n\n\nTLS connections can be used in each case with server side authentication to secure the request at the\nnetwork layer (confidentiality, replay attack protection, etc)\n\n\n4.6 Network security (TLS)\n\n\nThe TLS CA should be capable of issuing TLS certificates to (non-validating) peers, validators, and individual clients (or browsers capable of storing a private key). Preferably, these certificates are distinguished by type, per above. TLS certificates for CAs of the various types (such as TLS CA, ECA, TCA) could be issued by an intermediate CA (i.e., a CA that is subordinate to the root CA). Where there is not a particular traffic analysis issue, any given TLS connection can be mutually authenticated, except for requests to the TLS CA for TLS certificates.\n\n\nIn the current implementation the only trust anchor is the TLS CA self-signed certificate in order to accommodate the limitation of a single port to communicate with all three (co-located) servers, i.e., the TLS CA, the TCA and the ECA. Consequently, the TLS handshake is established with the TLS CA, which passes the resultant session keys to the co-located TCA and ECA. The trust in validity of the TCA and ECA self-signed certificates is therefore inherited from trust in the TLS CA. In an implementation that does not thus elevate the TLS CA above other CAs, the trust anchor should be replaced with a root CA under which the TLS CA and all other CAs are certified.\n\n\n4.7 Restrictions in the current release\n\n\nThis section lists the restrictions of the current release of the fabric.\nA particular focus is given on client operations and the design of transaction confidentiality,\nas depicted in Sections 4.7.1 and 4.7.2.\n\n\n\n\nClient side enrollment and transaction creation is performed entirely by a\n   non-validating peer that is trusted not to impersonate the user.\n   See, Section 4.7.1 for more information.\n\n\nA minimal set of confidentiality properties where a chain-code is accessible\n   by any entity that is member of the system, i.e., validators and users who\n   have registered to our membership services, and not accessible by any-one else.\n   The latter include any party that has access to the storage area where the\n   ledger is maintained, or other entities that are able to see the transactions\n   that are announced in the validator network. The design of the first release\n   is detailed in subsection 4.7.2\n\n\nThe code utilizes self-signed certificates for entities such as the\n   enrollment CA (ECA) and the transaction CA (TCA)\n\n\nReplay attack resistance mechanism is not available\n\n\nInvocation access control can be enforced at the application layer:\n   it is up to the application to leverage the infrastructure's tools properly\n   for security to be guaranteed. This means, that if the application ignores\n   to \nbind\n the transaction binding offered by our fabric, secure transaction\n   processing  may be at risk.\n\n\n\n\n4.7.1 Simplified client\n\n\nClient side enrollment and transaction creation is performed entirely by a non-validating peer who plays the role of an online wallet.\nIn particular, the end-user leverages his registration credentials \n to open an account to a non-validating peer\nand uses these credentials to further authorize the peer to build transactions on the user's behalf. It needs to be noted, that such\na design does not provide secure \nauthorization\n for the peer to submit transactions on behalf of the user, as a malicious peer\ncould impersonate the user. Details on the specifications of a design that deals with the security issues of online wallet can be found is Section 4.5.\nCurrently the maximum number of peers a user can register to and perform transactions through is one.\n\n\n4.7.2 Simplified transaction confidentiality\n\n\nDisclaimer:\n The current version of transaction confidentiality is minimal, and will be used as an intermediate step\nto reach a design that allows for fine grain (invocation) access control enforcement in the next versions.\n\n\nIn its current form, confidentiality of transactions is offered solely at the chain-level, i.e., that the\ncontent of a transaction included in a ledger, is readable by all members of that chain, i.e., validators\nand users. At the same time, application auditors that are not member of the system can be given\nthe means to perform auditing by passively observing the Blockchain data, while\nguaranteeing that they are given access solely to the transactions related to the application under audit.\nState is encrypted in a way that such auditing requirements are satisfied, while not disrupting the\nproper operation of the underlying consensus network.\n\n\nMore specifically, currently symmetric key encryption is supported in the process of offering transaction confidentiality.\nIn this setting, one of the main challenges that is specific to the blockchain setting,\nis that validators need to run consensus over the state of the blockchain, that, aside the transactions themselves,\nalso includes the state updates of individual contracts or chaincodes. Though this is trivial to do for non-confidential chaincodes,\n\nfor confidential chaincodes, one needs to design the state encryption mechanism such that the resulting ciphertexts are\nsemantically secure, and yet, identical if the plaintext state is the same.\n\n\nTo overcome this challenge, the fabric utilizes a key hierarchy that reduces the number of ciphertexts\nthat are encrypted under the same key. At the same time, as some of these keys are used for the generation of IVs,\nthis allows the validating parties to generate exactly the same ciphertext when executing the same transaction\n(this is necessary to remain agnostic to the underlying consensus algorithm) and offers the possibility of controlling audit by disclosing to auditing entities only the most relevant keys.\n\n\nMethod description:\n\nMembership service generates a symmetric key for the ledger (K\nchain\n) that is distributed\nat registration time to all the entities of the blockchain system, i.e., the clients and the\nvalidating entities that have issued credentials through the membership service of the chain.\nAt enrollment phase, user obtain (as before) an enrollment certificate, denoted by Cert\nu\ni\n\nfor user u\ni\n , while each validator v\nj\n obtain its enrollment certificate denoted by Cert\nv\nj\n.\n\n\nEntity enrollment would be enhanced, as follows. In addition to enrollment certificates,\nusers who wish to anonymously participate in transactions issue transaction certificates.\nFor simplicity transaction certificates of a user u\ni\n are denoted by TCert\nu\ni\n.\nTransaction certificates include the public part of a signature key-pair denoted by (tpk\nu\ni\n,tsk\nu\ni\n).\n\n\nIn order to defeat crypto-analysis and enforce confidentiality, the following key hierarchy is considered for generation and validation of confidential transactions:\nTo submit a confidential transaction (Tx) to the ledger, a client first samples a nonce (N), which is required to be unique among all the transactions submitted to the blockchain, and derive a transaction symmetric\nkey (K\nTx\n) by applying the HMAC function keyed with K\nchain\n and on input the nonce, K\nTx\n= HMAC(K\nchain\n, N). From K\nTx\n, the client derives two AES keys:\nK\nTxCID\n as HMAC(K\nTx\n, c\n1\n), K\nTxP\n as HMAC(K\nTx\n, c\n2\n)) to encrypt respectively the chain-code name or identifier CID and code (or payload) P.\nc\n1\n, c\n2\n are public constants. The nonce, the Encrypted Chaincode ID (ECID) and the Encrypted Payload (EP) are added in the transaction Tx structure, that is finally signed and so\nauthenticated. Figure below shows how encryption keys for the client's transaction are generated. Arrows in this figure denote application of an HMAC, keyed by the key at the source of the arrow and\nusing the number in the arrow as argument. Deployment/Invocation transactions' keys are indicated by d/i respectively.\n\n\n\n\nTo validate a confidential transaction Tx submitted to the blockchain by a client,\na validating entity first decrypts ECID and EP by re-deriving K\nTxCID\n and K\nTxP\n\nfrom K\nchain\n and Tx.Nonce as done before. Once the Chaincode ID and the\nPayload are recovered the transaction can be processed.\n\n\n\n\nWhen V validates a confidential transaction, the corresponding chaincode can access and modify the\nchaincode's state. V keeps the chaincode's state encrypted. In order to do so, V generates symmetric\nkeys as depicted in the figure above. Let iTx be a confidential transaction invoking a function\ndeployed at an early stage by the confidential transaction dTx (notice that iTx can be dTx itself\nin the case, for example, that dTx has a setup function that initializes the chaincode's state).\nThen, V generates two symmetric keys  K\nIV\n  and K\nstate\n as follows:\n\n\n\n\nIt computes  as  K\ndTx\n , i.e., the transaction key of the corresponding deployment\n   transaction, and then N\nstate\n = HMAC(K\ndtx\n ,hash(N\ni\n)), where N\ni\n\n   is the nonce appearing in the invocation transaction, and \nhash\n a hash function.\n\n\nIt sets K\nstate\n = HMAC(K\ndTx\n, c\n3\n || N\nstate\n),\n   truncated opportunely deeding on the underlying cipher used to encrypt; c\n3\n is a constant number\n\n\nIt sets K\nIV\n = HMAC(K\ndTx\n, c\n4\n || N\nstate\n); c\n4\n is a constant number\n\n\n\n\nIn order to encrypt a state variable S, a validator first generates the IV as HMAC(K\nIV\n, crt\nstate\n)\nproperly truncated, where crt\nstate\n is a counter value that increases each time a state update\nis requested for the same chaincode invocation. The counter is discarded after the execution of\nthe chaincode terminates. After IV has been generated, V encrypts with authentication (i.e., GSM mode)\nthe value of S concatenated with Nstate(Actually, N\nstate\n  doesn't need to be encrypted but\nonly authenticated). To the resulting ciphertext (CT), N\nstate\n and the IV used is appended.\nIn order to decrypt an encrypted state CT|| N\nstate'\n , a validator first generates the symmetric\nkeys K\ndTX\n' ,K\nstate\n' using N\nstate'\n and then decrypts CT.\n\n\nGeneration of IVs: In order to be agnostic to any underlying consensus algorithm, all the validating\nparties need a method to produce the same exact ciphertexts. In order to do so, the validators need\nto use the same IVs. Reusing the same IV with the same symmetric key completely breaks the security\nof the underlying cipher. Therefore, the process described before is followed. In particular, V first\nderives an IV generation key K\nIV\n by computing HMAC(K\ndTX\n, c\n4\n || N\nstate\n ),\nwhere c\n4\n is a constant number, and keeps a counter crt\nstate\n for the pair\n(dTx, iTx) with is initially set to 0. Then, each time a new ciphertext has to be generated, the validator\ngenerates a new IV by computing it as the output of HMAC(K\nIV\n, crt\nstate\n)\nand then increments the crt\nstate\n by one.\n\n\nAnother benefit that comes with the above key hierarchy is the ability to enable controlled auditing.\nFor example, while by releasing K\nchain\n one would provide read access to the whole chain,\nby releasing only K\nstate\n for a given pair of transactions (dTx,iTx) access would be granted to a state\nupdated by iTx, and so on.\n\n\nThe following figures demonstrate the format of a deployment and invocation transaction currently available in the code.\n\n\n\n\n\n\nOne can notice that both deployment and invocation transactions consist of two sections:\n\n\n\n\n\n\nSection \ngeneral-info\n: contains the administration details of the transaction, i.e., which chain this transaction corresponds to (is chained to), the type of transaction (that is set to ''deploymTx'' or ''invocTx''), the version number of confidentiality policy implemented, its creator identifier (expressed by means of TCert of Cert) and a nonce (facilitates primarily replay-attack resistance techniques).\n\n\n\n\n\n\nSection \ncode-info\n: contains information on the chain-code source code. For deployment transaction this is essentially the chain-code identifier/name and source code, while for invocation chain-code is the name of the function invoked and its arguments. As shown in the two figures code-info in both transactions are encrypted ultimately using the chain-specific symmetric key K\nchain\n.\n\n\n\n\n\n\n5. Byzantine Consensus\n\n\nThe \nobcpbft\n package is an implementation of the seminal \nPBFT\n consensus protocol [1], which provides consensus among validators despite a threshold of validators acting as \nByzantine\n, i.e., being malicious or failing in an unpredictable manner. In the default configuration, PBFT tolerates up to t\nn/3 Byzantine validators.\n\n\nBesides providing a reference implementation of the PBFT consensus protocol, \nobcpbft\n plugin contains also implementation of the novel \nSieve\n consensus protocol. Basically the idea behind Sieve is to provide a fabric-level protection from \nnon-deterministic\n transactions, which PBFT and similar existing protocols do not offer. \nobcpbft\n is easily configured to use either the classic PBFT or Sieve.  \n\n\nIn the default configuration, both PBFT and Sieve are designed to run on at least \n3t+1\n validators (replicas), tolerating up to \nt\n potentially faulty (including malicious, or \nByzantine\n) replicas.\n\n\n5.1 Overview\n\n\nThe \nobcpbft\n plugin provides a modular implementation of the \nCPI\n interface which can be configured to run PBFT or Sieve consensus protocol. The modularity comes from the fact that, internally, \nobcpbft\n defines the \ninnerCPI\n  interface (i.e., the \ninner consensus programming interface\n), that currently resides in \npbft-core.go\n.\n\n\nThe \ninnerCPI\n interface defines all\ninteractions between the inner PBFT consensus (called here \ncore PBFT\n and implemented in \npbft-core.go\n) and the outer consensus that uses the core PBFT.  This outer consensus is called \nconsumer\n within core PBFT. \nobcpbft\n package contains implementations of several core PBFT consumers:\n\n\n\n\nobc-classic.go\n, a shim around core PBFT that implements the \ninnerCPI\n interface and calls into the \nCPI\n interface;\n\n\nobc-batch.go\n, an \nobc-classic\n variant that adds batching capabilities to PBFT; and  \n\n\nobc-sieve.go\n, a core PBFT consumer that implements Sieve consensus protocol and \ninnerCPI\n interface, calling into the \nCPI interface\n.\n\n\n\n\nIn short, besides calls to send messages to other peers (\ninnerCPI.broadcast\n and \ninnerCPI.unicast\n), the \ninnerCPI\n interface defines indications that the core consensus protocol (core PBFT) exports to the consumer. These indications are modeled after a classical \ntotal order (atomic) broadcast\n API [2], with \ninnerCPI.execute\n call being used to signal the atomic delivery of a message. Classical total order broadcast is augmented with \nexternal validity\n checks [2] (\ninnerCPI.verify\n) and a functionality similar to the unreliable eventual leader failure detector \n [3] (\ninnerCPI.viewChange\n).\n\n\nBesides \ninnerCPI\n, core PBFT is defined by a set of calls into core PBFT. The most important call into core PBFT is \nrequest\n which is effectively used to invoke a total order broadcast primitive [2]. In the following, we first overview calls into core PBFT and then detail the \ninnerCPI\n interface. Then, we briefly describe Sieve consensus protocol which will be specified and described in more details elsewhere.  \n\n\n5.2 Core PBFT Functions\n\n\nThe following functions control for parallelism using a non-recursive lock and can therefore be invoked from multiple threads in parallel. However, the functions typically run to completion and may invoke functions from the CPI passed in.  Care must be taken to prevent livelocks.\n\n\n5.2.1 newPbftCore\n\n\nSignature:\n\n\nfunc newPbftCore(id uint64, config *viper.Viper, consumer innerCPI, ledger consensus.Ledger) *pbftCore\n\n\n\n\nThe \nnewPbftCore\n constructor instantiates a new PBFT box instance, with the specified \nid\n.  The \nconfig\n argument defines operating parameters of the PBFT network: number replicas \nN\n, checkpoint period \nK\n, and the timeouts for request completion and view change duration.\n\n\n\n\n\n\n\n\nconfiguration key\n\n\ntype\n\n\nexample value\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\ngeneral.N\n\n\ninteger\n\n\n4\n\n\nNumber of replicas\n\n\n\n\n\n\ngeneral.K\n\n\ninteger\n\n\n10\n\n\nCheckpoint period\n\n\n\n\n\n\ngeneral.timeout.request\n\n\nduration\n\n\n2s\n\n\nMax delay between request reception and execution\n\n\n\n\n\n\ngeneral.timeout.viewchange\n\n\nduration\n\n\n2s\n\n\nMax delay between view-change start and next request execution\n\n\n\n\n\n\n\n\nThe arguments \nconsumer\n and \nledger\n pass in interfaces that are used\nto query the application state and invoke application requests once\nthey have been totally ordered.  See the respective sections below for\nthese interfaces.\n\n\n5.2.2 request\n\n\nSignature:\n\n\nfunc (pbft *pbftCore) request(msgPayload []byte) error\n\n\n\n\nThe \nrequest\n method takes an opaque request payload and introduces this request into the total order consensus.  This payload will be passed to the CPI \nexecute\n function on all correct, up-to-date replicas once PBFT processing is complete.  The \nrequest\n method does not wait for execution before returning; \nrequest\n merely submits the request into the consensus.\n\n\nPBFT does not support submission of the same request multiple times, i.e. a nonce is required if the same conceptual request has to be executed multiple times.  However, PBFT does not reliably prevent replay of requests; a nonce or sequence number can be used by the application to prevent against replays by a Byzantine client.\n\n\nIn rare cases, a \nrequest\n may be dropped by the network, and it will never \nexecute\n; if the consumer cannot tolerate this, the consumer needs to implement retries itself.\n\n\n5.2.3 receive\n\n\nSignature:\n\n\nfunc (pbft *pbftCore) receive(msgPayload []byte) error\n\n\n\n\nThe \nreceive\n method takes an opaque message payload, which another instance passed to the \nbroadcast\n or \nunicast\n CPI functions.  All communication is expected to ensure integrity and provide authentication; e.g. by the use of TLS.  Note that currently authentication is not yet used.  Once authentication is provided, the function signature of \nreceive\n should include the id of the sending node.\n\n\nSee also the discussion below regarding \ninnerCPI.broadcast\n and \ninnerCPI.unicast\n.\n\n\n5.2.4 close\n\n\nSignature:\n\n\nfunc (pbft *pbftCore) close()\n\n\n\n\nThe \nclose\n method terminates all background operations. This interface is mostly exposed for testing, because during operation of the fabric, there is never a need to terminate the PBFT instance.\n\n\n5.3 Inner Consensus Programming Interface\n\n\nThe consumer application provides the inner consensus programming interface to core PBFT.  PBFT will call these functions to query state and signal events.\n\n\nDefinition:\n\n\ntype innerCPI interface {\n    broadcast(msgPayload []byte)\n    unicast(msgPayload []byte, receiverID uint64) (err error)\n    validate(txRaw []byte) error\n    execute(txRaw []byte, rawMetadata []byte)\n    viewChange(curView uint64)\n}\n\n\n\n\n5.3.1 broadcast\n\n\nSignature:\n\n\nfunc (cpi innerCPI) broadcast(msgPayload []byte)\n\n\n\n\nThe \nbroadcast\n function takes an opaque payload and delivers it to all other replicas via their \nreceive\n method.  Messages may be lost or reordered.  See also the section on \nreceive\n call coming into core PBFT.\n\n\n5.3.2 unicast\n\n\nSignature:\n\n\nfunc (cpi innerCPI) unicast(msgPayload []byte, receiverID uint64) (err error)\n\n\n\n\nThe \nunicast\n function is similar to \nbroadcast\n, but takes a destination replica id.\n\n\n5.3.3 validate\n\n\nSignature:\n\n\nfunc (cpi innerCPI) validate(txRaw []byte) error\n\n\n\n\nThe \nvalidate\n function is invoked whenever PBFT receives a new request, either locally via \nrequest\n, or via consensus messages.  The argument of \nvalidate\n is the opaque request that was provided to the PBFT \nrequest\n method.  If \nvalidate\n returns a non-\nnil\n error, the local replica will discard the request and behave as if it had never received the request.\n\n\nThe \nvalidate\n function can be used for syntactic validation of application requests (i.e., \nexternal validity\n checks [2]).  Care must be taken not to introduce non-determinism when validating requests; i.e. the validation must not use any state, e.g., if different replicas receive \nvalidate\n calls in different sequence, also with respect to \nexecute\n.  If non-determinism occurs during validation, the behavior of different replicas may diverge, which may lead to dropped requests or complete malfunction of the consensus.\n\n\n5.3.4 execute\n\n\nSignature:\n\n\nfunc (cpi innerCPI) execute(txRaw []byte, opts ...interface{})\n\n\n\n\nPBFT will invoke the \nexecute\n function when a request has been successfully totally ordered by the consensus protocol.  The argument passed to \nexecute\n is the opaque request, as it has been previously passed to \nrequest\n.  All correct, up-to-date replicas will receive the same sequence of \nexecute\n calls.  The application must be deterministic when processing the request.  Any non-determinism will lead to the state on replicas diverging, which is considered a byzantine behavior.\n\n\nSee also the discussion above on request replays in the \nrequest\n section.\n\n\n5.3.5 viewChange\n\n\nSignature:\n\n\nfunc (cpi innerCPI) viewChange(curView uint64)\n\n\n\n\nThe \nviewChange\n function is called by PBFT to signal a successful transition to a new view (and with it, a new primary).  This information is right now only of interest to the \nSieve\n consensus algorithm, which uses PBFT leader election to avoid having to implement its own.\n\n\nAssuming a fixed number of replicas, it is simple to map curView uint64 to replica ID using modulo arithmetic. Having this in mind, with core PBFT implementation, assuming eventual synchrony [4], it is straightforward to argue that the functionality of the \nviewChange\n call allows simple implementation of the \neventual leader\n unreliable failure detector \n [3].  \n\n\n5.4 Sieve Consensus protocol\n\n\nThe design goal of Sieve is to augment PBFT consensus protocol with two main design goals:\n\n\n\n\n\n\nEnabling \nconsensus on the output state of replicas\n, in addition to the consensus on the input state provided by PBFT. To achieve this, Sieve adopts the Execute-Verify (Eve) pattern introduced in [5].\n\n\n\n\n\n\nBecause the fabric allows execution of arbitrary chaincode, such chaincode may introduce \nnon-deterministic\n transactions. Although non-deterministic transaction should in principle be disallowed by, e.g., careful inspection of chaincode, using domain specific languages (DSLs), or by otherwise enforcing determinism, the design goal of Sieve is to provide a separate \nconsensus fabric-level\n protection against \nnon-deterministic\n transactions that can be used in combination with the above mentioned approaches.\n\n\nTo this end, Sieve detects and \nsieves out non-deterministic transactions\n (that manifest themselves as such). Hence, Sieve does not require all input transactions to consensus (i.e., the replicated state machine) to be deterministic. This feature of Sieve is new and has not been implemented by any existing Byzantine fault tolerant consensus protocols.\n\n\n\n\n\n\nA protocol achieving the above two goals should not be designed and implemented from scratch, and should reuse existing PBFT implementation, lowering code complexity and simplifying reasoning about a new consensus protocol. To this end, inspired by [6], Sieve is designed using a modular approach, reusing the core PBFT component of \nobcpbft\n.\n\n\nAlthough the details of Sieve will appear elsewhere [7], we briefly outline some design and implementation aspects below.\n\n\nIn a nutshell, Sieve requires replicas to deterministically agree on the output of the execution of a request.  If the request was deterministic in the first place, all correct replicas will have obtained the same output, and they can agree on this very result. However, if a request happens to produce divergent outputs at correct replicas, Sieve may  detect this divergent condition, and the replicas will agree to discard the result of the request, thereby retaining determinism.\n\n\nNotice that, as discussed further below, Sieve allows false negatives, i.e., execution of \nnon-deterministic\n requests that execute with the same result at a sufficient number of replicas. However, Sieve allows no false positives and any discarded request is certainly non-deterministic.\n\n\nThe Sieve protocol uses core PBFT to agree on whether to accept or discard a request.  Execution of requests to Sieve is coordinated by a \nleader\n, which maps to the current PBFT primary (leveraging \ninnerCPI.viewchange\n notification from core PBFT) .  Upon a new request, the leader will instruct all replicas to tentatively execute the request.  Every replica then reports the tentative result (i.e. application state) back to the leader.  The leader collects these \nverify\n reports in a \nverify-set\n, which unambiguously determines whether the request should be accepted or discarded.  This verify-set is then passed through the total order of core PBFT.\n\n\nWhen core PBFT executes this verify-set, all correct replicas will act in the same way.  If the verify-set proves that execution diverged between correct replicas, the request is considered non-deterministic, and the replicas will roll back the tentative execution and restore the original application state.  If all correct replicas obtained the same result for the tentative execution, the replicas accept the execution and commit the tentative application state.\n\n\nUnder adverse conditions, a request that diverged between correct replicas may appear like a deterministic request (we speak of \nfalse negative\n in Sieve detection of non-determinstic requests).  Nevertheless, Sieve requires at least one correct replica to obtain a certain outcome state in order for that state to be committed. Correct replicas that possibly observe diverging execution will discard their result and synchronize their state to match the agreed-upon execution.\n\n\n6. Application Programming Interface\n\n\nThe primary interface to the fabric is a REST API. The REST API allows applications to register users, query the blockchain, and to issue transactions. A CLI is also provided to cover a subset of the available APIs for development purposes. The CLI enables developers to quickly test chaincodes or query for status of transactions.\n\n\nApplications interact with a non-validating peer node through the REST API, which will require some form of authentication to ensure the entity has proper privileges. The application is responsible for implementing the appropriate authentication mechanism and the peer node will subsequently sign the outgoing messages with the client identity.\n\n\n \n\nThe fabric API design covers the categories below, though the implementation is incomplete for some of them in the current release. The \nREST API\n section will describe the APIs currently supported.\n\n\n\n\nIdentity - Enrollment to acquire or to revoke a certificate\n\n\nAddress - Target and source of a transaction\n\n\nTransaction - Unit of execution on the ledger\n\n\nChaincode - Program running on the ledger\n\n\nBlockchain - Contents of the ledger\n\n\nNetwork - Information about the blockchain peer network\n\n\nStorage - External store for files or documents\n\n\nEvent Stream - Sub/pub events on the blockchain\n\n\n\n\n6.1 REST Service\n\n\nThe REST service can be enabled (via configuration) on either validating or non-validating peers, but it is recommended to only enable the REST service on non-validating peers on production networks.\n\n\nfunc StartOpenchainRESTServer(server *oc.ServerOpenchain, devops *oc.Devops)\n\n\n\n\nThis function reads the \nrest.address\n value in the \ncore.yaml\n configuration file, which is the configuration file for the \npeer\n process. The value of the \nrest.address\n key defines the default address and port on which the peer will listen for HTTP REST requests.\n\n\nIt is assumed that the REST service receives requests from applications which have already authenticated the end user.\n\n\n6.2 REST API\n\n\nYou can work with the REST API through any tool of your choice. For example, the curl command line utility or a browser based client such as the Firefox Rest Client or Chrome Postman. You can likewise trigger REST requests directly through \nSwagger\n. To obtain the REST API Swagger description, click \nhere\n. The currently available APIs are summarized in the following section.\n\n\n6.2.1 REST Endpoints\n\n\n\n\nBlock\n\n\nGET /chain/blocks/{block-id}\n\n\nBlockchain\n\n\nGET /chain\n\n\nChaincode\n\n\nPOST /chaincode\n\n\nNetwork\n\n\nGET /network/peers\n\n\nRegistrar\n\n\nPOST /registrar\n\n\nGET /registrar/{enrollmentID}\n\n\nDELETE /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}/ecert\n\n\nGET /registrar/{enrollmentID}/tcert\n\n\nTransactions\n\n\nGET /transactions/{UUID}\n\n\n\n\n6.2.1.1 Block API\n\n\n\n\nGET /chain/blocks/{block-id}\n\n\n\n\nUse the Block API to retrieve the contents of various blocks from the blockchain. The returned Block message structure is defined in section \n3.2.1.1\n.\n\n\nBlock Retrieval Request:\n\n\nGET host:port/chain/blocks/173\n\n\n\n\nBlock Retrieval Response:\n\n\n{\n    \ntransactions\n: [\n        {\n            \ntype\n: 3,\n            \nchaincodeID\n: \nEgRteWNj\n,\n            \npayload\n: \nCh4IARIGEgRteWNjGhIKBmludm9rZRIBYRIBYhICMTA=\n,\n            \nuuid\n: \nf5978e82-6d8c-47d1-adec-f18b794f570e\n,\n            \ntimestamp\n: {\n                \nseconds\n: 1453758316,\n                \nnanos\n: 206716775\n            },\n            \ncert\n: \nMIIB/zCCAYWgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMTI1MjE0MTE3WhcNMTYwNDI0MjE0MTE3WjArMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQ4wDAYDVQQDEwVsdWthczB2MBAGByqGSM49AgEGBSuBBAAiA2IABC/BBkt8izf6Ew8UDd62EdWFikJhyCPY5VO9Wxq9JVzt3D6nubx2jO5JdfWt49q8V1Aythia50MZEDpmKhtM6z7LHOU1RxuxdjcYDOvkNJo6pX144U4N1J8/D3A+97qZpKN/MH0wDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwDQYDVR0OBAYEBAECAwQwDwYDVR0jBAgwBoAEAQIDBDA9BgYqAwQFBgcBAf8EMABNbPHZ0e/2EToi0H8mkouuUDwurgBYuUB+vZfeMewBre3wXG0irzMtfwHlfECRDDAKBggqhkjOPQQDAwNoADBlAjAoote5zYFv91lHzpbEwTfJL/+r+CG7oMVFUFuoSlvBSCObK2bDIbNkW4VQ+ZC9GTsCMQC5GCgy2oZdHw/x7XYzG2BiqmRkLRTiCS7vYCVJXLivU65P984HopxW0cEqeFM9co0=\n,\n            \nsignature\n: \nMGUCMCIJaCT3YRsjXt4TzwfmD9hg9pxYnV13kWgf7e1hAW5Nar//05kFtpVlq83X+YtcmAIxAK0IQlCgS6nqQzZEGCLd9r7cg1AkQOT/RgoWB8zcaVjh3bCmgYHsoPAPgMsi3TJktg==\n\n        }\n    ],\n    \nstateHash\n: \n7ftCvPeHIpsvSavxUoZM0u7o67MPU81ImOJIO7ZdMoH2mjnAaAAafYy9MIH3HjrWM1/Zla/Q6LsLzIjuYdYdlQ==\n,\n    \npreviousBlockHash\n: \nlT0InRg4Cvk4cKykWpCRKWDZ9YNYMzuHdUzsaeTeAcH3HdfriLEcTuxrFJ76W4jrWVvTBdI1etxuIV9AO6UF4Q==\n,\n    \nnonHashData\n: {\n        \nlocalLedgerCommitTimestamp\n: {\n            \nseconds\n: 1453758316,\n            \nnanos\n: 250834782\n        }\n    }\n}\n\n\n\n\n6.2.1.2 Blockchain API\n\n\n\n\nGET /chain\n\n\n\n\nUse the Chain API to retrieve the current state of the blockchain. The returned BlockchainInfo message is defined below.\n\n\nmessage BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}\n\n\n\n\n\n\n\n\nheight\n - Number of blocks in the blockchain, including the genesis block.\n\n\n\n\n\n\ncurrentBlockHash\n - The hash of the current or last block.\n\n\n\n\n\n\npreviousBlockHash\n - The hash of the previous block.\n\n\n\n\n\n\nBlockchain Retrieval Request:\n\n\nGET host:port/chain\n\n\n\n\nBlockchain Retrieval Response:\n\n\n{\n    \nheight\n: 174,\n    \ncurrentBlockHash\n: \nlIfbDax2NZMU3rG3cDR11OGicPLp1yebIkia33Zte9AnfqvffK6tsHRyKwsw0hZFZkCGIa9wHVkOGyFTcFxM5w==\n,\n    \npreviousBlockHash\n: \nVlz6Dv5OSy0OZpJvijrU1cmY2cNS5Ar3xX5DxAi/seaHHRPdssrljDeppDLzGx6ZVyayt8Ru6jO+E68IwMrXLQ==\n\n}\n\n\n\n\n6.2.1.3 Chaincode API\n\n\n\n\nPOST /chaincode\n\n\n\n\nUse the Chaincode API to deploy, invoke, and query chaincodes. The deploy request requires the client to supply a \npath\n parameter, pointing to the directory containing the chaincode in the file system. The response to a deploy request is either a message containing a confirmation of successful chaincode deployment or an error, containing a reason for the failure. It also contains the generated chaincode \nname\n in the \nmessage\n field, which is to be used in subsequent invocation and query transactions to uniquely identify the deployed chaincode.\n\n\nTo deploy a chaincode, supply the required ChaincodeSpec payload, defined in section \n3.1.2.2\n.\n\n\nDeploy Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n        \npath\n:\ngithub.com/hyperledger/fabic/examples/chaincode/go/chaincode_example02\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n1000\n, \nb\n, \n2000\n]\n    }\n  },\n  \nid\n: \n1\n  \n}\n\n\n\n\nDeploy Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nid\n: 1\n}\n\n\n\n\nWith security enabled, modify the required payload to include the \nsecureContext\n element passing the enrollment ID of a logged in user as follows:\n\n\nDeploy Request with security enabled:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n        \npath\n:\ngithub.com/hyperledger/fabic/examples/chaincode/go/chaincode_example02\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n1000\n, \nb\n, \n2000\n]\n    },\n    \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: \n1\n  \n}\n\n\n\n\nThe invoke request requires the client to supply a \nname\n parameter, which was previously returned in the response from the deploy transaction. The response to an invocation request is either a message containing a confirmation of successful execution or an error, containing a reason for the failure.\n\n\nTo invoke a function within a chaincode, supply the required ChaincodeSpec payload, defined in section \n3.1.2.2\n.\n\n\nInvoke Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n      \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninvoke\n,\n        \nargs\n:[\na\n, \nb\n, \n100\n]\n    }\n  },\n  \nid\n: \n3\n  \n}\n\n\n\n\nInvoke Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n5a4540e5-902b-422d-a6ab-e70ab36a2e6d\n\n    },\n    \nid\n: 3\n}\n\n\n\n\nWith security enabled, modify the required payload to include the \nsecureContext\n element passing the enrollment ID of a logged in user as follows:\n\n\nInvoke Request with security enabled:\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n      \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninvoke\n,\n        \nargs\n:[\na\n, \nb\n, \n100\n]\n    },\n    \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: \n3\n  \n}\n\n\n\n\nThe query request requires the client to supply a \nname\n parameter, which was previously returned in the response from the deploy transaction. The response to a query request depends on the chaincode implementation. The response will contain a message containing a confirmation of successful execution or an error, containing a reason for the failure. In the case of successful execution, the response will also contain values of requested state variables within the chaincode.\n\n\nTo invoke a query function within a chaincode, supply the required ChaincodeSpec payload, defined in section \n3.1.2.2\n.\n\n\nQuery Request:\n\n\nPOST host:port/chaincode/\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n      \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\nquery\n,\n        \nargs\n:[\na\n]\n    }\n  },\n  \nid\n: \n5\n  \n}\n\n\n\n\nQuery Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n-400\n\n    },\n    \nid\n: 5\n}\n\n\n\n\nWith security enabled, modify the required payload to include the \nsecureContext\n element passing the enrollment ID of a logged in user as follows:\n\n\nQuery Request with security enabled:\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n      \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\nquery\n,\n        \nargs\n:[\na\n]\n    },\n    \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: \n5\n  \n}\n\n\n\n\n6.2.1.4 Network API\n\n\nUse the Network API to retrieve information about the network of peer nodes comprising the blockchain fabric.\n\n\nThe /network/peers endpoint returns a list of all existing network connections for the target peer node. The list includes both validating and non-validating peers. The list of peers is returned as type \nPeersMessage\n, containing an array of \nPeerEndpoint\n, defined in section \n3.1.1\n.\n\n\nmessage PeersMessage {\n    repeated PeerEndpoint peers = 1;\n}\n\n\n\n\nNetwork Request:\n\n\nGET host:port/network/peers\n\n\n\n\nNetwork Response:\n\n\n{\n    \npeers\n: [\n        {\n            \nID\n: {\n                \nname\n: \nvp1\n\n            },\n            \naddress\n: \n172.17.0.4:30303\n,\n            \ntype\n: 1,\n            \npkiID\n: \nrUA+vX2jVCXev6JsXDNgNBMX03IV9mHRPWo6h6SI0KLMypBJLd+JoGGlqFgi+eq/\n\n        },\n        {\n            \nID\n: {\n                \nname\n: \nvp3\n\n            },\n            \naddress\n: \n172.17.0.5:30303\n,\n            \ntype\n: 1,\n            \npkiID\n: \nOBduaZJ72gmM+B9wp3aErQlofE0ulQfXfTHh377ruJjOpsUn0MyvsJELUTHpAbHI\n\n        },\n        {\n            \nID\n: {\n                \nname\n: \nvp2\n\n            },\n            \naddress\n: \n172.17.0.6:30303\n,\n            \ntype\n: 1,\n            \npkiID\n: \nGhtP0Y+o/XVmRNXGF6pcm9KLNTfCZp+XahTBqVRmaIumJZnBpom4ACayVbg4Q/Eb\n\n        }\n    ]\n}\n\n\n\n\n6.2.1.5 Registrar API (member services)\n\n\n\n\nPOST /registrar\n\n\nGET /registrar/{enrollmentID}\n\n\nDELETE /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}/ecert\n\n\nGET /registrar/{enrollmentID}/tcert\n\n\n\n\nUse the Registrar APIs to manage end user registration with the certificate authority (CA). These API endpoints are used to register a user with the CA, determine whether a given user is registered, and to remove any login tokens for a target user from local storage, preventing them from executing any further transactions. The Registrar APIs are also used to retrieve user enrollment and transaction certificates from the system.\n\n\nThe \n/registrar\n endpoint is used to register a user with the CA. The required Secret payload is defined below. The response to the registration request is either a confirmation of successful registration or an error, containing a reason for the failure.\n\n\nmessage Secret {\n    string enrollId = 1;\n    string enrollSecret = 2;\n}\n\n\n\n\n\n\nenrollId\n - Enrollment ID with the certificate authority.\n\n\nenrollSecret\n - Enrollment password with the certificate authority.\n\n\n\n\nEnrollment Request:\n\n\nPOST host:port/registrar\n\n{\n  \nenrollId\n: \nlukas\n,\n  \nenrollSecret\n: \nNPKYL39uKbkj\n\n}\n\n\n\n\nEnrollment Response:\n\n\n{\n    \nOK\n: \nLogin successful for user 'lukas'.\n\n}\n\n\n\n\nThe \nGET /registrar/{enrollmentID}\n endpoint is used to confirm whether a given user is registered with the CA. If so, a confirmation will be returned. Otherwise, an authorization error will result.\n\n\nVerify Enrollment Request:\n\n\nGET host:port/registrar/jim\n\n\n\n\nVerify Enrollment Response:\n\n\n{\n    \nOK\n: \nUser jim is already logged in.\n\n}\n\n\n\n\nVerify Enrollment Request:\n\n\nGET host:port/registrar/alex\n\n\n\n\nVerify Enrollment Response:\n\n\n{\n    \nError\n: \nUser alex must log in.\n\n}\n\n\n\n\nThe \nDELETE /registrar/{enrollmentID}\n endpoint is used to delete login tokens for a target user. If the login tokens are deleted successfully, a confirmation will be returned. Otherwise, an authorization error will result. No payload is required for this endpoint.\n\n\nRemove Enrollment Request:\n\n\nDELETE host:port/registrar/lukas\n\n\n\n\nRemove Enrollment Response:\n\n\n{\n    \nOK\n: \nDeleted login token and directory for user lukas.\n\n}\n\n\n\n\nThe \nGET /registrar/{enrollmentID}/ecert\n endpoint is used to retrieve the enrollment certificate of a given user from local storage. If the target user has already registered with the CA, the response will include a URL-encoded version of the enrollment certificate. If the target user has not yet registered, an error will be returned. If the client wishes to use the returned enrollment certificate after retrieval, keep in mind that it must be URL-decoded.\n\n\nEnrollment Certificate Retrieval Request:\n\n\nGET host:port/registrar/jim/ecert\n\n\n\n\nEnrollment Certificate Retrieval Response:\n\n\n{\n    \nOK\n: \n-----BEGIN+CERTIFICATE-----%0AMIIBzTCCAVSgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwNPQkMwHhcNMTYwMTIxMDYzNjEwWhcNMTYwNDIw%0AMDYzNjEwWjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNP%0AQkMwdjAQBgcqhkjOPQIBBgUrgQQAIgNiAARSLgjGD0omuJKYrJF5ClyYb3sGEGTU%0AH1mombSAOJ6GAOKEULt4L919sbSSChs0AEvTX7UDf4KNaKTrKrqo4khCoboMg1VS%0AXVTTPrJ%2BOxSJTXFZCohVgbhWh6ZZX2tfb7%2BjUDBOMA4GA1UdDwEB%2FwQEAwIHgDAM%0ABgNVHRMBAf8EAjAAMA0GA1UdDgQGBAQBAgMEMA8GA1UdIwQIMAaABAECAwQwDgYG%0AUQMEBQYHAQH%2FBAE0MAoGCCqGSM49BAMDA2cAMGQCMGz2RR0NsJOhxbo0CeVts2C5%0A%2BsAkKQ7v1Llbg78A1pyC5uBmoBvSnv5Dd0w2yOmj7QIwY%2Bn5pkLiwisxWurkHfiD%0AxizmN6vWQ8uhTd3PTdJiEEckjHKiq9pwD%2FGMt%2BWjP7zF%0A-----END+CERTIFICATE-----%0A\n\n}\n\n\n\n\nThe \n/registrar/{enrollmentID}/tcert\n endpoint retrieves the transaction certificates for a given user that has registered with the certificate authority. If the user has registered, a confirmation message will be returned containing an array of URL-encoded transaction certificates. Otherwise, an error will result. The desired number of transaction certificates is specified with the optional 'count' query parameter. The default number of returned transaction certificates is 1; and 500 is the maximum number of certificates that can be retrieved with a single request. If the client wishes to use the returned transaction certificates after retrieval, keep in mind that they must be URL-decoded.\n\n\nTransaction Certificate Retrieval Request:\n\n\nGET host:port/registrar/jim/tcert\n\n\n\n\nTransaction Certificate Retrieval Response:\n\n\n{\n    \nOK\n: [\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAQfwJORRED9RAsmSl%2FEowq1STBb%0A%2FoFteymZ96RUr%2BsKmF9PNrrUNvFZFhvukxZZjqhEcGiQqFyRf%2FBnVN%2BbtRzMo38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwSRWQFmErr0SmQO9AFP4GJYzQ%0APQMmcsCjKiJf%2Bw1df%2FLnXunCsCUlf%2FalIUaeSrT7MAoGCCqGSM49BAMDA0gAMEUC%0AIQC%2FnE71FBJd0hwNTLXWmlCJff4Yi0J%2BnDi%2BYnujp%2Fn9nQIgYWg0m0QFzddyJ0%2FF%0AKzIZEJlKgZTt8ZTlGg3BBrgl7qY%3D%0A-----END+CERTIFICATE-----%0A\n\n    ]\n}\n\n\n\n\nTransaction Certificate Retrieval Request:\n\n\nGET host:port/registrar/jim/tcert?count=5\n\n\n\n\nTransaction Certificate Retrieval Response:\n\n\n{\n    \nOK\n: [\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A\n,\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A\n,\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A\n,\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A\n,\n        \n-----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A\n\n    ]\n}\n\n\n\n\n6.2.1.6 Transactions API\n\n\n\n\nGET /transactions/{UUID}\n\n\n\n\nUse the Transaction API to retrieve an individual transaction matching the UUID from the blockchain. The returned transaction message is defined in section \n3.1.2.1\n.\n\n\nTransaction Retrieval Request:\n\n\nGET host:port/transactions/f5978e82-6d8c-47d1-adec-f18b794f570e\n\n\n\n\nTransaction Retrieval Response:\n\n\n{\n    \ntype\n: 3,\n    \nchaincodeID\n: \nEgRteWNj\n,\n    \npayload\n: \nCh4IARIGEgRteWNjGhIKBmludm9rZRIBYRIBYhICMTA=\n,\n    \nuuid\n: \nf5978e82-6d8c-47d1-adec-f18b794f570e\n,\n    \ntimestamp\n: {\n        \nseconds\n: 1453758316,\n        \nnanos\n: 206716775\n    },\n    \ncert\n: \nMIIB/zCCAYWgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMTI1MjE0MTE3WhcNMTYwNDI0MjE0MTE3WjArMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQ4wDAYDVQQDEwVsdWthczB2MBAGByqGSM49AgEGBSuBBAAiA2IABC/BBkt8izf6Ew8UDd62EdWFikJhyCPY5VO9Wxq9JVzt3D6nubx2jO5JdfWt49q8V1Aythia50MZEDpmKhtM6z7LHOU1RxuxdjcYDOvkNJo6pX144U4N1J8/D3A+97qZpKN/MH0wDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwDQYDVR0OBAYEBAECAwQwDwYDVR0jBAgwBoAEAQIDBDA9BgYqAwQFBgcBAf8EMABNbPHZ0e/2EToi0H8mkouuUDwurgBYuUB+vZfeMewBre3wXG0irzMtfwHlfECRDDAKBggqhkjOPQQDAwNoADBlAjAoote5zYFv91lHzpbEwTfJL/+r+CG7oMVFUFuoSlvBSCObK2bDIbNkW4VQ+ZC9GTsCMQC5GCgy2oZdHw/x7XYzG2BiqmRkLRTiCS7vYCVJXLivU65P984HopxW0cEqeFM9co0=\n,\n    \nsignature\n: \nMGUCMCIJaCT3YRsjXt4TzwfmD9hg9pxYnV13kWgf7e1hAW5Nar//05kFtpVlq83X+YtcmAIxAK0IQlCgS6nqQzZEGCLd9r7cg1AkQOT/RgoWB8zcaVjh3bCmgYHsoPAPgMsi3TJktg==\n\n}\n\n\n\n\n6.3 CLI\n\n\nThe CLI includes a subset of the available APIs to enable developers to quickly test and debug chaincodes or query for status of transactions. CLI is implemented in Golang and operable on multiple OS platforms. The currently available CLI commands are summarized in the following section.\n\n\n6.3.1 CLI Commands\n\n\nTo see what CLI commands are currently available in the implementation, execute the following:\n\n\n$ peer\n\n\n\nYou will receive a response similar to below:\n\n\n    Usage:\n      peer [command]\n\n    Available Commands:\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level=\n: Default logging level and overrides, see core.yaml for full syntax\n\n    Use \npeer [command] --help\n for more information about a command.\n\n\n\n\nSome of the available command line arguments for the \npeer\n command are listed below:\n\n\n\n\n\n\n-c\n - constructor: function to trigger in order to initialize the chaincode state upon deployment.\n\n\n\n\n\n\n-l\n - language: specifies the implementation language of the chaincode. Currently, only Golang is supported.\n\n\n\n\n\n\n-n\n - name: chaincode identifier returned from the deployment transaction. Must be used in subsequent invoke and query transactions.\n\n\n\n\n\n\n-p\n - path: identifies chaincode location in the local file system. Must be used as a parameter in the deployment transaction.\n\n\n\n\n\n\n-u\n - username: enrollment ID of a logged in user invoking the transaction.\n\n\n\n\n\n\nNot all of the above commands are fully implemented in the current release. The fully supported commands that are helpful for chaincode development and debugging are described below.\n\n\nNote, that any configuration settings for the peer node listed in the \ncore.yaml\n configuration file, which is the  configuration file for the \npeer\n process, may be modified on the command line with an environment variable. For example, to set the \npeer.id\n or the \npeer.addressAutoDetect\n settings, one may pass the \nCORE_PEER_ID=vp1\n and \nCORE_PEER_ADDRESSAUTODETECT=true\n on the command line.\n\n\n6.3.1.1 node start\n\n\nThe CLI \nnode start\n command will execute the peer process in either the development or production mode. The development mode is meant for running a single peer node locally, together with a local chaincode deployment. This allows a chaincode developer to modify and debug their code without standing up a complete network. An example for starting the peer in development mode follows:\n\n\npeer node start --peer-chaincodedev\n\n\n\n\nTo start the peer process in production mode, modify the above command as follows:\n\n\npeer node start\n\n\n\n\n6.3.1.2 network login\n\n\nThe CLI \nnetwork login\n command will login a user, that is already registered with the CA, through the CLI. To login through the CLI, issue the following command, where \nusername\n is the enrollment ID of a registered user.\n\n\npeer network login \nusername\n\n\n\n\n\nThe example below demonstrates the login process for user \njim\n.\n\n\npeer network login jim\n\n\n\n\nThe command will prompt for a password, which must match the enrollment password for this user registered with the certificate authority. If the password entered does not match the registered password, an error will result.\n\n\n22:21:31.246 [main] login -\n INFO 001 CLI client login...\n22:21:31.247 [main] login -\n INFO 002 Local data store for client loginToken: /var/hyperledger/production/client/\nEnter password for user 'jim': ************\n22:21:40.183 [main] login -\n INFO 003 Logging in user 'jim' on CLI interface...\n22:21:40.623 [main] login -\n INFO 004 Storing login token for user 'jim'.\n22:21:40.624 [main] login -\n INFO 005 Login successful for user 'jim'.\n\n\n\n\nYou can also pass a password for the user with \n-p\n parameter. An example is below.\n\n\npeer network login jim -p 123456\n\n\n\n\n6.3.1.3 chaincode deploy\n\n\nThe CLI \ndeploy\n command creates the docker image for the chaincode and subsequently deploys the package to the validating peer. An example is below.\n\n\npeer chaincode deploy -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\nFunction\n:\ninit\n, \nArgs\n: [\na\n,\n100\n, \nb\n, \n200\n]}'\n\n\n\n\nWith security enabled, the command must be modified to pass an enrollment id of a logged in user with the \n-u\n parameter. An example is below.\n\n\npeer chaincode deploy -u jim -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\nFunction\n:\ninit\n, \nArgs\n: [\na\n,\n100\n, \nb\n, \n200\n]}'\n\n\n\n\nNote:\n If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.\n\n\n6.3.1.4 chaincode invoke\n\n\nThe CLI \ninvoke\n command executes a specified function within the target chaincode. An example is below.\n\n\npeer chaincode invoke -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \ninvoke\n, \nArgs\n: [\na\n, \nb\n, \n10\n]}'\n\n\n\n\nWith security enabled, the command must be modified to pass an enrollment id of a logged in user with the \n-u\n parameter. An example is below.\n\n\npeer chaincode invoke -u jim -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \ninvoke\n, \nArgs\n: [\na\n, \nb\n, \n10\n]}'\n\n\n\n\n6.3.1.5 chaincode query\n\n\nThe CLI \nquery\n command triggers a specified query method within the target chaincode. The response that is returned depends on the chaincode implementation. An example is below.\n\n\npeer chaincode query -l golang -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \nquery\n, \nArgs\n: [\na\n]}'\n\n\n\n\nWith security enabled, the command must be modified to pass an enrollment id of a logged in user with the \n-u\n parameter. An example is below.\n\n\npeer chaincode query -u jim -l golang -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \nquery\n, \nArgs\n: [\na\n]}'\n\n\n\n\n7. Application Model\n\n\n7.1 Composition of an Application\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn application follows a MVC-B architecture \u2013 Model, View, Control, BlockChain.\n\n\n\n\n  \nVIEW LOGIC \u2013 Mobile or Web UI interacting with control logic.\n\n  \nCONTROL LOGIC \u2013 Coordinates between UI, Data Model and APIs to drive transitions and chain-code.\n\n  \nDATA MODEL \u2013 Application Data Model \u2013 manages off-chain data, including Documents and large files.\n\n  \nBLOCKCHAIN  LOGIC \u2013 Blockchain logic are extensions of the Controller Logic and Data Model, into the Blockchain realm.    Controller logic is enhanced by chaincode, and the data model is enhanced with transactions on the blockchain.\n\n\n\n\n\n\nFor example, a Bluemix PaaS application using Node.js might have a Web front-end user interface or a native mobile app with backend model on Cloudant data service. The control logic may interact with 1 or more chaincodes to process transactions on the blockchain.\n\n\n\n\n\n\n\n\n### 7.2 7.2 Sample Application\n\n\n## 8. Future Directions\n### 8.1 Enterprise Integration\n### 8.2 Performance and Scalability\n### 8.3 Additional Consensus Plugins\n### 8.4 Additional Languages\n\n\n## 9. References\n- [1] Miguel Castro, Barbara Liskov: Practical Byzantine fault tolerance and proactive recovery. ACM Trans. Comput. Syst. 20(4): 398-461 (2002)\n\n- [2] Christian Cachin, Rachid Guerraoui, Lu\u00eds E. T. Rodrigues: Introduction to Reliable and Secure Distributed Programming (2. ed.). Springer 2011, ISBN 978-3-642-15259-7, pp. I-XIX, 1-367\n\n- [3] Tushar Deepak Chandra, Vassos Hadzilacos, Sam Toueg: The Weakest Failure Detector for Solving Consensus. J. ACM 43(4): 685-722 (1996)\n\n- [4] Cynthia Dwork, Nancy A. Lynch, Larry J. Stockmeyer: Consensus in the presence of partial synchrony. J. ACM 35(2): 288-323 (1988)\n\n- [5] Manos Kapritsos, Yang Wang, Vivien Qu\u00e9ma, Allen Clement, Lorenzo Alvisi, Mike Dahlin: All about Eve: Execute-Verify Replication for Multi-Core Servers. OSDI 2012: 237-250\n\n- [6] Pierre-Louis Aublin, Rachid Guerraoui, Nikola Knezevic, Vivien Qu\u00e9ma, Marko Vukolic: The Next 700 BFT Protocols. ACM Trans. Comput. Syst. 32(4): 12:1-12:45 (2015)\n\n- [7] Christian Cachin, Simon Schubert, Marko Vukoli\u0107: [Non-determinism in Byzantine Fault-Tolerant Replication](http://arxiv.org/abs/1603.07351)", 
            "title": "Protocol spec"
        }, 
        {
            "location": "/protocol-spec/#preface", 
            "text": "This document is the protocol specification for a permissioned blockchain implementation for industry use-cases. It is not intended to be a complete explanation of the implementation, but rather a description of the interfaces and relationships between components in the system and the application.", 
            "title": "Preface"
        }, 
        {
            "location": "/protocol-spec/#intended-audience", 
            "text": "The intended audience for this specification includes the following groups:   Blockchain vendors who want to implement blockchain systems that conform to this specification  Tool developers who want to extend the capabilities of the fabric  Application developers who want to leverage blockchain technologies to enrich their applications", 
            "title": "Intended Audience"
        }, 
        {
            "location": "/protocol-spec/#authors", 
            "text": "The following authors have written sections of this document:  Binh Q Nguyen, Elli Androulaki, Angelo De Caro, Sheehan Anderson, Manish Sethi, Thorsten Kramp, Alessandro Sorniotti, Marko Vukolic, Florian Simon Schubert, Jason K Yellick, Konstantinos Christidis, Srinivasan Muralidharan, Anna D Derbakova, Dulce Ponceleon, David Kravitz, Diego Masini.", 
            "title": "Authors"
        }, 
        {
            "location": "/protocol-spec/#reviewers", 
            "text": "The following reviewers have contributed to this document:  Frank Lu, John Wolpert, Bishop Brock, Nitin Gaur, Sharon Weed, Konrad Pabjan.", 
            "title": "Reviewers"
        }, 
        {
            "location": "/protocol-spec/#acknowledgements", 
            "text": "The following contributors have provided invaluable technical input to this specification:\nGennaro Cuomo, Joseph A Latone, Christian Cachin", 
            "title": "Acknowledgements"
        }, 
        {
            "location": "/protocol-spec/#table-of-contents", 
            "text": "", 
            "title": "Table of Contents"
        }, 
        {
            "location": "/protocol-spec/#1-introduction", 
            "text": "1.1 What is the fabric?  1.2 Why the fabric?  1.3 Terminology", 
            "title": "1. Introduction"
        }, 
        {
            "location": "/protocol-spec/#2-fabric", 
            "text": "2.1 Architecture  2.1.1 Membership Services  2.1.2 Blockchain Services  2.1.3 Chaincode Services  2.1.4 Events  2.1.5 Application Programming Interface  2.1.6 Command Line Interface  2.2 Topology  2.2.1 Single Validating Peer  2.2.2 Multiple Validating Peers  2.2.3 Multichain", 
            "title": "2. Fabric"
        }, 
        {
            "location": "/protocol-spec/#3-protocol", 
            "text": "3.1 Message  3.1.1 Discovery Messages  3.1.2 Transaction Messages  3.1.2.1 Transaction Data Structure  3.1.2.2 Transaction Specification  3.1.2.3 Deploy Transaction  3.1.2.4 Invoke Transaction  3.1.2.5 Query Transaction  3.1.3 Synchronization Messages  3.1.4 Consensus Messages  3.2 Ledger  3.2.1 Blockchain  3.2.1.1 Block  3.2.1.2 Block Hashing  3.2.1.3 NonHashData  3.2.1.4 Transaction  3.2.2 World State  3.2.2.1 Hashing the world state  3.2.2.1.1 Bucket-tree  3.3 Chaincode  3.3.1 Virtual Machine Instantiation  3.3.2 Chaincode Protocol  3.3.2.1 Chaincode Deploy  3.3.2.2 Chaincode Invoke  3.3.2.3 Chaincode Query  3.3.2.4 Chaincode State  3.4 Pluggable Consensus Framework  3.4.1 Consenter interface  3.4.2 Consensus Programming Interface  3.4.3 Inquirer interface  3.4.4 Communicator interface  3.4.5 SecurityUtils interface  3.4.6 LedgerStack interface  3.4.7 Executor interface  3.4.7.1 Beginning a transaction batch  3.4.7.2 Executing transactions  3.4.7.3 Committing and rolling-back transactions  3.4.8 Ledger interface  3.4.8.1 ReadOnlyLedger interface  3.4.8.2 UtilLedger interface  3.4.8.3 WritableLedger interface  3.4.9 RemoteLedgers interface  3.4.10 Controller package  3.4.11 Helper package  3.5 Events  3.4.1 Event Stream  3.4.2 Event Structure  3.4.3 Event Adapters", 
            "title": "3. Protocol"
        }, 
        {
            "location": "/protocol-spec/#4-security", 
            "text": "Security    4.1 Business security requirements  4.2 User Privacy through Membership Services  4.2.1 User/Client Enrollment Process  4.2.2 Expiration and revocation of certificates  4.2.3 Online wallet service  4.3 Transaction security offerings at the infrastructure level  4.3.1 Security lifecycle of transactions  4.3.2 Transaction confidentiality  4.3.2.1 Confidentiality against users  4.3.2.2 Confidentiality against validators  4.3.3 Invocation access control  4.3.4 Replay attack resistance  4.4 Access control features on the application  4.4.1 Invocation access control  4.4.2 Read access control  4.5 Online wallet service  4.6 Network security (TLS)  4.7 Restrictions in the current release  4.7.1 Simplified client  4.7.1 Simplified transaction confidentiality", 
            "title": "4. Security"
        }, 
        {
            "location": "/protocol-spec/#5-byzantine-consensus", 
            "text": "5.1 Overview  5.2 Core PBFT  5.3 Inner Consensus Programming Interface  5.4 Sieve Consensus", 
            "title": "5. Byzantine Consensus"
        }, 
        {
            "location": "/protocol-spec/#6-application-programming-interface", 
            "text": "6.1 REST Service  6.2 REST API  6.3 CLI", 
            "title": "6. Application Programming Interface"
        }, 
        {
            "location": "/protocol-spec/#7-application-model", 
            "text": "7.1 Composition of an Application  7.2 Sample Application", 
            "title": "7. Application Model"
        }, 
        {
            "location": "/protocol-spec/#8-future-directions", 
            "text": "8.1 Enterprise Integration  8.2 Performance and Scalability  8.3 Additional Consensus Plugins  8.4 Additional Languages", 
            "title": "8. Future Directions"
        }, 
        {
            "location": "/protocol-spec/#9-references", 
            "text": "", 
            "title": "9. References"
        }, 
        {
            "location": "/protocol-spec/#1-introduction_1", 
            "text": "This document specifies the principles, architecture, and protocol of a blockchain implementation suitable for industrial use-cases.", 
            "title": "1. Introduction"
        }, 
        {
            "location": "/protocol-spec/#11-what-is-the-fabric", 
            "text": "The fabric is a ledger of digital events, called transactions, shared among  different participants, each having a stake in the system. The ledger can only be updated by consensus of the participants, and, once recorded, information can never be altered. Each recorded event is cryptographically verifiable with proof of agreement from the participants.  Transactions are secured, private, and confidential. Each participant registers with proof of identity to the network membership services to gain access to the system. Transactions are issued with derived certificates unlinkable to the individual participant, offering a complete anonymity on the network. Transaction content is encrypted with sophisticated key derivation functions to ensure only intended participants may see the content, protecting the confidentiality of the business transactions.  The ledger allows compliance with regulations as ledger entries are auditable in whole or in part. In collaboration with participants, auditors may obtain time-based certificates to allow viewing the ledger and linking transactions to provide an accurate assessment of the operations.  The fabric is an implementation of blockchain technology, where Bitcoin could be a simple application built on the fabric. It is a modular architecture allowing components to be plug-and-play by implementing this protocol specification. It features powerful container technology to host any main stream language for smart contracts development. Leveraging familiar and proven technologies is the motto of the fabric architecture.", 
            "title": "1.1 What is the fabric?"
        }, 
        {
            "location": "/protocol-spec/#12-why-the-fabric", 
            "text": "Early blockchain technology serves a set of purposes but is often not well-suited for the needs of specific industries. To meet the demands of modern markets, the fabric is based on an industry-focused design that addresses the multiple and varied requirements of specific industry use cases, extending the learning of the pioneers in this field while also addressing issues such as scalability. The fabric provides a new approach to enable permissioned networks, privacy, and confidentially on multiple blockchain networks.", 
            "title": "1.2 Why the fabric?"
        }, 
        {
            "location": "/protocol-spec/#13-terminology", 
            "text": "The following terminology is defined within the limited scope of this specification to help readers understand clearly and precisely the concepts described here.  Transaction  is a request to the blockchain to execute a function on the ledger. The function is implemented by a  chaincode .  Transactor  is an entity that issues transactions such as a client application.  Ledger  is a sequence of cryptographically linked blocks, containing transactions and current  world state .  World State  is the collection of variables containing the results of executed transactions.  Chaincode  is an application-level code (a.k.a.  smart contract ) stored on the ledger as a part of a transaction. Chaincode runs transactions that may modify the world state.  Validating Peer  is a computer node on the network responsible for running consensus, validating transactions, and maintaining the ledger.  Non-validating Peer  is a computer node on the network which functions as a proxy connecting transactors to the neighboring validating peers. A non-validating peer doesn't execute transactions but does verify them. It also hosts the event stream server and the REST service.  Permissioned Ledger  is a blockchain network where each entity or node is required to be a member of the network. Anonymous nodes are not allowed to connect.  Privacy  is required by the chain transactors to conceal their identities on the network. While members of the network may examine the transactions, the transactions can't be linked to the transactor without special privilege.  Confidentiality  is the ability to render the transaction content inaccessible to anyone other than the stakeholders of the transaction.  Auditability  of the blockchain is required, as business usage of blockchain needs to comply with regulations to make it easy for regulators to investigate transaction records.", 
            "title": "1.3 Terminology"
        }, 
        {
            "location": "/protocol-spec/#2-fabric_1", 
            "text": "The fabric is made up of the core components described in the subsections below.", 
            "title": "2. Fabric"
        }, 
        {
            "location": "/protocol-spec/#21-architecture", 
            "text": "The reference architecture is aligned in 3 categories: Membership, Blockchain, and Chaincode services. These categories are logical structures, not a physical depiction of partitioning of components into separate processes, address spaces or (virtual) machines.", 
            "title": "2.1 Architecture"
        }, 
        {
            "location": "/protocol-spec/#211-membership-services", 
            "text": "Membership provides services for managing identity, privacy, confidentiality and auditability on the network. In a non-permissioned blockchain, participation does not require authorization and all nodes can equally submit transactions and/or attempt to accumulate them into acceptable blocks, i.e. there are no distinctions of roles. Membership services combine elements of Public Key Infrastructure (PKI) and decentralization/consensus to transform a non-permissioned blockchain into a permissioned blockchain. In the latter, entities register in order to acquire long-term identity credentials (enrollment certificates), and may be distinguished according to entity type. In the case of users, such credentials enable the Transaction Certificate Authority (TCA) to issue pseudonymous credentials. Such credentials, i.e., transaction certificates, are used to authorize submitted transactions. Transaction certificates persist on the blockchain, and enable authorized auditors to cluster otherwise unlinkable transactions.", 
            "title": "2.1.1 Membership Services"
        }, 
        {
            "location": "/protocol-spec/#212-blockchain-services", 
            "text": "Blockchain services manage the distributed ledger through a peer-to-peer protocol, built on HTTP/2. The data structures are highly optimized to provide the most efficient hash algorithm for maintaining the world state replication. Different consensus (PBFT, Raft, PoW, PoS) may be plugged in and configured per deployment.", 
            "title": "2.1.2 Blockchain Services"
        }, 
        {
            "location": "/protocol-spec/#213-chaincode-services", 
            "text": "Chaincode services provides a secured and lightweight way to sandbox the chaincode execution on the validating nodes. The environment is a \u201clocked down\u201d and secured container along with a set of signed base images containing secure OS and chaincode language, runtime and SDK layers for Go, Java, and Node.js. Other languages can be enabled if required.", 
            "title": "2.1.3 Chaincode Services"
        }, 
        {
            "location": "/protocol-spec/#214-events", 
            "text": "Validating peers and chaincodes can emit events on the network that applications may listen for and take actions on. There is a set of pre-defined events, and chaincodes can generate custom events. Events are consumed by 1 or more event adapters. Adapters may further deliver events using other vehicles such as Web hooks or Kafka.", 
            "title": "2.1.4 Events"
        }, 
        {
            "location": "/protocol-spec/#215-application-programming-interface-api", 
            "text": "The primary interface to the fabric is a REST API and its variations over Swagger 2.0. The API allows applications to register users, query the blockchain, and to issue transactions. There is a set of APIs specifically for chaincode to interact with the stack to execute transactions and query transaction results.", 
            "title": "2.1.5 Application Programming Interface (API)"
        }, 
        {
            "location": "/protocol-spec/#216-command-line-interface-cli", 
            "text": "CLI includes a subset of the REST API to enable developers to quickly test chaincodes or query for status of transactions. CLI is implemented in Golang and operable on multiple OS platforms.", 
            "title": "2.1.6 Command Line Interface (CLI)"
        }, 
        {
            "location": "/protocol-spec/#22-topology", 
            "text": "A deployment of the fabric can consist of a membership service, many validating peers, non-validating peers, and 1 or more applications. All of these components make up a chain. There can be multiple chains; each one having its own operating parameters and security requirements.", 
            "title": "2.2 Topology"
        }, 
        {
            "location": "/protocol-spec/#221-single-validating-peer", 
            "text": "Functionally, a non-validating peer is a subset of a validating peer; that is, every capability on a non-validating peer may be enabled on a validating peer, so the simplest network may consist of a single validating peer node. This configuration is most appropriate for a development environment, where a single validating peer may be started up during the edit-compile-debug cycle.   A single validating peer doesn't require consensus, and by default uses the  noops  plugin, which executes transactions as they arrive. This gives the developer an immediate feedback during development.", 
            "title": "2.2.1 Single Validating Peer"
        }, 
        {
            "location": "/protocol-spec/#222-multiple-validating-peers", 
            "text": "Production or test networks should be made up of multiple validating and non-validating peers as necessary. Non-validating peers can take workload off the validating peers, such as handling API requests and processing events.   The validating peers form a mesh-network (every validating peer connects to every other validating peer) to disseminate information. A non-validating peer connects to a neighboring validating peer that it is allowed to connect to. Non-validating peers are optional since applications may communicate directly with validating peers.", 
            "title": "2.2.2 Multiple Validating Peers"
        }, 
        {
            "location": "/protocol-spec/#223-multichain", 
            "text": "Each network of validating and non-validating peers makes up a chain. Many chains may be created to address different needs, similar to having multiple Web sites, each serving a different purpose.", 
            "title": "2.2.3 Multichain"
        }, 
        {
            "location": "/protocol-spec/#3-protocol_1", 
            "text": "The fabric's peer-to-peer communication is built on  gRPC , which allows bi-directional stream-based messaging. It uses  Protocol Buffers  to serialize data structures for data transfer between peers. Protocol buffers are a language-neutral, platform-neutral and extensible mechanism for serializing structured data. Data structures, messages, and services are described using  proto3 language  notation.", 
            "title": "3. Protocol"
        }, 
        {
            "location": "/protocol-spec/#31-message", 
            "text": "Messages passed between nodes are encapsulated by  Message  proto structure, which consists of 4 types: Discovery, Transaction, Synchronization, and Consensus. Each type may define more subtypes embedded in the  payload .  message Message {\n   enum Type {\n        UNDEFINED = 0;\n\n        DISC_HELLO = 1;\n        DISC_DISCONNECT = 2;\n        DISC_GET_PEERS = 3;\n        DISC_PEERS = 4;\n        DISC_NEWMSG = 5;\n\n        CHAIN_STATUS = 6;\n        CHAIN_TRANSACTION = 7;\n        CHAIN_GET_TRANSACTIONS = 8;\n        CHAIN_QUERY = 9;\n\n        SYNC_GET_BLOCKS = 11;\n        SYNC_BLOCKS = 12;\n        SYNC_BLOCK_ADDED = 13;\n\n        SYNC_STATE_GET_SNAPSHOT = 14;\n        SYNC_STATE_SNAPSHOT = 15;\n        SYNC_STATE_GET_DELTAS = 16;\n        SYNC_STATE_DELTAS = 17;\n\n        RESPONSE = 20;\n        CONSENSUS = 21;\n    }\n    Type type = 1;\n    bytes payload = 2;\n    google.protobuf.Timestamp timestamp = 3;\n}  The  payload  is an opaque byte array containing other objects such as  Transaction  or  Response  depending on the type of the message. For example, if the  type  is  CHAIN_TRANSACTION , the  payload  is a  Transaction  object.", 
            "title": "3.1 Message"
        }, 
        {
            "location": "/protocol-spec/#311-discovery-messages", 
            "text": "Upon start up, a peer runs discovery protocol if  CORE_PEER_DISCOVERY_ROOTNODE  is specified.  CORE_PEER_DISCOVERY_ROOTNODE  is the IP address of another peer on the network (any peer) that serves as the starting point for discovering all the peers on the network. The protocol sequence begins with  DISC_HELLO , whose  payload  is a  HelloMessage  object, containing its endpoint:  message HelloMessage {\n  PeerEndpoint peerEndpoint = 1;\n  uint64 blockNumber = 2;\n}\nmessage PeerEndpoint {\n    PeerID ID = 1;\n    string address = 2;\n    enum Type {\n      UNDEFINED = 0;\n      VALIDATOR = 1;\n      NON_VALIDATOR = 2;\n    }\n    Type type = 3;\n    bytes pkiID = 4;\n}\n\nmessage PeerID {\n    string name = 1;\n}  Definition of fields:   PeerID  is any name given to the peer at start up or defined in the config file  PeerEndpoint  describes the endpoint and whether it's a validating or a non-validating peer  pkiID  is the cryptographic ID of the peer  address  is host or IP address and port of the peer in the format  ip:port  blockNumber  is the height of the blockchain the peer currently has   If the block height received upon  DISC_HELLO  is higher than the current block height of the peer, it immediately initiates the synchronization protocol to catch up with the network.  After  DISC_HELLO , peer sends  DISC_GET_PEERS  periodically to discover any additional peers joining the network. In response to  DISC_GET_PEERS , a peer sends  DISC_PEERS  with  payload  containing an array of  PeerEndpoint . Other discovery message types are not used at this point.", 
            "title": "3.1.1 Discovery Messages"
        }, 
        {
            "location": "/protocol-spec/#312-transaction-messages", 
            "text": "There are 3 types of transactions: Deploy, Invoke and Query. A deploy transaction installs the specified chaincode on the chain, while invoke and query transactions call a function of a deployed chaincode. Another type in consideration is Create transaction, where a deployed chaincode may be instantiated on the chain and is addressable. This type has not been implemented as of this writing.", 
            "title": "3.1.2 Transaction Messages"
        }, 
        {
            "location": "/protocol-spec/#3121-transaction-data-structure", 
            "text": "Messages with type  CHAIN_TRANSACTION  or  CHAIN_QUERY  carry a  Transaction  object in the  payload :  message Transaction {\n    enum Type {\n        UNDEFINED = 0;\n        CHAINCODE_DEPLOY = 1;\n        CHAINCODE_INVOKE = 2;\n        CHAINCODE_QUERY = 3;\n        CHAINCODE_TERMINATE = 4;\n    }\n    Type type = 1;\n    string uuid = 5;\n    bytes chaincodeID = 2;\n    bytes payloadHash = 3;\n\n    ConfidentialityLevel confidentialityLevel = 7;\n    bytes nonce = 8;\n    bytes cert = 9;\n    bytes signature = 10;\n\n    bytes metadata = 4;\n    google.protobuf.Timestamp timestamp = 6;\n}\n\nmessage TransactionPayload {\n    bytes payload = 1;\n}\n\nenum ConfidentialityLevel {\n    PUBLIC = 0;\n    CONFIDENTIAL = 1;\n}  Definition of fields: \n-  type  - The type of the transaction, which is 1 of the following:\n    -  UNDEFINED  - Reserved for future use.\n  -  CHAINCODE_DEPLOY  - Represents the deployment of a new chaincode.\n    -  CHAINCODE_INVOKE  - Represents a chaincode function execution that may read and modify the world state.\n    -  CHAINCODE_QUERY  - Represents a chaincode function execution that may only read the world state.\n    -  CHAINCODE_TERMINATE  - Marks a chaincode as inactive so that future functions of the chaincode can no longer be invoked.\n-  chaincodeID  - The ID of a chaincode which is a hash of the chaincode source, path to the source code, constructor function, and parameters.\n-  payloadHash  - Bytes defining the hash of  TransactionPayload.payload .\n-  metadata  - Bytes defining any associated transaction metadata that the application may use.\n-  uuid  - A unique ID for the transaction.\n-  timestamp  - A timestamp of when the transaction request was received by the peer.\n-  confidentialityLevel  - Level of data confidentiality. There are currently 2 levels. Future releases may define more levels.\n-  nonce  - Used for security.\n-  cert  - Certificate of the transactor.\n-  signature  - Signature of the transactor.\n-  TransactionPayload.payload  - Bytes defining the payload of the transaction. As the payload can be large, only the payload hash is included directly in the transaction message.  More detail on transaction security can be found in section 4.", 
            "title": "3.1.2.1 Transaction Data Structure"
        }, 
        {
            "location": "/protocol-spec/#3122-transaction-specification", 
            "text": "A transaction is always associated with a chaincode specification which defines the chaincode and the execution environment such as language and security context. Currently there is an implementation that uses Golang for writing chaincode. Other languages may be added in the future.  message ChaincodeSpec {\n    enum Type {\n        UNDEFINED = 0;\n        GOLANG = 1;\n        NODE = 2;\n    }\n    Type type = 1;\n    ChaincodeID chaincodeID = 2;\n    ChaincodeInput ctorMsg = 3;\n    int32 timeout = 4;\n    string secureContext = 5;\n    ConfidentialityLevel confidentialityLevel = 6;\n    bytes metadata = 7;\n}\n\nmessage ChaincodeID {\n    string path = 1;\n    string name = 2;\n}\n\nmessage ChaincodeInput {\n    string function = 1;\n    repeated string args  = 2;\n}  Definition of fields: \n-  chaincodeID  - The chaincode source code path and name.\n-  ctorMsg  - Function name and argument parameters to call.\n-  timeout  - Time in milliseconds to execute the transaction.\n-  confidentialityLevel  - Confidentiality level of this transaction.\n-  secureContext  - Security context of the transactor.\n-  metadata  - Any data the application wants to pass along.  The peer, receiving the  chaincodeSpec , wraps it in an appropriate transaction message and broadcasts to the network.", 
            "title": "3.1.2.2 Transaction Specification"
        }, 
        {
            "location": "/protocol-spec/#3123-deploy-transaction", 
            "text": "Transaction  type  of a deploy transaction is  CHAINCODE_DEPLOY  and the payload contains an object of  ChaincodeDeploymentSpec .  message ChaincodeDeploymentSpec {\n    ChaincodeSpec chaincodeSpec = 1;\n    google.protobuf.Timestamp effectiveDate = 2;\n    bytes codePackage = 3;\n}  Definition of fields: \n-  chaincodeSpec  - See section 3.1.2.2, above.\n-  effectiveDate  - Time when the chaincode is ready to accept invocations.\n-  codePackage  - gzip of the chaincode source.  The validating peers always verify the hash of the  codePackage  when they deploy the chaincode to make sure the package has not been tampered with since the deploy transaction entered the network.", 
            "title": "3.1.2.3 Deploy Transaction"
        }, 
        {
            "location": "/protocol-spec/#3124-invoke-transaction", 
            "text": "Transaction  type  of an invoke transaction is  CHAINCODE_INVOKE  and the  payload  contains an object of  ChaincodeInvocationSpec .  message ChaincodeInvocationSpec {\n    ChaincodeSpec chaincodeSpec = 1;\n}", 
            "title": "3.1.2.4 Invoke Transaction"
        }, 
        {
            "location": "/protocol-spec/#3125-query-transaction", 
            "text": "A query transaction is similar to an invoke transaction, but the message  type  is  CHAINCODE_QUERY .", 
            "title": "3.1.2.5 Query Transaction"
        }, 
        {
            "location": "/protocol-spec/#313-synchronization-messages", 
            "text": "Synchronization protocol starts with discovery, described above in section 3.1.1, when a peer realizes that it's behind or its current block is not the same with others. A peer broadcasts either  SYNC_GET_BLOCKS ,  SYNC_STATE_GET_SNAPSHOT , or  SYNC_STATE_GET_DELTAS  and receives  SYNC_BLOCKS ,  SYNC_STATE_SNAPSHOT , or  SYNC_STATE_DELTAS  respectively.  The installed consensus plugin (e.g. pbft) dictates how synchronization protocol is being applied. Each message is designed for a specific situation:  SYNC_GET_BLOCKS  requests for a range of contiguous blocks expressed in the message  payload , which is an object of  SyncBlockRange .  The correlationId specified is included in the  SyncBlockRange  of any replies to this message.  message SyncBlockRange {\n    uint64 correlationId = 1;\n    uint64 start = 2;\n    uint64 end = 3;\n}  A receiving peer responds with a  SYNC_BLOCKS  message whose  payload  contains an object of  SyncBlocks  message SyncBlocks {\n    SyncBlockRange range = 1;\n    repeated Block blocks = 2;\n}  The  start  and  end  indicate the starting and ending blocks inclusively. The order in which blocks are returned is defined by the  start  and  end  values. For example, if  start =3 and  end =5, the order of blocks will be 3, 4, 5. If  start =5 and  end =3, the order will be 5, 4, 3.  SYNC_STATE_GET_SNAPSHOT  requests for the snapshot of the current world state. The  payload  is an object of  SyncStateSnapshotRequest  message SyncStateSnapshotRequest {\n  uint64 correlationId = 1;\n}  The  correlationId  is used by the requesting peer to keep track of the response messages. A receiving peer replies with  SYNC_STATE_SNAPSHOT  message whose  payload  is an instance of  SyncStateSnapshot  message SyncStateSnapshot {\n    bytes delta = 1;\n    uint64 sequence = 2;\n    uint64 blockNumber = 3;\n    SyncStateSnapshotRequest request = 4;\n}  This message contains the snapshot or a chunk of the snapshot on the stream, and in which case, the sequence indicate the order starting at 0.  The terminating message will have len(delta) == 0.  SYNC_STATE_GET_DELTAS  requests for the state deltas of a range of contiguous blocks. By default, the Ledger maintains 500 transition deltas. A delta(j) is a state transition between block(i) and block(j) where i = j-1. The message  payload  contains an instance of  SyncStateDeltasRequest  message SyncStateDeltasRequest {\n    SyncBlockRange range = 1;\n}  A receiving peer responds with  SYNC_STATE_DELTAS , whose  payload  is an instance of  SyncStateDeltas  message SyncStateDeltas {\n    SyncBlockRange range = 1;\n    repeated bytes deltas = 2;\n}  A delta may be applied forward (from i to j) or backward (from j to i) in the state transition.", 
            "title": "3.1.3 Synchronization Messages"
        }, 
        {
            "location": "/protocol-spec/#314-consensus-messages", 
            "text": "Consensus deals with transactions, so a  CONSENSUS  message is initiated internally by the consensus framework when it receives a  CHAIN_TRANSACTION  message. The framework converts  CHAIN_TRANSACTION  into  CONSENSUS  then broadcasts to the validating nodes with the same  payload . The consensus plugin receives this message and process according to its internal algorithm. The plugin may create custom subtypes to manage consensus finite state machine. See section 3.4 for more details.", 
            "title": "3.1.4 Consensus Messages"
        }, 
        {
            "location": "/protocol-spec/#32-ledger", 
            "text": "The ledger consists of two primary pieces, the blockchain and the world state. The blockchain is a series of linked blocks that is used to record transactions within the ledger. The world state is a key-value database that chaincodes may use to store state when executed by a transaction.", 
            "title": "3.2 Ledger"
        }, 
        {
            "location": "/protocol-spec/#321-blockchain", 
            "text": "", 
            "title": "3.2.1 Blockchain"
        }, 
        {
            "location": "/protocol-spec/#3211-block", 
            "text": "The blockchain is defined as a linked list of blocks as each block contains the hash of the previous block in the chain. The two other important pieces of information that a block contains are the list of transactions contained within the block and the hash of the world state after executing all transactions in the block.  message Block {\n  version = 1;\n  google.protobuf.Timestamp timestamp = 2;\n  bytes transactionsHash = 3;\n  bytes stateHash = 4;\n  bytes previousBlockHash = 5;\n  bytes consensusMetadata = 6;\n  NonHashData nonHashData = 7;\n}\n\nmessage BlockTransactions {\n  repeated Transaction transactions = 1;\n}   version  - Version used to track any protocol changes.  timestamp  - The timestamp to be filled in by the block proposer.  transactionsHash  - The merkle root hash of the block's transactions.  stateHash  - The merkle root hash of the world state.  previousBlockHash  - The hash of the previous block.  consensusMetadata  - Optional metadata that the consensus may include in a block.  nonHashData  - A  NonHashData  message that is set to nil before computing the hash of the block, but stored as part of the block in the database.  BlockTransactions.transactions  - An array of Transaction messages. Transactions are not included in the block directly due to their size.", 
            "title": "3.2.1.1 Block"
        }, 
        {
            "location": "/protocol-spec/#3212-block-hashing", 
            "text": "The  previousBlockHash  hash is calculated using the following algorithm.   Serialize the Block message to bytes using the protocol buffer library.    Hash the serialized block message to 512 bits of output using the SHA3 SHAKE256 algorithm as described in  FIPS 202 .    The  transactionHash  is the root of the transaction merkle tree. Defining the merkle tree implementation is a TODO.    The  stateHash  is defined in section 3.2.2.1.", 
            "title": "3.2.1.2 Block Hashing"
        }, 
        {
            "location": "/protocol-spec/#3213-nonhashdata", 
            "text": "The NonHashData message is used to store block metadata that is not required to be the same value on all peers. These are suggested values.  message NonHashData {\n  google.protobuf.Timestamp localLedgerCommitTimestamp = 1;\n  repeated TransactionResult transactionResults = 2;\n}\n\nmessage TransactionResult {\n  string uuid = 1;\n  bytes result = 2;\n  uint32 errorCode = 3;\n  string error = 4;\n}    localLedgerCommitTimestamp  - A timestamp indicating when the block was commited to the local ledger.    TransactionResult  - An array of transaction results.    TransactionResult.uuid  - The ID of the transaction.    TransactionResult.result  - The return value of the transaction.    TransactionResult.errorCode  - A code that can be used to log errors associated with the transaction.    TransactionResult.error  - A string that can be used to log errors associated with the transaction.", 
            "title": "3.2.1.3 NonHashData"
        }, 
        {
            "location": "/protocol-spec/#3214-transaction-execution", 
            "text": "A transaction defines either the deployment of a chaincode or the execution of a chaincode. All transactions within a block are run before recording a block in the ledger. When chaincodes execute, they may modify the world state. The hash of the world state is then recorded in the block.", 
            "title": "3.2.1.4 Transaction Execution"
        }, 
        {
            "location": "/protocol-spec/#322-world-state", 
            "text": "The  world state  of a peer refers to the collection of the  states  of all the deployed chaincodes. Further, the state of a chaincode is represented as a collection of key-value pairs. Thus, logically, the world state of a peer is also a collection of key-value pairs where key consists of a tuple  {chaincodeID, ckey} . Here, we use the term  key  to represent a key in the world state i.e., a tuple  {chaincodeID, ckey}  and we use the term  cKey  to represent a unique key within a chaincode.  For the purpose of the description below,  chaincodeID  is assumed to be a valid utf8 string and  ckey  and the  value  can be a sequence of one or more arbitrary bytes.", 
            "title": "3.2.2 World State"
        }, 
        {
            "location": "/protocol-spec/#3221-hashing-the-world-state", 
            "text": "During the functioning of a network, many occasions such as committing transactions and synchronizing peers may require computing a crypto-hash of the world state observed by a peer. For instance, the consensus protocol may require to ensure that a  minimum  number of peers in the network observe the same world state.  Since, computing the crypto-hash of the world state could be an expensive operation, this is highly desirable to organize the world state such that it enables an efficient crypto-hash computation of the world state when a change occurs in the world state. Further, different organization designs may be suitable under different workloads conditions.  Because the fabric is expected to function under a variety of scenarios leading to different workloads conditions, a pluggable mechanism is supported for organizing the world state.", 
            "title": "3.2.2.1 Hashing the world state"
        }, 
        {
            "location": "/protocol-spec/#32211-bucket-tree", 
            "text": "Bucket-tree  is one of the implementations for organizing the world state. For the purpose of the description below, a key in the world state is represented as a concatenation of the two components ( chaincodeID  and  ckey )  separated by a  nil  byte i.e.,  key  =  chaincodeID + nil + cKey .  This method models a  merkle-tree  on top of buckets of a  hash table  in order to compute the crypto-hash of the  world state .  At the core of this method, the  key-values  of the world state are assumed to be stored in a hash-table that consists of a pre-decided number of buckets ( numBuckets ). A hash function ( hashFunction ) is employed to determine the bucket number that should contain a given key. Please note that the  hashFunction  does not represent a crypto-hash method such as SHA3, rather this is a regular programming language hash function that decides the bucket number for a given key.  For modeling the merkle-tree, the ordered buckets act as leaf nodes of the tree - lowest numbered bucket being the left most leaf node in the tree. For constructing the second-last level of the tree, a pre-decided number of leaf nodes ( maxGroupingAtEachLevel ), starting from left, are grouped together and for each such group, a node is inserted at the second-last level that acts as a common parent for all the leaf nodes in the group. Note that the number of children for the last parent node may be less than  maxGroupingAtEachLevel . This grouping method of constructing the next higher level is repeated until the root node of the tree is constructed.  An example setup with configuration  {numBuckets=10009 and maxGroupingAtEachLevel=10}  will result in a tree with number of nodes at different level as depicted in the following table.     Level  Number of nodes      0  1    1  2    2  11    3  101    4  1001    5  10009     For computing the crypto-hash of the world state, the crypto-hash of each bucket is computed and is assumed to be the crypto-hash of leaf-nodes of the merkle-tree. In order to compute crypto-hash of a bucket, the key-values present in the bucket are first serialized and crypto-hash function is applied on the serialized bytes. For serializing the key-values of a bucket, all the key-values with a common chaincodeID prefix are serialized separately and then appending together, in the ascending order of chaincodeIDs. For serializing the key-values of a chaincodeID, the following information is concatenated:\n   1. Length of chaincodeID (number of bytes in the chaincodeID)\n   - The utf8 bytes of the chaincodeID\n   - Number of key-values for the chaincodeID\n   - For each key-value (in sorted order of the ckey)\n      - Length of the ckey\n      - ckey bytes\n      - Length of the value\n      - value bytes  For all the numeric types in the above list of items (e.g., Length of chaincodeID), protobuf's varint encoding is assumed to be used. The purpose of the above encoding is to achieve a byte representation of the key-values within a bucket that can not be arrived at by any other combination of key-values and also to reduce the overall size of the serialized bytes.  For example, consider a bucket that contains three key-values namely,  chaincodeID1_key1:value1, chaincodeID1_key2:value2, and chaincodeID2_key1:value1 . The serialized bytes for the bucket would logically look as -  12 + chaincodeID1 + 2 + 4 + key1 + 6 + value1 + 4 + key2 + 6 + value2 + 12 + chaincodeID2 + 1 + 4 + key1 + 6 + value1  If a bucket has no key-value present, the crypto-hash is considered as  nil .  The crypto-hash of an intermediate node and root node are computed just like in a standard merkle-tree i.e., applying a crypto-hash function on the bytes obtained by concatenating the crypto-hash of all the children nodes, from left to right. Further, if a child has a crypto-hash as  nil , the crypto-hash of the child is omitted when concatenating the children crypto-hashes. If the node has a single child, the crypto-hash of the child is assumed to be the crypto-hash of the node. Finally, the crypto-hash of the root node is considered as the crypto-hash of the world state.  The above method offers performance benefits for computing crypto-hash when a few key-values change in the state. The major benefits include\n  - Computation of crypto-hashes of the unchanged buckets can be skipped\n  - The depth and breadth of the merkle-tree can be controlled by configuring the parameters  numBuckets  and  maxGroupingAtEachLevel . Both depth and breadth of the tree has different implication on the performance cost incurred by and resource demand of different resources (namely - disk I/O, storage, and memory)  In a particular deployment, all the peer nodes are expected to use same values for the configurations  numBuckets, maxGroupingAtEachLevel, and hashFunction . Further, if any of these configurations are to be changed at a later stage, the configurations should be changed on all the peer nodes so that the comparison of crypto-hashes across peer nodes is meaningful. Also, this may require to migrate the existing data based on the implementation. For example, an implementation is expected to store the last computed crypto-hashes for all the nodes in the tree which would need to be recalculated.", 
            "title": "3.2.2.1.1 Bucket-tree"
        }, 
        {
            "location": "/protocol-spec/#33-chaincode", 
            "text": "Chaincode is an application-level code deployed as a transaction (see section 3.1.2) to be distributed to the network and managed by each validating peer as isolated sandbox. Though any virtualization technology can support the sandbox, currently Docker container is utilized to run the chaincode. The protocol described in this section enables different virtualization support implementation to plug and play.", 
            "title": "3.3 Chaincode"
        }, 
        {
            "location": "/protocol-spec/#331-virtual-machine-instantiation", 
            "text": "A virtual machine implements the VM interface:    type VM interface {\n    build(ctxt context.Context, id string, args []string, env []string, attachstdin bool, attachstdout bool, reader io.Reader) error\n    start(ctxt context.Context, id string, args []string, env []string, attachstdin bool, attachstdout bool) error\n    stop(ctxt context.Context, id string, timeout uint, dontkill bool, dontremove bool) error\n}  The fabric instantiates the VM when it processes a Deploy transaction or other transactions on the chaincode while the VM for that chaincode is not running (either crashed or previously brought down due to inactivity). Each chaincode image is built by the  build  function, started by  start  and stopped by  stop  function.  Once the chaincode container is up, it makes a gRPC connection back to the validating peer that started the chaincode, and that establishes the channel for Invoke and Query transactions on the chaincode.", 
            "title": "3.3.1 Virtual Machine Instantiation"
        }, 
        {
            "location": "/protocol-spec/#332-chaincode-protocol", 
            "text": "Communication between a validating peer and its chaincodes is based on a bidirectional gRPC stream. There is a shim layer on the chaincode container to handle the message protocol between the chaincode and the validating peer using protobuf message.  message ChaincodeMessage {\n\n    enum Type {\n        UNDEFINED = 0;\n        REGISTER = 1;\n        REGISTERED = 2;\n        INIT = 3;\n        READY = 4;\n        TRANSACTION = 5;\n        COMPLETED = 6;\n        ERROR = 7;\n        GET_STATE = 8;\n        PUT_STATE = 9;\n        DEL_STATE = 10;\n        INVOKE_CHAINCODE = 11;\n        INVOKE_QUERY = 12;\n        RESPONSE = 13;\n        QUERY = 14;\n        QUERY_COMPLETED = 15;\n        QUERY_ERROR = 16;\n        RANGE_QUERY_STATE = 17;\n    }\n\n    Type type = 1;\n    google.protobuf.Timestamp timestamp = 2;\n    bytes payload = 3;\n    string uuid = 4;\n}  Definition of fields: \n-  Type  is the type of the message.\n-  payload  is the payload of the message. Each payload depends on the  Type .\n-  uuid  is a unique identifier of the message.  The message types are described in the following sub-sections.  A chaincode implements the  Chaincode  interface, which is called by the validating peer when it processes Deploy, Invoke or Query transactions.  type Chaincode interface {\ni   Init(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n    Invoke(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n    Query(stub *ChaincodeStub, function string, args []string) ([]byte, error)\n}  Init ,  Invoke  and  Query  functions take  function  and  args  as parameters to be used by those methods to support a variety of transactions.  Init  is a constructor function, which will only be invoked by the Deploy transaction. The  Query  function is not allowed to modify the state of the chaincode; it can only read and calculate the return value as a byte array.", 
            "title": "3.3.2 Chaincode Protocol"
        }, 
        {
            "location": "/protocol-spec/#3321-chaincode-deploy", 
            "text": "Upon deploy (chaincode container is started), the shim layer sends a one time  REGISTER  message to the validating peer with the  payload  containing the  ChaincodeID . The validating peer responds with  REGISTERED  or  ERROR  on success or failure respectively. The shim closes the connection and exits if it receives an  ERROR .  After registration, the validating peer sends  INIT  with the  payload  containing a  ChaincodeInput  object. The shim calls the  Init  function with the parameters from the  ChaincodeInput , enabling the chaincode to perform any initialization, such as setting up the persistent state.  The shim responds with  RESPONSE  or  ERROR  message depending on the returned value from the chaincode  Init  function. If there are no errors, the chaincode initialization is complete and is ready to receive Invoke and Query transactions.", 
            "title": "3.3.2.1 Chaincode Deploy"
        }, 
        {
            "location": "/protocol-spec/#3322-chaincode-invoke", 
            "text": "When processing an invoke transaction, the validating peer sends a  TRANSACTION  message to the chaincode container shim, which in turn calls the chaincode  Invoke  function, passing the parameters from the  ChaincodeInput  object. The shim responds to the validating peer with  RESPONSE  or  ERROR  message, indicating the completion of the function. If  ERROR  is received, the  payload  contains the error message generated by the chaincode.", 
            "title": "3.3.2.2 Chaincode Invoke"
        }, 
        {
            "location": "/protocol-spec/#3323-chaincode-query", 
            "text": "Similar to an invoke transaction, when processing a query, the validating peer sends a  QUERY  message to the chaincode container shim, which in turn calls the chaincode  Query  function, passing the parameters from the  ChaincodeInput  object. The  Query  function may return a state value or an error, which the shim forwards to the validating peer using  RESPONSE  or  ERROR  messages respectively.", 
            "title": "3.3.2.3 Chaincode Query"
        }, 
        {
            "location": "/protocol-spec/#3324-chaincode-state", 
            "text": "Each chaincode may define its own persistent state variables. For example, a chaincode may create assets such as TVs, cars, or stocks using state variables to hold the assets attributes. During  Invoke  function processing, the chaincode may update the state variables, for example, changing an asset owner. A chaincode manipulates the state variables by using the following message types:", 
            "title": "3.3.2.4 Chaincode State"
        }, 
        {
            "location": "/protocol-spec/#put_state", 
            "text": "Chaincode sends a  PUT_STATE  message to persist a key-value pair, with the  payload  containing  PutStateInfo  object.  message PutStateInfo {\n    string key = 1;\n    bytes value = 2;\n}", 
            "title": "PUT_STATE"
        }, 
        {
            "location": "/protocol-spec/#get_state", 
            "text": "Chaincode sends a  GET_STATE  message to retrieve the value whose key is specified in the  payload .", 
            "title": "GET_STATE"
        }, 
        {
            "location": "/protocol-spec/#del_state", 
            "text": "Chaincode sends a  DEL_STATE  message to delete the value whose key is specified in the  payload .", 
            "title": "DEL_STATE"
        }, 
        {
            "location": "/protocol-spec/#range_query_state", 
            "text": "Chaincode sends a  RANGE_QUERY_STATE  message to get a range of values. The message  payload  contains a  RangeQueryStateInfo  object.  message RangeQueryState {\n    string startKey = 1;\n    string endKey = 2;\n}  The  startKey  and  endKey  are inclusive and assumed to be in lexical order. The validating peer responds with  RESPONSE  message whose  payload  is a  RangeQueryStateResponse  object.  message RangeQueryStateResponse {\n    repeated RangeQueryStateKeyValue keysAndValues = 1;\n    bool hasMore = 2;\n    string ID = 3;\n}\nmessage RangeQueryStateKeyValue {\n    string key = 1;\n    bytes value = 2;\n}  If  hasMore=true  in the response, this indicates that additional keys are available in the requested range. The chaincode can request the next set of keys and values by sending a  RangeQueryStateNext  message with an ID that matches the ID returned in the response.  message RangeQueryStateNext {\n    string ID = 1;\n}  When the chaincode is finished reading from the range, it should send a  RangeQueryStateClose  message with the ID it wishes to close.  message RangeQueryStateClose {\n  string ID = 1;\n}", 
            "title": "RANGE_QUERY_STATE"
        }, 
        {
            "location": "/protocol-spec/#invoke_chaincode", 
            "text": "Chaincode may call another chaincode in the same transaction context by sending an  INVOKE_CHAINCODE  message to the validating peer with the  payload  containing a  ChaincodeSpec  object.", 
            "title": "INVOKE_CHAINCODE"
        }, 
        {
            "location": "/protocol-spec/#query_chaincode", 
            "text": "Chaincode may query another chaincode in the same transaction context by sending a  QUERY_CHAINCODE  message with the  payload  containing a  ChaincodeSpec  object.", 
            "title": "QUERY_CHAINCODE"
        }, 
        {
            "location": "/protocol-spec/#34-pluggable-consensus-framework", 
            "text": "The consensus framework defines the interfaces that every consensus  plugin  implements:   consensus.Consenter : interface that  allows consensus plugin to receive messages from the network.  consensus.CPI :   Consensus Programming Interface  ( CPI ) is used by consensus plugin to interact with rest of the stack. This interface is split in two parts:  consensus.Communicator : used to send (broadcast and unicast) messages to other validating peers.  consensus.LedgerStack : which is used as an interface to the execution framework as well as the ledger.     As described below in more details,  consensus.LedgerStack  encapsulates, among other interfaces, the  consensus.Executor  interface, which is the key part of the consensus framework. Namely,  consensus.Executor  interface allows for a (batch of) transaction to be started, executed, rolled back if necessary, previewed, and potentially committed. A particular property that every consensus plugin needs to satisfy is that batches (blocks)  of transactions are committed to the ledger (via  consensus.Executor.CommitTxBatch ) in total order across all validating peers (see  consensus.Executor  interface description below for more details).  Currently, consensus framework consists of 3 packages  consensus ,  controller , and  helper . The primary reason for  controller  and  helper  packages is to avoid \"import cycle\" in Go (golang) and minimize code changes for plugin to update.   controller  package specifies the consensus plugin used by a validating peer.  helper  package is a shim around a consensus plugin that helps it interact with the rest of the stack, such as maintaining message handlers to other peers.     There are 2 consensus plugins provided:  pbft  and  noops :   obcpbft  package contains consensus plugin that implements  PBFT  [1] and  Sieve  consensus protocols. See section 5 for more detail.  noops  is a ''dummy'' consensus plugin for development and test purposes. It doesn't perform consensus but processes all consensus messages. It also serves as a good simple sample to start learning how to code a consensus plugin.", 
            "title": "3.4 Pluggable Consensus Framework"
        }, 
        {
            "location": "/protocol-spec/#341-consenter-interface", 
            "text": "Definition:  type Consenter interface {\n    RecvMsg(msg *pb.Message) error\n}  The plugin's entry point for (external) client requests, and consensus messages generated internally (i.e. from the consensus module) during the consensus process. The  controller.NewConsenter  creates the plugin  Consenter .  RecvMsg  processes the incoming transactions in order to reach consensus.  See  helper.HandleMessage  below to understand how the peer interacts with this interface.", 
            "title": "3.4.1 Consenter interface"
        }, 
        {
            "location": "/protocol-spec/#342-cpi-interface", 
            "text": "Definition:  type CPI interface {\n    Inquirer\n    Communicator\n    SecurityUtils\n    LedgerStack\n}  CPI  allows the plugin to interact with the stack. It is implemented by the  helper.Helper  object. Recall that this object:   Is instantiated when the  helper.NewConsensusHandler  is called.  Is accessible to the plugin author when they construct their plugin's  consensus.Consenter  object.", 
            "title": "3.4.2 CPI interface"
        }, 
        {
            "location": "/protocol-spec/#343-inquirer-interface", 
            "text": "Definition:  type Inquirer interface {\n        GetNetworkInfo() (self *pb.PeerEndpoint, network []*pb.PeerEndpoint, err error)\n        GetNetworkHandles() (self *pb.PeerID, network []*pb.PeerID, err error)\n}  This interface is a part of the  consensus.CPI  interface. It is used to get the handles of the validating peers in the network ( GetNetworkHandles ) as well as details about the those validating peers ( GetNetworkInfo ):  Note that the peers are identified by a  pb.PeerID  object. This is a protobuf message (in the  protos  package), currently defined as (notice that this definition will likely be modified):  message PeerID {\n    string name = 1;\n}", 
            "title": "3.4.3 Inquirer interface"
        }, 
        {
            "location": "/protocol-spec/#344-communicator-interface", 
            "text": "Definition:  type Communicator interface {\n    Broadcast(msg *pb.Message) error\n    Unicast(msg *pb.Message, receiverHandle *pb.PeerID) error\n}  This interface is a part of the  consensus.CPI  interface. It is used to communicate with other peers on the network ( helper.Broadcast ,  helper.Unicast ):", 
            "title": "3.4.4 Communicator interface"
        }, 
        {
            "location": "/protocol-spec/#345-securityutils-interface", 
            "text": "Definition:  type SecurityUtils interface {\n        Sign(msg []byte) ([]byte, error)\n        Verify(peerID *pb.PeerID, signature []byte, message []byte) error\n}  This interface is a part of the  consensus.CPI  interface. It is used to handle the cryptographic operations of message signing ( Sign ) and verifying signatures ( Verify )", 
            "title": "3.4.5 SecurityUtils interface"
        }, 
        {
            "location": "/protocol-spec/#346-ledgerstack-interface", 
            "text": "Definition:  type LedgerStack interface {\n    Executor\n    Ledger\n    RemoteLedgers\n}  A key member of the  CPI  interface,  LedgerStack  groups interaction of consensus with the rest of the fabric, such as the execution of transactions, querying, and updating the ledger.  This interface supports querying the local blockchain and state, updating the local blockchain and state, and querying the blockchain and state of other nodes in the consensus network. It consists of three parts:  Executor ,  Ledger  and  RemoteLedgers  interfaces. These are described in the following.", 
            "title": "3.4.6 LedgerStack interface"
        }, 
        {
            "location": "/protocol-spec/#347-executor-interface", 
            "text": "Definition:  type Executor interface {\n    BeginTxBatch(id interface{}) error\n    ExecTXs(id interface{}, txs []*pb.Transaction) ([]byte, []error)  \n    CommitTxBatch(id interface{}, transactions []*pb.Transaction, transactionsResults []*pb.TransactionResult, metadata []byte) error  \n    RollbackTxBatch(id interface{}) error  \n    PreviewCommitTxBatchBlock(id interface{}, transactions []*pb.Transaction, metadata []byte) (*pb.Block, error)  \n}  The executor interface is the most frequently utilized portion of the  LedgerStack  interface, and is the only piece which is strictly necessary for a consensus network to make progress.  The interface allows for a transaction to be started, executed, rolled back if necessary, previewed, and potentially committed.  This interface is comprised of the following methods.", 
            "title": "3.4.7 Executor interface"
        }, 
        {
            "location": "/protocol-spec/#3471-beginning-a-transaction-batch", 
            "text": "BeginTxBatch(id interface{}) error  This call accepts an arbitrary  id , deliberately opaque, as a way for the consensus plugin to ensure only the transactions associated with this particular batch are executed. For instance, in the pbft implementation, this  id  is the an encoded hash of the transactions to be executed.", 
            "title": "3.4.7.1 Beginning a transaction batch"
        }, 
        {
            "location": "/protocol-spec/#3472-executing-transactions", 
            "text": "ExecTXs(id interface{}, txs []*pb.Transaction) ([]byte, []error)  This call accepts an array of transactions to execute against the current state of the ledger and returns the current state hash in addition to an array of errors corresponding to the array of transactions.  Note that a transaction resulting in an error has no effect on whether a transaction batch is safe to commit.  It is up to the consensus plugin to determine the behavior which should occur when failing transactions are encountered.  This call is safe to invoke multiple times.", 
            "title": "3.4.7.2 Executing transactions"
        }, 
        {
            "location": "/protocol-spec/#3473-committing-and-rolling-back-transactions", 
            "text": "RollbackTxBatch(id interface{}) error  This call aborts an execution batch.  This will undo the changes to the current state, and restore the ledger to its previous state.  It concludes the batch begun with  BeginBatchTx  and a new one must be created before executing any transactions.  PreviewCommitTxBatchBlock(id interface{}, transactions []*pb.Transaction, metadata []byte) (*pb.Block, error)  This call is most useful for consensus plugins which wish to test for non-deterministic transaction execution.  The hashable portions of the block returned are guaranteed to be identical to the block which would be committed if  CommitTxBatch  were immediately invoked.  This guarantee is violated if any new transactions are executed.  CommitTxBatch(id interface{}, transactions []*pb.Transaction, transactionsResults []*pb.TransactionResult, metadata []byte) error  This call commits a block to the blockchain.  Blocks must be committed to a blockchain in total order.  CommitTxBatch  concludes the transaction batch, and a new call to  BeginTxBatch  must be made before any new transactions are executed and committed.", 
            "title": "3.4.7.3 Committing and rolling-back transactions"
        }, 
        {
            "location": "/protocol-spec/#348-ledger-interface", 
            "text": "Definition:  type Ledger interface {\n    ReadOnlyLedger\n    UtilLedger\n    WritableLedger\n}  Ledger  interface is intended to allow the consensus plugin to interrogate and possibly update the current state and blockchain. It is comprised of the three interfaces described below.", 
            "title": "3.4.8 Ledger interface"
        }, 
        {
            "location": "/protocol-spec/#3481-readonlyledger-interface", 
            "text": "Definition:  type ReadOnlyLedger interface {\n    GetBlock(id uint64) (block *pb.Block, err error)\n    GetCurrentStateHash() (stateHash []byte, err error)\n    GetBlockchainSize() (uint64, error)\n}  ReadOnlyLedger  interface is intended to query the local copy of the ledger without the possibility of modifying it.  It is comprised of the following functions.  GetBlockchainSize() (uint64, error)  This call returns the current length of the blockchain ledger.  In general, this function should never fail, though in the unlikely event that this occurs, the error is passed to the caller to decide what if any recovery is necessary.  The block with the highest number will have block number  GetBlockchainSize()-1 .    Note that in the event that the local copy of the blockchain ledger is corrupt or incomplete, this call will return the highest block number in the chain, plus one.  This allows for a node to continue operating from the current state/block even when older blocks are corrupt or missing.  GetBlock(id uint64) (block *pb.Block, err error)  This call returns the block from the blockchain with block number  id .  In general, this call should not fail, except when the block queried exceeds the current blocklength, or when the underlying blockchain has somehow become corrupt.  A failure of  GetBlock  has a possible resolution of using the state transfer mechanism to retrieve it.  GetCurrentStateHash() (stateHash []byte, err error)  This call returns the current state hash for the ledger.  In general, this function should never fail, though in the unlikely event that this occurs, the error is passed to the caller to decide what if any recovery is necessary.", 
            "title": "3.4.8.1 ReadOnlyLedger interface"
        }, 
        {
            "location": "/protocol-spec/#3482-utilledger-interface", 
            "text": "Definition:  type UtilLedger interface {\n    HashBlock(block *pb.Block) ([]byte, error)\n    VerifyBlockchain(start, finish uint64) (uint64, error)\n}  UtilLedger   interface defines some useful utility functions which are provided by the local ledger.  Overriding these functions in a mock interface can be useful for testing purposes.  This interface is comprised of two functions.  HashBlock(block *pb.Block) ([]byte, error)  Although  *pb.Block  has a  GetHash  method defined, for mock testing, overriding this method can be very useful.  Therefore, it is recommended that the  GetHash  method never be directly invoked, but instead invoked via this  UtilLedger.HashBlock  interface.  In general, this method should never fail, but the error is still passed to the caller to decide what if any recovery is appropriate.  VerifyBlockchain(start, finish uint64) (uint64, error)  This utility method is intended for verifying large sections of the blockchain.  It proceeds from a high block  start  to a lower block  finish , returning the block number of the first block whose  PreviousBlockHash  does not match the block hash of the previous block as well as an error.  Note, this generally indicates the last good block number, not the first bad block number.", 
            "title": "3.4.8.2 UtilLedger interface"
        }, 
        {
            "location": "/protocol-spec/#3483-writableledger-interface", 
            "text": "Definition:  type WritableLedger interface {\n    PutBlock(blockNumber uint64, block *pb.Block) error\n    ApplyStateDelta(id interface{}, delta *statemgmt.StateDelta) error\n    CommitStateDelta(id interface{}) error\n    RollbackStateDelta(id interface{}) error\n    EmptyState() error\n}  WritableLedger   interface allows for the caller to update the blockchain.  Note that this is  NOT  intended for use in normal operation of a consensus plugin.  The current state should be modified by executing transactions using the  Executor  interface, and new blocks will be generated when transactions are committed.  This interface is instead intended primarily for state transfer or corruption recovery.  In particular, functions in this interface should  NEVER  be exposed directly via consensus messages, as this could result in violating the immutability promises of the blockchain concept.  This interface is comprised of the following functions.  -\n     PutBlock(blockNumber uint64, block *pb.Block) error  This function takes a provided, raw block, and inserts it into the blockchain at the given blockNumber.  Note that this intended to be an unsafe interface, so no error or sanity checking is performed.  Inserting a block with a number higher than the current block height is permitted, similarly overwriting existing already committed blocks is also permitted.  Remember, this does not affect the auditability or immutability of the chain, as the hashing techniques make it computationally infeasible to forge a block earlier in the chain.  Any attempt to rewrite the blockchain history is therefore easily detectable.  This is generally only useful to the state transfer API.  -\n     ApplyStateDelta(id interface{}, delta *statemgmt.StateDelta) error  This function takes a state delta, and applies it to the current state.  The delta will be applied to transition a state forward or backwards depending on the construction of the state delta.  Like the `Executor` methods, `ApplyStateDelta` accepts an opaque interface `id` which should also be passed into `CommitStateDelta` or `RollbackStateDelta` as appropriate.  -\n     CommitStateDelta(id interface{}) error  This function commits the state delta which was applied in `ApplyStateDelta`.  This is intended to be invoked after the caller to `ApplyStateDelta` has verified the state via the state hash obtained via `GetCurrentStateHash()`.  This call takes the same `id` which was passed into `ApplyStateDelta`.  -\n     RollbackStateDelta(id interface{}) error  This function unapplies a state delta which was applied in `ApplyStateDelta`.  This is intended to be invoked after the caller to `ApplyStateDelta` has detected the state hash obtained via `GetCurrentStateHash()` is incorrect.  This call takes the same `id` which was passed into `ApplyStateDelta`.  -\n     EmptyState() error  This function will delete the entire current state, resulting in a pristine empty state.  It is intended to be called before loading an entirely new state via deltas.  This is generally only useful to the state transfer API.", 
            "title": "3.4.8.3 WritableLedger interface"
        }, 
        {
            "location": "/protocol-spec/#349-remoteledgers-interface", 
            "text": "Definition:  type RemoteLedgers interface {\n    GetRemoteBlocks(peerID uint64, start, finish uint64) ( -chan *pb.SyncBlocks, error)\n    GetRemoteStateSnapshot(peerID uint64) ( -chan *pb.SyncStateSnapshot, error)\n    GetRemoteStateDeltas(peerID uint64, start, finish uint64) ( -chan *pb.SyncStateDeltas, error)\n}  The  RemoteLedgers  interface exists primarily to enable state transfer and to interrogate the blockchain state at  other replicas.  Just like the  WritableLedger  interface, it is not intended to be used in normal operation and is designed to be used for catchup, error recovery, etc.  For all functions in this interface it is the caller's responsibility to enforce timeouts.  This interface contains the following functions.    GetRemoteBlocks(peerID uint64, start, finish uint64) ( -chan *pb.SyncBlocks, error)  This function attempts to retrieve a stream of  *pb.SyncBlocks  from the peer designated by  peerID  for the range from  start  to  finish .  In general,  start  should be specified with a higher block number than  finish , as the blockchain must be validated from end to beginning.  The caller must validate that the desired block is being returned, as it is possible that slow results from another request could appear on this channel.  Invoking this call for the same  peerID  a second time will cause the first channel to close.    ```\nGetRemoteStateSnapshot(peerID uint64) ( -chan *pb.SyncStateSnapshot, error)\n```  This function attempts to retrieve a stream of  *pb.SyncStateSnapshot  from the peer designated by  peerID .  To apply the result, the existing state should first be emptied via the  WritableLedger   EmptyState  call, then the contained deltas in the stream should be applied sequentially.    -\n     GetRemoteStateDeltas(peerID uint64, start, finish uint64) ( -chan *pb.SyncStateDeltas, error)  This function attempts to retrieve a stream of `*pb.SyncStateDeltas` from the peer designated by `peerID` for the range from `start` to `finish`.  The caller must validated that the desired block delta is being returned, as it is possible that slow results from another request could appear on this channel.  Invoking this call for the same `peerID` a second time will cause the first channel to close.", 
            "title": "3.4.9 RemoteLedgers interface"
        }, 
        {
            "location": "/protocol-spec/#3410-controller-package", 
            "text": "", 
            "title": "3.4.10 controller package"
        }, 
        {
            "location": "/protocol-spec/#34101-controllernewconsenter", 
            "text": "Signature:  func NewConsenter(cpi consensus.CPI) (consenter consensus.Consenter)  This function reads the  peer.validator.consensus  value in  core.yaml  configuration file, which is the  configuration file for the  peer  process. The value of the  peer.validator.consensus  key defines whether the validating peer will run with the  noops  consensus plugin or the  obcpbft  one. (Notice that this should eventually be changed to either  noops  or  custom . In case of  custom , the validating peer will run with the consensus plugin defined in  consensus/config.yaml .)  The plugin author needs to edit the function's body so that it routes to the right constructor for their package. For example, for  obcpbft  we point to the  obcpft.GetPlugin  constructor.  This function is called by  helper.NewConsensusHandler  when setting the  consenter  field of the returned message handler. The input argument  cpi  is the output of the  helper.NewHelper  constructor and implements the  consensus.CPI  interface.", 
            "title": "3.4.10.1 controller.NewConsenter"
        }, 
        {
            "location": "/protocol-spec/#3411-helper-package", 
            "text": "", 
            "title": "3.4.11 helper package"
        }, 
        {
            "location": "/protocol-spec/#34111-high-level-overview", 
            "text": "A validating peer establishes a message handler ( helper.ConsensusHandler ) for every connected peer, via the  helper.NewConsesusHandler  function (a handler factory). Every incoming message is inspected on its type ( helper.HandleMessage ); if it's a message for which consensus needs to be reached, it's passed on to the peer's consenter object ( consensus.Consenter ). Otherwise it's passed on to the next message handler in the stack.", 
            "title": "3.4.11.1 High-level overview"
        }, 
        {
            "location": "/protocol-spec/#34112-helperconsensushandler", 
            "text": "Definition:  type ConsensusHandler struct {\n    chatStream  peer.ChatStream\n    consenter   consensus.Consenter\n    coordinator peer.MessageHandlerCoordinator\n    done        chan struct{}\n    peerHandler peer.MessageHandler\n}  Within the context of consensus, we focus only on the  coordinator  and  consenter  fields. The  coordinator , as the name implies, is used to coordinate between the peer's message handlers. This is, for instance, the object that is accessed when the peer wishes to  Broadcast . The  consenter  receives the messages for which consensus needs to be reached and processes them.  Notice that  fabric/peer/peer.go  defines the  peer.MessageHandler  (interface), and  peer.MessageHandlerCoordinator  (interface) types.", 
            "title": "3.4.11.2 helper.ConsensusHandler"
        }, 
        {
            "location": "/protocol-spec/#34113-helpernewconsensushandler", 
            "text": "Signature:  func NewConsensusHandler(coord peer.MessageHandlerCoordinator, stream peer.ChatStream, initiatedStream bool, next peer.MessageHandler) (peer.MessageHandler, error)  Creates a  helper.ConsensusHandler  object. Sets the same  coordinator  for every message handler. Also sets the  consenter  equal to:  controller.NewConsenter(NewHelper(coord))", 
            "title": "3.4.11.3 helper.NewConsensusHandler"
        }, 
        {
            "location": "/protocol-spec/#34114-helperhelper", 
            "text": "Definition:  type Helper struct {\n    coordinator peer.MessageHandlerCoordinator\n}  Contains the reference to the validating peer's  coordinator . Is the object that implements the  consensus.CPI  interface for the peer.", 
            "title": "3.4.11.4 helper.Helper"
        }, 
        {
            "location": "/protocol-spec/#34115-helpernewhelper", 
            "text": "Signature:  func NewHelper(mhc peer.MessageHandlerCoordinator) consensus.CPI  Returns a  helper.Helper  object whose  coordinator  is set to the input argument  mhc  (the  coordinator  field of the  helper.ConsensusHandler  message handler). This object implements the  consensus.CPI  interface, thus allowing the plugin to interact with the stack.", 
            "title": "3.4.11.5 helper.NewHelper"
        }, 
        {
            "location": "/protocol-spec/#34116-helperhandlemessage", 
            "text": "Recall that the  helper.ConsesusHandler  object returned by  helper.NewConsensusHandler  implements the  peer.MessageHandler  interface:  type MessageHandler interface {\n    RemoteLedger\n    HandleMessage(msg *pb.Message) error\n    SendMessage(msg *pb.Message) error\n    To() (pb.PeerEndpoint, error)\n    Stop() error\n}  Within the context of consensus, we focus only on the  HandleMessage  method. Signature:  func (handler *ConsensusHandler) HandleMessage(msg *pb.Message) error  The function inspects the  Type  of the incoming  Message . There are four cases:   Equal to  pb.Message_CONSENSUS : passed to the handler's  consenter.RecvMsg  function.  Equal to  pb.Message_CHAIN_TRANSACTION  (i.e. an external deployment request): a response message is sent to the user first, then the message is passed to the  consenter.RecvMsg  function.  Equal to  pb.Message_CHAIN_QUERY  (i.e. a query): passed to the  helper.doChainQuery  method so as to get executed locally.  Otherwise: passed to the  HandleMessage  method of the next handler down the stack.", 
            "title": "3.4.11.6 helper.HandleMessage"
        }, 
        {
            "location": "/protocol-spec/#35-events", 
            "text": "The event framework provides the ability to generate and consume predefined and custom events. There are 3 basic components:\n  - Event stream\n  - Event adapters\n  - Event structures", 
            "title": "3.5 Events"
        }, 
        {
            "location": "/protocol-spec/#351-event-stream", 
            "text": "An event stream is a gRPC channel capable of sending and receiving events. Each consumer establishes an event stream to the event framework and expresses the events that it is interested in. the event producer only sends appropriate events to the consumers who have connected to the producer over the event stream.  The event stream initializes the buffer and timeout parameters. The buffer holds the number of events waiting for delivery, and the timeout has 3 options when the buffer is full:   If timeout is less than 0, drop the newly arriving events  If timeout is 0, block on the event until the buffer becomes available  If timeout is greater than 0, wait for the specified timeout and drop the event if the buffer remains full after the timeout", 
            "title": "3.5.1 Event Stream"
        }, 
        {
            "location": "/protocol-spec/#3511-event-producer", 
            "text": "The event producer exposes a function to send an event,  Send(e *pb.Event) , where  Event  is either a pre-defined  Block  or a  Generic  event. More events will be defined in the future to include other elements of the fabric.  message Generic {\n    string eventType = 1;\n    bytes payload = 2;\n}  The  eventType  and  payload  are freely defined by the event producer. For example, JSON data may be used in the  payload . The  Generic  event may also be emitted by the chaincode or plugins to communicate with consumers.", 
            "title": "3.5.1.1 Event Producer"
        }, 
        {
            "location": "/protocol-spec/#3512-event-consumer", 
            "text": "The event consumer enables external applications to listen to events. Each event consumer registers an event adapter with the event stream. The consumer framework can be viewed as a bridge between the event stream and the adapter. A typical use of the event consumer framework is:  adapter =  adapter supplied by the client application to register and receive events \nconsumerClient = NewEventsClient( event consumer address , adapter)\nconsumerClient.Start()\n...\n...\nconsumerClient.Stop()", 
            "title": "3.5.1.2 Event Consumer"
        }, 
        {
            "location": "/protocol-spec/#352-event-adapters", 
            "text": "The event adapter encapsulates three facets of event stream interaction:\n  - an interface that returns the list of all events of interest\n  - an interface called by the event consumer framework on receipt of an event\n  - an interface called by the event consumer framework when the event bus terminates  The reference implementation provides Golang specific language binding.        EventAdapter interface {\n         GetInterestedEvents() ([]*ehpb.Interest, error)\n         Recv(msg *ehpb.Event) (bool,error)\n         Disconnected(err error)\n      }  Using gRPC as the event bus protocol allows the event consumer framework to be ported to different language bindings without affecting the event producer framework.", 
            "title": "3.5.2 Event Adapters"
        }, 
        {
            "location": "/protocol-spec/#353-event-structure", 
            "text": "This section details the message structures of the event system. Messages are described directly in Golang for simplicity.  The core message used for communication between the event consumer and producer is the Event.      message Event {\n        oneof Event {\n            //consumer events\n            Register register = 1;\n\n            //producer events\n            Block block = 2;\n            Generic generic = 3;\n       }\n    }  Per the above definition, an event has to be one of  Register ,  Block  or  Generic .  As mentioned in the previous sections, a consumer creates an event bus by establishing a connection with the producer and sending a  Register  event. The  Register  event is essentially an array of  Interest  messages declaring the events of interest to the consumer.      message Interest {\n        enum ResponseType {\n            //don't send events (used to cancel interest)\n            DONTSEND = 0;\n            //send protobuf objects\n            PROTOBUF = 1;\n            //marshall into JSON structure\n            JSON = 2;\n        }\n        string eventType = 1;\n        ResponseType responseType = 2;\n    }  Events can be sent directly as protobuf structures or can be sent as JSON structures by specifying the  responseType  appropriately.  Currently, the producer framework can generate a  Block  or a  Generic  event. A  Block  is a message used for encapsulating properties of a block in the blockchain.", 
            "title": "3.5.3 Event Structure"
        }, 
        {
            "location": "/protocol-spec/#4-security_1", 
            "text": "This section discusses the setting depicted in the figure below.\nIn particular, the system consists of the following entities:\nmembership management infrastructure, i.e., a set of entities that are\nresponsible for identifying an individual user (using any form of identification\nconsidered in the system, e.g., credit cards, id-cards), open an account for\nthat user to be able to register, and issue the necessary credentials to\nsuccessfully create transactions and deploy or invoke chaincode successfully\nthrough the fabric. \n * Peers, that are classified as validating peers, and non-validating peers.\n   Validating peers (also known as validators) order and process (check validity, execute,\n   and add to the blockchain) user-messages (transactions) submitted to the network.\n   Non validating peers (also known as peers) receive user transactions on behalf of users,\n   and after some fundamental validity checks, they forward the transactions to their\n   neighboring validating peers. Peers maintain an up-to-date copy of the blockchain,\n   but in contradiction to validators, they do not execute transactions\n   (a process also known as  transaction validation ).\n * End users of the system, that have registered to our membership service administration,\n   after having demonstrated ownership of what is considered  identity  in the system,\n   and have obtained credentials to install the client-software and submit transactions\n   to the system.\n * Client-software, the software that needs to be installed at the client side for the\n   latter to be able to complete his registration to our membership service and submit\n   transactions to the system.\n * Online wallets, entities that are trusted by a user to maintain that user's credentials,\n   and submit transactions solely upon user request to the network. Online wallets come\n   with their own software at the client-side, that is usually light-weight, as the\n   client only needs to authenticate himself and his requests to the wallet.\n   While it can be the case that peers can play the role of  online wallet  for a set of\n   users, in the following sessions the security of online wallets is detailed separately.  Users who wish to make use of the fabric, open an account at the membership management\nadministration, by proving ownership of identity as discussed in previous sections, new chaincodes\nare announced to the blockchain network by the chaincode creator (developer) through the means\nof a deployment transaction that the client-software would construct on behalf of the developer.\nSuch transaction is first received by a peer or validator, and afterwards circulated\nin the entire network of validators, this transaction is executed and finds its place to\nthe blockchain network. Users can also invoke a function of an already deployed chain-code\nthrough an invocation transaction.  The next section provides a summary of the business goals of the system that drive the security requirements. We then overview the security components and their operation and show how this design fulfills the security requirements.", 
            "title": "4. Security"
        }, 
        {
            "location": "/protocol-spec/#41-business-security-requirements", 
            "text": "This section presents business security requirements that are relevant to the context of the fabric. Incorporation of identity and role management.  In order to adequately support real business applications it is necessary to progress beyond ensuring cryptographic continuity. A workable B2B system must consequently move towards addressing proven/demonstrated identities or other attributes relevant to conducting business. Business transactions and consumer interactions with financial institutions need to be unambiguously mapped to account holders. Business contracts typically require demonstrable affiliation with specific institutions and/or possession of other specific properties of transacting parties. Accountability and non-frameability are two reasons that identity management is a critical component of such systems.  Accountability means that users of the system, individuals, or corporations, who misbehave can be traced back and be set accountable for their actions. In many cases, members of a B2B system are required to use their identities (in some form) to participate in the system, in a way such that accountability is guaranteed. Accountability and non-frameability are both essential security requirements in B2B systems and they are closely related. That is, a B2B system should guarantee that an honest user of such system cannot be framed to be accused as responsible for transactions originated by other users.  In addition a B2B system should be renewable and flexible in order to accommodate changes of participants\u2019s roles and/or affiliations.  Transactional privacy.  In B2B relationships there is a strong need for transactional privacy, i.e., allowing the end-user of a system to control the degree to which it interacts and shares information with its environment. For example, a corporation doing business through a transactional B2B system requires that its transactions are not visible to other corporations or industrial partners that are not authorized to share classified information with.  Transactional privacy in the fabric is offered by the mechanisms to achieve two properties with respect to non authorized users:    Transaction anonymity, where the owner of a transaction is hidden among the so called  anonymity set , which in the fabric, is the set of users.    Transaction unlinkability, where two or more transactions of the same user should not be linked as such.    Clearly depending on the context, non-authorized users can be anyone outside the system, or a subset of users.  Transactional privacy is strongly associated to the confidentiality of the content of a contractual agreement between two or more members of a B2B system, as well as to the anonymity and unlinkability of any authentication mechanism that should be in place within transactions.  Reconciling transactional privacy with identity management.  As described later in this document, the approach taken here to reconcile identity management with user privacy and to enable competitive institutions to transact effectively on a common blockchain (for both intra- and inter-institutional transactions) is as follows:    add certificates to transactions to implement a \u201cpermissioned\u201d blockchain    utilize a two-level system:    (relatively) static enrollment certificates (ECerts), acquired via registration with an enrollment certificate authority (CA).    transaction certificates (TCerts) that faithfully but pseudonymously represent enrolled users, acquired via a transaction CA.    offer mechanisms to conceal the content of transactions to unauthorized members of the system.    Audit support.  Commercial systems are occasionally subjected to audits. Auditors in such cases should be given the means to check a certain transaction, or a certain group of transactions, the activity of a particular user of the system, or the operation of the system itself. Thus, such capabilities should be offered by any system featuring transactions containing contractual agreements between business partners.", 
            "title": "4.1 Business security requirements"
        }, 
        {
            "location": "/protocol-spec/#42-user-privacy-through-membership-services", 
            "text": "Membership Services consists of an infrastructure of several entities that together manage the identity and privacy of users on the network. These services validate user\u2019s identity, register the user in the system, and provide all the credentials needed for him/her to be an active and compliant participant able to create and/or invoke transactions. A Public Key Infrastructure (PKI) is a framework based on public key cryptography that ensures not only the secure exchange of data over public networks but also affirms the identity of the other party. A PKI manages the generation, distribution and revocation of keys and digital certificates. Digital certificates are used to establish user credentials and to sign messages. Signing messages with a certificate ensures that the message has not been altered. Typically a PKI has a Certificate Authority (CA), a Registration Authority (RA), a certificate database, and a certificate storage. The RA is a trusted party that authenticates users and vets the legitimacy of data, certificates or other evidence submitted to support the user\u2019s request for one or more certificates that reflect that user\u2019s identity or other properties. A CA, upon advice from an RA, issues digital certificates for specific uses and is certified directly or hierarchically by a root CA. Alternatively, the user-facing communications and due diligence responsibilities of the RA can be subsumed as part of the CA. Membership Services is composed of the entities shown in the following figure. Introduction of such full PKI reinforces the strength of this system for B2B (over, e.g. Bitcoin).   Root Certificate Authority (Root CA):  entity that represents the trust anchor for the PKI scheme. Digital certificates verification follows a chain of trust. The Root CA is the top-most CA in the PKI hierarchy.  Registration Authority (RA):  a trusted entity that can ascertain the validity and identity of users who want to participate in the permissioned blockchain. It is responsible for out-of-band communication with the user to validate his/her identity and role.  It creates registration credentials needed for enrollment and information on root of trust.  Enrollment Certificate Authority (ECA):   responsible for issuing Enrollment Certificates (ECerts) after validating the registration credentials provided by the user.  Transaction Certificate Authority (TCA):  responsible for issuing Transaction Certificates (TCerts) after validating the enrollment credentials provided by the user.    TLS Certificate Authority (TLS-CA):  responsible for issuing TLS certificates and credentials that allow the user to make use of its network. It validates the credential(s) or evidence provided by the user that justifies issuance of a TLS certificate that includes specific information pertaining to the user.  In this specification, membership services is expressed through the following associated certificates issued by the PKI:  Enrollment Certificates (ECerts) \nECerts are long-term certificates. They are issued for all roles, i.e. users, non-validating peers, and validating peers. In the case of users, who submit transactions for candidate incorporation into the blockchain and who also own TCerts (discussed below), there are two possible structure and usage models for ECerts:    Model A:  ECerts contain the identity/enrollmentID of their owner and can be used to offer only nominal entity-authentication for TCert requests and/or within transactions. They contain the public part of two key pairs \u2013 a signature key-pair and an encryption/key agreement key-pair. ECerts are accessible to everyone.    Model B: ECerts contain the identity/enrollmentID of their owner and can be used to offer only nominal entity-authentication for TCert requests. They contain the public part of a signature key-pair, i.e., a signature verification public key. ECerts are preferably accessible to only TCA and auditors, as relying parties. They are invisible to transactions, and thus (unlike TCerts) their signature key pairs do not play a non-repudiation role at that level.    Transaction Certificates (TCerts) \nTCerts are short-term certificates for each transaction. They are issued by the TCA upon authenticated user-request. They securely authorize a transaction and may be configured to not reveal the identities of who is involved in the transaction or to selectively reveal such identity/enrollmentID information. They include the public part of a signature key-pair, and may be configured to also include the public part of a key agreement key pair. They are issued only to users. They are uniquely associated to the owner \u2013 they may be configured so that this association is known only by the TCA (and to authorized auditors). TCerts may be configured to not carry information of the identity of the user. They enable the user not only to anonymously participate in the system but also prevent linkability of transactions.  However, auditability and accountability requirements assume that the TCA is able to retrieve TCerts of a given identity, or retrieve the owner of a specific TCert. For details on how TCerts are used in deployment and invocation transactions see Section 4.3, Transaction Security offerings at the infrastructure level.    TCerts can accommodate encryption or key agreement public keys (as well as digital signature verification public keys).\nIf TCerts are thus equipped, then enrollment certificates need not also contain encryption or key agreement public keys.  Such a key agreement public key, Key_Agreement_TCertPub_Key, can be generated by the transaction certificate authority (TCA) using a method that is the same as that used to generate the Signature_Verification_TCertPub_Key, but using an index value of TCertIndex + 1 rather than TCertIndex, where TCertIndex is hidden within the TCert by the TCA for recovery by the TCert owner.  The structure of a Transaction Certificate (TCert) is as follows:  TCertID \u2013 transaction certificate ID (preferably generated by TCA randomly in order to avoid unintended linkability via the Hidden Enrollment ID field).  Hidden Enrollment ID: AES_Encrypt K (enrollmentID), where key K = [HMAC(Pre-K, TCertID)] 256-bit truncation  and where three distinct key distribution scenarios for Pre-K are defined below as (a), (b) and (c).  Hidden Private Keys Extraction: AES_Encrypt TCertOwner_EncryptKey (TCertIndex || known padding/parity check vector) where || denotes concatenation, and where each batch has a unique (per batch) time-stamp/random offset that is added to a counter (initialized at 1 in this implementation) in order to generate TCertIndex. The counter can be incremented by 2 each time in order to accommodate generation by the TCA of the public keys and recovery by the TCert owner of the private keys of both types, i.e., signature key pairs and key agreement key pairs.  Sign Verification Public Key \u2013 TCert signature verification public key.  Key Agreement Public Key \u2013 TCert key agreement public key.  Validity period \u2013 the time window during which the transaction certificate can be used for the outer/external signature of a transaction.  There are at least three useful ways to consider configuring the key distribution scenario for the Hidden Enrollment ID field: (a)  Pre-K is distributed during enrollment to user clients, peers and auditors, and is available to the TCA and authorized auditors. It may, for example, be derived from K chain  (described subsequently in this specification) or be independent of key(s) used for chaincode confidentiality.  (b)  Pre-K is available to validators, the TCA and authorized auditors. K is made available by a validator to a user (under TLS) in response to a successful query transaction. The query transaction can have the same format as the invocation transaction. Corresponding to Example 1 below, the querying user would learn the enrollmentID of the user who created the Deployment Transaction if the querying user owns one of the TCerts in the ACL of the Deployment Transaction. Corresponding to Example 2 below, the querying user would learn the enrollmentID of the user who created the Deployment Transaction if the enrollmentID of the TCert used to query matches one of the affiliations/roles in the Access Control field of the Deployment Transaction.  Example 1:   Example 2:   (c)  Pre-K is available to the TCA and authorized auditors. The TCert-specific K can be distributed the TCert owner (under TLS) along with the TCert, for each TCert in the batch. This enables targeted release by the TCert owner of K (and thus trusted notification of the TCert owner\u2019s enrollmentID). Such targeted release can use key agreement public keys of the intended recipients and/or PK chain  where SK chain  is available to validators as described subsequently in this specification. Such targeted release to other contract participants can be incorporated into a transaction or done out-of-band.  If the TCerts are used in conjunction with ECert Model A above, then using (c) where K is not distributed to the TCert owner may suffice.\nIf the TCerts are used in conjunction with ECert Model A above, then the Key Agreement Public Key field of the TCert may not be necessary.  The Transaction Certificate Authority (TCA) returns TCerts in batches, each batch contains the KeyDF_Key (Key-Derivation-Function Key) which is not included within every TCert but delivered to the client with the batch of TCerts (using TLS). The KeyDF_Key allows the TCert owner to derive TCertOwner_EncryptKey which in turn enables recovery of TCertIndex from AES_Encrypt TCertOwner_EncryptKey (TCertIndex || known padding/parity check vector).  TLS-Certificates (TLS-Certs) \nTLS-Certs are certificates used for system/component-to-system/component communications. They carry the identity of their owner and are used for network level security.  This implementation of membership services provides the following basic functionality: there is no expiration/revocation of ECerts; expiration of TCerts is provided via the validity period time window; there is no revocation of TCerts. The ECA, TCA, and TLS CA certificates are self-signed, where the TLS CA is provisioned as a trust anchor.", 
            "title": "4.2 User Privacy through Membership Services"
        }, 
        {
            "location": "/protocol-spec/#421-userclient-enrollment-process", 
            "text": "The next figure has a high-level description of the user enrollment process. It has an offline and an online phase.   Offline Process:  in Step 1, each user/non-validating peer/validating peer has to present strong identification credentials (proof of ID) to a Registration Authority (RA) offline. This has to be done out-of-band to provide the evidence needed by the RA to create (and store) an account for the user. In Step 2, the RA returns the associated username/password and trust anchor (TLS-CA Cert in this implementation) to the user. If the user has access to a local client then this is one way the client can be securely provisioned with the TLS-CA certificate as trust anchor.  Online Phase:  In Step 3, the user connects to the client to request to be enrolled in the system. The user sends his username and password to the client. On behalf of the user, the client sends the request to the PKI framework, Step 4, and receives a package, Step 5, containing several certificates, some of which should correspond to private/secret keys held by the client. Once the client verifies that the all the crypto material in the package is correct/valid, it stores the certificates in local storage and notifies the user. At this point the user enrollment has been completed.   Figure 4 shows a detailed description of the enrollment process. The PKI framework has the following entities \u2013 RA, ECA, TCA and TLS-CA. After Step 1, the RA calls the function \u201cAddEntry\u201d to enter the (username/password) in its database. At this point the user has been formally registered into the system database. The client needs the TLS-CA certificate (as trust anchor) to verify that the TLS handshake is set up appropriately with the server. In Step 4, the client sends the registration request to the ECA along with its enrollment public key and additional identity information such as username and password (under the TLS record layer protocol). The ECA verifies that such user really exists in the database. Once it establishes this assurance the user has the right to submit his/her enrollment public key and the ECA will certify it. This enrollment information is of a one-time use. The ECA updates the database marking that this registration request information (username/password) cannot be used again. The ECA constructs, signs and sends back to the client an enrollment certificate (ECert) that contains the user\u2019s enrollment public key (Step 5). It also sends the ECA Certificate (ECA-Cert) needed in future steps (client will need to prove to the TCA that his/her ECert was created by the proper ECA). (Although the ECA-Cert is self-signed in the initial implementation, the TCA and TLS-CA and ECA are co-located.) The client verifies, in Step 6, that the public key inside the ECert is the one originally submitted by the client (i.e. that the ECA is not cheating). It also verifies that all the expected information within the ECert is present and properly formed.  Similarly, In Step 7, the client sends a registration request to the TLS-CA along with its public key and identity information. The TLS-CA verifies that such user is in the database. The TLS-CA generates, and signs a TLS-Cert that contains the user\u2019s TLS public key (Step 8). TLS-CA sends the TLS-Cert and its certificate (TLS-CA Cert). Step 9 is analogous to Step 6, the client verifies that the public key inside the TLS Cert is the one originally submitted by the client and that the information in the TLS Cert is complete and properly formed. In Step 10, the client saves all certificates in local storage for both certificates. At this point the user enrollment has been completed.  In this implementation the enrollment process for validators is the same as that for peers. However, it is possible that a different implementation would have validators enroll directly through an on-line process.    Client:  Request for TCerts batch needs to include (in addition to count), ECert and signature of request using ECert private key (where Ecert private key is pulled from Local Storage).  TCA generates TCerts for batch:  Generates key derivation function key, KeyDF_Key, as HMAC(TCA_KDF_Key, EnrollPub_Key). Generates each TCert public key (using TCertPub_Key = EnrollPub_Key + ExpansionValue G, where 384-bit ExpansionValue = HMAC(Expansion_Key, TCertIndex) and 384-bit Expansion_Key = HMAC(KeyDF_Key, \u201c2\u201d)). Generates each AES_Encrypt TCertOwner_EncryptKey (TCertIndex || known padding/parity check vector), where || denotes concatenation and where TCertOwner_EncryptKey is derived as [HMAC(KeyDF_Key, \u201c1\u201d)] 256-bit truncation .  Client:  Deriving TCert private key from a TCert in order to be able to deploy or invoke or query: KeyDF_Key and ECert private key need to be pulled from Local Storage. KeyDF_Key is used to derive TCertOwner_EncryptKey as [HMAC(KeyDF_Key, \u201c1\u201d)] 256-bit truncation ; then TCertOwner_EncryptKey is used to decrypt the TCert field AES_Encrypt TCertOwner_EncryptKey (TCertIndex || known padding/parity check vector); then TCertIndex is used to derive TCert private key: TCertPriv_Key = (EnrollPriv_Key + ExpansionValue) modulo n, where 384-bit ExpansionValue = HMAC(Expansion_Key, TCertIndex) and 384-bit Expansion_Key = HMAC(KeyDF_Key, \u201c2\u201d).", 
            "title": "4.2.1 User/Client Enrollment Process"
        }, 
        {
            "location": "/protocol-spec/#422-expiration-and-revocation-of-certificates", 
            "text": "It is practical to support expiration of transaction certificates. The time window during which a transaction certificate can be used is expressed by a \u2018validity period\u2019 field. The challenge regarding support of expiration lies in the distributed nature of the system. That is, all validating entities must share the same information; i.e. be consistent with respect to the expiration of the validity period associated with the transactions to be executed and validated. To guarantee that the expiration of validity periods is done in a consistent manner across all validators, the concept of validity period identifier is introduced. This identifier acts as a logical clock enabling the system to uniquely identify a validity period. At genesis time the \u201ccurrent validity period\u201d of the chain gets initialized by the TCA. It is essential that this validity period identifier is given monotonically increasing values over time, such that it imposes a total order among validity periods.  A special type of transactions, system transactions, and the validity period identified are used together to announce the expiration of a validity period to the Blockchain. System transactions refer to contracts that have been defined in the genesis block and are part of the infrastructure. The validity period identified is updated periodically by the TCA invoking a system chaincode. Note that only the TCA should be allowed to update the validity period. The TCA sets the validity period for each transaction certificate by setting the appropriate integer values in the following two fields that define a range: \u2018not-before\u2019 and \u2018not-after\u2019 fields.  TCert Expiration:\nAt the time of processing a TCert, validators read from the state table associated with the ledger the value of \u2018current validity period\u2019 to check if the outer certificate associated with the transaction being evaluated is currently valid. That is, the current value in the state table has to be within the range defined by TCert sub-fields \u2018not-before\u2019 and \u2018not-after\u2019. If this is the case, the validator continues processing the transaction. In the case that the current value is not within range, the TCert has expired or is not yet valid and the validator should stop processing the transaction.  ECert Expiration:\nEnrollment certificates have different validity period length(s) than those in transaction certificates.  Revocation is supported in the form of Certificate Revocation Lists (CRLs). CRLs identify revoked certificates. Changes to the CRLs, incremental differences, are announced through the Blockchain.", 
            "title": "4.2.2 Expiration and revocation of certificates"
        }, 
        {
            "location": "/protocol-spec/#43-transaction-security-offerings-at-the-infrastructure-level", 
            "text": "Transactions in the fabric are user-messages submitted to be included\nin the ledger. As discussed in previous sections, these messages have a\nspecific structure, and enable users to deploy new chaincodes, invoke existing\nchaincodes, or query the state of existing chaincodes.\nTherefore, the way transactions are formed, announced and processed plays\nan important role to the privacy and security offerings of the entire system.  On one hand our membership service provides the means to authenticate transactions as\nhaving originated by valid users of the system, to disassociate transactions with user identities,\nbut while efficiently tracing the transactions a particular individual under certain conditions\n(law enforcement, auditing). In other words, membership services offer to transactions authentication\nmechanisms that marry user-privacy with accountability and non-repudiation.  On the other hand, membership services alone cannot offer full privacy of user-activities within\nthe fabric. First of all, for privacy provisions offered by the fabric to be complete,\nprivacy-preserving authentication mechanisms need to be accompanied by transaction confidentiality.\nThis becomes clear if one considers that the content of a chaincode, may leak information on who may have\ncreated it, and thus break the privacy of that chaincode's creator. The first subsection\ndiscusses transaction confidentiality.    Enforcing access control for the invocation of chaincode is an important security requirement.\nThe fabric exposes to the application (e.g., chaincode creator) the means for the application\nto perform its own invocation access control, while leveraging the fabric's membership services.\nSection 4.4 elaborates on this.   Replay attacks is another crucial aspect of the security of the chaincode,\nas a malicious user may copy a transaction that was added to the Blockchain\nin the past, and replay it in the network to distort its operation.\nThis is the topic of Section 4.3.3.  The rest of this Section presents an overview of how security mechanisms in the\ninfrastructure are incorporated in the transactions' lifecycle,\nand details each security mechanism separately.", 
            "title": "4.3 Transaction security offerings at the infrastructure level"
        }, 
        {
            "location": "/protocol-spec/#431-security-lifecycle-of-transactions", 
            "text": "Transactions are created on the client side. The client can be either plain\nclient, or a more specialized application, i.e., piece of\nsoftware that handles (server) or invokes (client) specific chaincodes\nthrough the blockchain. Such applications are built on top of the\nplatform (client) and are detailed in Section 4.4.  Developers of new chaincodes create a new deploy transaction by passing to\nthe fabric infrastructure:  the confidentiality/security version or type they want the transaction to conform with,  the set of users who wish to be given access to parts of the chaincode and\n  a proper representation of their (read) access rights   the chaincode specification,  code metadata, containing information that should be passed to the chaincode\n  at the time of its execution\n  (e.g., configuration parameters), and\n* transaction metadata, that is attached to the transaction structure,\n  and is only used by the application that deployed the chaincode.  Invoke and query transactions corresponding to chaincodes with confidentiality\nrestrictions are created using a similar approach. The transactor provides the\nidentifier of the chaincode to be executed, the name of the function to be\ninvoked and its arguments. Optionally, the invoker can pass to the\ntransaction creation function, code invocation metadata, that will be provided\nto the chaincode at the time of its execution. Transaction metadata is another\nfield that the application of the invoker or the invoker himself can leverage\nfor their own purposes.  Finally transactions at the client side, are signed by a certificate of their\ncreator and released to the network of validators.\nValidators receive the confidential transactions, and pass them through the following phases:   pre-validation  phase, where validators validate the transaction certificate against the accepted root certificate authority,\n  verify transaction certificate signature included in the transaction (statically), and check whether the transaction is a replay (see, later section for details on replay attack protection).   consensus  phase, where the validators add this transaction to the total order of transactions (ultimately included in the ledger)   pre-execution  phase, where validators verify the validity of the transaction / enrollment certificate against the current validity period,\n  decrypt the transaction (if the transaction is encrypted), and check that the transaction's plaintext is correctly formed(e.g., invocation access control is respected, included TCerts are correctly formed);\n  mini replay-attack check is also performed here within the transactions of the currently processed block.   execution  phase, where the (decrypted) chaincode is passed to a container, along with the associated code metadata, and is executed   commit* phase, where (encrypted) updates of that chaincodes state is committed to the ledger with the transaction itself.", 
            "title": "4.3.1 Security Lifecycle of Transactions"
        }, 
        {
            "location": "/protocol-spec/#432-transaction-confidentiality", 
            "text": "Transaction confidentiality requires that under the request of the developer, the plain-text\nof a chaincode, i.e., code, description, is not accessible or inferable (assuming a computational\nattacker) by any unauthorized entities(i.e., user or peer not authorized by the developer).\nFor the latter, it is important that for chaincodes with confidentiality requirements the\ncontent of both  deploy  and  invoke  transactions remains concealed. In the same spirit,\nnon-authorized parties, should not be able to associate invocations (invoke transactions) of a\nchaincode to the chaincode itself (deploy transaction) or these invocations to each other.  Additional requirements for any candidate solution is that it respects and supports the privacy\nand security provisions of the underlying membership service. In addition, it should not prevent\nthe enforcement of any invocation access control of the chain-code functions in the fabric, or\nthe implementation of enforcement of access-control mechanisms on the application (See Subsection 4.4).  In the following is provided the specification of transaction confidentiality\nmechanisms at the granularity of users. The last subsection provides some guidelines\non how to extend this functionality at the level of validators.\nInformation on the features supported in current release and its security\nprovisions, you can find in Section 4.7.  The goal is to achieve a design that will allow for granting or restricting\naccess to an entity to any subset of the following parts of a chain-code:\n1. chaincode content, i.e., complete (source) code of the\n   chaincode, \n2. chaincode function headers, i.e., the prototypes of the functions included in a chaincode,  \n3. chaincode [invocations  ] state, i.e., successive updates to the state of a specific chaincode,\n   when one or more functions of its are invoked\n4. all the above  Notice, that this design offers the application the capability to leverage the fabric's\nmembership service infrastructure and its public key infrastructure to build their own access\ncontrol policies and enforcement mechanisms.", 
            "title": "4.3.2 Transaction confidentiality"
        }, 
        {
            "location": "/protocol-spec/#4321-confidentiality-against-users", 
            "text": "To support fine-grained confidentiality control, i.e., restrict read-access to the\nplain-text of a chaincode to a subset of users that the chaincode creator\ndefines, a chain is bound to a single long-term encryption key-pair\n(PK chain , SK chain ).\nThough initially this key-pair is to be stored and maintained by each chain's\nPKI, in later releases, however, this restriction will be moved away,\nas chains (and the associated key-pairs) can be triggered through the Blockchain\nby any user with  special  (admin) privileges (See, Section 4.3.2.2).  Setup . At enrollment phase, users obtain (as before) an enrollment certificate,\ndenoted by Cert u i  for user u i , while each\nvalidator v j  obtain its enrollment certificate denoted by\nCert v j . Enrollment would grant users and validators the\nfollowing credentials:   Users:   a. claim and grant themselves signing key-pair (spk u , ssk u ),  b. claim and grant themselves encryption key-pair (epk u , esk u ),  c. obtain the encryption (public) key of the chain PK chain   Validators:   a. claim and grant themselves signing key-pair (spk v , ssk v ),  b. claim and grant themselves an encryption key-pair (epk v , esk v ),  c. obtain the decryption (secret) key of the chain SK chain  Thus, enrollment certificates contain the public part of two key-pairs:  one signature key-pair [denoted by (spk v j ,ssk v j )\n  for validators and by (spk u i , ssk u i ) for users], and  an encryption key-pair [denoted by (epk v j ,esk v j )\n  for validators and (epk u i , esk u i ) for users]  Chain, validator and user enrollment public keys are accessible to everyone.  In addition to enrollment certificates, users who wish to anonymously\nparticipate in transactions issue transaction certificates. For simplicity\ntransaction certificates of a user u i  are denoted by\nTCert u i . Transaction certificates include the public part\nof a signature key-pair denoted by \n(tpk u i ,tsk u i ).  The following section provides a high level description of how transaction\nformat accommodates read-access restrictions at the granularity of users.  Structure of deploy transaction. \nThe following figure depicts the structure of a typical deploy\ntransaction with confidentiality enabled.   One can notice that a deployment transaction consists of several sections:  Section  general-info : contains the administration details of the\n  transaction, i.e., which chain this transaction corresponds to (chained),\n  the type of transaction (that is set to ''deplTrans''), the version number of\n  confidentiality policy implemented, its creator identifier (expressed by means\n  of transaction certificate TCert of enrollment certificate Cert), and a Nonce,\n  that facilitates primarily replay-attack resistance techniques.  Section  code-info : contains information on the chain-code source code,\n  and function headers. As shown in the figure below, there is a symmetric key\n  used for the source-code of the chaincode (K C ), and another\n  symmetric key used for the function prototypes (K H ). A signature of\n  the creator of the chaincode is included on the plain-text code such that\n  the latter cannot be detached from the transaction and replayed by another\n  party.  Section  chain-validators : where appropriate key material is passed to the\n  validators for the latter to be able to (i) decrypt the chain-code source\n  (K C ), (ii) decrypt the headers,  and\n  (iii) encrypt the state when the chain-code has been\n  invoked accordingly(K S ). In particular, the chain-code creator\n  generates an encryption key-pair for the chain-code it deploys\n  (PK C , SK C ). It then uses PK C \n  to encrypt all the keys associated to the chain-code:\n    [(''code'',K C ) ,(''headr'',K H ),(''code-state'',K S ), Sig TCert u c (*)] PK c ,  \n  and passes the secret key SK C  to the validators using the\n  chain-specific public key:\n   [(''chaincode'',SK C ), Sig TCert u c ( )] PK chain .   Section  contract-users*: where the public encryption keys of the contract users,\n  i.e., users who are given read-access to parts of the chaincode, are used to encrypt\n  the keys  associated to their access rights:    SK c  for the users to be able to read any message associated to\n     that chain-code (invocation, state, etc),    K C  for the user to be able to read only the contract code,    K H  for the user to only be able to read the headers,    K S  for the user to be able to read the state associated to that contract.    Finally users are given the contract's public key PK c ,\n  for them to be able to encrypt information related to that contract for the validators\n  (or any in possession of SK c ) to be able to read it. Transaction certificate\n  of each contract user is appended to the transaction and follows that user's message.\n  This is done for users to be able to easily search the blockchain\n  for transactions they have been part of. Notice that the deployment transaction also\n  appends a message to the creator u c  of the chain-code, for the\n  latter to be able to retrieve this transaction through parsing the ledger and without\n  keeping any state locally.  The entire transaction is signed by a certificate of the chaincode creator, i.e., enrollment\nor transaction certificate as decided by the latter.\nTwo noteworthy points:  Messages that are included in a transaction in an encrypted format, i.e., code-functions, code-hdrs,\n  are signed before they are encrypted using the same TCert the entire transaction is signed with, or\n  even with a different TCert or the ECert of the user (if the transaction deployment should carry the identity\n  of its owner. A binding to the underlying transaction carrier should be included in the signed message, e.g.,\n  the hash of the TCert the transaction is signed, such that mix\\ match attacks are not possible.\n  Though we detail such attacks in Section 4.4, in these cases an attacker who sees a transaction should not be able\n  to isolate the ciphertext corresponding to, e.g., code-info, and use it for another transaction of her own.\n  Clearly, such an ability would disrupt the operation of the system, as a chaincode that was first created by user A,\n  will now also belong to malicious user B (who is not even able to read it).  To offer the ability to the users to cross-verify they are given access to the\n  correct key, i.e., to the same key as the other contract users, transaction\n  ciphertexts that are encrypted with a key K are accompanied by a commitment\n  to K, while the opening of this commitment value is passed to all users who\n  are entitled access to K in contract-users, and chain-validator sections.\n   \n  In this way, anyone who is entitled access to that key can verify that the key\n  has been properly passed to it. This part is omitted in the figure above to\n  avoid confusion.  Structure of invoke transaction. \nA transaction invoking the chain-code triggering the execution of a function of the chain-code with\nuser-specified arguments is structured as depicted in the figure below.   Invocation transaction as in the case of deployment transaction consists of a general-info  section, a  code-info  section, a section for the  chain-validators ,\nand one for the  contract users , signed altogether with one of the invoker's\ntransaction certificates.    General-info follows the same structure as the corresponding section of the\ndeployment transaction.\nThe only difference relates to the transaction type that is now set to ''InvocTx'',\nand the chain-code identifier or name that is now encrypted under the\nchain-specific encryption (public) key.    Code-info exhibits the same structure as the one of the deployment transaction.\nCode payload, as in the case of deployment transaction, consists of function\ninvocation details (the name of the function invoked, and associated arguments),\ncode-metadata provided by the application and the transaction's creator\n(invoker's u) certificate, TCert u . Code payload is signed by the\ntransaction certificate TCert u  of the invoker u, as in the case\nof deploy transactions. As in the case of\ndeploy transactions, code-metadata, and tx-metadata, are fields that are\nprovided by the application and can be used (as described in Section 4.4),\nfor the latter to implement their own access control mechanisms and roles.    Finally, contract-users and chain-validator sections provide the key the payload\nis encrypted with, the invoker's key, and the chain encryption key respectively.\nUpon receiving such transactions, the validators decrypt [code-name] PK chain  using the\nchain-specific secret key SK chain  and obtain the invoked chain-code identifier.\nGiven the latter, validators retrieve from their local storage the chaincode's\ndecryption key SK c , and use it to decrypt chain-validators' message,\nthat would equip them with the symmetric key K I  the invocation\ntransaction's payload was encrypted with.\nGiven the latter, validators decrypt code-info, and execute the chain-code\nfunction with the specified arguments,\nand the code-metadata attached(See, Section 4.4 for more details on the use of\ncode-metadata). While the chain-code is executed, updates of the state of that\nchain-code are possible.\nThese are encrypted using the state-specific key K s  that was defined\nduring that chain-code's deployment. In particular, K s  is used the\nsame way K iTx  is used in the design of our current release\n(See, Section 4.7).      Structure of query transaction. \nQuery transactions have the same format as invoke transactions.\nThe only difference is that Query transactions do not affect the state\nof the chaincode, and thus there is no need for the state to be retrieved\n(decrypted) and/or updated (encrypted) after the execution of the chaincode\ncompletes.", 
            "title": "4.3.2.1 Confidentiality against users"
        }, 
        {
            "location": "/protocol-spec/#4322-confidentiality-against-validators", 
            "text": "This section deals with ways of how to support execution of certain transactions\nunder a different (or subset) sets of validators in the current chain. This\nsection inhibits IP restrictions and will be expanded in the following few weeks.", 
            "title": "4.3.2.2 Confidentiality against validators"
        }, 
        {
            "location": "/protocol-spec/#433-replay-attack-resistance", 
            "text": "In replay attacks the attacker \"replays\" a message it \"eavesdropped\" on the network or ''saw'' on the Blockchain.\nReplay attacks are a big problem here, as they can incur into the validating entities re-doing a computationally intensive\nprocess (chaincode invocation) and/or affect the state of the corresponding chaincode, while it requires minimal or no\npower from the attacker side.  To make matters worse, if a transaction was a payment transaction, replays could\npotentially incur into the payment being performed more than once, without this being the original intention of the payer.\nExisting systems resist replay attacks as follows:  Record hashes of transactions in the system. This solution would require that validators maintain a log of the hash of\n  each transaction that has ever been announced through the network, and compare a new transaction against their locally\n  stored transaction record. Clearly such approach cannot scale for large networks, and could easily result into validators\n  spending a lot of time to do the check of whether a transaction has been replayed, than executing the actual transaction.  Leverage state that is maintained per user identity (Ethereum). Ethereum keeps some state, e.g., counter (initially set to 1)\n  for each identity/pseudonym in the system. Users also maintain their own counter (initially set to 0) for each\n  identity/pseudonym of theirs. Each time a user sends a transaction using an identity/pseudonym of his, he increases\n  his local counter by one and adds the resulting value to the transaction. The transaction is subsequently signed by that\n  user identity and released to the network. When picking up this transaction, validators check the counter value included\n  within and compare it with the one they have stored locally; if the value is the same, they increase the local value of\n  that identity's counter and accept the transaction. Otherwise, they reject the transaction as invalid or replay. \n  Although this would work well in cases where we have limited number of user identities/pseudonyms (e.g., not too large),\n  it would ultimately not scale in a system where users use a different identifier (transaction certificate) per transaction,\n  and thus have a number of user pseudonyms proportional to the number of transactions.  Other asset management systems, e.g., Bitcoin, though not directly dealing with replay attacks, they resist them. In systems\nthat manage (digital) assets, state is maintained on a per asset basis, i.e., validators only keep a record of who owns what.\nResistance to replay attacks come as a direct result from this, as replays of transactions would be immediately be\ndeemed as invalid by the protocol (since can only be shown to be derived from older owners of an asset/coin). While this would\nbe appropriate for asset management systems, this does not abide with the needs of a Blockchain systems with more generic\nuse than asset management.  In the fabric, replay attack protection uses a hybrid approach.\nThat is, users add in the transaction a nonce that is generated in a different manner\ndepending on whether the transaction is anonymous (followed and signed by a transaction certificate) or not\n(followed and signed by a long term enrollment certificate). More specifically:   Users submitting a transaction with their enrollment certificate should include in that\n  transaction a nonce that is a function of the nonce they used in the previous transaction\n  they issued with the same certificate (e.g., a counter function or a hash). The nonce included\n  in the first transaction of each enrollment certificate can be either pre-fixed by the system\n  (e.g., included in the genesis block) or chosen by the user. In the first case, the genesis block\n  would need to include nonceall , i.e., a fixed number and the nonce used by user with identity\n  IDA for his first enrollment certificate signed transaction would be\n   nonce round 0 IDA   - hash(IDA, nonce all ), \n  where IDA appears in the enrollment certificate. From that point onward successive transactions of\n  that user with enrollment certificate would include a nonce as follows\n   nonce round i IDA   - hash(nonce round {i-1} IDA ), \n  that is the nonce of the ith transaction would be using the hash of the nonce used in the {i-1}th transaction of that certificate.\n  Validators here continue to process a transaction they receive, as long as it satisfies the condition mentioned above.\n  Upon successful validation of transaction's format, the validators update their database with that nonce.   Storage overhead :    on the user side: only the most recently used nonce,    on validator side: O(n), where n is the number of users.   Users submitting a transaction with a transaction certificate\n  should include in the transaction a random nonce, that would guarantee that\n  two transactions do not result into the same hash. Validators add the hash of\n  this transaction in their local database if the transaction certificate used within\n  it has not expired. To avoid storing large amounts of hashes, validity periods of transaction certificates\n  are leveraged. In particular validators maintain an updated record of received\n  transactions' hashes within the current or future validity period.   Storage overhead  (only makes sense for validators here):  O(m), where m is the approximate number of\n  transactions within a validity period and corresponding validity period identifier (see below).", 
            "title": "4.3.3 Replay attack resistance"
        }, 
        {
            "location": "/protocol-spec/#44-access-control-features-on-the-application", 
            "text": "An application, is a piece of software that runs on top of a Blockchain client software, and,\nperforms a special task over the Blockchain, i.e., restaurant table reservation.\nApplication software have a version of\ndeveloper, enabling the latter to generate and manage a couple of chaincodes that are necessary for\nthe business this application serves, and a client-version that would allow the application's end-users\nto make use of the application, by invoking these chain-codes.\nThe use of the Blockchain can be transparent to the application end-users or not.  This section describes how an application leveraging chaincodes can implement its own access control policies,\nand guidelines on how our Membership services PKI can be leveraged for the same purpose.  The presentation is divided into enforcement of invocation access control,\nand enforcement of read-access control by the application.", 
            "title": "4.4 Access control features on the application"
        }, 
        {
            "location": "/protocol-spec/#441-invocation-access-control", 
            "text": "To allow the application to implement its own invocation access control at the\napplication layer securely, special support by the fabric must be provided.\nIn the following we elaborate on the tools exposed by the fabric to the\napplication for this purpose, and provide guidelines on how these should be used\nby the application for the latter to enforce access control securely.  Support from the infrastructure. \nFor the chaincode creator, let it be,  u c ,\nto be able to implement its own invocation access control at\nthe application layer securely, special support by the fabric must be provided.\nMore specifically fabric layer gives access to following capabilities:    The client-application can request the fabric to sign and verify any message with specific transaction certificates or enrollment certificate the client owns; this is expressed via the Certificate Handler interface    The client-application can request the fabric a unique  binding  to be used to bind authentication data of the application to the underlying transaction transporting it; this is expressed via the Transaction Handler interface    Support for a transaction format, that allows for the application to specify metadata, that are passed to the chain-code at deployment, and invocation time; the latter denoted by code-metadata.    The  Certificate Handler  interface allows to sign and verify any message using signing key-pair underlying the associated certificate.\nThe certificate can be a TCert or an ECert.  // CertificateHandler exposes methods to deal with an ECert/TCert\ntype CertificateHandler interface {\n\n    // GetCertificate returns the certificate's DER\n    GetCertificate() []byte\n\n    // Sign signs msg using the signing key corresponding to the certificate\n    Sign(msg []byte) ([]byte, error)\n\n    // Verify verifies msg using the verifying key corresponding to the certificate\n    Verify(signature []byte, msg []byte) error\n\n    // GetTransactionHandler returns a new transaction handler relative to this certificate\n    GetTransactionHandler() (TransactionHandler, error)\n}  The  Transaction Handler  interface allows to create transactions and give access to the underlying  binding  that can be leveraged to link\napplication data to the underlying transaction. Bindings are a concept that have been introduced in network transport protocols (See, https://tools.ietf.org/html/rfc5056),\nknown as  channel bindings , that  allows applications to establish that the two end-points of a secure channel at one network layer are the same as at a higher layer\nby binding authentication at the higher layer to the channel at the lower layer.\nThis allows applications to delegate session protection to lower layers, which has various performance benefits. \nTransaction bindings offer the ability to uniquely identify the fabric layer of the transaction that serves as the container that\napplication data uses to be added to the ledger.  // TransactionHandler represents a single transaction that can be uniquely determined or identified by the output of the GetBinding method.\n// This transaction is linked to a single Certificate (TCert or ECert).\ntype TransactionHandler interface {\n\n    // GetCertificateHandler returns the certificate handler relative to the certificate mapped to this transaction\n    GetCertificateHandler() (CertificateHandler, error)\n\n    // GetBinding returns a binding to the underlying transaction (container)\n    GetBinding() ([]byte, error)\n\n    // NewChaincodeDeployTransaction is used to deploy chaincode\n    NewChaincodeDeployTransaction(chaincodeDeploymentSpec *obc.ChaincodeDeploymentSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeExecute is used to execute chaincode's functions\n    NewChaincodeExecute(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeQuery is used to query chaincode's functions\n    NewChaincodeQuery(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n}  For version 1,  binding  consists of the  hash (TCert, Nonce), where TCert, is the transaction certificate\nused to sign the entire transaction, while Nonce, is the nonce number used within.  The  Client  interface is more generic, and offers a mean to get instances of the previous interfaces.  type Client interface {\n\n    ...\n\n    // GetEnrollmentCertHandler returns a CertificateHandler whose certificate is the enrollment certificate\n    GetEnrollmentCertificateHandler() (CertificateHandler, error)\n\n    // GetTCertHandlerNext returns a CertificateHandler whose certificate is the next available TCert\n    GetTCertificateHandlerNext() (CertificateHandler, error)\n\n    // GetTCertHandlerFromDER returns a CertificateHandler whose certificate is the one passed\n    GetTCertificateHandlerFromDER(der []byte) (CertificateHandler, error)\n\n}  To support application-level access control lists for controlling chaincode\ninvocation, the fabric's transaction and chaincode specification format\nhave an additional field to store application-specific metadata.\nThis field is depicted in both figures 1, by code-metadata. The content of this field is decided\nby the application, at the transaction creation time.\nThe fabric layer treats it as an unstructured stream of bytes.  \nmessage ChaincodeSpec {\n\n    ...\n\n    ConfidentialityLevel confidentialityLevel;\n    bytes metadata;\n\n    ...\n}\n\n\nmessage Transaction {\n    ...\n\n    bytes payload;\n    bytes metadata;\n\n    ...\n}  To assist chaincode execution, at the chain-code invocation time, the validators provide the\nchaincode with additional information, like the metadata and the binding.    Application invocation access control. \nThis section describes how the application can leverage the means provided by the fabric\nto implement its own access control on its chain-code functions.\nIn the scenario considered here, the following entities are identified:    C : is a chaincode that contains a single function, e.g., called  hello ;    u c : is the  C  deployer;    u i : is a user who is authorized to invoke  C 's functions. User u c  wants to ensure that only u i  can invoke the function  hello .    Deployment of a Chaincode:  At deployment time, u c  has full control on the deployment transaction's metadata,\n and can be used to store a list of ACLs (one per function), or a list of roles that are needed by the application. The format which is used to store these ACLs is up to the deployer's application, as the chain-code is the one\nwho would need to parse the metadata at execution time.\nTo define each of these lists/roles, u c  can use any TCerts/Certs of the u i  (or, if applicable, or other users who have been assigned that privilege or role). Let this be TCert u i .\nThe exchange of TCerts or Certs among the developer and authorized users is done through an out-of-band channel.  Assume that the application of u c 's requires that to invoke the  hello  function, a certain message  M  has to be authenticated by an authorized invoker (u i , in our example).\nOne can distinguish the following two cases:    M  is one of the chaincode's function arguments;    M  is the invocation message itself, i.e., function-name, function-arguments.    Chaincode invocation: \nTo invoke C, u i 's application needs to sign  M  using the TCert/ECert, that was used to identify u i 's participation in the chain-code at the associated\ndeployment transaction's metadata, i.e., TCert u i . More specifically, u i 's client application does the following:    Retrieves a CertificateHandler for Cert u i ,  cHandler ;    obtains a new TransactionHandler to issue the execute transaction,  txHandler  relative to his next available TCert or his ECert;    gets  txHandler 's  binding  by invoking  txHandler.getBinding() ;    signs  ' M  || txBinding'  by invoking  cHandler.Sign(' M  || txBinding') , let  sigma  be the output of the signing function;    issues a new execute transaction by invoking,  txHandler.NewChaincodeExecute(...) . Now,  sigma  can be included in the transaction as one of the arguments that are passed to the function (case 1) or as part of the code-metadata section of the payload(case 2).    Chaincode processing: \nThe validators, who receive the execute transaction issued u i , will provide to  hello  the following information:    The  binding  of the execute transaction, that can be independently computed at the validator side;    The  metadata  of the execute transaction (code-metadata section of the transaction);    The  metadata  of the deploy transaction (code-metadata component of the corresponding deployment transaction).    Notice that  sigma  is either part of the arguments of the invoked function, or stored inside the code-metadata of the invocation transaction (properly formatted by the client-application).\nApplication ACLs are included in the code-metadata section, that is also passed to the chain-code at execution time.\nFunction  hello  is responsible for checking that  sigma  is indeed a valid signature issued by TCert u i , on ' M  ||  txBinding' .", 
            "title": "4.4.1 Invocation access control"
        }, 
        {
            "location": "/protocol-spec/#442-read-access-control", 
            "text": "This section describes how the fabric's infrastructure offers support to the application to\nenforce its own read-access control policies at the level of users. As in the case of invocation access\ncontrol, the first part describes the infrastructure features that can be leveraged by the application for this\npurpose, and the last part details on the way applications should use these tools.  For the purpose of this discussion, we leverage a similar example as before, i.e.,    C : is a chaincode that contains a single function, e.g., called  hello ;    u A : is the  C 's deployer, also known as application;    u r : is a user who is authorized to read  C 's functions. User u A  wants to ensure that only u r  can read the function  hello .    Support from the infrastructure. \nFor  u A  to be able to implement its own read access control at the application layer securely, our infrastructure is required to\nsupport the transaction format for code deployment and invocation, as depicted in the two figures below.    More specifically fabric layer is required to provide the following functionality:    Provide minimal encryption capability such that data is only decryptable by a validator's (infrastructure) side; this means that the infrastructure should move closer to our future version, where an asymmetric encryption scheme is used for encrypting transactions. More specifically, an asymmetric key-pair is used for the chain, denoted by K chain  in the Figures above, but detailed in Section  Transaction Confidentiality .    The client-application can request the infrastructure sitting on the client-side to encrypt/decrypt information using a specific public encryption key, or that client's long-term decryption key.    The transaction format offers the ability to the application to store additional transaction metadata, that can be passed to the client-application after the latter's request. Transaction metadata, as opposed to code-metadata, is not encrypted or provided to the chain-code at execution time. Validators treat these metadata as a list of bytes they are not responsible for checking validity of.    Application read-access control. \nFor this reason the application may request and obtain access to the public encryption key of the user  u r ; let that be  PK u r . Optionally, u r  may be providing  u A  with a certificate of its, that would be leveraged by the application, say, TCert u r ; given the latter,\nthe application would, e.g., be able to trace that user's transactions w.r.t. the application's chain-codes. TCert u r , and PK u r , are\nexchanged in an out-of-band channel.  At deployment time, application  u A  performs the following steps:    Uses the underlying infrastructure to encrypt the information of  C , the application would like to make accessible to  u r , using PK u r .\n   Let C u r  be the resulting ciphertext.    (optional) C u r  can be concatenated with TCert u r    Passes the overall string as ''Tx-metadata'' of the confidential transaction to be constructed.    At invocation time, the client-application on u r 's node, would be able, by obtaining the deployment transaction to retrieve the content of  C .\nIt just needs to retrieve the  tx-metadata  field of the associated deployment transaction, and trigger the decryption functionality offered by our Blockchain\ninfrastrucure's client, for C u r . Notice that it is the application's responsibility to encrypt the correct  C  for u r .\nAlso, the use of  tx-metadata  field can be generalized to accommodate application-needs. E.g., it can be that invokers leverage the same field of invocation transactions\nto pass information to the developer of the application, etc.  Important Note:    It is essential to note that validators  do not provide  any decryption oracle to the chain-code\nthroughout its execution. Its infrastructure is though responsible for decrypting the payload of the chain-code itself (as well as\nthe code-metadata fields near it), and provide those to containers for deployment/execution.", 
            "title": "4.4.2 Read access control"
        }, 
        {
            "location": "/protocol-spec/#45-online-wallet-service", 
            "text": "This section describes the security design of a wallet service, which in this case is a node where end-users can register, move their key material to, and perform transactions through.\nBecause the wallet service is in possession of the user's key material, it is clear that without a secure authorization\nmechanism in place a malicious wallet service could successfully impersonate the user.\nWe thus emphasize that this design corresponds to a wallet service that is  trusted  to only perform transactions\non behalf of its clients, with the consent of the latter.\nThere are two cases for the registration of an end-user to an online wallet service:   When the user has registered with the registration authority and acquired his/her  enrollID, enrollPWD ,\n   but has not installed the client to trigger and complete the enrollment process;  When the user has already installed the client, and completed the enrollment phase.   Initially, the user interacts with the online wallet service to issue credentials that would allow him to authenticate\nto the wallet service. That is, the user is given a username, and password, where username identifies the user in the\nmembership service, denoted by AccPub, and password is the associated secret, denoted by AccSec, that is  shared  by\nboth user and service.  To enroll through the online wallet service, a user must provide the following request\nobject to the wallet service:  AccountRequest /* account request of u \\*/\n{\n    OBCSecCtx ,           /* credentials associated to network \\*/\n    AccPub sub u /sub ,   /* account identifier of u \\*/\n    AccSecProof sub u /sub   /* proof of AccSec sub u /sub \\*/\n }  OBCSecCtx refers to user credentials, which depending on the stage of his enrollment process, can be either his enrollment ID and password,  enrollID, enrollPWD  or his enrollment certificate and associated secret key(s)\n(ECert u , sk u ),  where  sk u  denotes for simplicity signing and decryption secret of the user.\nThe content of AccSecProof u  is an HMAC on the rest fields of request using the shared secret. Nonce-based methods\nsimilar to what we have in the fabric can be used to protect against replays.\nOBCSecCtx would give the online wallet service the necessary information to enroll the user or issue required TCerts.  For subsequent requests, the user u should provide to the wallet service a request of similar format.   TransactionRequest /* account request of u \\*/\n {\n      TxDetails,            /* specifications for the new transaction \\*/\n      AccPub sub u /sub ,       /* account identifier of u \\*/\n      AccSecProof sub u /sub    /* proof of AccSec sub u /sub  \\*/\n }  Here, TxDetails refer to the information needed by the online service to construct a transaction on behalf of the user, i.e.,\nthe type, and user-specified content of the transaction.  AccSecProof u  is again an HMAC on the rest fields of request using the shared secret.\nNonce-based methods similar to what we have in the fabric can be used to protect against replays.  TLS connections can be used in each case with server side authentication to secure the request at the\nnetwork layer (confidentiality, replay attack protection, etc)", 
            "title": "4.5 Online wallet service"
        }, 
        {
            "location": "/protocol-spec/#46-network-security-tls", 
            "text": "The TLS CA should be capable of issuing TLS certificates to (non-validating) peers, validators, and individual clients (or browsers capable of storing a private key). Preferably, these certificates are distinguished by type, per above. TLS certificates for CAs of the various types (such as TLS CA, ECA, TCA) could be issued by an intermediate CA (i.e., a CA that is subordinate to the root CA). Where there is not a particular traffic analysis issue, any given TLS connection can be mutually authenticated, except for requests to the TLS CA for TLS certificates.  In the current implementation the only trust anchor is the TLS CA self-signed certificate in order to accommodate the limitation of a single port to communicate with all three (co-located) servers, i.e., the TLS CA, the TCA and the ECA. Consequently, the TLS handshake is established with the TLS CA, which passes the resultant session keys to the co-located TCA and ECA. The trust in validity of the TCA and ECA self-signed certificates is therefore inherited from trust in the TLS CA. In an implementation that does not thus elevate the TLS CA above other CAs, the trust anchor should be replaced with a root CA under which the TLS CA and all other CAs are certified.", 
            "title": "4.6 Network security (TLS)"
        }, 
        {
            "location": "/protocol-spec/#47-restrictions-in-the-current-release", 
            "text": "This section lists the restrictions of the current release of the fabric.\nA particular focus is given on client operations and the design of transaction confidentiality,\nas depicted in Sections 4.7.1 and 4.7.2.   Client side enrollment and transaction creation is performed entirely by a\n   non-validating peer that is trusted not to impersonate the user.\n   See, Section 4.7.1 for more information.  A minimal set of confidentiality properties where a chain-code is accessible\n   by any entity that is member of the system, i.e., validators and users who\n   have registered to our membership services, and not accessible by any-one else.\n   The latter include any party that has access to the storage area where the\n   ledger is maintained, or other entities that are able to see the transactions\n   that are announced in the validator network. The design of the first release\n   is detailed in subsection 4.7.2  The code utilizes self-signed certificates for entities such as the\n   enrollment CA (ECA) and the transaction CA (TCA)  Replay attack resistance mechanism is not available  Invocation access control can be enforced at the application layer:\n   it is up to the application to leverage the infrastructure's tools properly\n   for security to be guaranteed. This means, that if the application ignores\n   to  bind  the transaction binding offered by our fabric, secure transaction\n   processing  may be at risk.", 
            "title": "4.7 Restrictions in the current release"
        }, 
        {
            "location": "/protocol-spec/#471-simplified-client", 
            "text": "Client side enrollment and transaction creation is performed entirely by a non-validating peer who plays the role of an online wallet.\nIn particular, the end-user leverages his registration credentials   to open an account to a non-validating peer\nand uses these credentials to further authorize the peer to build transactions on the user's behalf. It needs to be noted, that such\na design does not provide secure  authorization  for the peer to submit transactions on behalf of the user, as a malicious peer\ncould impersonate the user. Details on the specifications of a design that deals with the security issues of online wallet can be found is Section 4.5.\nCurrently the maximum number of peers a user can register to and perform transactions through is one.", 
            "title": "4.7.1 Simplified client"
        }, 
        {
            "location": "/protocol-spec/#472-simplified-transaction-confidentiality", 
            "text": "Disclaimer:  The current version of transaction confidentiality is minimal, and will be used as an intermediate step\nto reach a design that allows for fine grain (invocation) access control enforcement in the next versions.  In its current form, confidentiality of transactions is offered solely at the chain-level, i.e., that the\ncontent of a transaction included in a ledger, is readable by all members of that chain, i.e., validators\nand users. At the same time, application auditors that are not member of the system can be given\nthe means to perform auditing by passively observing the Blockchain data, while\nguaranteeing that they are given access solely to the transactions related to the application under audit.\nState is encrypted in a way that such auditing requirements are satisfied, while not disrupting the\nproper operation of the underlying consensus network.  More specifically, currently symmetric key encryption is supported in the process of offering transaction confidentiality.\nIn this setting, one of the main challenges that is specific to the blockchain setting,\nis that validators need to run consensus over the state of the blockchain, that, aside the transactions themselves,\nalso includes the state updates of individual contracts or chaincodes. Though this is trivial to do for non-confidential chaincodes, \nfor confidential chaincodes, one needs to design the state encryption mechanism such that the resulting ciphertexts are\nsemantically secure, and yet, identical if the plaintext state is the same.  To overcome this challenge, the fabric utilizes a key hierarchy that reduces the number of ciphertexts\nthat are encrypted under the same key. At the same time, as some of these keys are used for the generation of IVs,\nthis allows the validating parties to generate exactly the same ciphertext when executing the same transaction\n(this is necessary to remain agnostic to the underlying consensus algorithm) and offers the possibility of controlling audit by disclosing to auditing entities only the most relevant keys.  Method description: \nMembership service generates a symmetric key for the ledger (K chain ) that is distributed\nat registration time to all the entities of the blockchain system, i.e., the clients and the\nvalidating entities that have issued credentials through the membership service of the chain.\nAt enrollment phase, user obtain (as before) an enrollment certificate, denoted by Cert u i \nfor user u i  , while each validator v j  obtain its enrollment certificate denoted by Cert v j .  Entity enrollment would be enhanced, as follows. In addition to enrollment certificates,\nusers who wish to anonymously participate in transactions issue transaction certificates.\nFor simplicity transaction certificates of a user u i  are denoted by TCert u i .\nTransaction certificates include the public part of a signature key-pair denoted by (tpk u i ,tsk u i ).  In order to defeat crypto-analysis and enforce confidentiality, the following key hierarchy is considered for generation and validation of confidential transactions:\nTo submit a confidential transaction (Tx) to the ledger, a client first samples a nonce (N), which is required to be unique among all the transactions submitted to the blockchain, and derive a transaction symmetric\nkey (K Tx ) by applying the HMAC function keyed with K chain  and on input the nonce, K Tx = HMAC(K chain , N). From K Tx , the client derives two AES keys:\nK TxCID  as HMAC(K Tx , c 1 ), K TxP  as HMAC(K Tx , c 2 )) to encrypt respectively the chain-code name or identifier CID and code (or payload) P.\nc 1 , c 2  are public constants. The nonce, the Encrypted Chaincode ID (ECID) and the Encrypted Payload (EP) are added in the transaction Tx structure, that is finally signed and so\nauthenticated. Figure below shows how encryption keys for the client's transaction are generated. Arrows in this figure denote application of an HMAC, keyed by the key at the source of the arrow and\nusing the number in the arrow as argument. Deployment/Invocation transactions' keys are indicated by d/i respectively.   To validate a confidential transaction Tx submitted to the blockchain by a client,\na validating entity first decrypts ECID and EP by re-deriving K TxCID  and K TxP \nfrom K chain  and Tx.Nonce as done before. Once the Chaincode ID and the\nPayload are recovered the transaction can be processed.   When V validates a confidential transaction, the corresponding chaincode can access and modify the\nchaincode's state. V keeps the chaincode's state encrypted. In order to do so, V generates symmetric\nkeys as depicted in the figure above. Let iTx be a confidential transaction invoking a function\ndeployed at an early stage by the confidential transaction dTx (notice that iTx can be dTx itself\nin the case, for example, that dTx has a setup function that initializes the chaincode's state).\nThen, V generates two symmetric keys  K IV   and K state  as follows:   It computes  as  K dTx  , i.e., the transaction key of the corresponding deployment\n   transaction, and then N state  = HMAC(K dtx  ,hash(N i )), where N i \n   is the nonce appearing in the invocation transaction, and  hash  a hash function.  It sets K state  = HMAC(K dTx , c 3  || N state ),\n   truncated opportunely deeding on the underlying cipher used to encrypt; c 3  is a constant number  It sets K IV  = HMAC(K dTx , c 4  || N state ); c 4  is a constant number   In order to encrypt a state variable S, a validator first generates the IV as HMAC(K IV , crt state )\nproperly truncated, where crt state  is a counter value that increases each time a state update\nis requested for the same chaincode invocation. The counter is discarded after the execution of\nthe chaincode terminates. After IV has been generated, V encrypts with authentication (i.e., GSM mode)\nthe value of S concatenated with Nstate(Actually, N state   doesn't need to be encrypted but\nonly authenticated). To the resulting ciphertext (CT), N state  and the IV used is appended.\nIn order to decrypt an encrypted state CT|| N state'  , a validator first generates the symmetric\nkeys K dTX ' ,K state ' using N state'  and then decrypts CT.  Generation of IVs: In order to be agnostic to any underlying consensus algorithm, all the validating\nparties need a method to produce the same exact ciphertexts. In order to do so, the validators need\nto use the same IVs. Reusing the same IV with the same symmetric key completely breaks the security\nof the underlying cipher. Therefore, the process described before is followed. In particular, V first\nderives an IV generation key K IV  by computing HMAC(K dTX , c 4  || N state  ),\nwhere c 4  is a constant number, and keeps a counter crt state  for the pair\n(dTx, iTx) with is initially set to 0. Then, each time a new ciphertext has to be generated, the validator\ngenerates a new IV by computing it as the output of HMAC(K IV , crt state )\nand then increments the crt state  by one.  Another benefit that comes with the above key hierarchy is the ability to enable controlled auditing.\nFor example, while by releasing K chain  one would provide read access to the whole chain,\nby releasing only K state  for a given pair of transactions (dTx,iTx) access would be granted to a state\nupdated by iTx, and so on.  The following figures demonstrate the format of a deployment and invocation transaction currently available in the code.    One can notice that both deployment and invocation transactions consist of two sections:    Section  general-info : contains the administration details of the transaction, i.e., which chain this transaction corresponds to (is chained to), the type of transaction (that is set to ''deploymTx'' or ''invocTx''), the version number of confidentiality policy implemented, its creator identifier (expressed by means of TCert of Cert) and a nonce (facilitates primarily replay-attack resistance techniques).    Section  code-info : contains information on the chain-code source code. For deployment transaction this is essentially the chain-code identifier/name and source code, while for invocation chain-code is the name of the function invoked and its arguments. As shown in the two figures code-info in both transactions are encrypted ultimately using the chain-specific symmetric key K chain .", 
            "title": "4.7.2 Simplified transaction confidentiality"
        }, 
        {
            "location": "/protocol-spec/#5-byzantine-consensus_1", 
            "text": "The  obcpbft  package is an implementation of the seminal  PBFT  consensus protocol [1], which provides consensus among validators despite a threshold of validators acting as  Byzantine , i.e., being malicious or failing in an unpredictable manner. In the default configuration, PBFT tolerates up to t n/3 Byzantine validators.  Besides providing a reference implementation of the PBFT consensus protocol,  obcpbft  plugin contains also implementation of the novel  Sieve  consensus protocol. Basically the idea behind Sieve is to provide a fabric-level protection from  non-deterministic  transactions, which PBFT and similar existing protocols do not offer.  obcpbft  is easily configured to use either the classic PBFT or Sieve.    In the default configuration, both PBFT and Sieve are designed to run on at least  3t+1  validators (replicas), tolerating up to  t  potentially faulty (including malicious, or  Byzantine ) replicas.", 
            "title": "5. Byzantine Consensus"
        }, 
        {
            "location": "/protocol-spec/#51-overview", 
            "text": "The  obcpbft  plugin provides a modular implementation of the  CPI  interface which can be configured to run PBFT or Sieve consensus protocol. The modularity comes from the fact that, internally,  obcpbft  defines the  innerCPI   interface (i.e., the  inner consensus programming interface ), that currently resides in  pbft-core.go .  The  innerCPI  interface defines all\ninteractions between the inner PBFT consensus (called here  core PBFT  and implemented in  pbft-core.go ) and the outer consensus that uses the core PBFT.  This outer consensus is called  consumer  within core PBFT.  obcpbft  package contains implementations of several core PBFT consumers:   obc-classic.go , a shim around core PBFT that implements the  innerCPI  interface and calls into the  CPI  interface;  obc-batch.go , an  obc-classic  variant that adds batching capabilities to PBFT; and    obc-sieve.go , a core PBFT consumer that implements Sieve consensus protocol and  innerCPI  interface, calling into the  CPI interface .   In short, besides calls to send messages to other peers ( innerCPI.broadcast  and  innerCPI.unicast ), the  innerCPI  interface defines indications that the core consensus protocol (core PBFT) exports to the consumer. These indications are modeled after a classical  total order (atomic) broadcast  API [2], with  innerCPI.execute  call being used to signal the atomic delivery of a message. Classical total order broadcast is augmented with  external validity  checks [2] ( innerCPI.verify ) and a functionality similar to the unreliable eventual leader failure detector   [3] ( innerCPI.viewChange ).  Besides  innerCPI , core PBFT is defined by a set of calls into core PBFT. The most important call into core PBFT is  request  which is effectively used to invoke a total order broadcast primitive [2]. In the following, we first overview calls into core PBFT and then detail the  innerCPI  interface. Then, we briefly describe Sieve consensus protocol which will be specified and described in more details elsewhere.", 
            "title": "5.1 Overview"
        }, 
        {
            "location": "/protocol-spec/#52-core-pbft-functions", 
            "text": "The following functions control for parallelism using a non-recursive lock and can therefore be invoked from multiple threads in parallel. However, the functions typically run to completion and may invoke functions from the CPI passed in.  Care must be taken to prevent livelocks.", 
            "title": "5.2 Core PBFT Functions"
        }, 
        {
            "location": "/protocol-spec/#521-newpbftcore", 
            "text": "Signature:  func newPbftCore(id uint64, config *viper.Viper, consumer innerCPI, ledger consensus.Ledger) *pbftCore  The  newPbftCore  constructor instantiates a new PBFT box instance, with the specified  id .  The  config  argument defines operating parameters of the PBFT network: number replicas  N , checkpoint period  K , and the timeouts for request completion and view change duration.     configuration key  type  example value  description      general.N  integer  4  Number of replicas    general.K  integer  10  Checkpoint period    general.timeout.request  duration  2s  Max delay between request reception and execution    general.timeout.viewchange  duration  2s  Max delay between view-change start and next request execution     The arguments  consumer  and  ledger  pass in interfaces that are used\nto query the application state and invoke application requests once\nthey have been totally ordered.  See the respective sections below for\nthese interfaces.", 
            "title": "5.2.1 newPbftCore"
        }, 
        {
            "location": "/protocol-spec/#522-request", 
            "text": "Signature:  func (pbft *pbftCore) request(msgPayload []byte) error  The  request  method takes an opaque request payload and introduces this request into the total order consensus.  This payload will be passed to the CPI  execute  function on all correct, up-to-date replicas once PBFT processing is complete.  The  request  method does not wait for execution before returning;  request  merely submits the request into the consensus.  PBFT does not support submission of the same request multiple times, i.e. a nonce is required if the same conceptual request has to be executed multiple times.  However, PBFT does not reliably prevent replay of requests; a nonce or sequence number can be used by the application to prevent against replays by a Byzantine client.  In rare cases, a  request  may be dropped by the network, and it will never  execute ; if the consumer cannot tolerate this, the consumer needs to implement retries itself.", 
            "title": "5.2.2 request"
        }, 
        {
            "location": "/protocol-spec/#523-receive", 
            "text": "Signature:  func (pbft *pbftCore) receive(msgPayload []byte) error  The  receive  method takes an opaque message payload, which another instance passed to the  broadcast  or  unicast  CPI functions.  All communication is expected to ensure integrity and provide authentication; e.g. by the use of TLS.  Note that currently authentication is not yet used.  Once authentication is provided, the function signature of  receive  should include the id of the sending node.  See also the discussion below regarding  innerCPI.broadcast  and  innerCPI.unicast .", 
            "title": "5.2.3 receive"
        }, 
        {
            "location": "/protocol-spec/#524-close", 
            "text": "Signature:  func (pbft *pbftCore) close()  The  close  method terminates all background operations. This interface is mostly exposed for testing, because during operation of the fabric, there is never a need to terminate the PBFT instance.", 
            "title": "5.2.4 close"
        }, 
        {
            "location": "/protocol-spec/#53-inner-consensus-programming-interface", 
            "text": "The consumer application provides the inner consensus programming interface to core PBFT.  PBFT will call these functions to query state and signal events.  Definition:  type innerCPI interface {\n    broadcast(msgPayload []byte)\n    unicast(msgPayload []byte, receiverID uint64) (err error)\n    validate(txRaw []byte) error\n    execute(txRaw []byte, rawMetadata []byte)\n    viewChange(curView uint64)\n}", 
            "title": "5.3 Inner Consensus Programming Interface"
        }, 
        {
            "location": "/protocol-spec/#531-broadcast", 
            "text": "Signature:  func (cpi innerCPI) broadcast(msgPayload []byte)  The  broadcast  function takes an opaque payload and delivers it to all other replicas via their  receive  method.  Messages may be lost or reordered.  See also the section on  receive  call coming into core PBFT.", 
            "title": "5.3.1 broadcast"
        }, 
        {
            "location": "/protocol-spec/#532-unicast", 
            "text": "Signature:  func (cpi innerCPI) unicast(msgPayload []byte, receiverID uint64) (err error)  The  unicast  function is similar to  broadcast , but takes a destination replica id.", 
            "title": "5.3.2 unicast"
        }, 
        {
            "location": "/protocol-spec/#533-validate", 
            "text": "Signature:  func (cpi innerCPI) validate(txRaw []byte) error  The  validate  function is invoked whenever PBFT receives a new request, either locally via  request , or via consensus messages.  The argument of  validate  is the opaque request that was provided to the PBFT  request  method.  If  validate  returns a non- nil  error, the local replica will discard the request and behave as if it had never received the request.  The  validate  function can be used for syntactic validation of application requests (i.e.,  external validity  checks [2]).  Care must be taken not to introduce non-determinism when validating requests; i.e. the validation must not use any state, e.g., if different replicas receive  validate  calls in different sequence, also with respect to  execute .  If non-determinism occurs during validation, the behavior of different replicas may diverge, which may lead to dropped requests or complete malfunction of the consensus.", 
            "title": "5.3.3 validate"
        }, 
        {
            "location": "/protocol-spec/#534-execute", 
            "text": "Signature:  func (cpi innerCPI) execute(txRaw []byte, opts ...interface{})  PBFT will invoke the  execute  function when a request has been successfully totally ordered by the consensus protocol.  The argument passed to  execute  is the opaque request, as it has been previously passed to  request .  All correct, up-to-date replicas will receive the same sequence of  execute  calls.  The application must be deterministic when processing the request.  Any non-determinism will lead to the state on replicas diverging, which is considered a byzantine behavior.  See also the discussion above on request replays in the  request  section.", 
            "title": "5.3.4 execute"
        }, 
        {
            "location": "/protocol-spec/#535-viewchange", 
            "text": "Signature:  func (cpi innerCPI) viewChange(curView uint64)  The  viewChange  function is called by PBFT to signal a successful transition to a new view (and with it, a new primary).  This information is right now only of interest to the  Sieve  consensus algorithm, which uses PBFT leader election to avoid having to implement its own.  Assuming a fixed number of replicas, it is simple to map curView uint64 to replica ID using modulo arithmetic. Having this in mind, with core PBFT implementation, assuming eventual synchrony [4], it is straightforward to argue that the functionality of the  viewChange  call allows simple implementation of the  eventual leader  unreliable failure detector   [3].", 
            "title": "5.3.5 viewChange"
        }, 
        {
            "location": "/protocol-spec/#54-sieve-consensus-protocol", 
            "text": "The design goal of Sieve is to augment PBFT consensus protocol with two main design goals:    Enabling  consensus on the output state of replicas , in addition to the consensus on the input state provided by PBFT. To achieve this, Sieve adopts the Execute-Verify (Eve) pattern introduced in [5].    Because the fabric allows execution of arbitrary chaincode, such chaincode may introduce  non-deterministic  transactions. Although non-deterministic transaction should in principle be disallowed by, e.g., careful inspection of chaincode, using domain specific languages (DSLs), or by otherwise enforcing determinism, the design goal of Sieve is to provide a separate  consensus fabric-level  protection against  non-deterministic  transactions that can be used in combination with the above mentioned approaches.  To this end, Sieve detects and  sieves out non-deterministic transactions  (that manifest themselves as such). Hence, Sieve does not require all input transactions to consensus (i.e., the replicated state machine) to be deterministic. This feature of Sieve is new and has not been implemented by any existing Byzantine fault tolerant consensus protocols.    A protocol achieving the above two goals should not be designed and implemented from scratch, and should reuse existing PBFT implementation, lowering code complexity and simplifying reasoning about a new consensus protocol. To this end, inspired by [6], Sieve is designed using a modular approach, reusing the core PBFT component of  obcpbft .  Although the details of Sieve will appear elsewhere [7], we briefly outline some design and implementation aspects below.  In a nutshell, Sieve requires replicas to deterministically agree on the output of the execution of a request.  If the request was deterministic in the first place, all correct replicas will have obtained the same output, and they can agree on this very result. However, if a request happens to produce divergent outputs at correct replicas, Sieve may  detect this divergent condition, and the replicas will agree to discard the result of the request, thereby retaining determinism.  Notice that, as discussed further below, Sieve allows false negatives, i.e., execution of  non-deterministic  requests that execute with the same result at a sufficient number of replicas. However, Sieve allows no false positives and any discarded request is certainly non-deterministic.  The Sieve protocol uses core PBFT to agree on whether to accept or discard a request.  Execution of requests to Sieve is coordinated by a  leader , which maps to the current PBFT primary (leveraging  innerCPI.viewchange  notification from core PBFT) .  Upon a new request, the leader will instruct all replicas to tentatively execute the request.  Every replica then reports the tentative result (i.e. application state) back to the leader.  The leader collects these  verify  reports in a  verify-set , which unambiguously determines whether the request should be accepted or discarded.  This verify-set is then passed through the total order of core PBFT.  When core PBFT executes this verify-set, all correct replicas will act in the same way.  If the verify-set proves that execution diverged between correct replicas, the request is considered non-deterministic, and the replicas will roll back the tentative execution and restore the original application state.  If all correct replicas obtained the same result for the tentative execution, the replicas accept the execution and commit the tentative application state.  Under adverse conditions, a request that diverged between correct replicas may appear like a deterministic request (we speak of  false negative  in Sieve detection of non-determinstic requests).  Nevertheless, Sieve requires at least one correct replica to obtain a certain outcome state in order for that state to be committed. Correct replicas that possibly observe diverging execution will discard their result and synchronize their state to match the agreed-upon execution.", 
            "title": "5.4 Sieve Consensus protocol"
        }, 
        {
            "location": "/protocol-spec/#6-application-programming-interface_1", 
            "text": "The primary interface to the fabric is a REST API. The REST API allows applications to register users, query the blockchain, and to issue transactions. A CLI is also provided to cover a subset of the available APIs for development purposes. The CLI enables developers to quickly test chaincodes or query for status of transactions.  Applications interact with a non-validating peer node through the REST API, which will require some form of authentication to ensure the entity has proper privileges. The application is responsible for implementing the appropriate authentication mechanism and the peer node will subsequently sign the outgoing messages with the client identity.    \nThe fabric API design covers the categories below, though the implementation is incomplete for some of them in the current release. The  REST API  section will describe the APIs currently supported.   Identity - Enrollment to acquire or to revoke a certificate  Address - Target and source of a transaction  Transaction - Unit of execution on the ledger  Chaincode - Program running on the ledger  Blockchain - Contents of the ledger  Network - Information about the blockchain peer network  Storage - External store for files or documents  Event Stream - Sub/pub events on the blockchain", 
            "title": "6. Application Programming Interface"
        }, 
        {
            "location": "/protocol-spec/#61-rest-service", 
            "text": "The REST service can be enabled (via configuration) on either validating or non-validating peers, but it is recommended to only enable the REST service on non-validating peers on production networks.  func StartOpenchainRESTServer(server *oc.ServerOpenchain, devops *oc.Devops)  This function reads the  rest.address  value in the  core.yaml  configuration file, which is the configuration file for the  peer  process. The value of the  rest.address  key defines the default address and port on which the peer will listen for HTTP REST requests.  It is assumed that the REST service receives requests from applications which have already authenticated the end user.", 
            "title": "6.1 REST Service"
        }, 
        {
            "location": "/protocol-spec/#62-rest-api", 
            "text": "You can work with the REST API through any tool of your choice. For example, the curl command line utility or a browser based client such as the Firefox Rest Client or Chrome Postman. You can likewise trigger REST requests directly through  Swagger . To obtain the REST API Swagger description, click  here . The currently available APIs are summarized in the following section.", 
            "title": "6.2 REST API"
        }, 
        {
            "location": "/protocol-spec/#621-rest-endpoints", 
            "text": "Block  GET /chain/blocks/{block-id}  Blockchain  GET /chain  Chaincode  POST /chaincode  Network  GET /network/peers  Registrar  POST /registrar  GET /registrar/{enrollmentID}  DELETE /registrar/{enrollmentID}  GET /registrar/{enrollmentID}/ecert  GET /registrar/{enrollmentID}/tcert  Transactions  GET /transactions/{UUID}", 
            "title": "6.2.1 REST Endpoints"
        }, 
        {
            "location": "/protocol-spec/#6211-block-api", 
            "text": "GET /chain/blocks/{block-id}   Use the Block API to retrieve the contents of various blocks from the blockchain. The returned Block message structure is defined in section  3.2.1.1 .  Block Retrieval Request:  GET host:port/chain/blocks/173  Block Retrieval Response:  {\n     transactions : [\n        {\n             type : 3,\n             chaincodeID :  EgRteWNj ,\n             payload :  Ch4IARIGEgRteWNjGhIKBmludm9rZRIBYRIBYhICMTA= ,\n             uuid :  f5978e82-6d8c-47d1-adec-f18b794f570e ,\n             timestamp : {\n                 seconds : 1453758316,\n                 nanos : 206716775\n            },\n             cert :  MIIB/zCCAYWgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMTI1MjE0MTE3WhcNMTYwNDI0MjE0MTE3WjArMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQ4wDAYDVQQDEwVsdWthczB2MBAGByqGSM49AgEGBSuBBAAiA2IABC/BBkt8izf6Ew8UDd62EdWFikJhyCPY5VO9Wxq9JVzt3D6nubx2jO5JdfWt49q8V1Aythia50MZEDpmKhtM6z7LHOU1RxuxdjcYDOvkNJo6pX144U4N1J8/D3A+97qZpKN/MH0wDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwDQYDVR0OBAYEBAECAwQwDwYDVR0jBAgwBoAEAQIDBDA9BgYqAwQFBgcBAf8EMABNbPHZ0e/2EToi0H8mkouuUDwurgBYuUB+vZfeMewBre3wXG0irzMtfwHlfECRDDAKBggqhkjOPQQDAwNoADBlAjAoote5zYFv91lHzpbEwTfJL/+r+CG7oMVFUFuoSlvBSCObK2bDIbNkW4VQ+ZC9GTsCMQC5GCgy2oZdHw/x7XYzG2BiqmRkLRTiCS7vYCVJXLivU65P984HopxW0cEqeFM9co0= ,\n             signature :  MGUCMCIJaCT3YRsjXt4TzwfmD9hg9pxYnV13kWgf7e1hAW5Nar//05kFtpVlq83X+YtcmAIxAK0IQlCgS6nqQzZEGCLd9r7cg1AkQOT/RgoWB8zcaVjh3bCmgYHsoPAPgMsi3TJktg== \n        }\n    ],\n     stateHash :  7ftCvPeHIpsvSavxUoZM0u7o67MPU81ImOJIO7ZdMoH2mjnAaAAafYy9MIH3HjrWM1/Zla/Q6LsLzIjuYdYdlQ== ,\n     previousBlockHash :  lT0InRg4Cvk4cKykWpCRKWDZ9YNYMzuHdUzsaeTeAcH3HdfriLEcTuxrFJ76W4jrWVvTBdI1etxuIV9AO6UF4Q== ,\n     nonHashData : {\n         localLedgerCommitTimestamp : {\n             seconds : 1453758316,\n             nanos : 250834782\n        }\n    }\n}", 
            "title": "6.2.1.1 Block API"
        }, 
        {
            "location": "/protocol-spec/#6212-blockchain-api", 
            "text": "GET /chain   Use the Chain API to retrieve the current state of the blockchain. The returned BlockchainInfo message is defined below.  message BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}    height  - Number of blocks in the blockchain, including the genesis block.    currentBlockHash  - The hash of the current or last block.    previousBlockHash  - The hash of the previous block.    Blockchain Retrieval Request:  GET host:port/chain  Blockchain Retrieval Response:  {\n     height : 174,\n     currentBlockHash :  lIfbDax2NZMU3rG3cDR11OGicPLp1yebIkia33Zte9AnfqvffK6tsHRyKwsw0hZFZkCGIa9wHVkOGyFTcFxM5w== ,\n     previousBlockHash :  Vlz6Dv5OSy0OZpJvijrU1cmY2cNS5Ar3xX5DxAi/seaHHRPdssrljDeppDLzGx6ZVyayt8Ru6jO+E68IwMrXLQ== \n}", 
            "title": "6.2.1.2 Blockchain API"
        }, 
        {
            "location": "/protocol-spec/#6213-chaincode-api", 
            "text": "POST /chaincode   Use the Chaincode API to deploy, invoke, and query chaincodes. The deploy request requires the client to supply a  path  parameter, pointing to the directory containing the chaincode in the file system. The response to a deploy request is either a message containing a confirmation of successful chaincode deployment or an error, containing a reason for the failure. It also contains the generated chaincode  name  in the  message  field, which is to be used in subsequent invocation and query transactions to uniquely identify the deployed chaincode.  To deploy a chaincode, supply the required ChaincodeSpec payload, defined in section  3.1.2.2 .  Deploy Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n         path : github.com/hyperledger/fabic/examples/chaincode/go/chaincode_example02 \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  1000 ,  b ,  2000 ]\n    }\n  },\n   id :  1   \n}  Deploy Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     id : 1\n}  With security enabled, modify the required payload to include the  secureContext  element passing the enrollment ID of a logged in user as follows:  Deploy Request with security enabled:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n         path : github.com/hyperledger/fabic/examples/chaincode/go/chaincode_example02 \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  1000 ,  b ,  2000 ]\n    },\n     secureContext :  lukas \n  },\n   id :  1   \n}  The invoke request requires the client to supply a  name  parameter, which was previously returned in the response from the deploy transaction. The response to an invocation request is either a message containing a confirmation of successful execution or an error, containing a reason for the failure.  To invoke a function within a chaincode, supply the required ChaincodeSpec payload, defined in section  3.1.2.2 .  Invoke Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n       name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     ctorMsg : {\n         function : invoke ,\n         args :[ a ,  b ,  100 ]\n    }\n  },\n   id :  3   \n}  Invoke Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  5a4540e5-902b-422d-a6ab-e70ab36a2e6d \n    },\n     id : 3\n}  With security enabled, modify the required payload to include the  secureContext  element passing the enrollment ID of a logged in user as follows:  Invoke Request with security enabled:  {\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n       name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     ctorMsg : {\n         function : invoke ,\n         args :[ a ,  b ,  100 ]\n    },\n     secureContext :  lukas \n  },\n   id :  3   \n}  The query request requires the client to supply a  name  parameter, which was previously returned in the response from the deploy transaction. The response to a query request depends on the chaincode implementation. The response will contain a message containing a confirmation of successful execution or an error, containing a reason for the failure. In the case of successful execution, the response will also contain values of requested state variables within the chaincode.  To invoke a query function within a chaincode, supply the required ChaincodeSpec payload, defined in section  3.1.2.2 .  Query Request:  POST host:port/chaincode/\n\n{\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n       name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     ctorMsg : {\n         function : query ,\n         args :[ a ]\n    }\n  },\n   id :  5   \n}  Query Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  -400 \n    },\n     id : 5\n}  With security enabled, modify the required payload to include the  secureContext  element passing the enrollment ID of a logged in user as follows:  Query Request with security enabled:  {\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n     type :  GOLANG ,\n     chaincodeID :{\n       name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     ctorMsg : {\n         function : query ,\n         args :[ a ]\n    },\n     secureContext :  lukas \n  },\n   id :  5   \n}", 
            "title": "6.2.1.3 Chaincode API"
        }, 
        {
            "location": "/protocol-spec/#6214-network-api", 
            "text": "Use the Network API to retrieve information about the network of peer nodes comprising the blockchain fabric.  The /network/peers endpoint returns a list of all existing network connections for the target peer node. The list includes both validating and non-validating peers. The list of peers is returned as type  PeersMessage , containing an array of  PeerEndpoint , defined in section  3.1.1 .  message PeersMessage {\n    repeated PeerEndpoint peers = 1;\n}  Network Request:  GET host:port/network/peers  Network Response:  {\n     peers : [\n        {\n             ID : {\n                 name :  vp1 \n            },\n             address :  172.17.0.4:30303 ,\n             type : 1,\n             pkiID :  rUA+vX2jVCXev6JsXDNgNBMX03IV9mHRPWo6h6SI0KLMypBJLd+JoGGlqFgi+eq/ \n        },\n        {\n             ID : {\n                 name :  vp3 \n            },\n             address :  172.17.0.5:30303 ,\n             type : 1,\n             pkiID :  OBduaZJ72gmM+B9wp3aErQlofE0ulQfXfTHh377ruJjOpsUn0MyvsJELUTHpAbHI \n        },\n        {\n             ID : {\n                 name :  vp2 \n            },\n             address :  172.17.0.6:30303 ,\n             type : 1,\n             pkiID :  GhtP0Y+o/XVmRNXGF6pcm9KLNTfCZp+XahTBqVRmaIumJZnBpom4ACayVbg4Q/Eb \n        }\n    ]\n}", 
            "title": "6.2.1.4 Network API"
        }, 
        {
            "location": "/protocol-spec/#6215-registrar-api-member-services", 
            "text": "POST /registrar  GET /registrar/{enrollmentID}  DELETE /registrar/{enrollmentID}  GET /registrar/{enrollmentID}/ecert  GET /registrar/{enrollmentID}/tcert   Use the Registrar APIs to manage end user registration with the certificate authority (CA). These API endpoints are used to register a user with the CA, determine whether a given user is registered, and to remove any login tokens for a target user from local storage, preventing them from executing any further transactions. The Registrar APIs are also used to retrieve user enrollment and transaction certificates from the system.  The  /registrar  endpoint is used to register a user with the CA. The required Secret payload is defined below. The response to the registration request is either a confirmation of successful registration or an error, containing a reason for the failure.  message Secret {\n    string enrollId = 1;\n    string enrollSecret = 2;\n}   enrollId  - Enrollment ID with the certificate authority.  enrollSecret  - Enrollment password with the certificate authority.   Enrollment Request:  POST host:port/registrar\n\n{\n   enrollId :  lukas ,\n   enrollSecret :  NPKYL39uKbkj \n}  Enrollment Response:  {\n     OK :  Login successful for user 'lukas'. \n}  The  GET /registrar/{enrollmentID}  endpoint is used to confirm whether a given user is registered with the CA. If so, a confirmation will be returned. Otherwise, an authorization error will result.  Verify Enrollment Request:  GET host:port/registrar/jim  Verify Enrollment Response:  {\n     OK :  User jim is already logged in. \n}  Verify Enrollment Request:  GET host:port/registrar/alex  Verify Enrollment Response:  {\n     Error :  User alex must log in. \n}  The  DELETE /registrar/{enrollmentID}  endpoint is used to delete login tokens for a target user. If the login tokens are deleted successfully, a confirmation will be returned. Otherwise, an authorization error will result. No payload is required for this endpoint.  Remove Enrollment Request:  DELETE host:port/registrar/lukas  Remove Enrollment Response:  {\n     OK :  Deleted login token and directory for user lukas. \n}  The  GET /registrar/{enrollmentID}/ecert  endpoint is used to retrieve the enrollment certificate of a given user from local storage. If the target user has already registered with the CA, the response will include a URL-encoded version of the enrollment certificate. If the target user has not yet registered, an error will be returned. If the client wishes to use the returned enrollment certificate after retrieval, keep in mind that it must be URL-decoded.  Enrollment Certificate Retrieval Request:  GET host:port/registrar/jim/ecert  Enrollment Certificate Retrieval Response:  {\n     OK :  -----BEGIN+CERTIFICATE-----%0AMIIBzTCCAVSgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwNPQkMwHhcNMTYwMTIxMDYzNjEwWhcNMTYwNDIw%0AMDYzNjEwWjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNP%0AQkMwdjAQBgcqhkjOPQIBBgUrgQQAIgNiAARSLgjGD0omuJKYrJF5ClyYb3sGEGTU%0AH1mombSAOJ6GAOKEULt4L919sbSSChs0AEvTX7UDf4KNaKTrKrqo4khCoboMg1VS%0AXVTTPrJ%2BOxSJTXFZCohVgbhWh6ZZX2tfb7%2BjUDBOMA4GA1UdDwEB%2FwQEAwIHgDAM%0ABgNVHRMBAf8EAjAAMA0GA1UdDgQGBAQBAgMEMA8GA1UdIwQIMAaABAECAwQwDgYG%0AUQMEBQYHAQH%2FBAE0MAoGCCqGSM49BAMDA2cAMGQCMGz2RR0NsJOhxbo0CeVts2C5%0A%2BsAkKQ7v1Llbg78A1pyC5uBmoBvSnv5Dd0w2yOmj7QIwY%2Bn5pkLiwisxWurkHfiD%0AxizmN6vWQ8uhTd3PTdJiEEckjHKiq9pwD%2FGMt%2BWjP7zF%0A-----END+CERTIFICATE-----%0A \n}  The  /registrar/{enrollmentID}/tcert  endpoint retrieves the transaction certificates for a given user that has registered with the certificate authority. If the user has registered, a confirmation message will be returned containing an array of URL-encoded transaction certificates. Otherwise, an error will result. The desired number of transaction certificates is specified with the optional 'count' query parameter. The default number of returned transaction certificates is 1; and 500 is the maximum number of certificates that can be retrieved with a single request. If the client wishes to use the returned transaction certificates after retrieval, keep in mind that they must be URL-decoded.  Transaction Certificate Retrieval Request:  GET host:port/registrar/jim/tcert  Transaction Certificate Retrieval Response:  {\n     OK : [\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAQfwJORRED9RAsmSl%2FEowq1STBb%0A%2FoFteymZ96RUr%2BsKmF9PNrrUNvFZFhvukxZZjqhEcGiQqFyRf%2FBnVN%2BbtRzMo38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwSRWQFmErr0SmQO9AFP4GJYzQ%0APQMmcsCjKiJf%2Bw1df%2FLnXunCsCUlf%2FalIUaeSrT7MAoGCCqGSM49BAMDA0gAMEUC%0AIQC%2FnE71FBJd0hwNTLXWmlCJff4Yi0J%2BnDi%2BYnujp%2Fn9nQIgYWg0m0QFzddyJ0%2FF%0AKzIZEJlKgZTt8ZTlGg3BBrgl7qY%3D%0A-----END+CERTIFICATE-----%0A \n    ]\n}  Transaction Certificate Retrieval Request:  GET host:port/registrar/jim/tcert?count=5  Transaction Certificate Retrieval Response:  {\n     OK : [\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A ,\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A ,\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A ,\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A ,\n         -----BEGIN+CERTIFICATE-----%0AMIIBwDCCAWagAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoG%0AA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMzExMjEwMTI2WhcNMTYwNjA5%0AMjEwMTI2WjApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwNq%0AaW0wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAARwJxVezgDcTAgj2LtTKVm65qft%0AhRTYnIOQhhOx%2B%2B2NRu5r3Kn%2FXTf1php3NXOFY8ZQbY%2FQbFAwn%2FB0O68wlHiro38w%0AfTAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH%2FBAIwADANBgNVHQ4EBgQEAQIDBDAP%0ABgNVHSMECDAGgAQBAgMEMD0GBioDBAUGBwEB%2FwQwRVPMSKVcHsk4aGHxBWc8PGKj%0AqtTVTtuXnN45BynIx6lP6urpqkSuILgB1YOdRNefMAoGCCqGSM49BAMDA0gAMEUC%0AIAIjESYDp%2FXePKANGpsY3Tu%2F4A2IfeczbC3uB%2BpziltWAiEA6Stp%2FX4DmbJGgZe8%0APMNBgRKeoU6UbgTmed0ZEALLZP8%3D%0A-----END+CERTIFICATE-----%0A \n    ]\n}", 
            "title": "6.2.1.5 Registrar API (member services)"
        }, 
        {
            "location": "/protocol-spec/#6216-transactions-api", 
            "text": "GET /transactions/{UUID}   Use the Transaction API to retrieve an individual transaction matching the UUID from the blockchain. The returned transaction message is defined in section  3.1.2.1 .  Transaction Retrieval Request:  GET host:port/transactions/f5978e82-6d8c-47d1-adec-f18b794f570e  Transaction Retrieval Response:  {\n     type : 3,\n     chaincodeID :  EgRteWNj ,\n     payload :  Ch4IARIGEgRteWNjGhIKBmludm9rZRIBYRIBYhICMTA= ,\n     uuid :  f5978e82-6d8c-47d1-adec-f18b794f570e ,\n     timestamp : {\n         seconds : 1453758316,\n         nanos : 206716775\n    },\n     cert :  MIIB/zCCAYWgAwIBAgIBATAKBggqhkjOPQQDAzApMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQwwCgYDVQQDEwN0Y2EwHhcNMTYwMTI1MjE0MTE3WhcNMTYwNDI0MjE0MTE3WjArMQswCQYDVQQGEwJVUzEMMAoGA1UEChMDSUJNMQ4wDAYDVQQDEwVsdWthczB2MBAGByqGSM49AgEGBSuBBAAiA2IABC/BBkt8izf6Ew8UDd62EdWFikJhyCPY5VO9Wxq9JVzt3D6nubx2jO5JdfWt49q8V1Aythia50MZEDpmKhtM6z7LHOU1RxuxdjcYDOvkNJo6pX144U4N1J8/D3A+97qZpKN/MH0wDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwDQYDVR0OBAYEBAECAwQwDwYDVR0jBAgwBoAEAQIDBDA9BgYqAwQFBgcBAf8EMABNbPHZ0e/2EToi0H8mkouuUDwurgBYuUB+vZfeMewBre3wXG0irzMtfwHlfECRDDAKBggqhkjOPQQDAwNoADBlAjAoote5zYFv91lHzpbEwTfJL/+r+CG7oMVFUFuoSlvBSCObK2bDIbNkW4VQ+ZC9GTsCMQC5GCgy2oZdHw/x7XYzG2BiqmRkLRTiCS7vYCVJXLivU65P984HopxW0cEqeFM9co0= ,\n     signature :  MGUCMCIJaCT3YRsjXt4TzwfmD9hg9pxYnV13kWgf7e1hAW5Nar//05kFtpVlq83X+YtcmAIxAK0IQlCgS6nqQzZEGCLd9r7cg1AkQOT/RgoWB8zcaVjh3bCmgYHsoPAPgMsi3TJktg== \n}", 
            "title": "6.2.1.6 Transactions API"
        }, 
        {
            "location": "/protocol-spec/#63-cli", 
            "text": "The CLI includes a subset of the available APIs to enable developers to quickly test and debug chaincodes or query for status of transactions. CLI is implemented in Golang and operable on multiple OS platforms. The currently available CLI commands are summarized in the following section.", 
            "title": "6.3 CLI"
        }, 
        {
            "location": "/protocol-spec/#631-cli-commands", 
            "text": "To see what CLI commands are currently available in the implementation, execute the following:  $ peer  You will receive a response similar to below:      Usage:\n      peer [command]\n\n    Available Commands:\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level= : Default logging level and overrides, see core.yaml for full syntax\n\n    Use  peer [command] --help  for more information about a command.  Some of the available command line arguments for the  peer  command are listed below:    -c  - constructor: function to trigger in order to initialize the chaincode state upon deployment.    -l  - language: specifies the implementation language of the chaincode. Currently, only Golang is supported.    -n  - name: chaincode identifier returned from the deployment transaction. Must be used in subsequent invoke and query transactions.    -p  - path: identifies chaincode location in the local file system. Must be used as a parameter in the deployment transaction.    -u  - username: enrollment ID of a logged in user invoking the transaction.    Not all of the above commands are fully implemented in the current release. The fully supported commands that are helpful for chaincode development and debugging are described below.  Note, that any configuration settings for the peer node listed in the  core.yaml  configuration file, which is the  configuration file for the  peer  process, may be modified on the command line with an environment variable. For example, to set the  peer.id  or the  peer.addressAutoDetect  settings, one may pass the  CORE_PEER_ID=vp1  and  CORE_PEER_ADDRESSAUTODETECT=true  on the command line.", 
            "title": "6.3.1 CLI Commands"
        }, 
        {
            "location": "/protocol-spec/#6311-node-start", 
            "text": "The CLI  node start  command will execute the peer process in either the development or production mode. The development mode is meant for running a single peer node locally, together with a local chaincode deployment. This allows a chaincode developer to modify and debug their code without standing up a complete network. An example for starting the peer in development mode follows:  peer node start --peer-chaincodedev  To start the peer process in production mode, modify the above command as follows:  peer node start", 
            "title": "6.3.1.1 node start"
        }, 
        {
            "location": "/protocol-spec/#6312-network-login", 
            "text": "The CLI  network login  command will login a user, that is already registered with the CA, through the CLI. To login through the CLI, issue the following command, where  username  is the enrollment ID of a registered user.  peer network login  username   The example below demonstrates the login process for user  jim .  peer network login jim  The command will prompt for a password, which must match the enrollment password for this user registered with the certificate authority. If the password entered does not match the registered password, an error will result.  22:21:31.246 [main] login -  INFO 001 CLI client login...\n22:21:31.247 [main] login -  INFO 002 Local data store for client loginToken: /var/hyperledger/production/client/\nEnter password for user 'jim': ************\n22:21:40.183 [main] login -  INFO 003 Logging in user 'jim' on CLI interface...\n22:21:40.623 [main] login -  INFO 004 Storing login token for user 'jim'.\n22:21:40.624 [main] login -  INFO 005 Login successful for user 'jim'.  You can also pass a password for the user with  -p  parameter. An example is below.  peer network login jim -p 123456", 
            "title": "6.3.1.2 network login"
        }, 
        {
            "location": "/protocol-spec/#6313-chaincode-deploy", 
            "text": "The CLI  deploy  command creates the docker image for the chaincode and subsequently deploys the package to the validating peer. An example is below.  peer chaincode deploy -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{ Function : init ,  Args : [ a , 100 ,  b ,  200 ]}'  With security enabled, the command must be modified to pass an enrollment id of a logged in user with the  -u  parameter. An example is below.  peer chaincode deploy -u jim -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{ Function : init ,  Args : [ a , 100 ,  b ,  200 ]}'  Note:  If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.", 
            "title": "6.3.1.3 chaincode deploy"
        }, 
        {
            "location": "/protocol-spec/#6314-chaincode-invoke", 
            "text": "The CLI  invoke  command executes a specified function within the target chaincode. An example is below.  peer chaincode invoke -n  name_value_returned_from_deploy_command  -c '{ Function :  invoke ,  Args : [ a ,  b ,  10 ]}'  With security enabled, the command must be modified to pass an enrollment id of a logged in user with the  -u  parameter. An example is below.  peer chaincode invoke -u jim -n  name_value_returned_from_deploy_command  -c '{ Function :  invoke ,  Args : [ a ,  b ,  10 ]}'", 
            "title": "6.3.1.4 chaincode invoke"
        }, 
        {
            "location": "/protocol-spec/#6315-chaincode-query", 
            "text": "The CLI  query  command triggers a specified query method within the target chaincode. The response that is returned depends on the chaincode implementation. An example is below.  peer chaincode query -l golang -n  name_value_returned_from_deploy_command  -c '{ Function :  query ,  Args : [ a ]}'  With security enabled, the command must be modified to pass an enrollment id of a logged in user with the  -u  parameter. An example is below.  peer chaincode query -u jim -l golang -n  name_value_returned_from_deploy_command  -c '{ Function :  query ,  Args : [ a ]}'", 
            "title": "6.3.1.5 chaincode query"
        }, 
        {
            "location": "/protocol-spec/#7-application-model_1", 
            "text": "", 
            "title": "7. Application Model"
        }, 
        {
            "location": "/protocol-spec/#71-composition-of-an-application", 
            "text": "An application follows a MVC-B architecture \u2013 Model, View, Control, BlockChain.  \n   VIEW LOGIC \u2013 Mobile or Web UI interacting with control logic. \n   CONTROL LOGIC \u2013 Coordinates between UI, Data Model and APIs to drive transitions and chain-code. \n   DATA MODEL \u2013 Application Data Model \u2013 manages off-chain data, including Documents and large files. \n   BLOCKCHAIN  LOGIC \u2013 Blockchain logic are extensions of the Controller Logic and Data Model, into the Blockchain realm.    Controller logic is enhanced by chaincode, and the data model is enhanced with transactions on the blockchain.   \nFor example, a Bluemix PaaS application using Node.js might have a Web front-end user interface or a native mobile app with backend model on Cloudant data service. The control logic may interact with 1 or more chaincodes to process transactions on the blockchain.   \n\n### 7.2 7.2 Sample Application\n\n\n## 8. Future Directions\n### 8.1 Enterprise Integration\n### 8.2 Performance and Scalability\n### 8.3 Additional Consensus Plugins\n### 8.4 Additional Languages\n\n\n## 9. References\n- [1] Miguel Castro, Barbara Liskov: Practical Byzantine fault tolerance and proactive recovery. ACM Trans. Comput. Syst. 20(4): 398-461 (2002)\n\n- [2] Christian Cachin, Rachid Guerraoui, Lu\u00eds E. T. Rodrigues: Introduction to Reliable and Secure Distributed Programming (2. ed.). Springer 2011, ISBN 978-3-642-15259-7, pp. I-XIX, 1-367\n\n- [3] Tushar Deepak Chandra, Vassos Hadzilacos, Sam Toueg: The Weakest Failure Detector for Solving Consensus. J. ACM 43(4): 685-722 (1996)\n\n- [4] Cynthia Dwork, Nancy A. Lynch, Larry J. Stockmeyer: Consensus in the presence of partial synchrony. J. ACM 35(2): 288-323 (1988)\n\n- [5] Manos Kapritsos, Yang Wang, Vivien Qu\u00e9ma, Allen Clement, Lorenzo Alvisi, Mike Dahlin: All about Eve: Execute-Verify Replication for Multi-Core Servers. OSDI 2012: 237-250\n\n- [6] Pierre-Louis Aublin, Rachid Guerraoui, Nikola Knezevic, Vivien Qu\u00e9ma, Marko Vukolic: The Next 700 BFT Protocols. ACM Trans. Comput. Syst. 32(4): 12:1-12:45 (2015)\n\n- [7] Christian Cachin, Simon Schubert, Marko Vukoli\u0107: [Non-determinism in Byzantine Fault-Tolerant Replication](http://arxiv.org/abs/1603.07351)", 
            "title": "7.1 Composition of an Application"
        }, 
        {
            "location": "/API/ChaincodeAPI/", 
            "text": "Chaincode APIs\n\n\nWhen the \nInit\n, \nInvoke\n or \nQuery\n function of a chaincode is called, the fabric passes the \nstub *shim.ChaincodeStub\n parameter. This \nstub\n can be used to call APIs to access to the ledger services, transaction context, or to invoke other chaincodes.\n\n\nThe current APIs are defined in the \nshim package\n, generated by \ngodoc\n. However, it includes functions from \nchaincode.pb.go\n such as \nfunc (*Column) XXX_OneofFuncs\n that are not intended as public API. The best is to look at the function definitions in \nchaincode.go\n and \nchaincode samples\n for usage.", 
            "title": "Chaincode APIs"
        }, 
        {
            "location": "/API/ChaincodeAPI/#chaincode-apis", 
            "text": "When the  Init ,  Invoke  or  Query  function of a chaincode is called, the fabric passes the  stub *shim.ChaincodeStub  parameter. This  stub  can be used to call APIs to access to the ledger services, transaction context, or to invoke other chaincodes.  The current APIs are defined in the  shim package , generated by  godoc . However, it includes functions from  chaincode.pb.go  such as  func (*Column) XXX_OneofFuncs  that are not intended as public API. The best is to look at the function definitions in  chaincode.go  and  chaincode samples  for usage.", 
            "title": "Chaincode APIs"
        }, 
        {
            "location": "/API/CoreAPI/", 
            "text": "APIs - CLI, REST, and Node.js\n\n\nOverview\n\n\nThis document covers the available APIs for interacting with a peer node. Three interface choices are provided:\n\n\n\n\nCLI\n\n\nREST API\n\n\nNode.js Application\n\n\nUsing Swagger JS Plugin\n\n\nMarbles Demo Application\n\n\nCommercial Paper Demo Application\n\n\n\n\nNote:\n If you are working with APIs with security enabled, please review the \nsecurity setup instructions\n before proceeding.\n\n\nCLI\n\n\nTo view the currently available CLI commands, execute the following:\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric\nbuild/bin/peer\n\n\n\nYou will see output similar to the example below (\nNOTE:\n rootcommand below is hardcoded in \nmain.go\n. Currently, the build will create a \npeer\n executable file).\n\n\n    Usage:\n      peer [command]\n\n    Available Commands:\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level=\n: Default logging level and overrides, see core.yaml for full syntax\n\n\n    Use \npeer [command] --help\n for more information about a command.\n\n\n\n\n\nThe \npeer\n command supports several subcommands, as shown above. To\nfacilitate its use in scripted applications, the \npeer\n command always\nproduces a non-zero return code in the event of command failure. Upon success,\nmany of the subcommands produce a result on \nstdout\n as shown in the table\nbelow:\n\n\n\n\n\n\n\n\nCommand\n\n\nstdout\n result in the event of success\n\n\n\n\n\n\n\n\n\n\nnode start\n\n\nN/A\n\n\n\n\n\n\nnode status\n\n\nString form of \nStatusCode\n\n\n\n\n\n\nnode stop\n\n\nString form of \nStatusCode\n\n\n\n\n\n\nnetwork login\n\n\nN/A\n\n\n\n\n\n\nnetwork list\n\n\nThe list of network connections to the peer node.\n\n\n\n\n\n\nchaincode deploy\n\n\nThe chaincode container name (hash) required for subsequent \nchaincode invoke\n and \nchaincode query\n commands\n\n\n\n\n\n\nchaincode invoke\n\n\nThe transaction ID (UUID)\n\n\n\n\n\n\nchaincode query\n\n\nBy default, the query result is formatted as a printable string. Command line options support writing this value as raw bytes (-r, --raw), or formatted as the hexadecimal representation of the raw bytes (-x, --hex). If the query response is empty then nothing is output.\n\n\n\n\n\n\n\n\nDeploy a Chaincode\n\n\nDeploy creates the docker image for the chaincode and subsequently deploys the package to the validating peer. An example is below.\n\n\npeer chaincode deploy -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'\n\n\nThe response to the chaincode deploy command will contain the chaincode identifier (hash) which will be required on subsequent \nchaincode invoke\n and \nchaincode query\n commands in order to identify the deployed chaincode.\n\n\nWith security enabled, modify the command to include the -u parameter passing the username of a logged in user as follows:\n\n\npeer chaincode deploy -u jim -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'\n\n\nNote:\n If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.\n\n\nVerify Results\n\n\nTo verify that the block containing the latest transaction has been added to the blockchain, use the \n/chain\n REST endpoint from the command line. Target the IP address of either a validating or a non-validating node. In the example below, 172.17.0.2 is the IP address of a validating or a non-validating node and 5000 is the REST interface port defined in \ncore.yaml\n.\n\n\ncurl 172.17.0.2:5000/chain\n\n\nAn example of the response is below.\n\n\n{\n    \nheight\n:1,\n    \ncurrentBlockHash\n:\n4Yc4yCO95wcpWHW2NLFlf76OGURBBxYZMf3yUyvrEXs5TMai9qNKfy9Yn/==\n\n}\n\n\n\n\nThe returned BlockchainInfo message is defined inside \nfabric.proto\n.\n\n\nmessage BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}\n\n\n\n\nTo verify that a specific block is inside the blockchain, use the \n/chain/blocks/{Block}\n REST endpoint. Likewise, target the IP address of either a validating or a non-validating node on port 5000.\n\n\ncurl 172.17.0.2:5000/chain/blocks/0\n\n\nThe returned Block message structure is defined inside \nfabric.proto\n.\n\n\nmessage Block {\n    uint32 version = 1;\n    google.protobuf.Timestamp timestamp = 2;\n    repeated Transaction transactions = 3;\n    bytes stateHash = 4;\n    bytes previousBlockHash = 5;\n    bytes consensusMetadata = 6;\n    NonHashData nonHashData = 7;\n}\n\n\n\n\nAn example of a returned Block structure is below.\n\n\n{\n    \ntransactions\n:[{\n        \ntype\n:1,\n        \nchaincodeID\n: {\n            \npath\n:\ngithub.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n\n        },\n        \npayload\n:\nClwIARJYCk9naXRod...\n,\n        \nuuid\n:\nabdcec99-ae5e-415e-a8be-1fca8e38ba71\n\n    }],\n    \nstateHash\n:\nPY5YcQRu2g1vjiAqHHshoAhnq8CFP3MqzMslcEAJbnmXDtD+LopmkrUHrPMOGSF5UD7Kxqhbg1XUjmQAi84paw==\n\n}\n\n\n\n\nFor additional information on the available CLI commands, please see the \nprotocol specification\n section 6.3 on CLI.\n\n\nREST API\n\n\nYou can work with the REST API through any tool of your choice. For example, the curl command line utility or a browser based client such as the Firefox Rest Client or Chrome Postman. You can likewise trigger REST requests directly through \nSwagger\n. You can utilize the Swagger service directly or, if you prefer, you can set up Swagger locally by following the instructions \nhere\n.\n\n\nNote:\n The default REST interface port is 5000. It can be configured in \ncore.yaml\n using the \nrest.address\n property. If using Vagrant, the REST port mapping is defined in \nVagrantfile\n.\n\n\nNote on constructing a test blockchain\n If you want to test the REST API locally, construct a test blockchain by running the TestServerOpenchain_API_GetBlockCount test implemented inside \napi_test.go\n. This test will create a test blockchain with 5 blocks. Subsequently restart the peer process.\n\n\n    cd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\n    go test -v -run TestServerOpenchain_API_GetBlockCount\n\n\n\n\nREST Endpoints\n\n\nTo learn about the REST API through Swagger, please take a look at the Swagger document \nhere\n. You can upload the service description file to the Swagger service directly or, if you prefer, you can set up Swagger locally by following the instructions \nhere\n.\n\n\n\n\nBlock\n\n\nGET /chain/blocks/{Block}\n\n\nBlockchain\n\n\nGET /chain\n\n\nDevops\n [DEPRECATED]\n\n\nPOST /devops/deploy\n\n\nPOST /devops/invoke\n\n\nPOST /devops/query\n\n\nChaincode\n\n\nPOST /chaincode\n\n\n\n\n\n\nNetwork\n\n\nGET /network/peers\n\n\nRegistrar\n\n\nPOST /registrar\n\n\nDELETE /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}/ecert\n\n\nGET /registrar/{enrollmentID}/tcert\n\n\nTransactions\n\n\nGET /transactions/{UUID}\n\n\n\n\n\n\n\n\nBlock\n\n\n\n\nGET /chain/blocks/{Block}\n\n\n\n\nUse the Block API to retrieve the contents of various blocks from the blockchain. The returned Block message structure is defined inside \nfabric.proto\n.\n\n\nmessage Block {\n    uint32 version = 1;\n    google.protobuf.Timestamp Timestamp = 2;\n    repeated Transaction transactions = 3;\n    bytes stateHash = 4;\n    bytes previousBlockHash = 5;\n}\n\n\n\n\nBlockchain\n\n\n\n\nGET /chain\n\n\n\n\nUse the Chain API to retrieve the current state of the blockchain. The returned BlockchainInfo message is defined inside \nfabric.proto\n.\n\n\nmessage BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}\n\n\n\n\nDevops [DEPRECATED]\n\n\n\n\nPOST /devops/deploy\n\n\nPOST /devops/invoke\n\n\nPOST /devops/query\n\n\n\n\n[DEPRECATED] The /devops endpoints have been deprecated and are superseded by the \n/chaincode\n endpoint. Please use the \n/chaincode\n endpoint to deploy, invoke, and query a chaincode. [DEPRECATED]\n\n\nUse the Devops APIs to deploy, invoke, and query a chaincode. The required \nChaincodeSpec\n and \nChaincodeInvocationSpec\n payloads are defined in \nchaincode.proto\n.\n\n\nmessage ChaincodeSpec {\n\n    enum Type {\n        UNDEFINED = 0;\n        GOLANG = 1;\n        NODE = 2;\n    }\n\n    Type type = 1;\n    ChaincodeID chaincodeID = 2;\n    ChaincodeInput ctorMsg = 3;\n    int32 timeout = 4;\n    string secureContext = 5;\n    ConfidentialityLevel confidentialityLevel = 6;\n}\n\n\n\n\nmessage ChaincodeInvocationSpec {\n    ChaincodeSpec chaincodeSpec = 1;\n    //ChaincodeInput message = 2;\n}\n\n\n\n\nNote:\n The deploy transaction requires a 'path' parameter to locate the chaincode source-code in the file system, build it, and deploy it to the validating peers. On the other hand, invoke and query transactions require a 'name' parameter to reference the chaincode that has already been deployed. These 'path' and 'name' parameters are specified in the ChaincodeID, defined in \nchaincode.proto\n. The only exception to the aforementioned rule is when the peer is running in chaincode development mode (as opposed to production mode), i.e. the user starts the peer with \n--peer-chaincodedev\n and runs the chaincode manually in a separate terminal window. In that case, the deploy transaction requires a 'name' parameter that is specified by the end user.\n\n\nmessage ChaincodeID {\n    //deploy transaction will use the path\n    string path = 1;\n\n    //all other requests will use the name (really a hashcode) generated by\n    //the deploy transaction\n    string name = 2;\n}\n\n\n\n\nAn example of a valid ChaincodeSpec message for a deployment transaction is shown below. The 'path' parameter specifies the location of the chaincode in the filesystem. Eventually, we imagine that the 'path' will represent a location on GitHub.\n\n\n{\n    \ntype\n: \nGOLANG\n,\n    \nchaincodeID\n:{\n        \npath\n:\ngithub.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n100\n, \nb\n, \n200\n]\n    }\n  }\n\n\n\n\nAn example of a valid ChaincodeInvocationSpec message for an invocation transaction is shown below. Consult \nchaincode.proto\n for more information.\n\n\n{\n  \nchaincodeSpec\n:{\n      \ntype\n: \nGOLANG\n,\n      \nchaincodeID\n:{\n          \nname\n:\nmycc\n\n      },\n      \nctorMsg\n:{\n          \nfunction\n:\ninvoke\n,\n          \nargs\n:[\na\n, \nb\n, \n10\n]\n      }\n  }\n}\n\n\n\n\nWith security enabled, modify each of the above payloads to include the secureContext element, passing the enrollmentID of a logged in user as follows:\n\n\n{\n  \nchaincodeSpec\n:{\n      \ntype\n: \nGOLANG\n,\n      \nchaincodeID\n:{\n          \nname\n:\nmycc\n\n      },\n      \nctorMsg\n:{\n          \nfunction\n:\ninvoke\n,\n          \nargs\n:[\na\n, \nb\n, \n10\n]\n      },\n      \nsecureContext\n: \njim\n\n  }\n}\n\n\n\n\nNote:\n The deployment transaction will take a little time as the docker image is being created.\n\n\nThe response to a deploy request is either a message containing a confirmation of successful execution or an error, containing a reason for the failure. The response to a successful deployment request also contains the assigned chaincode name (hash), which is to be used in subsequent invocation and query transactions. An example is below:\n\n\n{\n    \nOK\n: \nSuccessfully deployed chainCode.\n,\n    \nmessage\n: \n3940678a8dff854c5ca4365fe0e29771edccb16b2103578c9d9207fea56b10559b43ff5c3025e68917f5a959f2a121d6b19da573016401d9a028b4211e10b20a\n\n}\n\n\n\n\nThe response to an invoke request is either a message containing a confirmation of successful execution or an error, containing a reason for the failure. The response to an invoke request also contains the transaction identifier (UUID). An example is below:\n\n\n{\n    \nOK\n: \nSuccessfully invoked chainCode.\n,\n    \nmessage\n: \n1ca30d0c-0153-46b4-8826-26dc7cfff852\n\n}\n\n\n\n\nThe response to a successful query request depends on the chaincode implementation. It may contain a string formatted value of a state variable, any string message, or not have an output. An example is below:\n\n\n{\n    \nOK\n: \n80\n\n}\n\n\n\n\n\nChaincode\n\n\n\n\nPOST /chaincode\n\n\n\n\nUse the /chaincode endpoint to deploy, invoke, and query a target chaincode. This endpoint supersedes the \n/devops\n endpoints and should be used for all chaincode operations. This service endpoint implements the \nJSON RPC 2.0 specification\n with the payload identifying the desired chaincode operation within the \nmethod\n field. The supported methods are \ndeploy\n, \ninvoke\n, and \nquery\n.\n\n\nThe /chaincode endpoint implements the \nJSON RPC 2.0 specification\n and as such, must have the required fields of \njsonrpc\n, \nmethod\n, and in our case \nparams\n supplied within the payload. The client should also add the \nid\n element within the payload if they wish to receive a response to the request. If the \nid\n element is missing from the request payload, the request is assumed to be a notification and the server will not produce a response.\n\n\nThe following sample payloads may be used to deploy, invoke, and query a sample chaincode. To deploy a chaincode, supply the \nChaincodeSpec\n identifying the chaincode to deploy within the request payload.\n\n\nChaincode Deployment Request without security enabled:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: 1,\n    \nchaincodeID\n:{\n        \npath\n:\ngithub.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n1000\n, \nb\n, \n2000\n]\n    }\n  },\n  \nid\n: 1\n}\n\n\n\n\nTo deploy a chaincode with security enabled, supply the \nsecureContext\n element containing the registrationID of a registered and logged in user together with the payload from above.\n\n\nChaincode Deployment Request with security enabled (add \nsecureContext\n element):\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: 1,\n    \nchaincodeID\n:{\n        \npath\n:\ngithub.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n1000\n, \nb\n, \n2000\n]\n    },\n    \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: 1\n}\n\n\n\n\nThe response to a chaincode deployment request will contain a \nstatus\n element confirming successful completion of the request. The response to a successful deployment request will likewise contain the generated chaincode hash which must be used in subsequent invocation and query requests sent to this chaincode.\n\n\nChaincode Deployment Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n    },\n    \nid\n: 1\n}\n\n\n\n\nTo invoke a chaincode, supply the \nChaincodeSpec\n identifying the chaincode to invoke within the request payload. Note the chaincode \nname\n field, which is the hash returned from the deployment request.\n\n\nChaincode Invocation Request without security enabled:\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\ninvoke\n,\n         \nargs\n:[\na\n, \nb\n, \n100\n]\n      }\n  },\n  \nid\n: 3\n}\n\n\n\n\nTo invoke a chaincode with security enabled, supply the \nsecureContext\n element containing the registrationID of a registered and logged in user together with the payload from above.\n\n\nChaincode Invocation Request with security enabled (add \nsecureContext\n element):\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\ninvoke\n,\n         \nargs\n:[\na\n, \nb\n, \n100\n]\n      },\n      \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: 3\n}\n\n\n\n\nThe response to a chaincode invocation request will contain a \nstatus\n element confirming successful completion of the request. The response will likewise contain the transaction id number for that specific transaction. The client may use the returned transaction id number to check on the status of the transaction after it has been submitted to the system, as the transaction execution is asynchronous.\n\n\nChaincode Invocation Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n5a4540e5-902b-422d-a6ab-e70ab36a2e6d\n\n    },\n    \nid\n: 3\n}\n\n\n\n\nTo query a chaincode, supply the \nChaincodeSpec\n identifying the chaincode to query within the request payload. Note the chaincode \nname\n field, which is the hash returned from the deployment request.\n\n\nChaincode Query Request without security enabled:\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\nquery\n,\n         \nargs\n:[\na\n]\n      }\n  },\n  \nid\n: 5\n}\n\n\n\n\nTo query a chaincode with security enabled, supply the \nsecureContext\n element containing the registrationID of a registered and logged in user together with the payload from above.\n\n\nChaincode Query Request with security enabled (add \nsecureContext\n element):\n\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\n52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\nquery\n,\n         \nargs\n:[\na\n]\n      },\n      \nsecureContext\n: \nlukas\n\n  },\n  \nid\n: 5\n}\n\n\n\n\nThe response to a chaincode query request will contain a \nstatus\n element confirming successful completion of the request. The response will likewise contain an appropriate \nmessage\n, as defined by the chaincode. The \nmessage\n received depends on the chaincode implementation and may be a string or number indicating the value of a specific chaincode variable.\n\n\nChaincode Query Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n-400\n\n    },\n    \nid\n: 5\n}\n\n\n\n\nNetwork\n\n\n\n\nGET /network/peers\n\n\n\n\nUse the Network APIs to retrieve information about the network of peer nodes comprising the blockchain network.\n\n\nThe /network/peers endpoint returns a list of all existing network connections for the target peer node. The list includes both validating and non-validating peers. The list of peers is returned as type \nPeersMessage\n, containing an array of \nPeerEndpoint\n.\n\n\nmessage PeersMessage {\n    repeated PeerEndpoint peers = 1;\n}\n\n\n\n\nmessage PeerEndpoint {\n    PeerID ID = 1;\n    string address = 2;\n    enum Type {\n      UNDEFINED = 0;\n      VALIDATOR = 1;\n      NON_VALIDATOR = 2;\n    }\n    Type type = 3;\n    bytes pkiID = 4;\n}\n\n\n\n\nmessage PeerID {\n    string name = 1;\n}\n\n\n\n\nRegistrar\n\n\n\n\nPOST /registrar\n\n\nDELETE /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}\n\n\nGET /registrar/{enrollmentID}/ecert\n\n\nGET /registrar/{enrollmentID}/tcert\n\n\n\n\nUse the Registrar APIs to manage end user registration with the CA. These API endpoints are used to register a user with the CA, determine whether a given user is registered, and to remove any login tokens for a target user preventing them from executing any further transactions. The Registrar APIs are also used to retrieve user enrollment and transaction certificates from the system.\n\n\nThe /registrar endpoint is used to register a user with the CA. The required Secret payload is defined in \ndevops.proto\n.\n\n\nmessage Secret {\n    string enrollId = 1;\n    string enrollSecret = 2;\n}\n\n\n\n\nThe response to the registration request is either a confirmation of successful registration or an error, containing a reason for the failure. An example of a valid Secret message to register user 'lukas' is shown below.\n\n\n{\n  \nenrollId\n: \nlukas\n,\n  \nenrollSecret\n: \nNPKYL39uKbkj\n\n}\n\n\n\n\nThe GET /registrar/{enrollmentID} endpoint is used to confirm whether a given user is registered with the CA. If so, a confirmation will be returned. Otherwise, an authorization error will result.\n\n\nThe DELETE /registrar/{enrollmentID} endpoint is used to delete login tokens for a target user. If the login tokens are deleted successfully, a confirmation will be returned. Otherwise, an authorization error will result. No payload is required for this endpoint. Note, that registration with the CA is a one time process for a given user, utilizing a single-use registrationID and registrationPW. If the user registration is deleted through this API, the user will not be able to register with the CA a second time.\n\n\nThe GET /registrar/{enrollmentID}/ecert endpoint is used to retrieve the enrollment certificate of a given user from local storage. If the target user has already registered with the CA, the response will include a URL-encoded version of the enrollment certificate. If the target user has not yet registered, an error will be returned. If the client wishes to use the returned enrollment certificate after retrieval, keep in mind that it must be URL-decoded. This can be accomplished with the QueryUnescape method in the \"net/url\" package.\n\n\nThe /registrar/{enrollmentID}/tcert endpoint retrieves the transaction certificates for a given user that has registered with the certificate authority. If the user has registered, a confirmation message will be returned containing an array of URL-encoded transaction certificates. Otherwise, an error will result. The desired number of transaction certificates is specified with the optional 'count' query parameter. The default number of returned transaction certificates is 1; and 500 is the maximum number of certificates that can be retrieved with a single request. If the client wishes to use the returned transaction certificates after retrieval, keep in mind that they must be URL-decoded. This can be accomplished with the QueryUnescape method in the \"net/url\" package.\n\n\nTransactions\n\n\n\n\nGET /transactions/{UUID}\n\n\n\n\nUse the /transactions/{UUID} endpoint to retrieve an individual transaction matching the UUID from the blockchain. The returned transaction message is defined inside \nfabric.proto\n.\n\n\nmessage Transaction {\n    enum Type {\n        UNDEFINED = 0;\n        CHAINCODE_DEPLOY = 1;\n        CHAINCODE_INVOKE = 2;\n        CHAINCODE_QUERY = 3;\n        CHAINCODE_TERMINATE = 4;\n    }\n    Type type = 1;\n    bytes chaincodeID = 2;\n    bytes payload = 3;\n    string uuid = 4;\n    google.protobuf.Timestamp timestamp = 5;\n\n    ConfidentialityLevel confidentialityLevel = 6;\n    bytes nonce = 7;\n\n    bytes cert = 8;\n    bytes signature = 9;\n}\n\n\n\n\nFor additional information on the REST endpoints and more detailed examples, please see the \nprotocol specification\n section 6.2 on the REST API.\n\n\nTo set up Swagger-UI\n\n\nSwagger\n is a convenient package that allows you to describe and document your REST API in a single file. The REST API is described in \nrest_api.json\n. To interact with the peer node directly through the Swagger-UI, you can upload the available Swagger definition to the \nSwagger service\n. Alternatively, you may set up a Swagger installation on your machine by following the instructions below.\n\n\n\n\n\n\nYou can use Node.js to serve up the rest_api.json locally. To do so, make sure you have Node.js installed on your local machine. If it is not installed, please download the \nNode.js\n package and install it.\n\n\n\n\n\n\nInstall the Node.js http-server package with the command below:\n\n\nnpm install http-server -g\n\n\n\n\n\n\nStart up an http-server on your local machine to serve up the rest_api.json.\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\nhttp-server -a 0.0.0.0 -p 5554 --cors\n\n\n\n\n\n\nMake sure that you are successfully able to access the API description document within your browser at this link:\n\n\nhttp://localhost:5554/rest_api.json\n\n\n\n\n\n\nDownload the Swagger-UI package with the following command:\n\n\ngit clone https://github.com/swagger-api/swagger-ui.git\n\n\n\n\n\n\nNavigate to the /swagger-ui/dist directory and click on the index.html file to bring up the Swagger-UI interface inside your browser.\n\n\n\n\n\n\nStart up the peer node with no connections to a leader or validator as follows.\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric\nbuild/bin/peer node start\n\n\n\n\n\n\nIf you need to construct a test blockchain on the local peer node, run the the TestServerOpenchain_API_GetBlockCount test implemented inside \napi_test.go\n. This test will create a blockchain with 5 blocks. Subsequently restart the peer process.\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\ngo test -v -run TestServerOpenchain_API_GetBlockCount\n\n\n\n\n\n\nGo back to the Swagger-UI interface inside your browser and load the API description. You should now be able to issue queries against the pre-built blockchain directly from Swagger.\n\n\n\n\n\n\nNode.js Application\n\n\nYou can interface with the peer process from a Node.js application. One way to accomplish that is by relying on the Swagger API description document, \nrest_api.json\n and the \nswagger-js plugin\n. Another way to accomplish that relies upon the IBM Blockchain \nJS SDK\n. Use the approach that you find the most convenient.\n\n\nUsing Swagger JS Plugin\n\n\n\n\nDemonstrates interfacing with a peer node from a Node.js application.\n\n\nUtilizes the Node.js swagger-js plugin: https://github.com/swagger-api/swagger-js\n\n\n\n\nTo run:\n\n\n\n\n\n\nBuild and install the \nfabric core\n.\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric\nmake peer\n\n\n\n\n\n\nRun a local peer node only (not a complete network) with:\n\n\nbuild/bin/peer node start\n\n\n\n\n\n\nSet up a test blockchain data structure (with 5 blocks only) by running a test from within Vagrant as follows. Subsequently restart the peer process.\n\n\ncd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\ngo test -v -run TestServerOpenchain_API_GetBlockCount\n\n\n\n\n\n\nStart up an http-server on your local machine to serve up the rest_api.json.\n\n\nnpm install http-server -g\ncd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\nhttp-server -a 0.0.0.0 -p 5554 --cors\n\n\n\n\n\n\nDownload and unzip \nSample_1.zip\n\n\nunzip Sample_1.zip -d Sample_1\ncd Sample_1\n\n\n\n\n\n\nUpdate the api_url variable within \nopenchain.js\n to the appropriate URL if it is not already the default\n\n\nvar api_url = 'http://localhost:5554/rest_api.json';\n\n\n\n\n\n\nRun the Node.js app\n\n\nnode ./openchain.js\n\n\n\n\n\n\nYou will observe several responses on the console and the program will appear to hang for a few moments at the end. This is expected, as is it waiting for the invocation transaction to complete in order to then execute a query. You can take a look at the sample output of the program inside the 'openchain_test' file located in the Sample_1 directory.\n\n\nMarbles Demo Application\n\n\n\n\nDemonstrates an alternative way of interfacing with a peer node from a Node.js app.\n\n\nDemonstrates deploying a Blockchain application as a Bluemix service.\n\n\n\n\nHold on to your hats everyone, this application is going to demonstrate transferring marbles between two users leveraging IBM Blockchain. We are going to do this in Node.js and a bit of GoLang. The backend of this application will be the GoLang code running in our blockchain network. The chaincode itself will create a marble by storing it to the chaincode state. The chaincode itself is able to store data as a string in a key/value pair setup. Thus we will stringify JSON objects to store more complex structures.\n\n\nFor more inforation on the IBM Blockchain marbles demo, set-up, and instructions, please visit \nthis page\n.\n\n\nCommercial Paper Demo Application\n\n\n\n\nDemonstrates an alternative way of interfacing with a peer node from a Node.js app.\n\n\nDemonstrates deploying a Blockchain application as a Bluemix service.\n\n\n\n\nThis application is a demonstration of how a commercial paper trading network might be implemented on IBM Blockchain. The components of the demo are:\n\n\n\n\nAn interface for creating new users on the network.\n\n\nAn interface for creating new commercial papers to trade.\n\n\nA Trade Center for buying and selling existing trades.\n\n\nA special interface just for auditors of the network to examine trades.\n\n\n\n\nFor more inforation on the IBM Blockchain commercial paper demo, set-up, and instructions, please visit \nthis page\n.", 
            "title": "CoreAPI"
        }, 
        {
            "location": "/API/CoreAPI/#apis-cli-rest-and-nodejs", 
            "text": "", 
            "title": "APIs - CLI, REST, and Node.js"
        }, 
        {
            "location": "/API/CoreAPI/#overview", 
            "text": "This document covers the available APIs for interacting with a peer node. Three interface choices are provided:   CLI  REST API  Node.js Application  Using Swagger JS Plugin  Marbles Demo Application  Commercial Paper Demo Application   Note:  If you are working with APIs with security enabled, please review the  security setup instructions  before proceeding.", 
            "title": "Overview"
        }, 
        {
            "location": "/API/CoreAPI/#cli", 
            "text": "To view the currently available CLI commands, execute the following:  cd /opt/gopath/src/github.com/hyperledger/fabric\nbuild/bin/peer  You will see output similar to the example below ( NOTE:  rootcommand below is hardcoded in  main.go . Currently, the build will create a  peer  executable file).      Usage:\n      peer [command]\n\n    Available Commands:\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level= : Default logging level and overrides, see core.yaml for full syntax\n\n\n    Use  peer [command] --help  for more information about a command.  The  peer  command supports several subcommands, as shown above. To\nfacilitate its use in scripted applications, the  peer  command always\nproduces a non-zero return code in the event of command failure. Upon success,\nmany of the subcommands produce a result on  stdout  as shown in the table\nbelow:     Command  stdout  result in the event of success      node start  N/A    node status  String form of  StatusCode    node stop  String form of  StatusCode    network login  N/A    network list  The list of network connections to the peer node.    chaincode deploy  The chaincode container name (hash) required for subsequent  chaincode invoke  and  chaincode query  commands    chaincode invoke  The transaction ID (UUID)    chaincode query  By default, the query result is formatted as a printable string. Command line options support writing this value as raw bytes (-r, --raw), or formatted as the hexadecimal representation of the raw bytes (-x, --hex). If the query response is empty then nothing is output.", 
            "title": "CLI"
        }, 
        {
            "location": "/API/CoreAPI/#deploy-a-chaincode", 
            "text": "Deploy creates the docker image for the chaincode and subsequently deploys the package to the validating peer. An example is below.  peer chaincode deploy -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'  The response to the chaincode deploy command will contain the chaincode identifier (hash) which will be required on subsequent  chaincode invoke  and  chaincode query  commands in order to identify the deployed chaincode.  With security enabled, modify the command to include the -u parameter passing the username of a logged in user as follows:  peer chaincode deploy -u jim -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'  Note:  If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.", 
            "title": "Deploy a Chaincode"
        }, 
        {
            "location": "/API/CoreAPI/#verify-results", 
            "text": "To verify that the block containing the latest transaction has been added to the blockchain, use the  /chain  REST endpoint from the command line. Target the IP address of either a validating or a non-validating node. In the example below, 172.17.0.2 is the IP address of a validating or a non-validating node and 5000 is the REST interface port defined in  core.yaml .  curl 172.17.0.2:5000/chain  An example of the response is below.  {\n     height :1,\n     currentBlockHash : 4Yc4yCO95wcpWHW2NLFlf76OGURBBxYZMf3yUyvrEXs5TMai9qNKfy9Yn/== \n}  The returned BlockchainInfo message is defined inside  fabric.proto .  message BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}  To verify that a specific block is inside the blockchain, use the  /chain/blocks/{Block}  REST endpoint. Likewise, target the IP address of either a validating or a non-validating node on port 5000.  curl 172.17.0.2:5000/chain/blocks/0  The returned Block message structure is defined inside  fabric.proto .  message Block {\n    uint32 version = 1;\n    google.protobuf.Timestamp timestamp = 2;\n    repeated Transaction transactions = 3;\n    bytes stateHash = 4;\n    bytes previousBlockHash = 5;\n    bytes consensusMetadata = 6;\n    NonHashData nonHashData = 7;\n}  An example of a returned Block structure is below.  {\n     transactions :[{\n         type :1,\n         chaincodeID : {\n             path : github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 \n        },\n         payload : ClwIARJYCk9naXRod... ,\n         uuid : abdcec99-ae5e-415e-a8be-1fca8e38ba71 \n    }],\n     stateHash : PY5YcQRu2g1vjiAqHHshoAhnq8CFP3MqzMslcEAJbnmXDtD+LopmkrUHrPMOGSF5UD7Kxqhbg1XUjmQAi84paw== \n}  For additional information on the available CLI commands, please see the  protocol specification  section 6.3 on CLI.", 
            "title": "Verify Results"
        }, 
        {
            "location": "/API/CoreAPI/#rest-api", 
            "text": "You can work with the REST API through any tool of your choice. For example, the curl command line utility or a browser based client such as the Firefox Rest Client or Chrome Postman. You can likewise trigger REST requests directly through  Swagger . You can utilize the Swagger service directly or, if you prefer, you can set up Swagger locally by following the instructions  here .  Note:  The default REST interface port is 5000. It can be configured in  core.yaml  using the  rest.address  property. If using Vagrant, the REST port mapping is defined in  Vagrantfile .  Note on constructing a test blockchain  If you want to test the REST API locally, construct a test blockchain by running the TestServerOpenchain_API_GetBlockCount test implemented inside  api_test.go . This test will create a test blockchain with 5 blocks. Subsequently restart the peer process.      cd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\n    go test -v -run TestServerOpenchain_API_GetBlockCount", 
            "title": "REST API"
        }, 
        {
            "location": "/API/CoreAPI/#rest-endpoints", 
            "text": "To learn about the REST API through Swagger, please take a look at the Swagger document  here . You can upload the service description file to the Swagger service directly or, if you prefer, you can set up Swagger locally by following the instructions  here .   Block  GET /chain/blocks/{Block}  Blockchain  GET /chain  Devops  [DEPRECATED]  POST /devops/deploy  POST /devops/invoke  POST /devops/query  Chaincode  POST /chaincode    Network  GET /network/peers  Registrar  POST /registrar  DELETE /registrar/{enrollmentID}  GET /registrar/{enrollmentID}  GET /registrar/{enrollmentID}/ecert  GET /registrar/{enrollmentID}/tcert  Transactions  GET /transactions/{UUID}", 
            "title": "REST Endpoints"
        }, 
        {
            "location": "/API/CoreAPI/#block", 
            "text": "GET /chain/blocks/{Block}   Use the Block API to retrieve the contents of various blocks from the blockchain. The returned Block message structure is defined inside  fabric.proto .  message Block {\n    uint32 version = 1;\n    google.protobuf.Timestamp Timestamp = 2;\n    repeated Transaction transactions = 3;\n    bytes stateHash = 4;\n    bytes previousBlockHash = 5;\n}", 
            "title": "Block"
        }, 
        {
            "location": "/API/CoreAPI/#blockchain", 
            "text": "GET /chain   Use the Chain API to retrieve the current state of the blockchain. The returned BlockchainInfo message is defined inside  fabric.proto .  message BlockchainInfo {\n    uint64 height = 1;\n    bytes currentBlockHash = 2;\n    bytes previousBlockHash = 3;\n}", 
            "title": "Blockchain"
        }, 
        {
            "location": "/API/CoreAPI/#devops-deprecated", 
            "text": "POST /devops/deploy  POST /devops/invoke  POST /devops/query   [DEPRECATED] The /devops endpoints have been deprecated and are superseded by the  /chaincode  endpoint. Please use the  /chaincode  endpoint to deploy, invoke, and query a chaincode. [DEPRECATED]  Use the Devops APIs to deploy, invoke, and query a chaincode. The required  ChaincodeSpec  and  ChaincodeInvocationSpec  payloads are defined in  chaincode.proto .  message ChaincodeSpec {\n\n    enum Type {\n        UNDEFINED = 0;\n        GOLANG = 1;\n        NODE = 2;\n    }\n\n    Type type = 1;\n    ChaincodeID chaincodeID = 2;\n    ChaincodeInput ctorMsg = 3;\n    int32 timeout = 4;\n    string secureContext = 5;\n    ConfidentialityLevel confidentialityLevel = 6;\n}  message ChaincodeInvocationSpec {\n    ChaincodeSpec chaincodeSpec = 1;\n    //ChaincodeInput message = 2;\n}  Note:  The deploy transaction requires a 'path' parameter to locate the chaincode source-code in the file system, build it, and deploy it to the validating peers. On the other hand, invoke and query transactions require a 'name' parameter to reference the chaincode that has already been deployed. These 'path' and 'name' parameters are specified in the ChaincodeID, defined in  chaincode.proto . The only exception to the aforementioned rule is when the peer is running in chaincode development mode (as opposed to production mode), i.e. the user starts the peer with  --peer-chaincodedev  and runs the chaincode manually in a separate terminal window. In that case, the deploy transaction requires a 'name' parameter that is specified by the end user.  message ChaincodeID {\n    //deploy transaction will use the path\n    string path = 1;\n\n    //all other requests will use the name (really a hashcode) generated by\n    //the deploy transaction\n    string name = 2;\n}  An example of a valid ChaincodeSpec message for a deployment transaction is shown below. The 'path' parameter specifies the location of the chaincode in the filesystem. Eventually, we imagine that the 'path' will represent a location on GitHub.  {\n     type :  GOLANG ,\n     chaincodeID :{\n         path : github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  100 ,  b ,  200 ]\n    }\n  }  An example of a valid ChaincodeInvocationSpec message for an invocation transaction is shown below. Consult  chaincode.proto  for more information.  {\n   chaincodeSpec :{\n       type :  GOLANG ,\n       chaincodeID :{\n           name : mycc \n      },\n       ctorMsg :{\n           function : invoke ,\n           args :[ a ,  b ,  10 ]\n      }\n  }\n}  With security enabled, modify each of the above payloads to include the secureContext element, passing the enrollmentID of a logged in user as follows:  {\n   chaincodeSpec :{\n       type :  GOLANG ,\n       chaincodeID :{\n           name : mycc \n      },\n       ctorMsg :{\n           function : invoke ,\n           args :[ a ,  b ,  10 ]\n      },\n       secureContext :  jim \n  }\n}  Note:  The deployment transaction will take a little time as the docker image is being created.  The response to a deploy request is either a message containing a confirmation of successful execution or an error, containing a reason for the failure. The response to a successful deployment request also contains the assigned chaincode name (hash), which is to be used in subsequent invocation and query transactions. An example is below:  {\n     OK :  Successfully deployed chainCode. ,\n     message :  3940678a8dff854c5ca4365fe0e29771edccb16b2103578c9d9207fea56b10559b43ff5c3025e68917f5a959f2a121d6b19da573016401d9a028b4211e10b20a \n}  The response to an invoke request is either a message containing a confirmation of successful execution or an error, containing a reason for the failure. The response to an invoke request also contains the transaction identifier (UUID). An example is below:  {\n     OK :  Successfully invoked chainCode. ,\n     message :  1ca30d0c-0153-46b4-8826-26dc7cfff852 \n}  The response to a successful query request depends on the chaincode implementation. It may contain a string formatted value of a state variable, any string message, or not have an output. An example is below:  {\n     OK :  80 \n}", 
            "title": "Devops [DEPRECATED]"
        }, 
        {
            "location": "/API/CoreAPI/#chaincode", 
            "text": "POST /chaincode   Use the /chaincode endpoint to deploy, invoke, and query a target chaincode. This endpoint supersedes the  /devops  endpoints and should be used for all chaincode operations. This service endpoint implements the  JSON RPC 2.0 specification  with the payload identifying the desired chaincode operation within the  method  field. The supported methods are  deploy ,  invoke , and  query .  The /chaincode endpoint implements the  JSON RPC 2.0 specification  and as such, must have the required fields of  jsonrpc ,  method , and in our case  params  supplied within the payload. The client should also add the  id  element within the payload if they wish to receive a response to the request. If the  id  element is missing from the request payload, the request is assumed to be a notification and the server will not produce a response.  The following sample payloads may be used to deploy, invoke, and query a sample chaincode. To deploy a chaincode, supply the  ChaincodeSpec  identifying the chaincode to deploy within the request payload.  Chaincode Deployment Request without security enabled:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type : 1,\n     chaincodeID :{\n         path : github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  1000 ,  b ,  2000 ]\n    }\n  },\n   id : 1\n}  To deploy a chaincode with security enabled, supply the  secureContext  element containing the registrationID of a registered and logged in user together with the payload from above.  Chaincode Deployment Request with security enabled (add  secureContext  element):  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type : 1,\n     chaincodeID :{\n         path : github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  1000 ,  b ,  2000 ]\n    },\n     secureContext :  lukas \n  },\n   id : 1\n}  The response to a chaincode deployment request will contain a  status  element confirming successful completion of the request. The response to a successful deployment request will likewise contain the generated chaincode hash which must be used in subsequent invocation and query requests sent to this chaincode.  Chaincode Deployment Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n    },\n     id : 1\n}  To invoke a chaincode, supply the  ChaincodeSpec  identifying the chaincode to invoke within the request payload. Note the chaincode  name  field, which is the hash returned from the deployment request.  Chaincode Invocation Request without security enabled:  {\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n      },\n       ctorMsg : {\n          function : invoke ,\n          args :[ a ,  b ,  100 ]\n      }\n  },\n   id : 3\n}  To invoke a chaincode with security enabled, supply the  secureContext  element containing the registrationID of a registered and logged in user together with the payload from above.  Chaincode Invocation Request with security enabled (add  secureContext  element):  {\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n      },\n       ctorMsg : {\n          function : invoke ,\n          args :[ a ,  b ,  100 ]\n      },\n       secureContext :  lukas \n  },\n   id : 3\n}  The response to a chaincode invocation request will contain a  status  element confirming successful completion of the request. The response will likewise contain the transaction id number for that specific transaction. The client may use the returned transaction id number to check on the status of the transaction after it has been submitted to the system, as the transaction execution is asynchronous.  Chaincode Invocation Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  5a4540e5-902b-422d-a6ab-e70ab36a2e6d \n    },\n     id : 3\n}  To query a chaincode, supply the  ChaincodeSpec  identifying the chaincode to query within the request payload. Note the chaincode  name  field, which is the hash returned from the deployment request.  Chaincode Query Request without security enabled:  {\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n      },\n       ctorMsg : {\n          function : query ,\n          args :[ a ]\n      }\n  },\n   id : 5\n}  To query a chaincode with security enabled, supply the  secureContext  element containing the registrationID of a registered and logged in user together with the payload from above.  Chaincode Query Request with security enabled (add  secureContext  element):  {\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : 52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586 \n      },\n       ctorMsg : {\n          function : query ,\n          args :[ a ]\n      },\n       secureContext :  lukas \n  },\n   id : 5\n}  The response to a chaincode query request will contain a  status  element confirming successful completion of the request. The response will likewise contain an appropriate  message , as defined by the chaincode. The  message  received depends on the chaincode implementation and may be a string or number indicating the value of a specific chaincode variable.  Chaincode Query Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  -400 \n    },\n     id : 5\n}", 
            "title": "Chaincode"
        }, 
        {
            "location": "/API/CoreAPI/#network", 
            "text": "GET /network/peers   Use the Network APIs to retrieve information about the network of peer nodes comprising the blockchain network.  The /network/peers endpoint returns a list of all existing network connections for the target peer node. The list includes both validating and non-validating peers. The list of peers is returned as type  PeersMessage , containing an array of  PeerEndpoint .  message PeersMessage {\n    repeated PeerEndpoint peers = 1;\n}  message PeerEndpoint {\n    PeerID ID = 1;\n    string address = 2;\n    enum Type {\n      UNDEFINED = 0;\n      VALIDATOR = 1;\n      NON_VALIDATOR = 2;\n    }\n    Type type = 3;\n    bytes pkiID = 4;\n}  message PeerID {\n    string name = 1;\n}", 
            "title": "Network"
        }, 
        {
            "location": "/API/CoreAPI/#registrar", 
            "text": "POST /registrar  DELETE /registrar/{enrollmentID}  GET /registrar/{enrollmentID}  GET /registrar/{enrollmentID}/ecert  GET /registrar/{enrollmentID}/tcert   Use the Registrar APIs to manage end user registration with the CA. These API endpoints are used to register a user with the CA, determine whether a given user is registered, and to remove any login tokens for a target user preventing them from executing any further transactions. The Registrar APIs are also used to retrieve user enrollment and transaction certificates from the system.  The /registrar endpoint is used to register a user with the CA. The required Secret payload is defined in  devops.proto .  message Secret {\n    string enrollId = 1;\n    string enrollSecret = 2;\n}  The response to the registration request is either a confirmation of successful registration or an error, containing a reason for the failure. An example of a valid Secret message to register user 'lukas' is shown below.  {\n   enrollId :  lukas ,\n   enrollSecret :  NPKYL39uKbkj \n}  The GET /registrar/{enrollmentID} endpoint is used to confirm whether a given user is registered with the CA. If so, a confirmation will be returned. Otherwise, an authorization error will result.  The DELETE /registrar/{enrollmentID} endpoint is used to delete login tokens for a target user. If the login tokens are deleted successfully, a confirmation will be returned. Otherwise, an authorization error will result. No payload is required for this endpoint. Note, that registration with the CA is a one time process for a given user, utilizing a single-use registrationID and registrationPW. If the user registration is deleted through this API, the user will not be able to register with the CA a second time.  The GET /registrar/{enrollmentID}/ecert endpoint is used to retrieve the enrollment certificate of a given user from local storage. If the target user has already registered with the CA, the response will include a URL-encoded version of the enrollment certificate. If the target user has not yet registered, an error will be returned. If the client wishes to use the returned enrollment certificate after retrieval, keep in mind that it must be URL-decoded. This can be accomplished with the QueryUnescape method in the \"net/url\" package.  The /registrar/{enrollmentID}/tcert endpoint retrieves the transaction certificates for a given user that has registered with the certificate authority. If the user has registered, a confirmation message will be returned containing an array of URL-encoded transaction certificates. Otherwise, an error will result. The desired number of transaction certificates is specified with the optional 'count' query parameter. The default number of returned transaction certificates is 1; and 500 is the maximum number of certificates that can be retrieved with a single request. If the client wishes to use the returned transaction certificates after retrieval, keep in mind that they must be URL-decoded. This can be accomplished with the QueryUnescape method in the \"net/url\" package.", 
            "title": "Registrar"
        }, 
        {
            "location": "/API/CoreAPI/#transactions", 
            "text": "GET /transactions/{UUID}   Use the /transactions/{UUID} endpoint to retrieve an individual transaction matching the UUID from the blockchain. The returned transaction message is defined inside  fabric.proto .  message Transaction {\n    enum Type {\n        UNDEFINED = 0;\n        CHAINCODE_DEPLOY = 1;\n        CHAINCODE_INVOKE = 2;\n        CHAINCODE_QUERY = 3;\n        CHAINCODE_TERMINATE = 4;\n    }\n    Type type = 1;\n    bytes chaincodeID = 2;\n    bytes payload = 3;\n    string uuid = 4;\n    google.protobuf.Timestamp timestamp = 5;\n\n    ConfidentialityLevel confidentialityLevel = 6;\n    bytes nonce = 7;\n\n    bytes cert = 8;\n    bytes signature = 9;\n}  For additional information on the REST endpoints and more detailed examples, please see the  protocol specification  section 6.2 on the REST API.", 
            "title": "Transactions"
        }, 
        {
            "location": "/API/CoreAPI/#to-set-up-swagger-ui", 
            "text": "Swagger  is a convenient package that allows you to describe and document your REST API in a single file. The REST API is described in  rest_api.json . To interact with the peer node directly through the Swagger-UI, you can upload the available Swagger definition to the  Swagger service . Alternatively, you may set up a Swagger installation on your machine by following the instructions below.    You can use Node.js to serve up the rest_api.json locally. To do so, make sure you have Node.js installed on your local machine. If it is not installed, please download the  Node.js  package and install it.    Install the Node.js http-server package with the command below:  npm install http-server -g    Start up an http-server on your local machine to serve up the rest_api.json.  cd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\nhttp-server -a 0.0.0.0 -p 5554 --cors    Make sure that you are successfully able to access the API description document within your browser at this link:  http://localhost:5554/rest_api.json    Download the Swagger-UI package with the following command:  git clone https://github.com/swagger-api/swagger-ui.git    Navigate to the /swagger-ui/dist directory and click on the index.html file to bring up the Swagger-UI interface inside your browser.    Start up the peer node with no connections to a leader or validator as follows.  cd /opt/gopath/src/github.com/hyperledger/fabric\nbuild/bin/peer node start    If you need to construct a test blockchain on the local peer node, run the the TestServerOpenchain_API_GetBlockCount test implemented inside  api_test.go . This test will create a blockchain with 5 blocks. Subsequently restart the peer process.  cd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\ngo test -v -run TestServerOpenchain_API_GetBlockCount    Go back to the Swagger-UI interface inside your browser and load the API description. You should now be able to issue queries against the pre-built blockchain directly from Swagger.", 
            "title": "To set up Swagger-UI"
        }, 
        {
            "location": "/API/CoreAPI/#nodejs-application", 
            "text": "You can interface with the peer process from a Node.js application. One way to accomplish that is by relying on the Swagger API description document,  rest_api.json  and the  swagger-js plugin . Another way to accomplish that relies upon the IBM Blockchain  JS SDK . Use the approach that you find the most convenient.", 
            "title": "Node.js Application"
        }, 
        {
            "location": "/API/CoreAPI/#using-swagger-js-plugin", 
            "text": "Demonstrates interfacing with a peer node from a Node.js application.  Utilizes the Node.js swagger-js plugin: https://github.com/swagger-api/swagger-js   To run:    Build and install the  fabric core .  cd /opt/gopath/src/github.com/hyperledger/fabric\nmake peer    Run a local peer node only (not a complete network) with:  build/bin/peer node start    Set up a test blockchain data structure (with 5 blocks only) by running a test from within Vagrant as follows. Subsequently restart the peer process.  cd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\ngo test -v -run TestServerOpenchain_API_GetBlockCount    Start up an http-server on your local machine to serve up the rest_api.json.  npm install http-server -g\ncd /opt/gopath/src/github.com/hyperledger/fabric/core/rest\nhttp-server -a 0.0.0.0 -p 5554 --cors    Download and unzip  Sample_1.zip  unzip Sample_1.zip -d Sample_1\ncd Sample_1    Update the api_url variable within  openchain.js  to the appropriate URL if it is not already the default  var api_url = 'http://localhost:5554/rest_api.json';    Run the Node.js app  node ./openchain.js    You will observe several responses on the console and the program will appear to hang for a few moments at the end. This is expected, as is it waiting for the invocation transaction to complete in order to then execute a query. You can take a look at the sample output of the program inside the 'openchain_test' file located in the Sample_1 directory.", 
            "title": "Using Swagger JS Plugin"
        }, 
        {
            "location": "/API/CoreAPI/#marbles-demo-application", 
            "text": "Demonstrates an alternative way of interfacing with a peer node from a Node.js app.  Demonstrates deploying a Blockchain application as a Bluemix service.   Hold on to your hats everyone, this application is going to demonstrate transferring marbles between two users leveraging IBM Blockchain. We are going to do this in Node.js and a bit of GoLang. The backend of this application will be the GoLang code running in our blockchain network. The chaincode itself will create a marble by storing it to the chaincode state. The chaincode itself is able to store data as a string in a key/value pair setup. Thus we will stringify JSON objects to store more complex structures.  For more inforation on the IBM Blockchain marbles demo, set-up, and instructions, please visit  this page .", 
            "title": "Marbles Demo Application"
        }, 
        {
            "location": "/API/CoreAPI/#commercial-paper-demo-application", 
            "text": "Demonstrates an alternative way of interfacing with a peer node from a Node.js app.  Demonstrates deploying a Blockchain application as a Bluemix service.   This application is a demonstration of how a commercial paper trading network might be implemented on IBM Blockchain. The components of the demo are:   An interface for creating new users on the network.  An interface for creating new commercial papers to trade.  A Trade Center for buying and selling existing trades.  A special interface just for auditors of the network to examine trades.   For more inforation on the IBM Blockchain commercial paper demo, set-up, and instructions, please visit  this page .", 
            "title": "Commercial Paper Demo Application"
        }, 
        {
            "location": "/API/MemberServicesAPI/", 
            "text": "Certificate Authority API\n\n\nEach of the CA services is split into two \nGRPC\n interfaces, namely a public one (indicated by a \nP\n suffix) and an administrator one (indicated by an \nA\n suffix).\n\n\nEnrollment Certificate Authority\n\n\nThe administrator interface of the ECA provides the following functions:\n\n\nservice ECAA { // admin\n    rpc RegisterUser(RegisterUserReq) returns (Token);\n    rpc ReadUserSet(ReadUserSetReq) returns (UserSet);\n    rpc RevokeCertificate(ECertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc PublishCRL(ECertCRLReq) returns (CAStatus); // not yet implemented\n}\n\n\n\nThe \nRegisterUser\n function allows you to register a new user by specifiying her name and roles in the \nRegisterUserReq\n structure.  If the user has not be registered before, the ECA registers the new user and returns a unique one-time password, which can be used by the user to request her enrollment certificate pair via the public interface of the ECA.  Otherwise an error is returned.\n\n\nThe \nReadUserSet\n function allows only auditors to retrieve the list of users registered with the blockchain.\n\n\nThe public interface of the ECA provides the following functions:\n\n\nservice ECAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificatePair(ECertCreateReq) returns (ECertCreateResp);\n    rpc ReadCertificatePair(ECertReadReq) returns (CertPair);\n    rpc ReadCertificateByHash(Hash) returns (Cert);\n    rpc RevokeCertificatePair(ECertRevokeReq) returns (CAStatus); // not yet implemented\n}\n\n\n\nThe \nReadCACertificate\n function returns the certificate of the ECA itself.\n\n\nThe \nCreateCertificatePair\n functions allows a user to create and read her enrollment certificate pair.  For this, the user has to do two successive invocations of this functions.  Firstly, both the signature and encryption public keys have to be handed to the ECA together with the one-time password returned by the \nRegisterUser\n function invocation before.  The request has to be signed by the user's private signature key to demonstrate that the user is in possession of the private signature key indeed.  The ECA in return gives the user a challenge encrypted with the user's public encryption key.  The has to decrypt the challenge, thereby demonstrating that she is in possession of the private encryption key indeed, and re-issue the certificate creation request passing the decrypted challenge instead of the one-time password passed in the invocation.  If the challenge has been decrypted correctly, the ECA issues and returns the enrollment certificate pair for the user.\n\n\nThe \nReadCertificatePair\n function allows any user of the blockchain to read the certificate pair of any other user of the blockchain.\n\n\nThe \nReadCertificatePairByHash\n function allows any user of the blockchain to read a certificate from the ECA matching a given hash.\n\n\nTransaction Certificate Authority\n\n\nThe administrator interface of the TCA provides the following functions:\n\n\nservice TCAA { // admin\n    rpc RevokeCertificate(TCertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc RevokeCertificateSet(TCertRevokeSetReq) returns (CAStatus); // not yet implemented\n    rpc PublishCRL(TCertCRLReq) returns (CAStatus); // not yet implemented\n}\n\n\n\nThe public interface of the TCA provides the following functions:\n\n\nservice TCAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificate(TCertCreateReq) returns (TCertCreateResp);\n    rpc CreateCertificateSet(TCertCreateSetReq) returns (TCertCreateSetResp);\n    rpc RevokeCertificate(TCertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc RevokeCertificateSet(TCertRevokeSetReq) returns (CAStatus); // not yet implemented\n}\n\n\n\nThe \nReadCACertificate\n function returns the certificate of the TCA itself.\n\n\nThe \nCreateCertificate\n function allows a user to create and retrieve a new transaction certificate.\n\n\nThe \nCreateCertificateSet\n function allows a user to create and retrieve a set of transaction certificates in a single call.\n\n\nTLS Certificate Authority\n\n\nThe administrator interface of the TLSCA provides the following functions:\n\n\nservice TLSCAA { // admin\n    rpc RevokeCertificate(TLSCertRevokeReq) returns (CAStatus); not yet implemented\n}\n\n\n\nThe public interface of the TLSCA provides the following functions:\n\n\nservice TLSCAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificate(TLSCertCreateReq) returns (TLSCertCreateResp);\n    rpc ReadCertificate(TLSCertReadReq) returns (Cert);\n    rpc RevokeCertificate(TLSCertRevokeReq) returns (CAStatus); // not yet implemented\n}\n\n\n\nThe \nReadCACertificate\n function returns the certificate of the TLSCA itself.\n\n\nThe \nCreateCertificate\n function allows a user to create and retrieve a new TLS certificate.\n\n\nThe \nReadCertificate\n function allows a user to retrieve a previously created TLS certificate.", 
            "title": "MemberServicesAPI"
        }, 
        {
            "location": "/API/MemberServicesAPI/#certificate-authority-api", 
            "text": "Each of the CA services is split into two  GRPC  interfaces, namely a public one (indicated by a  P  suffix) and an administrator one (indicated by an  A  suffix).", 
            "title": "Certificate Authority API"
        }, 
        {
            "location": "/API/MemberServicesAPI/#enrollment-certificate-authority", 
            "text": "The administrator interface of the ECA provides the following functions:  service ECAA { // admin\n    rpc RegisterUser(RegisterUserReq) returns (Token);\n    rpc ReadUserSet(ReadUserSetReq) returns (UserSet);\n    rpc RevokeCertificate(ECertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc PublishCRL(ECertCRLReq) returns (CAStatus); // not yet implemented\n}  The  RegisterUser  function allows you to register a new user by specifiying her name and roles in the  RegisterUserReq  structure.  If the user has not be registered before, the ECA registers the new user and returns a unique one-time password, which can be used by the user to request her enrollment certificate pair via the public interface of the ECA.  Otherwise an error is returned.  The  ReadUserSet  function allows only auditors to retrieve the list of users registered with the blockchain.  The public interface of the ECA provides the following functions:  service ECAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificatePair(ECertCreateReq) returns (ECertCreateResp);\n    rpc ReadCertificatePair(ECertReadReq) returns (CertPair);\n    rpc ReadCertificateByHash(Hash) returns (Cert);\n    rpc RevokeCertificatePair(ECertRevokeReq) returns (CAStatus); // not yet implemented\n}  The  ReadCACertificate  function returns the certificate of the ECA itself.  The  CreateCertificatePair  functions allows a user to create and read her enrollment certificate pair.  For this, the user has to do two successive invocations of this functions.  Firstly, both the signature and encryption public keys have to be handed to the ECA together with the one-time password returned by the  RegisterUser  function invocation before.  The request has to be signed by the user's private signature key to demonstrate that the user is in possession of the private signature key indeed.  The ECA in return gives the user a challenge encrypted with the user's public encryption key.  The has to decrypt the challenge, thereby demonstrating that she is in possession of the private encryption key indeed, and re-issue the certificate creation request passing the decrypted challenge instead of the one-time password passed in the invocation.  If the challenge has been decrypted correctly, the ECA issues and returns the enrollment certificate pair for the user.  The  ReadCertificatePair  function allows any user of the blockchain to read the certificate pair of any other user of the blockchain.  The  ReadCertificatePairByHash  function allows any user of the blockchain to read a certificate from the ECA matching a given hash.", 
            "title": "Enrollment Certificate Authority"
        }, 
        {
            "location": "/API/MemberServicesAPI/#transaction-certificate-authority", 
            "text": "The administrator interface of the TCA provides the following functions:  service TCAA { // admin\n    rpc RevokeCertificate(TCertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc RevokeCertificateSet(TCertRevokeSetReq) returns (CAStatus); // not yet implemented\n    rpc PublishCRL(TCertCRLReq) returns (CAStatus); // not yet implemented\n}  The public interface of the TCA provides the following functions:  service TCAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificate(TCertCreateReq) returns (TCertCreateResp);\n    rpc CreateCertificateSet(TCertCreateSetReq) returns (TCertCreateSetResp);\n    rpc RevokeCertificate(TCertRevokeReq) returns (CAStatus); // not yet implemented\n    rpc RevokeCertificateSet(TCertRevokeSetReq) returns (CAStatus); // not yet implemented\n}  The  ReadCACertificate  function returns the certificate of the TCA itself.  The  CreateCertificate  function allows a user to create and retrieve a new transaction certificate.  The  CreateCertificateSet  function allows a user to create and retrieve a set of transaction certificates in a single call.", 
            "title": "Transaction Certificate Authority"
        }, 
        {
            "location": "/API/MemberServicesAPI/#tls-certificate-authority", 
            "text": "The administrator interface of the TLSCA provides the following functions:  service TLSCAA { // admin\n    rpc RevokeCertificate(TLSCertRevokeReq) returns (CAStatus); not yet implemented\n}  The public interface of the TLSCA provides the following functions:  service TLSCAP { // public\n    rpc ReadCACertificate(Empty) returns (Cert);\n    rpc CreateCertificate(TLSCertCreateReq) returns (TLSCertCreateResp);\n    rpc ReadCertificate(TLSCertReadReq) returns (Cert);\n    rpc RevokeCertificate(TLSCertRevokeReq) returns (CAStatus); // not yet implemented\n}  The  ReadCACertificate  function returns the certificate of the TLSCA itself.  The  CreateCertificate  function allows a user to create and retrieve a new TLS certificate.  The  ReadCertificate  function allows a user to retrieve a previously created TLS certificate.", 
            "title": "TLS Certificate Authority"
        }, 
        {
            "location": "/API/SandboxSetup/", 
            "text": "Writing, Building, and Running Chaincode in a Development Environment\n\n\nChaincode developers need a way to test and debug their chaincode without having to set up a complete peer network. This document describes how to write, build, and test chaincode in a local development environment.\n\n\nMultiple terminal windows inside the Vagrant development environment are required. One Vagrant terminal runs the validating peer; another Vagrant terminal runs the chaincode; the third Vagrant terminal runs the CLI or REST API commands to execute transactions. When running with security enabled, an additional fourth Vagrant terminal window is required to run the \nCertificate Authority (CA)\n server. Detailed instructions are provided in the sections below:\n\n\n\n\nSecurity Setup (optional)\n\n\nVagrant Terminal 1 (validating peer)\n\n\nVagrant Terminal 2 (chaincode)\n\n\nVagrant Terminal 3 (CLI or REST API)\n\n\nChaincode deploy via CLI and REST\n\n\nChaincode invoke via CLI and REST\n\n\nChaincode query via CLI and REST\n\n\n\n\n\n\nRemoving temporary files when security is enabled\n\n\n\n\nSee the \nlogging control\n reference for information on controlling\nlogging output from the \npeer\n and chaincodes.\n\n\nSecurity Setup (optional)\n\n\nFrom your command line terminal, move to the \ndevenv\n subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:\n\n\nvagrant ssh\n\n\n\nTo set up the local development environment with security enabled, you must first build and run the \nCertificate Authority (CA)\n server:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake membersrvc \n membersrvc\n\n\n\nRunning the above commands builds and runs the CA server with the default setup, which is defined in the \nmembersrvc.yaml\n configuration file. The default configuration includes multiple users who are already registered with the CA; these users are listed in the \neca.users\n section of the configuration file. To register additional users with the CA for testing, modify the \neca.users\n section of the \nmembersrvc.yaml\n file to include additional \nenrollmentID\n and \nenrollmentPW\n pairs. Note the integer that precedes the \nenrollmentPW\n. That integer indicates the role of the user, where 1 = client, 2 = non-validating peer, 4 = validating peer, and 8 = auditor.\n\n\nVagrant Terminal 1 (validating peer)\n\n\nNote:\n To run with security enabled, first modify the \ncore.yaml\n configuration file to set the \nsecurity.enabled\n value to \ntrue\n before building the peer executable. Alternatively, you can enable security by running the peer with environment variable \nCORE_SECURITY_ENABLED=true\n. To enable privacy and confidentiality of transactions (requires security to also be enabled), modify the \ncore.yaml\n configuration file to set the \nsecurity.privacy\n value to \ntrue\n as well. Alternatively, you can enable privacy by running the peer with environment variable \nCORE_SECURITY_PRIVACY=true\n. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).\n\n\nFrom your command line terminal, move to the \ndevenv\n subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:\n\n\nvagrant ssh\n\n\n\nBuild and run the peer process to enable security and privacy after setting \nsecurity.enabled\n and \nsecurity.privacy\n settings to \ntrue\n.\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer\npeer node start --peer-chaincodedev\n\n\n\nAlternatively, enable security and privacy on the peer with environment variables:\n\n\nCORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer node start --peer-chaincodedev\n\n\n\nVagrant Terminal 2 (chaincode)\n\n\nFrom your command line terminal, move to the \ndevenv\n subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:\n\n\nvagrant ssh\n\n\n\nBuild the \nchaincode_example02\n code, which is provided in the source code repository:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\ngo build\n\n\n\nWhen you are ready to start creating your own chaincode, create a new subdirectory inside of /fabric/examples/go/chaincode to store your chaincode files. You can copy the \nchaincode_example02\n file to the new directory and modify it.\n\n\nRun the following chaincode command to start and register the chaincode with the validating peer (started in Vagrant terminal 1):\n\n\nCORE_CHAINCODE_ID_NAME=mycc CORE_PEER_ADDRESS=0.0.0.0:30303 ./chaincode_example02\n\n\n\nThe chaincode console will display the message \"Received REGISTERED, ready for invocations\", which indicates that the chaincode is ready to receive requests. Follow the steps below to send a chaincode deploy, invoke or query transaction. If the \"Received REGISTERED\" message is not displayed, then an error has occurred during the deployment; revisit the previous steps to resolve the issue.\n\n\nVagrant Terminal 3 (CLI or REST API)\n\n\nNote on REST API port\n\n\nThe default REST interface port is 5000. It can be configured in \ncore.yaml\n using the \nrest.address\n property. If using Vagrant, the REST port mapping is defined in \nVagrantfile\n.\n\n\nNote on security functionality\n\n\nCurrent security implementation assumes that end user authentication takes place at the application layer and is not handled by the fabric. Authentication may be performed through any means considered appropriate for the target application. Upon successful user authentication, the application will perform user registration with the CA exactly once. If registration is attempted a second time for the same user, an error will result. During registration, the application sends a request to the certificate authority to verify the user registration and if successful, the CA responds with the user certificates and keys. The enrollment and transaction certificates received from the CA will be stored locally inside \n/var/hyperledger/production/crypto/client/\n directory. This directory resides on a specific peer node which allows the user to transact only through this specific peer while using the stored crypto material. If the end user needs to perform transactions through more then one peer node, the application is responsible for replicating the crypto material to other peer nodes. This is necessary as registering a given user with the CA a second time will fail.\n\n\nWith security enabled, the CLI commands and REST payloads must be modified to include the \nenrollmentID\n of a registered user who is logged in; otherwise an error will result. A registered user can be logged in through the CLI or the REST API by following the instructions below. To log in through the CLI, issue the following commands, where \nusername\n is one of the \nenrollmentID\n values listed in the \neca.users\n section of the \nmembersrvc.yaml\n file.\n\n\nFrom your command line terminal, move to the \ndevenv\n subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:\n\n\nvagrant ssh\n\n\n\nRegister the user though the CLI, substituting for \nusername\n appropriately:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric/peer\npeer network login \nusername\n\n\n\n\nThe command will prompt for a password, which must match the \nenrollmentPW\n listed for the target user in the \neca.users\n section of the \nmembersrvc.yaml\n file. If the password entered does not match the \nenrollmentPW\n, an error will result.\n\n\nTo log in through the REST API, send a POST request to the \n/registrar\n endpoint, containing the \nenrollmentID\n and \nenrollmentPW\n listed in the \neca.users\n section of the \nmembersrvc.yaml\n file.\n\n\nREST Request:\n\n\nPOST localhost:5000/registrar\n\n{\n  \nenrollId\n: \njim\n,\n  \nenrollSecret\n: \n6avZQLwcUe9b\n\n}\n\n\n\n\nREST Response:\n\n\n200 OK\n{\n    \nOK\n: \nLogin successful for user 'jim'.\n\n}\n\n\n\n\nChaincode deploy via CLI and REST\n\n\nFirst, send a chaincode deploy transaction, only once, to the validating peer. The CLI connects to the validating peer using the properties defined in the core.yaml file. \nNote:\n The deploy transaction typically requires a \npath\n parameter to locate, build, and deploy the chaincode. However, because these instructions are specific to local development mode and the chaincode is deployed manually, the \nname\n parameter is used instead.\n\n\npeer chaincode deploy -n mycc -c '{\nFunction\n:\ninit\n, \nArgs\n: [\na\n,\n100\n, \nb\n, \n200\n]}'\n\n\n\n\nAlternatively, you can run the chaincode deploy transaction through the REST API.\n\n\nREST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: 1,\n    \nchaincodeID\n:{\n        \nname\n: \nmycc\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n100\n, \nb\n, \n200\n]\n    }\n  },\n  \nid\n: 1\n}\n\n\n\n\nREST Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \nmycc\n\n    },\n    \nid\n: 1\n}\n\n\n\n\nNote:\n When security is enabled, modify the CLI command and the REST API payload to pass the \nenrollmentID\n of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the \nnote on security functionality\n. On the CLI, the \nenrollmentID\n is passed with the \n-u\n parameter; in the REST API, the \nenrollmentID\n is passed with the \nsecureContext\n element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).\n\n\n  CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode deploy -u jim -n mycc -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'\n\n\n\nREST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ndeploy\n,\n  \nparams\n: {\n    \ntype\n: 1,\n    \nchaincodeID\n:{\n        \nname\n: \nmycc\n\n    },\n    \nctorMsg\n: {\n        \nfunction\n:\ninit\n,\n        \nargs\n:[\na\n, \n100\n, \nb\n, \n200\n]\n    },\n    \nsecureContext\n: \njim\n\n  },\n  \nid\n: 1\n}\n\n\n\n\nThe deploy transaction initializes the chaincode by executing a target initializing function. Though the example shows \"init\", the name could be arbitrarily chosen by the chaincode developer. You should see the following output in the chaincode window:\n\n\n2015/11/15 15:19:31 Received INIT(uuid:005dea42-d57f-4983-803e-3232e551bf61), initializing chaincode\nAval = 100, Bval = 200\n\n\n\nChaincode invoke via CLI and REST\n\n\nRun the chaincode invoking transaction on the CLI as many times as desired. The \n-n\n argument should match the value provided in the chaincode window (started in Vagrant terminal 2):\n\n\npeer chaincode invoke -l golang -n mycc -c '{\"Function\": \"invoke\", \"Args\": [\"a\", \"b\", \"10\"]}'\n\n\n\nAlternatively, run the chaincode invoking transaction through the REST API.\n\n\nREST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\nmycc\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\ninvoke\n,\n         \nargs\n:[\na\n, \nb\n, \n10\n]\n      }\n  },\n  \nid\n: 3\n}\n\n\n\n\nREST Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n5a4540e5-902b-422d-a6ab-e70ab36a2e6d\n\n    },\n    \nid\n: 3\n}\n\n\n\n\nNote:\n When security is enabled, modify the CLI command and REST API payload to pass the \nenrollmentID\n of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the \nnote on security functionality\n. On the CLI, the \nenrollmentID\n is passed with the \n-u\n parameter; in the REST API, the \nenrollmentID\n is passed with the \nsecureContext\n element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).\n\n\n  CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode invoke -u jim -l golang -n mycc -c '{\"Function\": \"invoke\", \"Args\": [\"a\", \"b\", \"10\"]}'\n\n\n\n REST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \ninvoke\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\nmycc\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\ninvoke\n,\n         \nargs\n:[\na\n, \nb\n, \n10\n]\n      },\n      \nsecureContext\n: \njim\n\n  },\n  \nid\n: 3\n}\n\n\n\n\nThe invoking transaction runs the specified chaincode function name \"invoke\" with the arguments. This transaction transfers 10 units from A to B. You should see the following output in the chaincode window:\n\n\n2015/11/15 15:39:11 Received RESPONSE. Payload 200, Uuid 075d72a4-4d1f-4a1d-a735-4f6f60d597a9\nAval = 90, Bval = 210\n\n\n\nChaincode query via CLI and REST\n\n\nRun a query on the chaincode to retrieve the desired values. The \n-n\n argument should match the value provided in the chaincode window (started in Vagrant terminal 2):\n\n\npeer chaincode query -l golang -n mycc -c '{\"Function\": \"query\", \"Args\": [\"b\"]}'\n\n\n\nThe response should be similar to the following:\n\n\n{\"Name\":\"b\",\"Amount\":\"210\"}\n\n\n\nIf a name other than \"a\" or \"b\" is provided in a query sent to \nchaincode_example02\n, you should see an error response similar to the following:\n\n\n{\"Error\":\"Nil amount for c\"}\n\n\n\nAlternatively, run the chaincode query transaction through the REST API.\n\n\n REST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\nmycc\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\nquery\n,\n         \nargs\n:[\na\n]\n      }\n  },\n  \nid\n: 5\n}\n\n\n\n\nREST Response:\n\n\n{\n    \njsonrpc\n: \n2.0\n,\n    \nresult\n: {\n        \nstatus\n: \nOK\n,\n        \nmessage\n: \n90\n\n    },\n    \nid\n: 5\n}\n\n\n\n\nNote:\n When security is enabled, modify the CLI command and REST API payload to pass the \nenrollmentID\n of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the \nnote on security functionality\n. On the CLI, the \nenrollmentID\n is passed with the \n-u\n parameter; in the REST API, the \nenrollmentID\n is passed with the \nsecureContext\n element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).\n\n\n  CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode query -u jim -l golang -n mycc -c '{\"Function\": \"query\", \"Args\": [\"b\"]}'\n\n\n\nREST Request:\n\n\nPOST host:port/chaincode\n\n{\n  \njsonrpc\n: \n2.0\n,\n  \nmethod\n: \nquery\n,\n  \nparams\n: {\n      \ntype\n: 1,\n      \nchaincodeID\n:{\n          \nname\n:\nmycc\n\n      },\n      \nctorMsg\n: {\n         \nfunction\n:\nquery\n,\n         \nargs\n:[\na\n]\n      },\n      \nsecureContext\n: \njim\n\n  },\n  \nid\n: 5\n}\n\n\n\n\nRemoving temporary files when security is enabled\n\n\nAfter the completion of a chaincode test with security enabled, remove the temporary files that were created by the CA server process. To remove the client enrollment certificate, enrollment key, transaction certificate chain, etc., run the following commands. Note, that you must run these commands if you want to register a user who has already been registered previously.\n\n\nFrom your command line terminal, move to the \ndevenv\n subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:\n\n\nvagrant ssh\n\n\n\nAnd then run:\n\n\nrm -rf /var/hyperledger/production", 
            "title": "SandboxSetup"
        }, 
        {
            "location": "/API/SandboxSetup/#writing-building-and-running-chaincode-in-a-development-environment", 
            "text": "Chaincode developers need a way to test and debug their chaincode without having to set up a complete peer network. This document describes how to write, build, and test chaincode in a local development environment.  Multiple terminal windows inside the Vagrant development environment are required. One Vagrant terminal runs the validating peer; another Vagrant terminal runs the chaincode; the third Vagrant terminal runs the CLI or REST API commands to execute transactions. When running with security enabled, an additional fourth Vagrant terminal window is required to run the  Certificate Authority (CA)  server. Detailed instructions are provided in the sections below:   Security Setup (optional)  Vagrant Terminal 1 (validating peer)  Vagrant Terminal 2 (chaincode)  Vagrant Terminal 3 (CLI or REST API)  Chaincode deploy via CLI and REST  Chaincode invoke via CLI and REST  Chaincode query via CLI and REST    Removing temporary files when security is enabled   See the  logging control  reference for information on controlling\nlogging output from the  peer  and chaincodes.", 
            "title": "Writing, Building, and Running Chaincode in a Development Environment"
        }, 
        {
            "location": "/API/SandboxSetup/#security-setup-optional", 
            "text": "From your command line terminal, move to the  devenv  subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:  vagrant ssh  To set up the local development environment with security enabled, you must first build and run the  Certificate Authority (CA)  server:  cd $GOPATH/src/github.com/hyperledger/fabric\nmake membersrvc   membersrvc  Running the above commands builds and runs the CA server with the default setup, which is defined in the  membersrvc.yaml  configuration file. The default configuration includes multiple users who are already registered with the CA; these users are listed in the  eca.users  section of the configuration file. To register additional users with the CA for testing, modify the  eca.users  section of the  membersrvc.yaml  file to include additional  enrollmentID  and  enrollmentPW  pairs. Note the integer that precedes the  enrollmentPW . That integer indicates the role of the user, where 1 = client, 2 = non-validating peer, 4 = validating peer, and 8 = auditor.", 
            "title": "Security Setup (optional)"
        }, 
        {
            "location": "/API/SandboxSetup/#vagrant-terminal-1-validating-peer", 
            "text": "Note:  To run with security enabled, first modify the  core.yaml  configuration file to set the  security.enabled  value to  true  before building the peer executable. Alternatively, you can enable security by running the peer with environment variable  CORE_SECURITY_ENABLED=true . To enable privacy and confidentiality of transactions (requires security to also be enabled), modify the  core.yaml  configuration file to set the  security.privacy  value to  true  as well. Alternatively, you can enable privacy by running the peer with environment variable  CORE_SECURITY_PRIVACY=true . If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).  From your command line terminal, move to the  devenv  subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:  vagrant ssh  Build and run the peer process to enable security and privacy after setting  security.enabled  and  security.privacy  settings to  true .  cd $GOPATH/src/github.com/hyperledger/fabric\nmake peer\npeer node start --peer-chaincodedev  Alternatively, enable security and privacy on the peer with environment variables:  CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer node start --peer-chaincodedev", 
            "title": "Vagrant Terminal 1 (validating peer)"
        }, 
        {
            "location": "/API/SandboxSetup/#vagrant-terminal-2-chaincode", 
            "text": "From your command line terminal, move to the  devenv  subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:  vagrant ssh  Build the  chaincode_example02  code, which is provided in the source code repository:  cd $GOPATH/src/github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\ngo build  When you are ready to start creating your own chaincode, create a new subdirectory inside of /fabric/examples/go/chaincode to store your chaincode files. You can copy the  chaincode_example02  file to the new directory and modify it.  Run the following chaincode command to start and register the chaincode with the validating peer (started in Vagrant terminal 1):  CORE_CHAINCODE_ID_NAME=mycc CORE_PEER_ADDRESS=0.0.0.0:30303 ./chaincode_example02  The chaincode console will display the message \"Received REGISTERED, ready for invocations\", which indicates that the chaincode is ready to receive requests. Follow the steps below to send a chaincode deploy, invoke or query transaction. If the \"Received REGISTERED\" message is not displayed, then an error has occurred during the deployment; revisit the previous steps to resolve the issue.", 
            "title": "Vagrant Terminal 2 (chaincode)"
        }, 
        {
            "location": "/API/SandboxSetup/#vagrant-terminal-3-cli-or-rest-api", 
            "text": "", 
            "title": "Vagrant Terminal 3 (CLI or REST API)"
        }, 
        {
            "location": "/API/SandboxSetup/#note-on-rest-api-port", 
            "text": "The default REST interface port is 5000. It can be configured in  core.yaml  using the  rest.address  property. If using Vagrant, the REST port mapping is defined in  Vagrantfile .", 
            "title": "Note on REST API port"
        }, 
        {
            "location": "/API/SandboxSetup/#note-on-security-functionality", 
            "text": "Current security implementation assumes that end user authentication takes place at the application layer and is not handled by the fabric. Authentication may be performed through any means considered appropriate for the target application. Upon successful user authentication, the application will perform user registration with the CA exactly once. If registration is attempted a second time for the same user, an error will result. During registration, the application sends a request to the certificate authority to verify the user registration and if successful, the CA responds with the user certificates and keys. The enrollment and transaction certificates received from the CA will be stored locally inside  /var/hyperledger/production/crypto/client/  directory. This directory resides on a specific peer node which allows the user to transact only through this specific peer while using the stored crypto material. If the end user needs to perform transactions through more then one peer node, the application is responsible for replicating the crypto material to other peer nodes. This is necessary as registering a given user with the CA a second time will fail.  With security enabled, the CLI commands and REST payloads must be modified to include the  enrollmentID  of a registered user who is logged in; otherwise an error will result. A registered user can be logged in through the CLI or the REST API by following the instructions below. To log in through the CLI, issue the following commands, where  username  is one of the  enrollmentID  values listed in the  eca.users  section of the  membersrvc.yaml  file.  From your command line terminal, move to the  devenv  subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:  vagrant ssh  Register the user though the CLI, substituting for  username  appropriately:  cd $GOPATH/src/github.com/hyperledger/fabric/peer\npeer network login  username   The command will prompt for a password, which must match the  enrollmentPW  listed for the target user in the  eca.users  section of the  membersrvc.yaml  file. If the password entered does not match the  enrollmentPW , an error will result.  To log in through the REST API, send a POST request to the  /registrar  endpoint, containing the  enrollmentID  and  enrollmentPW  listed in the  eca.users  section of the  membersrvc.yaml  file.  REST Request:  POST localhost:5000/registrar\n\n{\n   enrollId :  jim ,\n   enrollSecret :  6avZQLwcUe9b \n}  REST Response:  200 OK\n{\n     OK :  Login successful for user 'jim'. \n}", 
            "title": "Note on security functionality"
        }, 
        {
            "location": "/API/SandboxSetup/#chaincode-deploy-via-cli-and-rest", 
            "text": "First, send a chaincode deploy transaction, only once, to the validating peer. The CLI connects to the validating peer using the properties defined in the core.yaml file.  Note:  The deploy transaction typically requires a  path  parameter to locate, build, and deploy the chaincode. However, because these instructions are specific to local development mode and the chaincode is deployed manually, the  name  parameter is used instead.  peer chaincode deploy -n mycc -c '{ Function : init ,  Args : [ a , 100 ,  b ,  200 ]}'  Alternatively, you can run the chaincode deploy transaction through the REST API.  REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type : 1,\n     chaincodeID :{\n         name :  mycc \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  100 ,  b ,  200 ]\n    }\n  },\n   id : 1\n}  REST Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  mycc \n    },\n     id : 1\n}  Note:  When security is enabled, modify the CLI command and the REST API payload to pass the  enrollmentID  of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the  note on security functionality . On the CLI, the  enrollmentID  is passed with the  -u  parameter; in the REST API, the  enrollmentID  is passed with the  secureContext  element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).    CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode deploy -u jim -n mycc -c '{\"Function\":\"init\", \"Args\": [\"a\",\"100\", \"b\", \"200\"]}'  REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  deploy ,\n   params : {\n     type : 1,\n     chaincodeID :{\n         name :  mycc \n    },\n     ctorMsg : {\n         function : init ,\n         args :[ a ,  100 ,  b ,  200 ]\n    },\n     secureContext :  jim \n  },\n   id : 1\n}  The deploy transaction initializes the chaincode by executing a target initializing function. Though the example shows \"init\", the name could be arbitrarily chosen by the chaincode developer. You should see the following output in the chaincode window:  2015/11/15 15:19:31 Received INIT(uuid:005dea42-d57f-4983-803e-3232e551bf61), initializing chaincode\nAval = 100, Bval = 200", 
            "title": "Chaincode deploy via CLI and REST"
        }, 
        {
            "location": "/API/SandboxSetup/#chaincode-invoke-via-cli-and-rest", 
            "text": "Run the chaincode invoking transaction on the CLI as many times as desired. The  -n  argument should match the value provided in the chaincode window (started in Vagrant terminal 2):  peer chaincode invoke -l golang -n mycc -c '{\"Function\": \"invoke\", \"Args\": [\"a\", \"b\", \"10\"]}'  Alternatively, run the chaincode invoking transaction through the REST API.  REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : mycc \n      },\n       ctorMsg : {\n          function : invoke ,\n          args :[ a ,  b ,  10 ]\n      }\n  },\n   id : 3\n}  REST Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  5a4540e5-902b-422d-a6ab-e70ab36a2e6d \n    },\n     id : 3\n}  Note:  When security is enabled, modify the CLI command and REST API payload to pass the  enrollmentID  of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the  note on security functionality . On the CLI, the  enrollmentID  is passed with the  -u  parameter; in the REST API, the  enrollmentID  is passed with the  secureContext  element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).    CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode invoke -u jim -l golang -n mycc -c '{\"Function\": \"invoke\", \"Args\": [\"a\", \"b\", \"10\"]}'   REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  invoke ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : mycc \n      },\n       ctorMsg : {\n          function : invoke ,\n          args :[ a ,  b ,  10 ]\n      },\n       secureContext :  jim \n  },\n   id : 3\n}  The invoking transaction runs the specified chaincode function name \"invoke\" with the arguments. This transaction transfers 10 units from A to B. You should see the following output in the chaincode window:  2015/11/15 15:39:11 Received RESPONSE. Payload 200, Uuid 075d72a4-4d1f-4a1d-a735-4f6f60d597a9\nAval = 90, Bval = 210", 
            "title": "Chaincode invoke via CLI and REST"
        }, 
        {
            "location": "/API/SandboxSetup/#chaincode-query-via-cli-and-rest", 
            "text": "Run a query on the chaincode to retrieve the desired values. The  -n  argument should match the value provided in the chaincode window (started in Vagrant terminal 2):  peer chaincode query -l golang -n mycc -c '{\"Function\": \"query\", \"Args\": [\"b\"]}'  The response should be similar to the following:  {\"Name\":\"b\",\"Amount\":\"210\"}  If a name other than \"a\" or \"b\" is provided in a query sent to  chaincode_example02 , you should see an error response similar to the following:  {\"Error\":\"Nil amount for c\"}  Alternatively, run the chaincode query transaction through the REST API.   REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : mycc \n      },\n       ctorMsg : {\n          function : query ,\n          args :[ a ]\n      }\n  },\n   id : 5\n}  REST Response:  {\n     jsonrpc :  2.0 ,\n     result : {\n         status :  OK ,\n         message :  90 \n    },\n     id : 5\n}  Note:  When security is enabled, modify the CLI command and REST API payload to pass the  enrollmentID  of a logged in user. To log in a registered user through the CLI or the REST API, follow the instructions in the  note on security functionality . On the CLI, the  enrollmentID  is passed with the  -u  parameter; in the REST API, the  enrollmentID  is passed with the  secureContext  element. If you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).    CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode query -u jim -l golang -n mycc -c '{\"Function\": \"query\", \"Args\": [\"b\"]}'  REST Request:  POST host:port/chaincode\n\n{\n   jsonrpc :  2.0 ,\n   method :  query ,\n   params : {\n       type : 1,\n       chaincodeID :{\n           name : mycc \n      },\n       ctorMsg : {\n          function : query ,\n          args :[ a ]\n      },\n       secureContext :  jim \n  },\n   id : 5\n}", 
            "title": "Chaincode query via CLI and REST"
        }, 
        {
            "location": "/API/SandboxSetup/#removing-temporary-files-when-security-is-enabled", 
            "text": "After the completion of a chaincode test with security enabled, remove the temporary files that were created by the CA server process. To remove the client enrollment certificate, enrollment key, transaction certificate chain, etc., run the following commands. Note, that you must run these commands if you want to register a user who has already been registered previously.  From your command line terminal, move to the  devenv  subdirectory of your workspace environment. Log into a Vagrant terminal by executing the following command:  vagrant ssh  And then run:  rm -rf /var/hyperledger/production", 
            "title": "Removing temporary files when security is enabled"
        }, 
        {
            "location": "/FAQ/chaincode_FAQ/", 
            "text": "Chaincode (Smart Contracts and Digital Assets)\n\n\n\n\nDoes the fabric implementation support smart contract logic?\n\n\nYes. Chaincode is the fabric\u2019s interpretation of the smart contract method/algorithm, with additional features.\n\n\nA chaincode is programmatic code deployed on the network, where it is executed and validated by chain validators together during the consensus process. Developers can use chaincodes to develop business contracts, asset definitions, and collectively-managed decentralized applications.\n\n\n\n\nHow do I create a business contract using the fabric?\n\n\nThere are generally two ways to develop business contracts: the first way is to code individual contracts into standalone instances of chaincode; the second way, and probably the more efficient way, is to use chaincode to create decentralized applications that manage the life cycle of one or multiple types of business contracts, and let end users instantiate instances of contracts within these applications.\n\n\n\n\nHow do I create assets using the fabric?\n\n\nUsers can use chaincode (for business rules) and membership service (for digital tokens) to design assets, as well as the logic that manages them.\n\n\nThere are two popular approaches to defining assets in most blockchain solutions: the stateless UTXO model, where account balances are encoded into past transaction records; and the account model, where account balances are kept in state storage space on the ledger.\n\n\nEach approach carries its own benefits and drawbacks. This blockchain fabric does not advocate either one over the other. Instead, one of our first requirements was to ensure that both approaches can be easily implemented with tools available in the fabric.\n\n\n\n\nWhich languages are supported for writing chaincode?\n\n\nChaincode can be written in any programming language and executed in containers inside the fabric context layer. We are also looking into developing a templating language (such as Apache Velocity) that can either get compiled into chaincode or have its interpreter embedded into a chaincode container.\n\n\nThe fabric's first fully supported chaincode language is Golang, and support for JavaScript and Java is planned for 2016. Support for additional languages and the development of a fabric-specific templating language have been discussed, and more details will be released in the near future.\n\n\n\n\nDoes the fabric have native currency?\n\n\nNo. However, if you really need a native currency for your chain network, you can develop your own native currency with chaincode. One common attribute of native currency is that some amount will get transacted (the chaincode defining that currency will get called) every time a transaction is processed on its chain.", 
            "title": "ChaincodeFAQ"
        }, 
        {
            "location": "/FAQ/chaincode_FAQ/#chaincode-smart-contracts-and-digital-assets", 
            "text": "", 
            "title": "Chaincode (Smart Contracts and Digital Assets)"
        }, 
        {
            "location": "/FAQ/chaincode_FAQ/#does-the-fabric-implementation-support-smart-contract-logic", 
            "text": "Yes. Chaincode is the fabric\u2019s interpretation of the smart contract method/algorithm, with additional features.  A chaincode is programmatic code deployed on the network, where it is executed and validated by chain validators together during the consensus process. Developers can use chaincodes to develop business contracts, asset definitions, and collectively-managed decentralized applications.", 
            "title": "Does the fabric implementation support smart contract logic?"
        }, 
        {
            "location": "/FAQ/chaincode_FAQ/#how-do-i-create-a-business-contract-using-the-fabric", 
            "text": "There are generally two ways to develop business contracts: the first way is to code individual contracts into standalone instances of chaincode; the second way, and probably the more efficient way, is to use chaincode to create decentralized applications that manage the life cycle of one or multiple types of business contracts, and let end users instantiate instances of contracts within these applications.", 
            "title": "How do I create a business contract using the fabric?"
        }, 
        {
            "location": "/FAQ/chaincode_FAQ/#how-do-i-create-assets-using-the-fabric", 
            "text": "Users can use chaincode (for business rules) and membership service (for digital tokens) to design assets, as well as the logic that manages them.  There are two popular approaches to defining assets in most blockchain solutions: the stateless UTXO model, where account balances are encoded into past transaction records; and the account model, where account balances are kept in state storage space on the ledger.  Each approach carries its own benefits and drawbacks. This blockchain fabric does not advocate either one over the other. Instead, one of our first requirements was to ensure that both approaches can be easily implemented with tools available in the fabric.", 
            "title": "How do I create assets using the fabric?"
        }, 
        {
            "location": "/FAQ/chaincode_FAQ/#which-languages-are-supported-for-writing-chaincode", 
            "text": "Chaincode can be written in any programming language and executed in containers inside the fabric context layer. We are also looking into developing a templating language (such as Apache Velocity) that can either get compiled into chaincode or have its interpreter embedded into a chaincode container.  The fabric's first fully supported chaincode language is Golang, and support for JavaScript and Java is planned for 2016. Support for additional languages and the development of a fabric-specific templating language have been discussed, and more details will be released in the near future.", 
            "title": "Which languages are supported for writing chaincode?"
        }, 
        {
            "location": "/FAQ/chaincode_FAQ/#does-the-fabric-have-native-currency", 
            "text": "No. However, if you really need a native currency for your chain network, you can develop your own native currency with chaincode. One common attribute of native currency is that some amount will get transacted (the chaincode defining that currency will get called) every time a transaction is processed on its chain.", 
            "title": "Does the fabric have native currency?"
        }, 
        {
            "location": "/FAQ/confidentiality_FAQ/", 
            "text": "Confidentiality\n\n\n\n\nHow is the confidentiality of transactions and business logic achieved?\n\n\nThe security module works in conjunction with the membership service module to provide access control service to any data recorded and business logic deployed on a chain network.\n\n\nWhen a code is deployed on a chain network, whether it is used to define a business contract or an asset, its creator can put access control on it so that only transactions issued by authorized entities will be processed and validated by chain validators.\n\n\nRaw transaction records are permanently stored in the ledger. While the contents of non-confidential transactions are open to all participants, the contents of confidential transactions are encrypted with secret keys known only to their originators, validators, and authorized auditors. Only holders of the secret keys can interpret transaction contents.\n\n\n\n\nWhat if none of the stakeholders of a business contract are validators?\n\n\nIn some business scenarios, full confidentiality of contract logic may be required \u2013 such that only contract counterparties and auditors can access and interpret their chaincode. Under these scenarios, counter parties would need to spin off a new child chain with only themselves as validators.", 
            "title": "ConfidentialityFAQ"
        }, 
        {
            "location": "/FAQ/confidentiality_FAQ/#confidentiality", 
            "text": "", 
            "title": "Confidentiality"
        }, 
        {
            "location": "/FAQ/confidentiality_FAQ/#how-is-the-confidentiality-of-transactions-and-business-logic-achieved", 
            "text": "The security module works in conjunction with the membership service module to provide access control service to any data recorded and business logic deployed on a chain network.  When a code is deployed on a chain network, whether it is used to define a business contract or an asset, its creator can put access control on it so that only transactions issued by authorized entities will be processed and validated by chain validators.  Raw transaction records are permanently stored in the ledger. While the contents of non-confidential transactions are open to all participants, the contents of confidential transactions are encrypted with secret keys known only to their originators, validators, and authorized auditors. Only holders of the secret keys can interpret transaction contents.", 
            "title": "How is the confidentiality of transactions and business logic achieved?"
        }, 
        {
            "location": "/FAQ/confidentiality_FAQ/#what-if-none-of-the-stakeholders-of-a-business-contract-are-validators", 
            "text": "In some business scenarios, full confidentiality of contract logic may be required \u2013 such that only contract counterparties and auditors can access and interpret their chaincode. Under these scenarios, counter parties would need to spin off a new child chain with only themselves as validators.", 
            "title": "What if none of the stakeholders of a business contract are validators?"
        }, 
        {
            "location": "/FAQ/consensus_FAQ/", 
            "text": "Consensus Algorithm\n\n\n\n\nWhich Consensus Algorithm is used in the fabric?\n\n\nThe fabric is built on a pluggable architecture such that developers can configure their deployment with the consensus module that best suits their needs. The initial release package will offer three consensus implementations for users to select from: 1) No-op (consensus ignored); 2) Classic PBFT; and 3) SIEVE (an enhanced version of classic PBFT). \n\n\n\n\nWhat is the SIEVE Consensus Algorithm?\n\n\nThere are many limitations in existing consensus algorithms, especially for solving challenges around security, performance, efficiency, and scalability. To solve these problems and make blockchain ready for business, the team has been researching several approaches to improve the existing algorithms. \n\n\nOne such improvement is \u201cSIEVE\u201d, a consensus algorithm inspired by classic PBFT [Castro and Liskov, OSDI\u201999] and the Eve consensus protocol [Kapritsos et al., OSDI\u20192012]. \n\n\nIn short, SIEVE augments the original PBFT algorithm by adding speculative execution and verification phases to: 1) detect and filter out possible non-deterministic requests and establish the determinism of transactions entering the PBFT 3-phase agreement protocol, and 2) allow consensus to be run on output state of validators, in addition to the consensus on their input state offered by Classic PBFT. SIEVE is derived from PBFT in a modular way (inspired by ideas described in  [Aublin et al., TOCS'15]) by reusing the PBFT view-change protocol to lower its complexity and avoid implementing a new consensus protocol from scratch.\n\n\nA research paper will be published by IBM Research to describe this new algorithm in further detail, and we will continue to make further research investments in the subject and share our results with the community.", 
            "title": "ConsensusFAQ"
        }, 
        {
            "location": "/FAQ/consensus_FAQ/#consensus-algorithm", 
            "text": "", 
            "title": "Consensus Algorithm"
        }, 
        {
            "location": "/FAQ/consensus_FAQ/#which-consensus-algorithm-is-used-in-the-fabric", 
            "text": "The fabric is built on a pluggable architecture such that developers can configure their deployment with the consensus module that best suits their needs. The initial release package will offer three consensus implementations for users to select from: 1) No-op (consensus ignored); 2) Classic PBFT; and 3) SIEVE (an enhanced version of classic PBFT).", 
            "title": "Which Consensus Algorithm is used in the fabric?"
        }, 
        {
            "location": "/FAQ/consensus_FAQ/#what-is-the-sieve-consensus-algorithm", 
            "text": "There are many limitations in existing consensus algorithms, especially for solving challenges around security, performance, efficiency, and scalability. To solve these problems and make blockchain ready for business, the team has been researching several approaches to improve the existing algorithms.   One such improvement is \u201cSIEVE\u201d, a consensus algorithm inspired by classic PBFT [Castro and Liskov, OSDI\u201999] and the Eve consensus protocol [Kapritsos et al., OSDI\u20192012].   In short, SIEVE augments the original PBFT algorithm by adding speculative execution and verification phases to: 1) detect and filter out possible non-deterministic requests and establish the determinism of transactions entering the PBFT 3-phase agreement protocol, and 2) allow consensus to be run on output state of validators, in addition to the consensus on their input state offered by Classic PBFT. SIEVE is derived from PBFT in a modular way (inspired by ideas described in  [Aublin et al., TOCS'15]) by reusing the PBFT view-change protocol to lower its complexity and avoid implementing a new consensus protocol from scratch.  A research paper will be published by IBM Research to describe this new algorithm in further detail, and we will continue to make further research investments in the subject and share our results with the community.", 
            "title": "What is the SIEVE Consensus Algorithm?"
        }, 
        {
            "location": "/FAQ/identity_management_FAQ/", 
            "text": "Identity Management (Membership Service)\n\n\n\n\nWhat is unique about the fabric's Membership Service module?\n\n\nOne of the things that makes the Membership Service module stand out from the pack is our implementation of the latest advances in cryptography.\n\n\nIn addition to ensuring private, auditable transactions, our Membership Service module introduces the concept of enrollment and transaction certificates. This innovation ensures that only verified owners can create asset tokens, allowing an infinite number of transaction certificates to be issued through parent enrollment certificates while guaranteeing the private keys of asset tokens can be regenerated if lost. \n\n\nIssuers also have the ability revoke transaction certificates or designate them to expire within a certain timeframe, allowing greater control over the asset tokens they have issued. \n\n\nLike most other modules on the fabric, you can always replace the default module with another membership service option should the need arise.\n\n\n\n\nDoes its Membership Service make the fabric a centralized solution?\n\n\nNo. The only role of the Membership Service module is to issue digital certificates to validated entities that want to participate in the network. It does not execute transactions nor is it aware of how or when these certificates are used in any particular network.\n\n\nHowever, because certificates are the way networks regulate and manage their users, the module serves a central regulatory and organizational role.", 
            "title": "Identity managementFAQ"
        }, 
        {
            "location": "/FAQ/identity_management_FAQ/#identity-management-membership-service", 
            "text": "", 
            "title": "Identity Management (Membership Service)"
        }, 
        {
            "location": "/FAQ/identity_management_FAQ/#what-is-unique-about-the-fabrics-membership-service-module", 
            "text": "One of the things that makes the Membership Service module stand out from the pack is our implementation of the latest advances in cryptography.  In addition to ensuring private, auditable transactions, our Membership Service module introduces the concept of enrollment and transaction certificates. This innovation ensures that only verified owners can create asset tokens, allowing an infinite number of transaction certificates to be issued through parent enrollment certificates while guaranteeing the private keys of asset tokens can be regenerated if lost.   Issuers also have the ability revoke transaction certificates or designate them to expire within a certain timeframe, allowing greater control over the asset tokens they have issued.   Like most other modules on the fabric, you can always replace the default module with another membership service option should the need arise.", 
            "title": "What is unique about the fabric's Membership Service module?"
        }, 
        {
            "location": "/FAQ/identity_management_FAQ/#does-its-membership-service-make-the-fabric-a-centralized-solution", 
            "text": "No. The only role of the Membership Service module is to issue digital certificates to validated entities that want to participate in the network. It does not execute transactions nor is it aware of how or when these certificates are used in any particular network.  However, because certificates are the way networks regulate and manage their users, the module serves a central regulatory and organizational role.", 
            "title": "Does its Membership Service make the fabric a centralized solution?"
        }, 
        {
            "location": "/FAQ/usage_FAQ/", 
            "text": "Usage\n\n\n\n\nWhat are the expected performance figures for the fabric?\n\n\nThe performance of any chain network depends on several factors: proximity of the validating nodes, number of validators, encryption method, transaction message size, security level set, business logic running, and the consensus algorithm deployed, among others.\n\n\nThe current performance goal for the fabric is to achieve 100,000 transactions per second in a standard production environment of about 15 validating nodes running in close proximity. The team is committed to continuously improving the performance and the scalability of the system.\n\n\n\n\nDo I have to own a validating node to transact on a chain network?\n\n\nNo. You can still transact on a chain network by owning a non-validating node (NV-node).\n\n\nAlthough transactions initiated by NV-nodes will eventually be forwarded to their validating peers for consensus processing, NV-nodes establish their own connections to the membership service module and can therefore package transactions independently. This allows NV-node owners to independently register and manage certificates, a powerful feature that empowers NV-node owners to create custom-built applications for their clients while managing their client certificates.\n\n\nIn addition, NV-nodes retain full copies of the ledger, enabling local queries of the ledger data. \n\n\n\n\nWhat does the error string \"state may be inconsistent, cannot query\" as a query result mean?\n\n\nSometimes, a validating peer will be out of sync with the rest of the network.  Although determining this condition is not always possible, validating peers make a best effort determination to detect it, and internally mark themselves as out of date.\n\n\nWhen under this condition, rather than reply with out of date or potentially incorrect data, the peer will reply to chaincode queries with the error string \"state may be inconsistent, cannot query\".\n\n\nIn the future, more sophisticated reporting mechanisms may be introduced such as returning the stale value and a flag that the value is stale.", 
            "title": "UsageFAQ"
        }, 
        {
            "location": "/FAQ/usage_FAQ/#usage", 
            "text": "", 
            "title": "Usage"
        }, 
        {
            "location": "/FAQ/usage_FAQ/#what-are-the-expected-performance-figures-for-the-fabric", 
            "text": "The performance of any chain network depends on several factors: proximity of the validating nodes, number of validators, encryption method, transaction message size, security level set, business logic running, and the consensus algorithm deployed, among others.  The current performance goal for the fabric is to achieve 100,000 transactions per second in a standard production environment of about 15 validating nodes running in close proximity. The team is committed to continuously improving the performance and the scalability of the system.", 
            "title": "What are the expected performance figures for the fabric?"
        }, 
        {
            "location": "/FAQ/usage_FAQ/#do-i-have-to-own-a-validating-node-to-transact-on-a-chain-network", 
            "text": "No. You can still transact on a chain network by owning a non-validating node (NV-node).  Although transactions initiated by NV-nodes will eventually be forwarded to their validating peers for consensus processing, NV-nodes establish their own connections to the membership service module and can therefore package transactions independently. This allows NV-node owners to independently register and manage certificates, a powerful feature that empowers NV-node owners to create custom-built applications for their clients while managing their client certificates.  In addition, NV-nodes retain full copies of the ledger, enabling local queries of the ledger data.", 
            "title": "Do I have to own a validating node to transact on a chain network?"
        }, 
        {
            "location": "/FAQ/usage_FAQ/#what-does-the-error-string-state-may-be-inconsistent-cannot-query-as-a-query-result-mean", 
            "text": "Sometimes, a validating peer will be out of sync with the rest of the network.  Although determining this condition is not always possible, validating peers make a best effort determination to detect it, and internally mark themselves as out of date.  When under this condition, rather than reply with out of date or potentially incorrect data, the peer will reply to chaincode queries with the error string \"state may be inconsistent, cannot query\".  In the future, more sophisticated reporting mechanisms may be introduced such as returning the stale value and a flag that the value is stale.", 
            "title": "What does the error string \"state may be inconsistent, cannot query\" as a query result mean?"
        }, 
        {
            "location": "/biz/usecases/", 
            "text": "Canonical Use Cases\n\n\n\n\nB2B Contract\n\n\nBusiness contracts can be codified to allow two or more parties to automate contractual agreements in a trusted way.  Although information on blockchain is naturally \u201cpublic\u201d, B2B contracts may require privacy control to protect sensitive business information from being disclosed to outside parties that also have access to the ledger.\n\n\n\n\nWhile confidential agreements are a key business case, there are many scenarios where contracts can and should be easily discoverable by all parties on a ledger. For example, a ledger used to create offers (asks) seeking bids, by definition, requires access without restriction. This type of contract may need to be standardized so that bidders can easily find them, effectively creating an electronic trading platform with smart contracts (aka chaincode).\n\n\nPersona\n\n\n\n\n\n\nContract participant \u2013 Contract counter parties\n\n\n\n\n\n\nThird party participant \u2013 A third party stakeholder guaranteeing the integrity of the contract.\n\n\n\n\n\n\nKey Components\n\n\n\n\n\n\nMulti-sig contract activation - When a contract is first deployed by one of the counter parties, it will be in the pending activation state. To activate a contract, signatures from other counterparties and/or third party participants are required.\n\n\n\n\n\n\nMulti-sig contract execution - Some contracts will require one of many signatures to execute. For example, in trade finance, a payment instruction can only be executed if either the recipient or an authorized third party (e.g. UPS) confirms the shipment of the good.\n\n\n\n\n\n\nDiscoverability - If a contract is a business offer seeking bids, it must be easily searchable. In addition, such contracts must have the built-in intelligence to evaluate, select and honor bids.\n\n\n\n\n\n\nAtomicity of contract execution - Atomicity of the contract is needed to guarantee that asset transfers can only occur when payment is received (Delivery vs. Payment). If any step in the execution process fails, the entire transaction must be rolled back.\n\n\n\n\n\n\nContract to chain-code communication - Contracts must be able to communicate with chaincodes that are deployed on the same ledger.\n\n\n\n\n\n\nLonger Duration contract - Timer is required to support B2B contracts that have long execution windows.\n\n\n\n\n\n\nReuseable contracts - Often-used contracts can be standardized for reuse.\n\n\n\n\n\n\nAuditable contractual agreement - Any contract can be made auditable to third parties.\n\n\n\n\n\n\nContract life-cycle management - B2B contracts are unique and cannot always be standardized. An efficient contract management system is needed to enhance the scalability of the ledger network.\n\n\n\n\n\n\nValidation access \u2013 Only nodes with validation rights are allowed to validate transactions of a B2B contract.\n\n\n\n\n\n\nView access \u2013 B2B contracts may include confidential information, so only accounts with predefined access rights are allowed to view and interrogate them.\n\n\n\n\n\n\n\n\nManufacturing Supply Chain\n\n\nFinal assemblers, such as automobile manufacturers, can create a supply chain network managed by its peers and suppliers so that a final assembler can better manage its suppliers and be more responsive to events that would require vehicle recalls (possibly triggered by faulty parts provided by a supplier). The blockchain fabric must provide a standard protocol to allow every participant on a supply chain network to input and track numbered parts that are produced and used on a specific vehicle.\n\n\nWhy is this specific example an abstract use case? Because while all blockchain cases store immutable information, and some add the need for transfer of assets between parties, this case emphasizes the need to provide deep searchability backwards through as many as 5-10 transaction layers. This backwards search capability is the core of establishing provenance of any manufactured good that is made up of other component goods and supplies.\n\n\n\n\nPersona\n\n\n\n\n\n\nFinal Assembler \u2013 The business entity that performs the final assembly of a product.\n\n\n\n\n\n\nPart supplier \u2013 Supplier of parts. Suppliers can also be assemblers by assembling parts that they receive from their  sub-suppliers, and then sending their finished product to the final (root) assembler.\n\n\n\n\n\n\nKey Components\n\n\n\n\n\n\nPayment upon delivery of goods - Integration with off-chain payment systems is required, so that payment instructions can be sent when parts are received.\n\n\n\n\n\n\nThird party Audit -  All supplied parts must be auditable by third parties. For example, regulators might need to track the total number of parts supplied by a specific supplier, for tax accounting purposes.\n\n\n\n\n\n\nObfuscation of shipments - Balances must be obfuscated so that no supplier can deduce the business activities of any other supplier.\n\n\n\n\n\n\nObfuscation of market size - Total balances must be obfuscated so that part suppliers cannot deduce their own market share to use as leverage when negotiating contractual terms.\n\n\n\n\n\n\nValidation Access \u2013 Only nodes with validation rights are allowed to validate transactions (shipment of parts).\n\n\n\n\n\n\nView access \u2013 Only accounts with view access rights are allowed to interrogate balances of shipped parts and available parts.\n\n\n\n\n\n\n\n\nAsset Depository\n\n\nAssets such as financial securities must be able to be dematerialized on a blockchain network so that all stakeholders of an asset type will have direct access to that asset, allowing them to initiate trades and acquire information on an asset without going through layers of intermediaries. Trades should be settled in near real time and all stakeholders must be able to access asset information in near real time. A stakeholder should be able to add business rules on any given asset type, as one example of using automation logic to further reduce operating costs.\n\n\n\nPersona\n\n\n\n\n\n\nInvestor \u2013 Beneficial and legal owner of an asset.\n\n\n\n\n\n\nIssuer \u2013 Business entity that issued the asset which is now dematerialized on the ledger network.\n\n\n\n\n\n\nCustodian \u2013 Hired by investors to manage their assets, and offer other value-add services on top of the assets being managed.\n\n\n\n\n\n\nSecurities Depository \u2013 Depository of dematerialized assets.\n\n\n\n\n\n\nKey Components\n\n\n\n\n\n\nAsset to cash - Integration with off-chain payment systems is necessary so that issuers can make payments to and receive payments from investors.\n\n\n\n\n\n\nReference Rate - Some types of assets (such as floating rate notes) may have attributes linked to external data (such as  reference rate), and such information must be fed into the ledger network.\n\n\n\n\n\n\nAsset Timer - Many types of financial assets have predefined life spans and are required to make periodic payments to their owners, so a timer is required to automate the operation management of these assets.\n\n\n\n\n\n\nAsset Auditor - Asset transactions must be made auditable to third parties. For example, regulators may want to audit transactions and movements of assets to measure market risks.\n\n\n\n\n\n\nObfuscation of account balances - Individual account balances must be obfuscated so that no one can deduce the exact amount that an investor owns.\n\n\n\n\n\n\nValidation Access \u2013 Only nodes with validation rights are allowed to validate transactions that update the balances of an asset type (this could be restricted to CSD and/or the issuer).\n\n\n\n\n\n\nView access \u2013 Only accounts with view access rights are allowed to interrogate the chaincode that defines an asset type. If an asset represents shares of publicly traded companies, then the view access right must be granted to every entity on the network.\n\n\n\n\n\n\n\n\nExtended Use Cases\n\n\nThe following extended use cases examine additional requirements and scenarios.\n\n\nOne Trade, One Contract\n\n\nFrom the time that a trade is captured by the front office until the trade is finally settled, only one contract that specifies the trade will be created and used by all participants. The middle office will enrich the same electronic contract submitted by the front office, and that same contract will then be used by counter parties to confirm and affirm the trade. Finally, securities depository will settle the trade by executing the trading instructions specified on the contract. When dealing with bulk trades, the original contract can be broken down into sub-contracts that are always linked to the original parent contract.\n\n\n\n\n\n\nDirect Communication\n\n\nCompany A announces its intention to raise 2 Billion USD by way of rights issue. Because this is a voluntary action, Company A needs to ensure that complete details of the offer are sent to shareholders in real time, regardless of how many intermediaries are involved in the process (such as receiving/paying agents, CSD, ICSD, local/global custodian banks, asset management firms, etc). Once a shareholder has made a decision, that decision will also be processed and settled (including the new issuance of shares) in real time. If a shareholder sold its rights to a third party, the securities depository must be able to record the new shares under the name of their new rightful owner.\n\n\n\n\n\n\nSeparation of Asset Ownership and Custodian\u2019s Duties\n\n\nAssets should always be owned by their actual owners, and asset owners must be able to allow third-party professionals to manage their assets without having to pass legal ownership of assets to third parties (such as nominee or street name entities). If issuers need to send messages or payments to asset owners (for example, listed share holders), issuers send them directly to asset owners. Third-party asset managers and/or custodians can always buy, sell, and lend assets on behalf of their owners. Under this arrangement, asset custodians can focus on providing value-add services to shareowners, without worrying about asset ownership duties such as managing and redirecting payments from issuers to shareowners.\n\n\n\n\n\n\nInteroperability of Assets\n\n\nIf an organization requires 20,000 units of asset B, but instead owns 10,000 units of asset A, it needs a way to exchange asset A for asset B. Though the current market might not offer enough liquidity to fulfill this trade quickly, there might be plenty of liquidity available between asset A and asset C, and also between asset C and asset B. Instead of settling for market limits on direct trading (A for B) in this case, a chain network connects buyers with \"buried\" sellers, finds the best match (which could be buried under several layers of assets), and executes the transaction.", 
            "title": "Usecase"
        }, 
        {
            "location": "/biz/usecases/#canonical-use-cases", 
            "text": "", 
            "title": "Canonical Use Cases"
        }, 
        {
            "location": "/biz/usecases/#b2b-contract", 
            "text": "Business contracts can be codified to allow two or more parties to automate contractual agreements in a trusted way.  Although information on blockchain is naturally \u201cpublic\u201d, B2B contracts may require privacy control to protect sensitive business information from being disclosed to outside parties that also have access to the ledger.   While confidential agreements are a key business case, there are many scenarios where contracts can and should be easily discoverable by all parties on a ledger. For example, a ledger used to create offers (asks) seeking bids, by definition, requires access without restriction. This type of contract may need to be standardized so that bidders can easily find them, effectively creating an electronic trading platform with smart contracts (aka chaincode).", 
            "title": "B2B Contract"
        }, 
        {
            "location": "/biz/usecases/#persona", 
            "text": "Contract participant \u2013 Contract counter parties    Third party participant \u2013 A third party stakeholder guaranteeing the integrity of the contract.", 
            "title": "Persona"
        }, 
        {
            "location": "/biz/usecases/#key-components", 
            "text": "Multi-sig contract activation - When a contract is first deployed by one of the counter parties, it will be in the pending activation state. To activate a contract, signatures from other counterparties and/or third party participants are required.    Multi-sig contract execution - Some contracts will require one of many signatures to execute. For example, in trade finance, a payment instruction can only be executed if either the recipient or an authorized third party (e.g. UPS) confirms the shipment of the good.    Discoverability - If a contract is a business offer seeking bids, it must be easily searchable. In addition, such contracts must have the built-in intelligence to evaluate, select and honor bids.    Atomicity of contract execution - Atomicity of the contract is needed to guarantee that asset transfers can only occur when payment is received (Delivery vs. Payment). If any step in the execution process fails, the entire transaction must be rolled back.    Contract to chain-code communication - Contracts must be able to communicate with chaincodes that are deployed on the same ledger.    Longer Duration contract - Timer is required to support B2B contracts that have long execution windows.    Reuseable contracts - Often-used contracts can be standardized for reuse.    Auditable contractual agreement - Any contract can be made auditable to third parties.    Contract life-cycle management - B2B contracts are unique and cannot always be standardized. An efficient contract management system is needed to enhance the scalability of the ledger network.    Validation access \u2013 Only nodes with validation rights are allowed to validate transactions of a B2B contract.    View access \u2013 B2B contracts may include confidential information, so only accounts with predefined access rights are allowed to view and interrogate them.", 
            "title": "Key Components"
        }, 
        {
            "location": "/biz/usecases/#manufacturing-supply-chain", 
            "text": "Final assemblers, such as automobile manufacturers, can create a supply chain network managed by its peers and suppliers so that a final assembler can better manage its suppliers and be more responsive to events that would require vehicle recalls (possibly triggered by faulty parts provided by a supplier). The blockchain fabric must provide a standard protocol to allow every participant on a supply chain network to input and track numbered parts that are produced and used on a specific vehicle.  Why is this specific example an abstract use case? Because while all blockchain cases store immutable information, and some add the need for transfer of assets between parties, this case emphasizes the need to provide deep searchability backwards through as many as 5-10 transaction layers. This backwards search capability is the core of establishing provenance of any manufactured good that is made up of other component goods and supplies.", 
            "title": "Manufacturing Supply Chain"
        }, 
        {
            "location": "/biz/usecases/#persona_1", 
            "text": "Final Assembler \u2013 The business entity that performs the final assembly of a product.    Part supplier \u2013 Supplier of parts. Suppliers can also be assemblers by assembling parts that they receive from their  sub-suppliers, and then sending their finished product to the final (root) assembler.", 
            "title": "Persona"
        }, 
        {
            "location": "/biz/usecases/#key-components_1", 
            "text": "Payment upon delivery of goods - Integration with off-chain payment systems is required, so that payment instructions can be sent when parts are received.    Third party Audit -  All supplied parts must be auditable by third parties. For example, regulators might need to track the total number of parts supplied by a specific supplier, for tax accounting purposes.    Obfuscation of shipments - Balances must be obfuscated so that no supplier can deduce the business activities of any other supplier.    Obfuscation of market size - Total balances must be obfuscated so that part suppliers cannot deduce their own market share to use as leverage when negotiating contractual terms.    Validation Access \u2013 Only nodes with validation rights are allowed to validate transactions (shipment of parts).    View access \u2013 Only accounts with view access rights are allowed to interrogate balances of shipped parts and available parts.", 
            "title": "Key Components"
        }, 
        {
            "location": "/biz/usecases/#asset-depository", 
            "text": "Assets such as financial securities must be able to be dematerialized on a blockchain network so that all stakeholders of an asset type will have direct access to that asset, allowing them to initiate trades and acquire information on an asset without going through layers of intermediaries. Trades should be settled in near real time and all stakeholders must be able to access asset information in near real time. A stakeholder should be able to add business rules on any given asset type, as one example of using automation logic to further reduce operating costs.", 
            "title": "Asset Depository"
        }, 
        {
            "location": "/biz/usecases/#persona_2", 
            "text": "Investor \u2013 Beneficial and legal owner of an asset.    Issuer \u2013 Business entity that issued the asset which is now dematerialized on the ledger network.    Custodian \u2013 Hired by investors to manage their assets, and offer other value-add services on top of the assets being managed.    Securities Depository \u2013 Depository of dematerialized assets.", 
            "title": "Persona"
        }, 
        {
            "location": "/biz/usecases/#key-components_2", 
            "text": "Asset to cash - Integration with off-chain payment systems is necessary so that issuers can make payments to and receive payments from investors.    Reference Rate - Some types of assets (such as floating rate notes) may have attributes linked to external data (such as  reference rate), and such information must be fed into the ledger network.    Asset Timer - Many types of financial assets have predefined life spans and are required to make periodic payments to their owners, so a timer is required to automate the operation management of these assets.    Asset Auditor - Asset transactions must be made auditable to third parties. For example, regulators may want to audit transactions and movements of assets to measure market risks.    Obfuscation of account balances - Individual account balances must be obfuscated so that no one can deduce the exact amount that an investor owns.    Validation Access \u2013 Only nodes with validation rights are allowed to validate transactions that update the balances of an asset type (this could be restricted to CSD and/or the issuer).    View access \u2013 Only accounts with view access rights are allowed to interrogate the chaincode that defines an asset type. If an asset represents shares of publicly traded companies, then the view access right must be granted to every entity on the network.", 
            "title": "Key Components"
        }, 
        {
            "location": "/biz/usecases/#extended-use-cases", 
            "text": "The following extended use cases examine additional requirements and scenarios.", 
            "title": "Extended Use Cases"
        }, 
        {
            "location": "/biz/usecases/#one-trade-one-contract", 
            "text": "From the time that a trade is captured by the front office until the trade is finally settled, only one contract that specifies the trade will be created and used by all participants. The middle office will enrich the same electronic contract submitted by the front office, and that same contract will then be used by counter parties to confirm and affirm the trade. Finally, securities depository will settle the trade by executing the trading instructions specified on the contract. When dealing with bulk trades, the original contract can be broken down into sub-contracts that are always linked to the original parent contract.", 
            "title": "One Trade, One Contract"
        }, 
        {
            "location": "/biz/usecases/#direct-communication", 
            "text": "Company A announces its intention to raise 2 Billion USD by way of rights issue. Because this is a voluntary action, Company A needs to ensure that complete details of the offer are sent to shareholders in real time, regardless of how many intermediaries are involved in the process (such as receiving/paying agents, CSD, ICSD, local/global custodian banks, asset management firms, etc). Once a shareholder has made a decision, that decision will also be processed and settled (including the new issuance of shares) in real time. If a shareholder sold its rights to a third party, the securities depository must be able to record the new shares under the name of their new rightful owner.", 
            "title": "Direct Communication"
        }, 
        {
            "location": "/biz/usecases/#separation-of-asset-ownership-and-custodians-duties", 
            "text": "Assets should always be owned by their actual owners, and asset owners must be able to allow third-party professionals to manage their assets without having to pass legal ownership of assets to third parties (such as nominee or street name entities). If issuers need to send messages or payments to asset owners (for example, listed share holders), issuers send them directly to asset owners. Third-party asset managers and/or custodians can always buy, sell, and lend assets on behalf of their owners. Under this arrangement, asset custodians can focus on providing value-add services to shareowners, without worrying about asset ownership duties such as managing and redirecting payments from issuers to shareowners.", 
            "title": "Separation of Asset Ownership and Custodian\u2019s Duties"
        }, 
        {
            "location": "/biz/usecases/#interoperability-of-assets", 
            "text": "If an organization requires 20,000 units of asset B, but instead owns 10,000 units of asset A, it needs a way to exchange asset A for asset B. Though the current market might not offer enough liquidity to fulfill this trade quickly, there might be plenty of liquidity available between asset A and asset C, and also between asset C and asset B. Instead of settling for market limits on direct trading (A for B) in this case, a chain network connects buyers with \"buried\" sellers, finds the best match (which could be buried under several layers of assets), and executes the transaction.", 
            "title": "Interoperability of Assets"
        }, 
        {
            "location": "/dev-setup/ca-setup/", 
            "text": "Certificate Authority (CA) Setup\n\n\nOverview\n\n\nThe \nCertificate Authority\n (CA) provides a number of certificate services to users of a blockchain.  More specifically, these services relate to \nuser enrollment\n, \ntransactions\n deployed or invoked on the blockchain, and \nTLS\n-secured connections between users or components of the blockchain.\n\n\nEnrollment Certificate Authority\n\n\nThe \nenrollment certificate authority\n (ECA) is the place where new users are initially registered with the blockchain and where those users can then request an \nenrollment certificate pair\n.  One certificate is for data signing, one is for data encryption.  The public keys to be embedded in the certificates have to be of type ECDSA, whereby the key for data encryption is then converted by the user to be used in an \nECIES\n (Elliptic Curve Integrated Encryption System) fashion.\n\n\nTransaction Certificate Authority\n\n\nOnce a user is enrolled, he or she can request \ntransaction certificates\n from the \ntransaction certificate authority\n (TCA) to be used for deployment and invocation transactions on the blockchain.  Although a single transaction certificate can be used for multiple transactions, for privacy reasons it is recommended to use a new transaction certificate for each transaction.\n\n\nTLS Certificate Authority\n\n\nIn addition to enrollment and transaction certificates, users of the blockchain need \nTLS certificates\n for TLS-securing their communication channels.  TLS certificates can be requested from the \nTLS certificate authority\n (TLSCA).\n\n\nConfiguration\n\n\nAll CA services are provided by a single process, which can be configured to some extent by setting parameters in the CA configuration file membersrvc.yaml, which is located in root of the same directory as the CA binary.  More specifically, the following parameters can be set:\n\n\n\n\nserver.gomaxprocs\n: limits the number of operating system threads used by the CA.\n\n\nserver.rootpath\n: the root path of the directory where the CA stores its state.\n\n\nserver.cadir\n: the name of the directory where the CA stores its state.\n\n\nserver.port\n: the port at which all CA services listen (multiplexing of services over the same port is provided by \nGRPC\n).\n\n\n\n\nFurthermore, logging levels can be enabled/disabled by adjusting the following settings:\n\n\n\n\nlogging.trace\n (off by default, useful for debugging the code only)\n\n\nlogging.info\n\n\nlogging.warning\n\n\nlogging.error\n\n\nlogging.panic\n\n\n\n\nAlternatively, these fields can be set via environment variables, which---if set---have precedence over entries in the yaml file.  The corresponding environment variables are named as follows:\n\n\nMEMBERSRVC_CA_SERVER_GOMAXPROCS\nMEMBERSRVC_CA_SERVER_ROOTPATH\nMEMBERSRVC_CA_SERVER_CADIR\nMEMBERSRVC_CA_SERVER_PORT\n\n\n\nIn addition, the CA may be preloaded with registered users, where each user's name, roles, and password are specified:\n\n\neca:\n    users:\n        alice: 2 DRJ20pEql15a\n        bob: 4 7avZQLwcUe9q\n\n\n\nThe role value is simply a bitmask of the following:\n\n\nCLIENT = 1;\nPEER = 2;\nVALIDATOR = 4;\nAUDITOR = 8;\n\n\n\nFor example, a peer who is also a validator would have a role value of 6.\n\n\nWhen the CA is started for the first time, it will generate all of its required states (e.g., internal databases, CA certificates, blockchain keys, etc.) and writes this state to the directory given in its configuration.  The certificates for the CA services (i.e., for the ECA, TCA, and TLSCA) are self-signed as the current default.  If those certificates shall be signed by some root CA, this can be done manually by using the \n*.priv\n and \n*.pub\n private and public keys in the CA state directory, and replacing the self-signed \n*.cert\n certificates with root-signed ones..  The next time the CA is launched, it will read and use those root-signed certificates.\n\n\nBuild and Run\n\n\nThe CA can be built with the following command executed in the \nmembersrvc\n directory:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake membersrvc\n\n\n\nThe CA can be started with the following command:\n\n\nbuild/bin/membersrvc\n\n\n\nThe CA looks for an \nmembersrvc.yaml\n configuration file in $GOPATH/src/github.com/hyperledger/fabric/membersrvc.  If the CA is started for the first time, it creates all its required state (e.g., internal databases, CA certificates, blockchain keys, etc.) and write each state to the directory given in the CA configuration.", 
            "title": "Ca setup"
        }, 
        {
            "location": "/dev-setup/ca-setup/#certificate-authority-ca-setup", 
            "text": "", 
            "title": "Certificate Authority (CA) Setup"
        }, 
        {
            "location": "/dev-setup/ca-setup/#overview", 
            "text": "The  Certificate Authority  (CA) provides a number of certificate services to users of a blockchain.  More specifically, these services relate to  user enrollment ,  transactions  deployed or invoked on the blockchain, and  TLS -secured connections between users or components of the blockchain.", 
            "title": "Overview"
        }, 
        {
            "location": "/dev-setup/ca-setup/#enrollment-certificate-authority", 
            "text": "The  enrollment certificate authority  (ECA) is the place where new users are initially registered with the blockchain and where those users can then request an  enrollment certificate pair .  One certificate is for data signing, one is for data encryption.  The public keys to be embedded in the certificates have to be of type ECDSA, whereby the key for data encryption is then converted by the user to be used in an  ECIES  (Elliptic Curve Integrated Encryption System) fashion.", 
            "title": "Enrollment Certificate Authority"
        }, 
        {
            "location": "/dev-setup/ca-setup/#transaction-certificate-authority", 
            "text": "Once a user is enrolled, he or she can request  transaction certificates  from the  transaction certificate authority  (TCA) to be used for deployment and invocation transactions on the blockchain.  Although a single transaction certificate can be used for multiple transactions, for privacy reasons it is recommended to use a new transaction certificate for each transaction.", 
            "title": "Transaction Certificate Authority"
        }, 
        {
            "location": "/dev-setup/ca-setup/#tls-certificate-authority", 
            "text": "In addition to enrollment and transaction certificates, users of the blockchain need  TLS certificates  for TLS-securing their communication channels.  TLS certificates can be requested from the  TLS certificate authority  (TLSCA).", 
            "title": "TLS Certificate Authority"
        }, 
        {
            "location": "/dev-setup/ca-setup/#configuration", 
            "text": "All CA services are provided by a single process, which can be configured to some extent by setting parameters in the CA configuration file membersrvc.yaml, which is located in root of the same directory as the CA binary.  More specifically, the following parameters can be set:   server.gomaxprocs : limits the number of operating system threads used by the CA.  server.rootpath : the root path of the directory where the CA stores its state.  server.cadir : the name of the directory where the CA stores its state.  server.port : the port at which all CA services listen (multiplexing of services over the same port is provided by  GRPC ).   Furthermore, logging levels can be enabled/disabled by adjusting the following settings:   logging.trace  (off by default, useful for debugging the code only)  logging.info  logging.warning  logging.error  logging.panic   Alternatively, these fields can be set via environment variables, which---if set---have precedence over entries in the yaml file.  The corresponding environment variables are named as follows:  MEMBERSRVC_CA_SERVER_GOMAXPROCS\nMEMBERSRVC_CA_SERVER_ROOTPATH\nMEMBERSRVC_CA_SERVER_CADIR\nMEMBERSRVC_CA_SERVER_PORT  In addition, the CA may be preloaded with registered users, where each user's name, roles, and password are specified:  eca:\n    users:\n        alice: 2 DRJ20pEql15a\n        bob: 4 7avZQLwcUe9q  The role value is simply a bitmask of the following:  CLIENT = 1;\nPEER = 2;\nVALIDATOR = 4;\nAUDITOR = 8;  For example, a peer who is also a validator would have a role value of 6.  When the CA is started for the first time, it will generate all of its required states (e.g., internal databases, CA certificates, blockchain keys, etc.) and writes this state to the directory given in its configuration.  The certificates for the CA services (i.e., for the ECA, TCA, and TLSCA) are self-signed as the current default.  If those certificates shall be signed by some root CA, this can be done manually by using the  *.priv  and  *.pub  private and public keys in the CA state directory, and replacing the self-signed  *.cert  certificates with root-signed ones..  The next time the CA is launched, it will read and use those root-signed certificates.", 
            "title": "Configuration"
        }, 
        {
            "location": "/dev-setup/ca-setup/#build-and-run", 
            "text": "The CA can be built with the following command executed in the  membersrvc  directory:  cd $GOPATH/src/github.com/hyperledger/fabric\nmake membersrvc  The CA can be started with the following command:  build/bin/membersrvc  The CA looks for an  membersrvc.yaml  configuration file in $GOPATH/src/github.com/hyperledger/fabric/membersrvc.  If the CA is started for the first time, it creates all its required state (e.g., internal databases, CA certificates, blockchain keys, etc.) and write each state to the directory given in the CA configuration.", 
            "title": "Build and Run"
        }, 
        {
            "location": "/dev-setup/devenv/", 
            "text": "Setting up the development environment\n\n\nOverview\n\n\nThe current development environment utilizes Vagrant running an Ubuntu image, which in turn launches Docker containers. Conceptually, the Host launches a VM, which in turn launches Docker containers.\n\n\nHost -\n VM -\n Docker\n\n\nThis model allows developers to leverage their favorite OS/editors and execute the system in a controlled environment that is consistent amongst the development team.\n\n\n\n\nNote that your Host should not run within a VM. If you attempt this, the VM within your Host may fail to boot with a message indicating that VT-x is not available.\n\n\n\n\nPrerequisites\n\n\n\n\nGit client\n\n\nGo\n - 1.6 or later\n\n\nVagrant\n - 1.7.4 or later\n\n\nVirtualBox\n - 5.0 or later\n\n\n\n\nBIOS Enabled Virtualization - Varies based on hardware\n\n\n\n\n\n\nNote: The BIOS Enabled Virtualization may be within the CPU or Security settings of the BIOS\n\n\n\n\n\n\nSteps\n\n\nSet your GOPATH\n\n\nMake sure you have properly setup your Host's \nGOPATH environment variable\n. This allows for both building within the Host and the VM.\n\n\nNote to Windows users\n\n\nIf you are running Windows, before running any \ngit clone\n commands, run the following command.\n\n\ngit config --get core.autocrlf\n\n\n\n\nIf \ncore.autocrlf\n is set to \ntrue\n, you must set it to \nfalse\n by running\n\n\ngit config --global core.autocrlf false\n\n\n\n\nIf you continue with \ncore.autocrlf\n set to \ntrue\n, the \nvagrant up\n command will fail with the error \n./setup.sh: /bin/bash^M: bad interpreter: No such file or directory\n\n\nCloning the Peer project\n\n\nCreate a fork of the \nfabric\n repository using the GitHub web interface. Next, clone your fork in the appropriate location.\n\n\ncd $GOPATH/src\nmkdir -p github.com/hyperledger\ncd github.com/hyperledger\ngit clone https://github.com/\nusername\n/fabric.git\n\n\n\n\nBoostrapping the VM using Vagrant\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant up\n\n\n\n\nNOTE:\n If you intend to run the development environment behind an HTTP Proxy, you need to configure the guest so that the provisioning process may complete.  You can achieve this via the \nvagrant-proxyconf\n plugin. Install with \nvagrant plugin install vagrant-proxyconf\n and then set the VAGRANT_HTTP_PROXY and VAGRANT_HTTPS_PROXY environment variables \nbefore\n you execute \nvagrant up\n. More details are available here: https://github.com/tmatilai/vagrant-proxyconf/\n\n\nNOTE:\n The first time you run this command it may take quite a while to complete (it could take 30 minutes or more depending on your environment) and at times it may look like it's not doing anything. As long you don't get any error messages just leave it alone, it's all good, it's just cranking.\n\n\nNOTE to Windows 10 Users:\n There is a known problem with vagrant on Windows 10 (see \nmitchellh/vagrant#6754\n). If the \nvagrant up\n command fails it may be because you do not have Microsoft Visual C++ Redistributable installed. You can download the missing package at the following address: http://www.microsoft.com/en-us/download/details.aspx?id=8328\n\n\nOnce complete, you should now be able to SSH into your new VM with the following command from the same directory.\n\n\nvagrant ssh\n\n\n\nOnce inside the VM, you can find the peer project under $GOPATH/src/github.com/hyperledger/fabric (as well as /hyperledger).\n\n\nNOTE:\n any time you \ngit clone\n any of the projects in your Host's fabric directory (under $GOPATH/src/github.com/hyperledger/fabric), the update will be instantly available within the VM fabric directory.", 
            "title": "Devenv"
        }, 
        {
            "location": "/dev-setup/devenv/#setting-up-the-development-environment", 
            "text": "", 
            "title": "Setting up the development environment"
        }, 
        {
            "location": "/dev-setup/devenv/#overview", 
            "text": "The current development environment utilizes Vagrant running an Ubuntu image, which in turn launches Docker containers. Conceptually, the Host launches a VM, which in turn launches Docker containers.  Host -  VM -  Docker  This model allows developers to leverage their favorite OS/editors and execute the system in a controlled environment that is consistent amongst the development team.   Note that your Host should not run within a VM. If you attempt this, the VM within your Host may fail to boot with a message indicating that VT-x is not available.", 
            "title": "Overview"
        }, 
        {
            "location": "/dev-setup/devenv/#prerequisites", 
            "text": "Git client  Go  - 1.6 or later  Vagrant  - 1.7.4 or later  VirtualBox  - 5.0 or later   BIOS Enabled Virtualization - Varies based on hardware    Note: The BIOS Enabled Virtualization may be within the CPU or Security settings of the BIOS", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/dev-setup/devenv/#steps", 
            "text": "", 
            "title": "Steps"
        }, 
        {
            "location": "/dev-setup/devenv/#set-your-gopath", 
            "text": "Make sure you have properly setup your Host's  GOPATH environment variable . This allows for both building within the Host and the VM.", 
            "title": "Set your GOPATH"
        }, 
        {
            "location": "/dev-setup/devenv/#note-to-windows-users", 
            "text": "If you are running Windows, before running any  git clone  commands, run the following command.  git config --get core.autocrlf  If  core.autocrlf  is set to  true , you must set it to  false  by running  git config --global core.autocrlf false  If you continue with  core.autocrlf  set to  true , the  vagrant up  command will fail with the error  ./setup.sh: /bin/bash^M: bad interpreter: No such file or directory", 
            "title": "Note to Windows users"
        }, 
        {
            "location": "/dev-setup/devenv/#cloning-the-peer-project", 
            "text": "Create a fork of the  fabric  repository using the GitHub web interface. Next, clone your fork in the appropriate location.  cd $GOPATH/src\nmkdir -p github.com/hyperledger\ncd github.com/hyperledger\ngit clone https://github.com/ username /fabric.git", 
            "title": "Cloning the Peer project"
        }, 
        {
            "location": "/dev-setup/devenv/#boostrapping-the-vm-using-vagrant", 
            "text": "cd $GOPATH/src/github.com/hyperledger/fabric/devenv\nvagrant up  NOTE:  If you intend to run the development environment behind an HTTP Proxy, you need to configure the guest so that the provisioning process may complete.  You can achieve this via the  vagrant-proxyconf  plugin. Install with  vagrant plugin install vagrant-proxyconf  and then set the VAGRANT_HTTP_PROXY and VAGRANT_HTTPS_PROXY environment variables  before  you execute  vagrant up . More details are available here: https://github.com/tmatilai/vagrant-proxyconf/  NOTE:  The first time you run this command it may take quite a while to complete (it could take 30 minutes or more depending on your environment) and at times it may look like it's not doing anything. As long you don't get any error messages just leave it alone, it's all good, it's just cranking.  NOTE to Windows 10 Users:  There is a known problem with vagrant on Windows 10 (see  mitchellh/vagrant#6754 ). If the  vagrant up  command fails it may be because you do not have Microsoft Visual C++ Redistributable installed. You can download the missing package at the following address: http://www.microsoft.com/en-us/download/details.aspx?id=8328  Once complete, you should now be able to SSH into your new VM with the following command from the same directory.  vagrant ssh  Once inside the VM, you can find the peer project under $GOPATH/src/github.com/hyperledger/fabric (as well as /hyperledger).  NOTE:  any time you  git clone  any of the projects in your Host's fabric directory (under $GOPATH/src/github.com/hyperledger/fabric), the update will be instantly available within the VM fabric directory.", 
            "title": "Boostrapping the VM using Vagrant"
        }, 
        {
            "location": "/dev-setup/devnet-setup/", 
            "text": "Setting Up a Network For Development\n\n\nThis document covers setting up a network on your local machine for development using Docker containers.\n\n\nAll commands should be run from within the Vagrant environment described in \nSetting Up Development Environment\n.\nSee \nLogging Control\n for information on controlling\nlogging output from the \npeer\n and chaincodes.\n\n\nNote:\n When running with security enabled, follow the security setup instructions described in \nChaincode Development\n to set up the CA server and log in registered users before sending chaincode transactions. In this case peers started using Docker images need to point to the correct CA address (default is localhost). CA addresses have to be specified in \npeer/core.yaml\n variables paddr of eca, tca and tlsca. Furthermore, if you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).\n\n\nSetting up Docker image\n\n\nTo create a Docker image for the \nhyperledger/fabric\n, first clean out any active containers (hyperledger/fabric-peer and chaincode) using \ndocker ps -a\n and \ndocker rm\n commands. Second, remove any old images with \ndocker images\n and \ndocker rmi\n commands. \nCareful:\n Do not remove any other images (like busybox or hyperledger/fabric-baseimage) as they are needed for a correct execution.\n\n\nNow we are ready to build a new docker image:\n\n\n    cd $GOPATH/src/github.com/hyperledger/fabric\n    make peer-image\n\n\n\n\nCheck the available images again with \ndocker images\n, and you should see \nhyperledger/fabric-peer\n image.\n\n\nStarting up validating peers\n\n\nFrom the Vagrant environment, find out which IP address your docker0 interface is on with \nip add\n command. For example,\n\n\nvagrant@vagrant-ubuntu-trusty-64:/opt/gopath/src/github.com/hyperledger/fabric$ ip add\n\n\n detail removed \n\n\n3: docker0: \nNO-CARRIER,BROADCAST,MULTICAST,UP\n mtu 1500 qdisc noqueue state DOWN group default\n    link/ether 02:42:ad:be:70:cb brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:adff:febe:70cb/64 scope link\n       valid_lft forever preferred_lft forever\n\n\n\n\nYour output might contain something like \ninet 172.17.0.1/16 scope global docker0\n. That means docker0 interface is on IP address 172.17.0.1. Use that IP address for the \nCORE_VM_ENDPOINT\n option. For more information on the environment variables, see \ncore.yaml\n configuration file in the \nfabric\n repository.\n\n\nThe ID value of \nCORE_PEER_ID\n must be lowercase since we use the ID as part of chaincode containers we build, and docker does not accept uppercase. The ID must also be unique for each validating peer.\n\n\nBy default, we are using a consensus plugin called \nNOOPS\n, which doesn't really do consensus. If you want to use some other consensus plugin, see Using Consensus Plugin section at the end of the document.\n\n\nStart up the first validating peer:\n\n\ndocker run --rm -it -e CORE_VM_ENDPOINT=http://172.17.0.1:2375 -e CORE_PEER_ID=vp0 -e CORE_PEER_ADDRESSAUTODETECT=true hyperledger/fabric-peer peer node start\n\n\n\n\nIf starting the peer with security/privacy enabled, environment variables for security, CA address and peer's ID and password must be included:\n\n\ndocker run --rm -it -e CORE_VM_ENDPOINT=http://172.17.0.1:2375 -e CORE_PEER_ID=vp0 -e CORE_PEER_ADDRESSAUTODETECT=true -e CORE_SECURITY_ENABLED=true -e CORE_SECURITY_PRIVACY=true -e CORE_PEER_PKI_ECA_PADDR=172.17.0.1:50051 -e CORE_PEER_PKI_TCA_PADDR=172.17.0.1:50051 -e CORE_PEER_PKI_TLSCA_PADDR=172.17.0.1:50051 -e CORE_SECURITY_ENROLLID=vp0 -e CORE_SECURITY_ENROLLSECRET=vp0_secret  hyperledger/fabric-peer peer node start\n\n\n\n\nAdditionally, the validating peer \nenrollID\n and \nenrollSecret\n (\nvp0\n and \nvp0_secret\n) has to be added to \nmembersrvc.yaml\n.\n\n\nStart up the second validating peer:\n\n\nWe need to get the IP address of the first validating peer, which will act as the root node that the new peer will connect to. The address is printed out on the terminal window of the first peer (e.g. 172.17.0.2) and should be passed in with the \nCORE_PEER_DISCOVERY_ROOTNODE\n environment variable. We'll use \nvp1\n as the ID for the second validating peer.\n\n\ndocker run --rm -it -e CORE_VM_ENDPOINT=http://172.17.0.1:2375 -e CORE_PEER_ID=vp1 -e CORE_PEER_ADDRESSAUTODETECT=true -e CORE_SECURITY_ENABLED=true -e CORE_SECURITY_PRIVACY=true -e CORE_PEER_PKI_ECA_PADDR=172.17.0.1:50051 -e CORE_PEER_PKI_TCA_PADDR=172.17.0.1:50051 -e CORE_PEER_PKI_TLSCA_PADDR=172.17.0.1:50051 -e CORE_SECURITY_ENROLLID=vp1 -e CORE_SECURITY_ENROLLSECRET=vp1_secret -e CORE_PEER_DISCOVERY_ROOTNODE=172.17.0.2:30303 hyperledger/fabric-peer peer node start\n\n\n\n\nAgain, the validating peer \nenrollID\n and \nenrollSecret\n (\nvp1\n and \nvp1_secret\n) has to be added to \nmembersrvc.yaml\n.\n\n\nYou can start up a few more validating peers in a similar manner if you wish. Remember to change the peer ID and add the enrollID/enrollSecret to the \nmembersrvc.yaml\n.\n\n\nEnroll/Login a test user (if security is enabled):\n\n\nIf security is enabled, you must enroll a user with the certificate authority before sending requests. Choose a user that is already registered, i.e. added to the \nmembersrvc.yaml\n. Then, execute the command below to log in the user on the target validating peer. \nCORE_PEER_ADDRESS\n specifies the target validating peer for which the user is to be logged in.\n\n\nCORE_PEER_ADDRESS=172.17.0.2:30303 peer network login jim\n\n\n\n\nNote:\n The certificate authority allows the enrollID and enrollSecret credentials to be used only \nonce\n. Therefore, login by the same user from any other validating peer will result in an error. Currently, the application layer is responsible for duplicating the crypto material returned from the CA to other peer nodes. If you want to test secure transactions from more than one peer node without replicating the returned key and certificate, you can log in with a different user on other peer nodes.\n\n\nDeploy, Invoke, and Query a Chaincode\n\n\nNote:\n When security is enabled, modify the CLI commands to deploy, invoke, or query a chaincode to pass the username of a logged in user. To log in a registered user through the CLI, execute the login command from the section above. On the CLI the username is passed with the -u parameter.\n\n\nWe can use the sample chaincode to test the network. You may find the chaincode here \n$GOPATH/src/github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n.\n\n\nDeploy the chaincode to the network. We can deploy to any validating peer by specifying \nCORE_PEER_ADDRESS\n:\n\n\nCORE_PEER_ADDRESS=172.17.0.2:30303 peer chaincode deploy -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\nFunction\n:\ninit\n, \nArgs\n: [\na\n,\n100\n, \nb\n, \n200\n]}'\n\n\n\n\nWith security enabled, modify the command as follows:\n\n\nCORE_PEER_ADDRESS=172.17.0.2:30303 CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode deploy -u jim -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{\nFunction\n:\ninit\n, \nArgs\n: [\na\n,\n100\n, \nb\n, \n200\n]}'\n\n\n\n\nYou can watch for the message \"Received build request for chaincode spec\" on the output screen of all validating peers.\n\n\nNote:\n If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.\n\n\nOn successful completion, the above command will print the \"name\" assigned to the deployed chaincode. This \"name\" is used as the value of the \"-n\" parameter in invoke and query commands described below. For example the value of \"name\" could be\n\n\nbb540edfc1ee2ac0f5e2ec6000677f4cd1c6728046d5e32dede7fea11a42f86a6943b76a8f9154f4792032551ed320871ff7b7076047e4184292e01e3421889c\n\n\n\nIn a script the name can be captured for subsequent use. For example, run\n\n\nNAME=`CORE_PEER_ADDRESS=172.17.0.2:30303 CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode deploy ...`\n\n\n\nand then replace \nname_value_returned_from_deploy_command\n in the examples below with \n$NAME\n.\n\n\nWe can run an invoke transaction to move 10 units from the value of \na\n to the value of \nb\n:\n\n\nCORE_PEER_ADDRESS=172.17.0.2:30303 peer chaincode invoke -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \ninvoke\n, \nArgs\n: [\na\n, \nb\n, \n10\n]}'\n\n\n\n\nWith security enabled, modify the command as follows:\n\n\nCORE_PEER_ADDRESS=172.17.0.2:30303 CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode invoke -u jim -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \ninvoke\n, \nArgs\n: [\na\n, \nb\n, \n10\n]}'\n\n\n\n\nWe can also run a query to see the current value \na\n has:\n\n\nCORE_PEER_ADDRESS=172.17.0.2:30303 peer chaincode query -l golang -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \nquery\n, \nArgs\n: [\na\n]}'\n\n\n\n\nWith security enabled, modify the command as follows:\n\n\nCORE_PEER_ADDRESS=172.17.0.2:30303 CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode query -u jim -l golang -n \nname_value_returned_from_deploy_command\n -c '{\nFunction\n: \nquery\n, \nArgs\n: [\na\n]}'\n\n\n\n\nUsing Consensus Plugin\n\n\nA consensus plugin might require some specific configuration that you need to set up. For example, to use Byzantine consensus plugin provided as part of the fabric, perform the following configuration:\n\n\n\n\nIn \ncore.yaml\n, set the \npeer.validator.consensus\n value to \npbft\n\n\nIn \ncore.yaml\n, make sure the \npeer.id\n is set sequentially as \nvpX\n where \nX\n is an integer that starts from \n0\n and goes to \nN-1\n. For example, with 4 validating peers, set the \npeer.id\n to\nvp0\n, \nvp1\n, \nvp2\n, \nvp3\n.\n\n\nIn \nconsensus/obcpbft/config.yaml\n, set the \ngeneral.mode\n value to either \nclassic\n, \nbatch\n, or \nsieve\n, and the \ngeneral.N\n value to the number of validating peers on the network (if you do \nbatch\n, also set \ngeneral.batchsize\n to the number of transactions per batch)\n\n\nIn \nconsensus/obcpbft/config.yaml\n, optionally set timer values for the batch period (\ngeneral.timeout.batch\n), the acceptable delay between request and execution (\ngeneral.timeout.request\n), and for view-change (\ngeneral.timeout.viewchange\n)\n\n\n\n\nSee \ncore.yaml\n and \nconsensus/obcpbft/config.yaml\n for more detail.\n\n\nAll of these setting may be overriden via the command line environment variables, eg. \nCORE_PEER_VALIDATOR_CONSENSUS_PLUGIN=pbft\n or \nCORE_PBFT_GENERAL_MODE=sieve", 
            "title": "Devnet setup"
        }, 
        {
            "location": "/dev-setup/devnet-setup/#setting-up-a-network-for-development", 
            "text": "This document covers setting up a network on your local machine for development using Docker containers.  All commands should be run from within the Vagrant environment described in  Setting Up Development Environment .\nSee  Logging Control  for information on controlling\nlogging output from the  peer  and chaincodes.  Note:  When running with security enabled, follow the security setup instructions described in  Chaincode Development  to set up the CA server and log in registered users before sending chaincode transactions. In this case peers started using Docker images need to point to the correct CA address (default is localhost). CA addresses have to be specified in  peer/core.yaml  variables paddr of eca, tca and tlsca. Furthermore, if you are enabling security and privacy on the peer process with environment variables, it is important to include these environment variables in the command when executing all subsequent peer operations (e.g. deploy, invoke, or query).", 
            "title": "Setting Up a Network For Development"
        }, 
        {
            "location": "/dev-setup/devnet-setup/#setting-up-docker-image", 
            "text": "To create a Docker image for the  hyperledger/fabric , first clean out any active containers (hyperledger/fabric-peer and chaincode) using  docker ps -a  and  docker rm  commands. Second, remove any old images with  docker images  and  docker rmi  commands.  Careful:  Do not remove any other images (like busybox or hyperledger/fabric-baseimage) as they are needed for a correct execution.  Now we are ready to build a new docker image:      cd $GOPATH/src/github.com/hyperledger/fabric\n    make peer-image  Check the available images again with  docker images , and you should see  hyperledger/fabric-peer  image.", 
            "title": "Setting up Docker image"
        }, 
        {
            "location": "/dev-setup/devnet-setup/#starting-up-validating-peers", 
            "text": "From the Vagrant environment, find out which IP address your docker0 interface is on with  ip add  command. For example,  vagrant@vagrant-ubuntu-trusty-64:/opt/gopath/src/github.com/hyperledger/fabric$ ip add  detail removed  \n\n3: docker0:  NO-CARRIER,BROADCAST,MULTICAST,UP  mtu 1500 qdisc noqueue state DOWN group default\n    link/ether 02:42:ad:be:70:cb brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:adff:febe:70cb/64 scope link\n       valid_lft forever preferred_lft forever  Your output might contain something like  inet 172.17.0.1/16 scope global docker0 . That means docker0 interface is on IP address 172.17.0.1. Use that IP address for the  CORE_VM_ENDPOINT  option. For more information on the environment variables, see  core.yaml  configuration file in the  fabric  repository.  The ID value of  CORE_PEER_ID  must be lowercase since we use the ID as part of chaincode containers we build, and docker does not accept uppercase. The ID must also be unique for each validating peer.  By default, we are using a consensus plugin called  NOOPS , which doesn't really do consensus. If you want to use some other consensus plugin, see Using Consensus Plugin section at the end of the document.", 
            "title": "Starting up validating peers"
        }, 
        {
            "location": "/dev-setup/devnet-setup/#start-up-the-first-validating-peer", 
            "text": "docker run --rm -it -e CORE_VM_ENDPOINT=http://172.17.0.1:2375 -e CORE_PEER_ID=vp0 -e CORE_PEER_ADDRESSAUTODETECT=true hyperledger/fabric-peer peer node start  If starting the peer with security/privacy enabled, environment variables for security, CA address and peer's ID and password must be included:  docker run --rm -it -e CORE_VM_ENDPOINT=http://172.17.0.1:2375 -e CORE_PEER_ID=vp0 -e CORE_PEER_ADDRESSAUTODETECT=true -e CORE_SECURITY_ENABLED=true -e CORE_SECURITY_PRIVACY=true -e CORE_PEER_PKI_ECA_PADDR=172.17.0.1:50051 -e CORE_PEER_PKI_TCA_PADDR=172.17.0.1:50051 -e CORE_PEER_PKI_TLSCA_PADDR=172.17.0.1:50051 -e CORE_SECURITY_ENROLLID=vp0 -e CORE_SECURITY_ENROLLSECRET=vp0_secret  hyperledger/fabric-peer peer node start  Additionally, the validating peer  enrollID  and  enrollSecret  ( vp0  and  vp0_secret ) has to be added to  membersrvc.yaml .", 
            "title": "Start up the first validating peer:"
        }, 
        {
            "location": "/dev-setup/devnet-setup/#start-up-the-second-validating-peer", 
            "text": "We need to get the IP address of the first validating peer, which will act as the root node that the new peer will connect to. The address is printed out on the terminal window of the first peer (e.g. 172.17.0.2) and should be passed in with the  CORE_PEER_DISCOVERY_ROOTNODE  environment variable. We'll use  vp1  as the ID for the second validating peer.  docker run --rm -it -e CORE_VM_ENDPOINT=http://172.17.0.1:2375 -e CORE_PEER_ID=vp1 -e CORE_PEER_ADDRESSAUTODETECT=true -e CORE_SECURITY_ENABLED=true -e CORE_SECURITY_PRIVACY=true -e CORE_PEER_PKI_ECA_PADDR=172.17.0.1:50051 -e CORE_PEER_PKI_TCA_PADDR=172.17.0.1:50051 -e CORE_PEER_PKI_TLSCA_PADDR=172.17.0.1:50051 -e CORE_SECURITY_ENROLLID=vp1 -e CORE_SECURITY_ENROLLSECRET=vp1_secret -e CORE_PEER_DISCOVERY_ROOTNODE=172.17.0.2:30303 hyperledger/fabric-peer peer node start  Again, the validating peer  enrollID  and  enrollSecret  ( vp1  and  vp1_secret ) has to be added to  membersrvc.yaml .  You can start up a few more validating peers in a similar manner if you wish. Remember to change the peer ID and add the enrollID/enrollSecret to the  membersrvc.yaml .", 
            "title": "Start up the second validating peer:"
        }, 
        {
            "location": "/dev-setup/devnet-setup/#enrolllogin-a-test-user-if-security-is-enabled", 
            "text": "If security is enabled, you must enroll a user with the certificate authority before sending requests. Choose a user that is already registered, i.e. added to the  membersrvc.yaml . Then, execute the command below to log in the user on the target validating peer.  CORE_PEER_ADDRESS  specifies the target validating peer for which the user is to be logged in.  CORE_PEER_ADDRESS=172.17.0.2:30303 peer network login jim  Note:  The certificate authority allows the enrollID and enrollSecret credentials to be used only  once . Therefore, login by the same user from any other validating peer will result in an error. Currently, the application layer is responsible for duplicating the crypto material returned from the CA to other peer nodes. If you want to test secure transactions from more than one peer node without replicating the returned key and certificate, you can log in with a different user on other peer nodes.", 
            "title": "Enroll/Login a test user (if security is enabled):"
        }, 
        {
            "location": "/dev-setup/devnet-setup/#deploy-invoke-and-query-a-chaincode", 
            "text": "Note:  When security is enabled, modify the CLI commands to deploy, invoke, or query a chaincode to pass the username of a logged in user. To log in a registered user through the CLI, execute the login command from the section above. On the CLI the username is passed with the -u parameter.  We can use the sample chaincode to test the network. You may find the chaincode here  $GOPATH/src/github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 .  Deploy the chaincode to the network. We can deploy to any validating peer by specifying  CORE_PEER_ADDRESS :  CORE_PEER_ADDRESS=172.17.0.2:30303 peer chaincode deploy -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{ Function : init ,  Args : [ a , 100 ,  b ,  200 ]}'  With security enabled, modify the command as follows:  CORE_PEER_ADDRESS=172.17.0.2:30303 CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode deploy -u jim -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c '{ Function : init ,  Args : [ a , 100 ,  b ,  200 ]}'  You can watch for the message \"Received build request for chaincode spec\" on the output screen of all validating peers.  Note:  If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.  On successful completion, the above command will print the \"name\" assigned to the deployed chaincode. This \"name\" is used as the value of the \"-n\" parameter in invoke and query commands described below. For example the value of \"name\" could be  bb540edfc1ee2ac0f5e2ec6000677f4cd1c6728046d5e32dede7fea11a42f86a6943b76a8f9154f4792032551ed320871ff7b7076047e4184292e01e3421889c  In a script the name can be captured for subsequent use. For example, run  NAME=`CORE_PEER_ADDRESS=172.17.0.2:30303 CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode deploy ...`  and then replace  name_value_returned_from_deploy_command  in the examples below with  $NAME .  We can run an invoke transaction to move 10 units from the value of  a  to the value of  b :  CORE_PEER_ADDRESS=172.17.0.2:30303 peer chaincode invoke -n  name_value_returned_from_deploy_command  -c '{ Function :  invoke ,  Args : [ a ,  b ,  10 ]}'  With security enabled, modify the command as follows:  CORE_PEER_ADDRESS=172.17.0.2:30303 CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode invoke -u jim -n  name_value_returned_from_deploy_command  -c '{ Function :  invoke ,  Args : [ a ,  b ,  10 ]}'  We can also run a query to see the current value  a  has:  CORE_PEER_ADDRESS=172.17.0.2:30303 peer chaincode query -l golang -n  name_value_returned_from_deploy_command  -c '{ Function :  query ,  Args : [ a ]}'  With security enabled, modify the command as follows:  CORE_PEER_ADDRESS=172.17.0.2:30303 CORE_SECURITY_ENABLED=true CORE_SECURITY_PRIVACY=true peer chaincode query -u jim -l golang -n  name_value_returned_from_deploy_command  -c '{ Function :  query ,  Args : [ a ]}'", 
            "title": "Deploy, Invoke, and Query a Chaincode"
        }, 
        {
            "location": "/dev-setup/devnet-setup/#using-consensus-plugin", 
            "text": "A consensus plugin might require some specific configuration that you need to set up. For example, to use Byzantine consensus plugin provided as part of the fabric, perform the following configuration:   In  core.yaml , set the  peer.validator.consensus  value to  pbft  In  core.yaml , make sure the  peer.id  is set sequentially as  vpX  where  X  is an integer that starts from  0  and goes to  N-1 . For example, with 4 validating peers, set the  peer.id  to vp0 ,  vp1 ,  vp2 ,  vp3 .  In  consensus/obcpbft/config.yaml , set the  general.mode  value to either  classic ,  batch , or  sieve , and the  general.N  value to the number of validating peers on the network (if you do  batch , also set  general.batchsize  to the number of transactions per batch)  In  consensus/obcpbft/config.yaml , optionally set timer values for the batch period ( general.timeout.batch ), the acceptable delay between request and execution ( general.timeout.request ), and for view-change ( general.timeout.viewchange )   See  core.yaml  and  consensus/obcpbft/config.yaml  for more detail.  All of these setting may be overriden via the command line environment variables, eg.  CORE_PEER_VALIDATOR_CONSENSUS_PLUGIN=pbft  or  CORE_PBFT_GENERAL_MODE=sieve", 
            "title": "Using Consensus Plugin"
        }, 
        {
            "location": "/dev-setup/install/", 
            "text": "Installation\n\n\nInstall the blockchain fabric by completing the following tasks:\n\n\n\n\nBuilding the fabric core\n\n\nBuilding outside of Vagrant\n\n\nCode contributions\n\n\nWriting Chaincode\n\n\nSetting Up a Network\n\n\nWorking with CLI, REST, and Node.js\n\n\nConfiguration\n\n\nLogging\n\n\n\n\nBuilding the fabric core \n\n\nThe following instructions assume that you have followed the \ndevelopment environment getting started instructions\n.\n\n\nTo access your VM, run\n\n\nvagrant ssh\n\n\n\n\nFrom within the VM, you can build, run, and test your environment.\n\n\n1. Go build\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer\n\n\n\n\n2. Run/Execute\n\n\nTo see what commands are available, simply execute the following commands:\n\n\n$ peer\n\n\n\n\nYou should see some output similar to below (\nNOTE\n: The root command below is hardcoded in the \nmain.go\n and the build creates the \npeer\n executable).\n\n\n    Usage:\n      peer [command]\n\n    Available Commands:\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level=\n: Default logging level and overrides, see core.yaml for full syntax\n\n\n    Use \npeer [command] --help\n for more information about a command.\n\n\n\n\n\nThe \nnode start\n command will initiate a peer process, with which one can interact by executing other commands. For example, the \nnode status\n command will return the status of the running peer. The full list of commands is the following:\n\n\n      node\n        start       Starts the node.\n        status      Returns status of the node.\n        stop        Stops the running node.\n      network\n        login       Logs in user to CLI.\n        list        Lists all network peers.\n      chaincode\n        deploy      Deploy the specified chaincode to the network.\n        invoke      Invoke the specified chaincode.\n        query       Query using the specified chaincode.\n      help        Help about any command\n\n\n\n\nNote:\n If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.\n\n\n3. Test\n\n\nNew code must be accompanied by test cases both in unit and Behave tests.\n\n\n3.1 Go Unit Tests\n\n\nUse the following sequence to run all unit tests\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake unit-test\n\n\n\nTo run a specific test use the \n-run RE\n flag where RE is a regular expression that matches the test case name. To run tests with verbose output use the \n-v\n flag. For example, to run the \nTestGetFoo\n test case, change to the directory containing the \nfoo_test.go\n and call/excecute\n\n\ngo test -v -run=TestGetFoo\n\n\n\n3.2 Node.js Unit Tests\n\n\nYou must also run the Node.js unit tests to insure that the Node.js client SDK is not broken by your changes. To run the Node.js unit tests, follow the instructions \nhere\n.\n\n\n3.3 Behave Tests\n\n\nBehave\n tests will setup networks of peers with different security and consensus configurations and verify that transactions run properly. To run these tests\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake behave\n\n\n\n\nSome of the Behave tests run inside Docker containers. If a test fails and you want to have the logs from the Docker containers, run the tests with this option\n\n\nbehave -D logs=Y\n\n\n\n\nNote, in order to run behave directly, you must run 'make images' first to build the necessary \npeer\n and \nmember services\n docker images. These images can also be individually built when \ngo test\n is called with the following parameters:\n\n\ngo test github.com/hyperledger/fabric/core/container -run=BuildImage_Peer\ngo test github.com/hyperledger/fabric/core/container -run=BuildImage_Obcca\n\n\n\n\nBuilding outside of Vagrant \n\n\nIt is possible to build the project and run peers outside of Vagrant. Generally speaking, one has to 'translate' the vagrant \nsetup file\n to the platform of your choice.\n\n\nPrerequisites\n\n\n\n\nGit client\n\n\nGo\n - 1.6 or later\n\n\nRocksDB\n version 4.1 and its dependencies\n\n\nDocker\n\n\nPip\n\n\nSet the maximum number of open files to 10000 or greater for your OS\n\n\n\n\nDocker\n\n\nMake sure that the Docker daemon initialization includes the options\n\n\n-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock\n\n\n\n\nTypically, docker runs as a \nservice\n task, with configuration file at \n/etc/default/docker\n.\n\n\nBe aware that the Docker bridge (the \nCORE_VM_ENDPOINT\n) may not come\nup at the IP address currently assumed by the test environment\n(\n172.17.0.1\n). Use \nifconfig\n or \nip addr\n to find the docker bridge.\n\n\nBuilding RocksDB\n\n\napt-get install -y libsnappy-dev zlib1g-dev libbz2-dev\ncd /tmp\ngit clone https://github.com/facebook/rocksdb.git\ncd rocksdb\ngit checkout v4.1\nPORTABLE=1 make shared_lib\nINSTALL_PATH=/usr/local make install-shared\n\n\n\n\npip\n, \nbehave\n and \ndocker-compose\n\n\npip install --upgrade pip\npip install behave nose docker-compose\npip install -I flask==0.10.1 python-dateutil==2.2 pytz==2014.3 pyyaml==3.10 couchdb==1.0 flask-cors==2.0.1 requests==2.4.3\n\n\n\n\nBuilding on Z\n\n\nTo make building on Z easier and faster, \nthis script\n is provided (which is similar to the \nsetup file\n provided for vagrant). This script has been tested only on RHEL 7.2 and has some assumptions one might want to re-visit (firewall settings, development as root user, etc.). It is however sufficient for development in a personally-assigned VM instance.\n\n\nTo get started, from a freshly installed OS:\n\n\nsudo su\nyum install git\nmkdir -p $HOME/git/src/github.com/hyperledger\ncd $HOME/git/src/github.com/hyperledger\ngit clone https://github.com/hyperledger/fabric.git\nsource fabric/devenv/setupRHELonZ.sh\n\n\n\n\nFrom there, follow instructions at \nInstallation\n:\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer unit-test behave\n\n\n\n\nBuilding on OSX\n\n\nFirst, install Docker, as described \nhere\n.\nThe database by default writes to /var/hyperledger. You can override this in the \ncore.yaml\n configuration file, under \npeer.fileSystemPath\n.\n\n\nbrew install go rocksdb snappy gnu-tar     # For RocksDB version 4.1, you can compile your own, as described earlier\n\n# You will need the following two for every shell you want to use\neval $(docker-machine env)\nexport PATH=\n/usr/local/opt/gnu-tar/libexec/gnubin:$PATH\n\n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer\n\n\n\n\nCode contributions \n\n\nWe welcome contributions to the Hyperledger Project in many forms. There's always plenty to do! Full details of how to contribute to this project are documented in the \nCONTRIBUTING.md\n file.\n\n\nSetting Up a Network \n\n\nTo set up an development network composed of several validating peers, follow the instructions on the \nDevnet Setup\n page. This network leverages Docker to manage multiple peer instances on the same machine, allowing you to quickly test your chaincode.\n\n\nWriting Chaincode \n\n\nSince chaincode is written in Go language, you can set up the environment to accommodate the rapid edit-compile-run of your chaincode. Follow the instructions on the \nSandbox Setup\n page, which allows you to run your chaincode off the blockchain.\n\n\nWorking with CLI, REST, and Node.js \n\n\nWhen you are ready to start interacting with the peer node through the available APIs and packages, follow the instructions on the \nCoreAPI Documentation\n page.\n\n\nConfiguration \n\n\nConfiguration utilizes the \nviper\n and \ncobra\n libraries.\n\n\nThere is a \ncore.yaml\n file that contains the configuration for the peer process. Many of the configuration settings can be overridden on the command line by setting ENV variables that match the configuration setting, but by prefixing with \n'CORE_'\n. For example, logging level manipulation through the environment is shown below:\n\n\nCORE_PEER_LOGGING_LEVEL=CRITICAL peer\n\n\n\nLogging \n\n\nLogging utilizes the \ngo-logging\n library.  \n\n\nThe available log levels in order of increasing verbosity are: \nCRITICAL | ERROR | WARNING | NOTICE | INFO | DEBUG\n\n\nSee \nspecific logging control\n instructions when running the peer process.", 
            "title": "Install"
        }, 
        {
            "location": "/dev-setup/install/#installation", 
            "text": "Install the blockchain fabric by completing the following tasks:   Building the fabric core  Building outside of Vagrant  Code contributions  Writing Chaincode  Setting Up a Network  Working with CLI, REST, and Node.js  Configuration  Logging", 
            "title": "Installation"
        }, 
        {
            "location": "/dev-setup/install/#building-the-fabric-core", 
            "text": "The following instructions assume that you have followed the  development environment getting started instructions .  To access your VM, run  vagrant ssh  From within the VM, you can build, run, and test your environment.", 
            "title": "Building the fabric core "
        }, 
        {
            "location": "/dev-setup/install/#1-go-build", 
            "text": "cd $GOPATH/src/github.com/hyperledger/fabric\nmake peer", 
            "title": "1. Go build"
        }, 
        {
            "location": "/dev-setup/install/#2-runexecute", 
            "text": "To see what commands are available, simply execute the following commands:  $ peer  You should see some output similar to below ( NOTE : The root command below is hardcoded in the  main.go  and the build creates the  peer  executable).      Usage:\n      peer [command]\n\n    Available Commands:\n      node        node specific commands.\n      network     network specific commands.\n      chaincode   chaincode specific commands.\n      help        Help about any command\n\n    Flags:\n      -h, --help[=false]: help for peer\n          --logging-level= : Default logging level and overrides, see core.yaml for full syntax\n\n\n    Use  peer [command] --help  for more information about a command.  The  node start  command will initiate a peer process, with which one can interact by executing other commands. For example, the  node status  command will return the status of the running peer. The full list of commands is the following:        node\n        start       Starts the node.\n        status      Returns status of the node.\n        stop        Stops the running node.\n      network\n        login       Logs in user to CLI.\n        list        Lists all network peers.\n      chaincode\n        deploy      Deploy the specified chaincode to the network.\n        invoke      Invoke the specified chaincode.\n        query       Query using the specified chaincode.\n      help        Help about any command  Note:  If your GOPATH environment variable contains more than one element, the chaincode must be found in the first one or deployment will fail.", 
            "title": "2. Run/Execute"
        }, 
        {
            "location": "/dev-setup/install/#3-test", 
            "text": "New code must be accompanied by test cases both in unit and Behave tests.", 
            "title": "3. Test"
        }, 
        {
            "location": "/dev-setup/install/#31-go-unit-tests", 
            "text": "Use the following sequence to run all unit tests  cd $GOPATH/src/github.com/hyperledger/fabric\nmake unit-test  To run a specific test use the  -run RE  flag where RE is a regular expression that matches the test case name. To run tests with verbose output use the  -v  flag. For example, to run the  TestGetFoo  test case, change to the directory containing the  foo_test.go  and call/excecute  go test -v -run=TestGetFoo", 
            "title": "3.1 Go Unit Tests"
        }, 
        {
            "location": "/dev-setup/install/#32-nodejs-unit-tests", 
            "text": "You must also run the Node.js unit tests to insure that the Node.js client SDK is not broken by your changes. To run the Node.js unit tests, follow the instructions  here .", 
            "title": "3.2 Node.js Unit Tests"
        }, 
        {
            "location": "/dev-setup/install/#33-behave-tests", 
            "text": "Behave  tests will setup networks of peers with different security and consensus configurations and verify that transactions run properly. To run these tests  cd $GOPATH/src/github.com/hyperledger/fabric\nmake behave  Some of the Behave tests run inside Docker containers. If a test fails and you want to have the logs from the Docker containers, run the tests with this option  behave -D logs=Y  Note, in order to run behave directly, you must run 'make images' first to build the necessary  peer  and  member services  docker images. These images can also be individually built when  go test  is called with the following parameters:  go test github.com/hyperledger/fabric/core/container -run=BuildImage_Peer\ngo test github.com/hyperledger/fabric/core/container -run=BuildImage_Obcca", 
            "title": "3.3 Behave Tests"
        }, 
        {
            "location": "/dev-setup/install/#building-outside-of-vagrant", 
            "text": "It is possible to build the project and run peers outside of Vagrant. Generally speaking, one has to 'translate' the vagrant  setup file  to the platform of your choice.", 
            "title": "Building outside of Vagrant "
        }, 
        {
            "location": "/dev-setup/install/#prerequisites", 
            "text": "Git client  Go  - 1.6 or later  RocksDB  version 4.1 and its dependencies  Docker  Pip  Set the maximum number of open files to 10000 or greater for your OS", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/dev-setup/install/#docker", 
            "text": "Make sure that the Docker daemon initialization includes the options  -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock  Typically, docker runs as a  service  task, with configuration file at  /etc/default/docker .  Be aware that the Docker bridge (the  CORE_VM_ENDPOINT ) may not come\nup at the IP address currently assumed by the test environment\n( 172.17.0.1 ). Use  ifconfig  or  ip addr  to find the docker bridge.", 
            "title": "Docker"
        }, 
        {
            "location": "/dev-setup/install/#building-rocksdb", 
            "text": "apt-get install -y libsnappy-dev zlib1g-dev libbz2-dev\ncd /tmp\ngit clone https://github.com/facebook/rocksdb.git\ncd rocksdb\ngit checkout v4.1\nPORTABLE=1 make shared_lib\nINSTALL_PATH=/usr/local make install-shared", 
            "title": "Building RocksDB"
        }, 
        {
            "location": "/dev-setup/install/#pip-behave-and-docker-compose", 
            "text": "pip install --upgrade pip\npip install behave nose docker-compose\npip install -I flask==0.10.1 python-dateutil==2.2 pytz==2014.3 pyyaml==3.10 couchdb==1.0 flask-cors==2.0.1 requests==2.4.3", 
            "title": "pip, behave and docker-compose"
        }, 
        {
            "location": "/dev-setup/install/#building-on-z", 
            "text": "To make building on Z easier and faster,  this script  is provided (which is similar to the  setup file  provided for vagrant). This script has been tested only on RHEL 7.2 and has some assumptions one might want to re-visit (firewall settings, development as root user, etc.). It is however sufficient for development in a personally-assigned VM instance.  To get started, from a freshly installed OS:  sudo su\nyum install git\nmkdir -p $HOME/git/src/github.com/hyperledger\ncd $HOME/git/src/github.com/hyperledger\ngit clone https://github.com/hyperledger/fabric.git\nsource fabric/devenv/setupRHELonZ.sh  From there, follow instructions at  Installation :  cd $GOPATH/src/github.com/hyperledger/fabric\nmake peer unit-test behave", 
            "title": "Building on Z"
        }, 
        {
            "location": "/dev-setup/install/#building-on-osx", 
            "text": "First, install Docker, as described  here .\nThe database by default writes to /var/hyperledger. You can override this in the  core.yaml  configuration file, under  peer.fileSystemPath .  brew install go rocksdb snappy gnu-tar     # For RocksDB version 4.1, you can compile your own, as described earlier\n\n# You will need the following two for every shell you want to use\neval $(docker-machine env)\nexport PATH= /usr/local/opt/gnu-tar/libexec/gnubin:$PATH \n\ncd $GOPATH/src/github.com/hyperledger/fabric\nmake peer", 
            "title": "Building on OSX"
        }, 
        {
            "location": "/dev-setup/install/#code-contributions", 
            "text": "We welcome contributions to the Hyperledger Project in many forms. There's always plenty to do! Full details of how to contribute to this project are documented in the  CONTRIBUTING.md  file.", 
            "title": "Code contributions "
        }, 
        {
            "location": "/dev-setup/install/#setting-up-a-network", 
            "text": "To set up an development network composed of several validating peers, follow the instructions on the  Devnet Setup  page. This network leverages Docker to manage multiple peer instances on the same machine, allowing you to quickly test your chaincode.", 
            "title": "Setting Up a Network "
        }, 
        {
            "location": "/dev-setup/install/#writing-chaincode", 
            "text": "Since chaincode is written in Go language, you can set up the environment to accommodate the rapid edit-compile-run of your chaincode. Follow the instructions on the  Sandbox Setup  page, which allows you to run your chaincode off the blockchain.", 
            "title": "Writing Chaincode "
        }, 
        {
            "location": "/dev-setup/install/#working-with-cli-rest-and-nodejs", 
            "text": "When you are ready to start interacting with the peer node through the available APIs and packages, follow the instructions on the  CoreAPI Documentation  page.", 
            "title": "Working with CLI, REST, and Node.js "
        }, 
        {
            "location": "/dev-setup/install/#configuration", 
            "text": "Configuration utilizes the  viper  and  cobra  libraries.  There is a  core.yaml  file that contains the configuration for the peer process. Many of the configuration settings can be overridden on the command line by setting ENV variables that match the configuration setting, but by prefixing with  'CORE_' . For example, logging level manipulation through the environment is shown below:  CORE_PEER_LOGGING_LEVEL=CRITICAL peer", 
            "title": "Configuration "
        }, 
        {
            "location": "/dev-setup/install/#logging", 
            "text": "Logging utilizes the  go-logging  library.    The available log levels in order of increasing verbosity are:  CRITICAL | ERROR | WARNING | NOTICE | INFO | DEBUG  See  specific logging control  instructions when running the peer process.", 
            "title": "Logging "
        }, 
        {
            "location": "/dev-setup/logging-control/", 
            "text": "Logging Control\n\n\nOverview\n\n\nLogging in the \npeer\n application and in the \nshim\n interface to\nchaincodes is programmed using facilities provided by the\n\ngithub.com/op/go-logging\n package. This package supports\n\n\n\n\nLogging control based on the severity of the message\n\n\nLogging control based on the software \nmodule\n generating the message\n\n\nDifferent pretty-printing options based on the severity of the message\n\n\n\n\nAll logs are currently directed to \nstderr\n, and the pretty-printing is\ncurrently fixed. However global and module-level control of logging by\nseverity is provided for both users and developers.  There are currently no\nformalized rules for the types of information provided at each severity level,\nhowever when submitting bug reports the developers may want to see full logs\ndown to the DEBUG level.\n\n\nIn pretty-printed logs the logging level is indicated both by color and by a\n4-character code, e.g, \"ERRO\" for ERROR, \"DEBU\" for DEBUG, etc.  In the\nlogging context a \nmodule\n is an arbitrary name (string) given by developers\nto groups of related messages.  In the pretty-printed example below, the\nlogging modules \"peer\", \"rest\" and \"main\" are generating logs.\n\n\n16:47:09.634 [peer] GetLocalAddress -\n INFO 033 Auto detected peer address: 9.3.158.178:30303\n16:47:09.635 [rest] StartOpenchainRESTServer -\n INFO 035 Initializing the REST service...\n16:47:09.635 [main] serve -\n INFO 036 Starting peer with id=name:\"vp1\" , network id=dev, address=9.3.158.178:30303, discovery.rootnode=, validator=true\n\n\n\nAn arbitrary number of logging modules can be created at runtime, therefore\nthere is no \"master list\" of modules, and logging control constructs can not\ncheck whether logging modules actually do or will exist.\n\n\nPEER\n\n\nThe logging level of the \npeer\n command can be controlled from the command\nline for each invocation using the \n--logging-level\n flag, for example\n\n\npeer node start --logging-level=debug\n\n\n\nThe default logging level for each individual \npeer\n subcommand can also\nbe set in the \nopenchain.yaml\n file. For example the key \nlogging.peer\n sets\nthe default level for the \npeer\n subcommmand.\n\n\nLogging severity levels are specified using case-insensitive strings chosen\nfrom\n\n\nCRITICAL | ERROR | WARNING | NOTICE | INFO | DEBUG\n\n\n\nThe full logging level specification for the \npeer\n is of the form\n\n\n[\nmodule\n[,\nmodule\n...]=]\nlevel\n[:[\nmodule\n[,\nmodule\n...]=]\nlevel\n...]\n\n\n\nA logging level by itself is taken as the overall default. Otherwise,\noverrides for individual or groups of modules can be specified using the \n\n\nmodule\n[,\nmodule\n...]=\nlevel\n\n\n\n\nsyntax. Examples of \n specifications (valid for both --logging-level and\n\nopenchain.yaml\n settings):\n\n\ninfo                                       - Set default to INFO\nwarning:main,db=debug:chaincode=info       - Default WARNING; Override for main,db,chaincode\nchaincode=info:main=debug:db=debug:warning - Same as above\n\n\n\nGo chaincodes\n\n\nAs independently executed programs, user-provided chaincodes can use any\nappropriate technique to create their private logs - from simple print\nstatements to fully-annotated and level-controlled logs. The chaincode \nshim\n\npackage provides APIs that allow a chaincode to create and manage logging\nobjects whose logs will be formatted and interleaved consistently with the\n\nshim\n logs.\n\n\nNewLogger(name string) *ChaincodeLogger\n - Create a logging object for use by a chaincode\n\n\n(c *ChaincodeLogger) SetLevel(level LoggingLevel)\n - Set the logging level of the logger\n\n\n(c *ChaincodeLogger) IsEnabledFor(level LoggingLevel) bool\n - Return true if logs will be generated at the given level\n\n\nLogLevel(levelString string) (LoggingLevel, error)\n - Convert a string to a \nLoggingLevel\n\n\nA \nLoggingLevel\n is a member of the enumeration\n\n\nLogDebug, LogInfo, LogNotice, LogWarning, LogError, LogCritical\n\n\n\n\nwhich can be used directly, or generated by passing a case-insensitive version\nof the strings\n\n\nDEBUG, INFO, NOTICE, WARNING, ERROR, CRITICAL\n\n\n\n\nto the \nLogLevel\n API.\n\n\nFormatted logging at various severity levels is provided by the functions\n\n\n(c *ChaincodeLogger) Debugf(format string, args ...interface{})\n(c *ChaincodeLogger) Infof(format string, args ...interface{})\n(c *ChaincodeLogger) Noticef(format string, args ...interface{})\n(c *ChaincodeLogger) Warningf(format string, args ...interface{})\n(c *ChaincodeLogger) Errorf(format string, args ...interface{})\n(c *ChaincodeLogger) Criticalf(format string, args ...interface{})\n\n\n\n\nIn the current implementation, the logs produced by the \nshim\n and a\n\nChaincodeLogger\n are timestamped, marked with the logger \nname\n and severity\nlevel, and written to \nstderr\n. Note that logging level control is currently\nbased on the \nname\n provided when the \nChaincodeLogger\n is created. To avoid\nambiguities, all \nChaincodeLogger\n should be given unique names other than\n\"shim\". The logger \nname\n will appear in all log messages created by the\nlogger. The \nshim\n logs as \"shim\".\n\n\nGo language chaincodes can also control the logging level of the chaincode\n\nshim\n interface through the \nSetLoggingLevel\n API.\n\n\nSetLoggingLevel(LoggingLevel level)\n - Control the logging level of the shim\n\n\nThe default logging level for the shim is \nLogDebug\n.\n\n\nBelow is a simple example of how a chaincode might create a private logging\nobject logging at the \nLogInfo\n level, and also control the amount of logging\nprovided by the \nshim\n based on an environment variable.\n\n\nvar logger = shim.NewLogger(\nmyChaincode\n)\n\nfunc main() {\n\n    logger.SetLevel(shim.LogInfo)\n\n    logLevel, _ := shim.LogLevel(os.Getenv(\nSHIM_LOGGING_LEVEL\n))\n    shim.SetLoggingLevel(logLevel)\n    ...\n}", 
            "title": "Logging control"
        }, 
        {
            "location": "/dev-setup/logging-control/#logging-control", 
            "text": "", 
            "title": "Logging Control"
        }, 
        {
            "location": "/dev-setup/logging-control/#overview", 
            "text": "Logging in the  peer  application and in the  shim  interface to\nchaincodes is programmed using facilities provided by the github.com/op/go-logging  package. This package supports   Logging control based on the severity of the message  Logging control based on the software  module  generating the message  Different pretty-printing options based on the severity of the message   All logs are currently directed to  stderr , and the pretty-printing is\ncurrently fixed. However global and module-level control of logging by\nseverity is provided for both users and developers.  There are currently no\nformalized rules for the types of information provided at each severity level,\nhowever when submitting bug reports the developers may want to see full logs\ndown to the DEBUG level.  In pretty-printed logs the logging level is indicated both by color and by a\n4-character code, e.g, \"ERRO\" for ERROR, \"DEBU\" for DEBUG, etc.  In the\nlogging context a  module  is an arbitrary name (string) given by developers\nto groups of related messages.  In the pretty-printed example below, the\nlogging modules \"peer\", \"rest\" and \"main\" are generating logs.  16:47:09.634 [peer] GetLocalAddress -  INFO 033 Auto detected peer address: 9.3.158.178:30303\n16:47:09.635 [rest] StartOpenchainRESTServer -  INFO 035 Initializing the REST service...\n16:47:09.635 [main] serve -  INFO 036 Starting peer with id=name:\"vp1\" , network id=dev, address=9.3.158.178:30303, discovery.rootnode=, validator=true  An arbitrary number of logging modules can be created at runtime, therefore\nthere is no \"master list\" of modules, and logging control constructs can not\ncheck whether logging modules actually do or will exist.", 
            "title": "Overview"
        }, 
        {
            "location": "/dev-setup/logging-control/#peer", 
            "text": "The logging level of the  peer  command can be controlled from the command\nline for each invocation using the  --logging-level  flag, for example  peer node start --logging-level=debug  The default logging level for each individual  peer  subcommand can also\nbe set in the  openchain.yaml  file. For example the key  logging.peer  sets\nthe default level for the  peer  subcommmand.  Logging severity levels are specified using case-insensitive strings chosen\nfrom  CRITICAL | ERROR | WARNING | NOTICE | INFO | DEBUG  The full logging level specification for the  peer  is of the form  [ module [, module ...]=] level [:[ module [, module ...]=] level ...]  A logging level by itself is taken as the overall default. Otherwise,\noverrides for individual or groups of modules can be specified using the   module [, module ...]= level   syntax. Examples of   specifications (valid for both --logging-level and openchain.yaml  settings):  info                                       - Set default to INFO\nwarning:main,db=debug:chaincode=info       - Default WARNING; Override for main,db,chaincode\nchaincode=info:main=debug:db=debug:warning - Same as above", 
            "title": "PEER"
        }, 
        {
            "location": "/dev-setup/logging-control/#go-chaincodes", 
            "text": "As independently executed programs, user-provided chaincodes can use any\nappropriate technique to create their private logs - from simple print\nstatements to fully-annotated and level-controlled logs. The chaincode  shim \npackage provides APIs that allow a chaincode to create and manage logging\nobjects whose logs will be formatted and interleaved consistently with the shim  logs.  NewLogger(name string) *ChaincodeLogger  - Create a logging object for use by a chaincode  (c *ChaincodeLogger) SetLevel(level LoggingLevel)  - Set the logging level of the logger  (c *ChaincodeLogger) IsEnabledFor(level LoggingLevel) bool  - Return true if logs will be generated at the given level  LogLevel(levelString string) (LoggingLevel, error)  - Convert a string to a  LoggingLevel  A  LoggingLevel  is a member of the enumeration  LogDebug, LogInfo, LogNotice, LogWarning, LogError, LogCritical  which can be used directly, or generated by passing a case-insensitive version\nof the strings  DEBUG, INFO, NOTICE, WARNING, ERROR, CRITICAL  to the  LogLevel  API.  Formatted logging at various severity levels is provided by the functions  (c *ChaincodeLogger) Debugf(format string, args ...interface{})\n(c *ChaincodeLogger) Infof(format string, args ...interface{})\n(c *ChaincodeLogger) Noticef(format string, args ...interface{})\n(c *ChaincodeLogger) Warningf(format string, args ...interface{})\n(c *ChaincodeLogger) Errorf(format string, args ...interface{})\n(c *ChaincodeLogger) Criticalf(format string, args ...interface{})  In the current implementation, the logs produced by the  shim  and a ChaincodeLogger  are timestamped, marked with the logger  name  and severity\nlevel, and written to  stderr . Note that logging level control is currently\nbased on the  name  provided when the  ChaincodeLogger  is created. To avoid\nambiguities, all  ChaincodeLogger  should be given unique names other than\n\"shim\". The logger  name  will appear in all log messages created by the\nlogger. The  shim  logs as \"shim\".  Go language chaincodes can also control the logging level of the chaincode shim  interface through the  SetLoggingLevel  API.  SetLoggingLevel(LoggingLevel level)  - Control the logging level of the shim  The default logging level for the shim is  LogDebug .  Below is a simple example of how a chaincode might create a private logging\nobject logging at the  LogInfo  level, and also control the amount of logging\nprovided by the  shim  based on an environment variable.  var logger = shim.NewLogger( myChaincode )\n\nfunc main() {\n\n    logger.SetLevel(shim.LogInfo)\n\n    logLevel, _ := shim.LogLevel(os.Getenv( SHIM_LOGGING_LEVEL ))\n    shim.SetLoggingLevel(logLevel)\n    ...\n}", 
            "title": "Go chaincodes"
        }, 
        {
            "location": "/tech/application-ACL/", 
            "text": "Hyperledger Fabric - Application Access Control Lists\n\n\nOverview\n\n\nWe consider the following entities: \n\n\n\n\nHelloWorld\n: is a chaincode that contains a single function called \nhello\n;\n\n\nAlice\n: is the \nHelloWorld\n deployer;\n\n\nBob\n: is the \nHelloWorld\n's functions invoker.\n\n\n\n\nAlice wants to ensure that only Bob can invoke the function \nhello\n.\n\n\nFabric Support\n\n\nTo allow Alice to specify her own access control lists and Bob to gain access, the fabric layer gives access to following capabilities:\n\n\n\n\nAlice and Bob can sign and verify any message with specific transaction certificates or enrollment certificate they own;\n\n\nThe fabric allows to \nname\n each transaction by means of a unique \nbinding\n to be used to bind application data\nto the underlying transaction transporting it;\n\n\nExtended transaction format.\n\n\n\n\nThe fabric layer exposes the following interfaces and functions to allow the application layer to define its own ACLS.\n\n\nCertificate Handler\n\n\nThe following interface allows to sign and verify any message using signing key-pair underlying the associated certificate.\nThe certificate can be a TCert or an ECert.\n\n\n// CertificateHandler exposes methods to deal with an ECert/TCert\ntype CertificateHandler interface {\n\n    // GetCertificate returns the certificate's DER\n    GetCertificate() []byte\n\n    // Sign signs msg using the signing key corresponding to the certificate\n    Sign(msg []byte) ([]byte, error)\n\n    // Verify verifies msg using the verifying key corresponding to the certificate\n    Verify(signature []byte, msg []byte) error\n\n    // GetTransactionHandler returns a new transaction handler relative to this certificate\n    GetTransactionHandler() (TransactionHandler, error)\n}\n\n\n\n\nTransaction Handler\n\n\nThe following interface allows to create transactions and give access to the underlying \nbinding\n that can be leveraged to link\napplication data to the underlying transaction.\n\n\n// TransactionHandler represents a single transaction that can be named by the output of the GetBinding method.\n// This transaction is linked to a single Certificate (TCert or ECert).\ntype TransactionHandler interface {\n\n    // GetCertificateHandler returns the certificate handler relative to the certificate mapped to this transaction\n    GetCertificateHandler() (CertificateHandler, error)\n\n    // GetBinding returns a binding to the underlying transaction\n    GetBinding() ([]byte, error)\n\n    // NewChaincodeDeployTransaction is used to deploy chaincode\n    NewChaincodeDeployTransaction(chaincodeDeploymentSpec *obc.ChaincodeDeploymentSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeExecute is used to execute chaincode's functions\n    NewChaincodeExecute(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeQuery is used to query chaincode's functions\n    NewChaincodeQuery(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n}\n\n\n\n\nClient\n\n\nThe following interface offers a mean to get instances of the previous interfaces.\n\n\ntype Client interface {\n\n    ...\n\n    // GetEnrollmentCertHandler returns a CertificateHandler whose certificate is the enrollment certificate\n    GetEnrollmentCertificateHandler() (CertificateHandler, error)\n\n    // GetTCertHandlerNext returns a CertificateHandler whose certificate is the next available TCert\n    GetTCertificateHandlerNext() (CertificateHandler, error)\n\n    // GetTCertHandlerFromDER returns a CertificateHandler whose certificate is the one passed\n    GetTCertificateHandlerFromDER(der []byte) (CertificateHandler, error)\n\n}\n\n\n\n\nTransaction Format\n\n\nTo support application-level ACLs, the fabric's transaction and chaincode specification format have an additional field to store application-specific metadata.\nThe content of this field is decided by the application. The fabric layer treats it as an unstructured stream of bytes.    \n\n\n\nmessage ChaincodeSpec {\n\n    ...\n\n    ConfidentialityLevel confidentialityLevel;\n    bytes metadata;\n\n    ...\n}\n\n\nmessage Transaction {\n    ...\n\n    bytes payload;\n    bytes metadata;\n\n    ...    \n}\n\n\n\n\nAnother way to achieve this is to have the payload containing the metadata itself.  \n\n\nValidators\n\n\nTo assist chaincode execution, the validators provide the chaincode additional information, like the metadata and the binding.  \n\n\nApplication-level access control\n\n\nDeploy Transaction\n\n\nAlice has full control on the deployment transaction's metadata. \nIn particular, the metadata can be used to store a list of ACLs (one per function), or a list of roles. \nTo define each of these lists/roles, Alice can use any TCerts/ECerts of the users who have been assigned \nthat privilege or role. The latter is done offline. \n\n\nNow, Alice requires that to invoke the \nhello\n function, a certain message \nM\n has to be authenticated by an authorized invoker (Bob, in our case). \nWe distinguish the following two cases:\n\n\n\n\nM\n is one of the chaincode's function arguments;\n\n\nM\n is the invocation message itself, i.e., function-name, arguments.\n\n\n\n\nExecute Transaction\n\n\nTo invoke \nhello\n, Bob needs to sign \nM\n using the TCert/ECert Alice has used to name him in the deployment transaction's metadata.\nLet's call this certificate CertBob. At this point Bob does the following:   \n\n\n\n\nBob gets a CertificateHandler for CertBob, \ncHandlerBob\n;\n\n\nBob gets a new TransactionHandler to issue the execute transaction, \ntxHandler\n relative to his next available TCert or his ECert; \n\n\nBob gets \ntxHandler\n's \nbinding\n by invoking \ntxHandler.getBinding()\n;\n\n\nBob signs \n'M || txBinding'\n by invoking \ncHandlerBob.Sign('M || txBinding')\n, let \nsignature\n be the output of the signing function;\n\n\nBob issues a new execute transaction by invoking, \ntxHandler.NewChaincodeExecute(...)\n. Now, \nsignature\n can be included\n  in the transaction as one of the argument to be passed to the function or as transaction metadata.\n\n\n\n\nChaincode Execution\n\n\nThe validators, who receive the execute transaction issued by Bob, will provide to \nhello\n the following information:\n\n\n\n\nThe \nbinding\n of the execute transaction;\n\n\nThe \nmetadata\n of the execute transaction;\n\n\nThe \nmetadata\n of the deploy transaction.\n\n\n\n\nThen, \nhello\n is responsible for checking that \nsignature\n is indeed a valid signature issued by Bob.", 
            "title": "Application ACL"
        }, 
        {
            "location": "/tech/application-ACL/#hyperledger-fabric-application-access-control-lists", 
            "text": "", 
            "title": "Hyperledger Fabric - Application Access Control Lists"
        }, 
        {
            "location": "/tech/application-ACL/#overview", 
            "text": "We consider the following entities:    HelloWorld : is a chaincode that contains a single function called  hello ;  Alice : is the  HelloWorld  deployer;  Bob : is the  HelloWorld 's functions invoker.   Alice wants to ensure that only Bob can invoke the function  hello .", 
            "title": "Overview"
        }, 
        {
            "location": "/tech/application-ACL/#fabric-support", 
            "text": "To allow Alice to specify her own access control lists and Bob to gain access, the fabric layer gives access to following capabilities:   Alice and Bob can sign and verify any message with specific transaction certificates or enrollment certificate they own;  The fabric allows to  name  each transaction by means of a unique  binding  to be used to bind application data\nto the underlying transaction transporting it;  Extended transaction format.   The fabric layer exposes the following interfaces and functions to allow the application layer to define its own ACLS.", 
            "title": "Fabric Support"
        }, 
        {
            "location": "/tech/application-ACL/#certificate-handler", 
            "text": "The following interface allows to sign and verify any message using signing key-pair underlying the associated certificate.\nThe certificate can be a TCert or an ECert.  // CertificateHandler exposes methods to deal with an ECert/TCert\ntype CertificateHandler interface {\n\n    // GetCertificate returns the certificate's DER\n    GetCertificate() []byte\n\n    // Sign signs msg using the signing key corresponding to the certificate\n    Sign(msg []byte) ([]byte, error)\n\n    // Verify verifies msg using the verifying key corresponding to the certificate\n    Verify(signature []byte, msg []byte) error\n\n    // GetTransactionHandler returns a new transaction handler relative to this certificate\n    GetTransactionHandler() (TransactionHandler, error)\n}", 
            "title": "Certificate Handler"
        }, 
        {
            "location": "/tech/application-ACL/#transaction-handler", 
            "text": "The following interface allows to create transactions and give access to the underlying  binding  that can be leveraged to link\napplication data to the underlying transaction.  // TransactionHandler represents a single transaction that can be named by the output of the GetBinding method.\n// This transaction is linked to a single Certificate (TCert or ECert).\ntype TransactionHandler interface {\n\n    // GetCertificateHandler returns the certificate handler relative to the certificate mapped to this transaction\n    GetCertificateHandler() (CertificateHandler, error)\n\n    // GetBinding returns a binding to the underlying transaction\n    GetBinding() ([]byte, error)\n\n    // NewChaincodeDeployTransaction is used to deploy chaincode\n    NewChaincodeDeployTransaction(chaincodeDeploymentSpec *obc.ChaincodeDeploymentSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeExecute is used to execute chaincode's functions\n    NewChaincodeExecute(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n\n    // NewChaincodeQuery is used to query chaincode's functions\n    NewChaincodeQuery(chaincodeInvocation *obc.ChaincodeInvocationSpec, uuid string) (*obc.Transaction, error)\n}", 
            "title": "Transaction Handler"
        }, 
        {
            "location": "/tech/application-ACL/#client", 
            "text": "The following interface offers a mean to get instances of the previous interfaces.  type Client interface {\n\n    ...\n\n    // GetEnrollmentCertHandler returns a CertificateHandler whose certificate is the enrollment certificate\n    GetEnrollmentCertificateHandler() (CertificateHandler, error)\n\n    // GetTCertHandlerNext returns a CertificateHandler whose certificate is the next available TCert\n    GetTCertificateHandlerNext() (CertificateHandler, error)\n\n    // GetTCertHandlerFromDER returns a CertificateHandler whose certificate is the one passed\n    GetTCertificateHandlerFromDER(der []byte) (CertificateHandler, error)\n\n}", 
            "title": "Client"
        }, 
        {
            "location": "/tech/application-ACL/#transaction-format", 
            "text": "To support application-level ACLs, the fabric's transaction and chaincode specification format have an additional field to store application-specific metadata.\nThe content of this field is decided by the application. The fabric layer treats it as an unstructured stream of bytes.      \nmessage ChaincodeSpec {\n\n    ...\n\n    ConfidentialityLevel confidentialityLevel;\n    bytes metadata;\n\n    ...\n}\n\n\nmessage Transaction {\n    ...\n\n    bytes payload;\n    bytes metadata;\n\n    ...    \n}  Another way to achieve this is to have the payload containing the metadata itself.", 
            "title": "Transaction Format"
        }, 
        {
            "location": "/tech/application-ACL/#validators", 
            "text": "To assist chaincode execution, the validators provide the chaincode additional information, like the metadata and the binding.", 
            "title": "Validators"
        }, 
        {
            "location": "/tech/application-ACL/#application-level-access-control", 
            "text": "", 
            "title": "Application-level access control"
        }, 
        {
            "location": "/tech/application-ACL/#deploy-transaction", 
            "text": "Alice has full control on the deployment transaction's metadata. \nIn particular, the metadata can be used to store a list of ACLs (one per function), or a list of roles. \nTo define each of these lists/roles, Alice can use any TCerts/ECerts of the users who have been assigned \nthat privilege or role. The latter is done offline.   Now, Alice requires that to invoke the  hello  function, a certain message  M  has to be authenticated by an authorized invoker (Bob, in our case). \nWe distinguish the following two cases:   M  is one of the chaincode's function arguments;  M  is the invocation message itself, i.e., function-name, arguments.", 
            "title": "Deploy Transaction"
        }, 
        {
            "location": "/tech/application-ACL/#execute-transaction", 
            "text": "To invoke  hello , Bob needs to sign  M  using the TCert/ECert Alice has used to name him in the deployment transaction's metadata.\nLet's call this certificate CertBob. At this point Bob does the following:      Bob gets a CertificateHandler for CertBob,  cHandlerBob ;  Bob gets a new TransactionHandler to issue the execute transaction,  txHandler  relative to his next available TCert or his ECert;   Bob gets  txHandler 's  binding  by invoking  txHandler.getBinding() ;  Bob signs  'M || txBinding'  by invoking  cHandlerBob.Sign('M || txBinding') , let  signature  be the output of the signing function;  Bob issues a new execute transaction by invoking,  txHandler.NewChaincodeExecute(...) . Now,  signature  can be included\n  in the transaction as one of the argument to be passed to the function or as transaction metadata.", 
            "title": "Execute Transaction"
        }, 
        {
            "location": "/tech/application-ACL/#chaincode-execution", 
            "text": "The validators, who receive the execute transaction issued by Bob, will provide to  hello  the following information:   The  binding  of the execute transaction;  The  metadata  of the execute transaction;  The  metadata  of the deploy transaction.   Then,  hello  is responsible for checking that  signature  is indeed a valid signature issued by Bob.", 
            "title": "Chaincode Execution"
        }, 
        {
            "location": "/tech/attributes/", 
            "text": "Attributes support\n\n\nTo support attributes the user has to pass them during TCert creation, these attributes can be used  during transaction deployment, execution or query for Attribute Based Access Control (ABAC) to determine whether the user can or cannot execute a specific chaincode  or used attributes' values for other purposes. A mechanism to validate the ownership of attributes is required in order to prove if the attributes passed by the user are correct. The Attribute Certificate Authority (ACA) has the responsibility of validate attributes and to return an Attribute Certificate (ACert) with the valid attribute values.\nAttributes values are encrypted using the keys defined below (section Attributes keys).\n\n\nAttributes Keys\n\n\nThe attributes are encrypted using a key derived from a hierarchy called PreKey tree. This approach consists in deriving keys from a parent key, allowing the parent key owner, get access to derived keys. This way keys used to encrypt attributes are different among attributes and TCerts avoiding linkability while allowing an authorized auditor who owns a parent key to derive the keys in the lower levels.  \n\n\nExample of prekey tree\n\n\nPre3K_BI\n        |_Pre2K_B = HMAC(Pre3K_BI, \u201cbanks\u201d)\n        |   |_Pre1K_BankA = HMAC(Pre2K_B, \u201cBank A\u201d)\n        |   |   |_Pre0K_BankA = HMAC(Pre1K_BankA, TCertID)\n        |   |       |_PositionKey_BankA_TIdx = HMAC(Pre0K_BankA, \"position\")\n        |   |       |_CompanyKey_BankA_TIdx = HMAC(Pre0K_BankA, \"company\")\n        |   |\n        |   |_Pre1K_BankB = HMAC(Pre2K_B, \u201cBanKB\u201d)\n        |       |_Pre0K_BankB = HMAC(Pre1K_BankB, TCertID)\n        |            |_PositionKey_BankB_TIdx = HMAC(Pre0K_BankB, \"position\")\n        |            |_CompanyKey_BankB_TIdx = HMAC(Pre0K_BankB, \"company\")\n        |\n        |_Pre2K_I = HMAC(Pre3K_BI, \"institutions\")\n            |_Pre1K_InstitutionA= HMAC(Pre2K_I, \"Institution A\u201d)\n               |_Pre0K_InstitutionA = HMAC(_Pre1K_InstitutionA, TCertID)\n                    |_PositionKey_InstA_TIdx = HMAC(Pre0K_InstitutionA, \"position\")\n                    |_CompanyKey_InstA_TIdx = HMAC(Pre0K_InstitutionA, \"company\")\n\n\n\n\n\nPre3K_BI: is available to TCA and auditors for banks and institutions.\n\n\nPre2K_B: is available to auditors for banks\n\n\nPre1K_BankA: is available to auditors for Bank A.\n\n\nPre1K_BankB: is available to auditors for Bank B.\n\n\nPre2K_I: is available to auditors for institutions.\n\n\nPre1K_InstitutionA: is available to auditors for Institution A.\n\n\n\n\nEach TCert has a different PreK0 (for example Pre0K_BankA) and each TCert attribute has a different attribute key (for example PositionKey_BankA_TIdx).\n\n\nAttribute Certificate Authority\n\n\nAttribute Certificate Authority (ACA) has the responsibility of certify the ownership of the attributes. ACA has a database to hold attributes for each user and affiliation.\n\n\n\n\nid: The id passed by the user during enrollment\n\n\naffiliation: The entity which the user is affiliated to\n\n\nattributeName: The name used to look for the attribute, e.g. 'position'\n\n\nattributeValue: The value of the attribute, e.g. 'software engineer'\n\n\nvalidFrom: The start of the attribute's validity period\n\n\nvalidTo: The end of the attribute's validity period\n\n\n\n\ngRPC ACA API\n\n\n\n\nFetchAttributes\n\n\n\n\n    rpc FetchAttributes(ACAFetchAttrReq) returns (ACAFetchAttrResp);\n\n    message ACAFetchAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Cert eCert = 2;                  // ECert of involved user.\n        Signature signature = 3;         // Signed using the ECA private key.\n    }\n\n    message ACAFetchAttrResp {\n        enum StatusCode {\n            SUCCESS = 000;\n            FAILURE = 100;\n        }\n        StatusCode status = 1;\n    }\n\n\n\n\n\n\nRequestAttributes\n\n\n\n\n    rpc RequestAttributes(ACAAttrReq) returns (ACAAttrResp);\n\n    message ACAAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Identity id = 2;\n        Cert eCert = 3;                                // ECert of involved user.\n        repeated TCertAttributeHash attributes = 4;    // Pairs attribute-key, attribute-value-hash\n        Signature signature = 5;                       // Signed using the TCA private key.\n    }\n\n    message ACAAttrResp {\n        enum StatusCode {\n            FULL_SUCCESSFUL     = 000;\n            PARTIAL_SUCCESSFUL  = 001;\n            NO_ATTRIBUTES_FOUND = 010;\n            FAILURE             = 100;\n        }\n        StatusCode status = 1;\n        Cert cert = 2;                  // ACert with the owned attributes.\n        Signature signature = 3;        // Signed using the ACA private key.\n    }\n\n\n\n\n\n\nRefreshAttributes\n\n\n\n\n    rpc RefreshAttributes(ACARefreshReq) returns (ACARefreshResp);\n\n    message ACARefreshAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Cert eCert = 2;                              // ECert of the involved user.\n        Signature signature = 3;                     // Signed using enrollPrivKey\n    }\n\n    message ACARefreshAttrResp {\n        enum StatusCode {\n            SUCCESS = 000;\n            FAILURE = 100;\n        }\n        StatusCode status = 1;\n    }\n\n\n\n\nFLOW\n\n\n\n\nDuring enrollment\n\n\n\n\nThe user requests an Enrollment Certificate (ECert) to ECA\n\n\nECA creates the ECert and responds to the user with it.\n\n\nECA issues a fetch request under TLS to the ACA passing the newly generated ECert as a parameter. This request is signed with the ECA's private key.\n\n\nThe request triggers ACA asynchronous mechanism that fetches attributes' values from external sources and populates the attributes database (in the current implementation attributes are loaded from an internal configuration file).\n\n\n\n\nDuring TCert generation\n\n\n\n\nWhen the user needs TCerts to create a new transaction it requests a batch of TCerts to the TCA, and provides the following:\n\n\nThe batch size (i.e. how many TCerts the user is expecting)\n\n\nIts ECert\n\n\nA list of attributes (e.g. Company, Position)\n\n\nUnder TLS TCA sends a RequestAttributes() to ACA to verify if the user is in possession of those attributes. This request is signed with TCA's private key and it contains:\n\n\nUser's ECert\n\n\nA list of attribute names \"company, position, ...\"\n\n\nACA performs a query to the internal attributes database and there are three possible scenarios***:\n     a. The user does not have any of the specified attributes \u2013 An error is returned.\n     b. The user has all the specified attributes \u2013 An X.509 certificate (ACert) with all the specified attributes and the ECert public key is returned.\n     c. The user has a subset of the requested attributes \u2013 An X.509 certificate (ACert) with just the subset of the specified attributes and the ECert public key is returned.\n\n\nTCA checks the validity period of the ACert's attributes and updates the list by eliminating those that are expired. Then for scenarios b and c from the previous item it checks how many (and which ones) of the attributes the user will actually receive inside each TCert. This information needs to be returned to the user in order to decide whether the TCerts are useful or if further actions needs to be performed (i.e. issue a RefreshAttributes command and request a new batch, throw an error or make use of the TCerts as they are).\n\n\nTCA could have other criteria to update the valid list of attributes.\n\n\nTCA creates the batch of TCerts. Each TCert contains the valid attributes encrypted with keys derived from the Prekey tree (each key is unique per attribute, per TCert and per user).\n\n\nTCA returns the batch of TCerts to the user along with a root key (Prek0) from which each attribute encryption key was derived. There is a Prek0 per TCert. All the TCerts in the batch have the same attributes and the validity period of the TCerts is the same for the entire batch.\n\n\n\n\n*** \nIn the current implementation an attributes refresh is executed automatically before this step, but once the refresh service is implemented the user will have the responsibility of keeping his/her attributes updated by invoking this method.\n\n\nAssumptions\n\n\n\n\nAn Attribute Certificate Authority (ACA) has been incorporated to the Membership Services internally to provide a trusted source for attribute values.\n\n\nIn the current implementation attributes are loaded from a configuration file (membersrvc.yml).\n\n\nRefresh attributes service is not implemented yet, instead, attributes are refreshed in each RequestAttribute invocation.", 
            "title": "Attributes"
        }, 
        {
            "location": "/tech/attributes/#attributes-support", 
            "text": "To support attributes the user has to pass them during TCert creation, these attributes can be used  during transaction deployment, execution or query for Attribute Based Access Control (ABAC) to determine whether the user can or cannot execute a specific chaincode  or used attributes' values for other purposes. A mechanism to validate the ownership of attributes is required in order to prove if the attributes passed by the user are correct. The Attribute Certificate Authority (ACA) has the responsibility of validate attributes and to return an Attribute Certificate (ACert) with the valid attribute values.\nAttributes values are encrypted using the keys defined below (section Attributes keys).", 
            "title": "Attributes support"
        }, 
        {
            "location": "/tech/attributes/#attributes-keys", 
            "text": "The attributes are encrypted using a key derived from a hierarchy called PreKey tree. This approach consists in deriving keys from a parent key, allowing the parent key owner, get access to derived keys. This way keys used to encrypt attributes are different among attributes and TCerts avoiding linkability while allowing an authorized auditor who owns a parent key to derive the keys in the lower levels.", 
            "title": "Attributes Keys"
        }, 
        {
            "location": "/tech/attributes/#example-of-prekey-tree", 
            "text": "Pre3K_BI\n        |_Pre2K_B = HMAC(Pre3K_BI, \u201cbanks\u201d)\n        |   |_Pre1K_BankA = HMAC(Pre2K_B, \u201cBank A\u201d)\n        |   |   |_Pre0K_BankA = HMAC(Pre1K_BankA, TCertID)\n        |   |       |_PositionKey_BankA_TIdx = HMAC(Pre0K_BankA, \"position\")\n        |   |       |_CompanyKey_BankA_TIdx = HMAC(Pre0K_BankA, \"company\")\n        |   |\n        |   |_Pre1K_BankB = HMAC(Pre2K_B, \u201cBanKB\u201d)\n        |       |_Pre0K_BankB = HMAC(Pre1K_BankB, TCertID)\n        |            |_PositionKey_BankB_TIdx = HMAC(Pre0K_BankB, \"position\")\n        |            |_CompanyKey_BankB_TIdx = HMAC(Pre0K_BankB, \"company\")\n        |\n        |_Pre2K_I = HMAC(Pre3K_BI, \"institutions\")\n            |_Pre1K_InstitutionA= HMAC(Pre2K_I, \"Institution A\u201d)\n               |_Pre0K_InstitutionA = HMAC(_Pre1K_InstitutionA, TCertID)\n                    |_PositionKey_InstA_TIdx = HMAC(Pre0K_InstitutionA, \"position\")\n                    |_CompanyKey_InstA_TIdx = HMAC(Pre0K_InstitutionA, \"company\")   Pre3K_BI: is available to TCA and auditors for banks and institutions.  Pre2K_B: is available to auditors for banks  Pre1K_BankA: is available to auditors for Bank A.  Pre1K_BankB: is available to auditors for Bank B.  Pre2K_I: is available to auditors for institutions.  Pre1K_InstitutionA: is available to auditors for Institution A.   Each TCert has a different PreK0 (for example Pre0K_BankA) and each TCert attribute has a different attribute key (for example PositionKey_BankA_TIdx).", 
            "title": "Example of prekey tree"
        }, 
        {
            "location": "/tech/attributes/#attribute-certificate-authority", 
            "text": "Attribute Certificate Authority (ACA) has the responsibility of certify the ownership of the attributes. ACA has a database to hold attributes for each user and affiliation.   id: The id passed by the user during enrollment  affiliation: The entity which the user is affiliated to  attributeName: The name used to look for the attribute, e.g. 'position'  attributeValue: The value of the attribute, e.g. 'software engineer'  validFrom: The start of the attribute's validity period  validTo: The end of the attribute's validity period", 
            "title": "Attribute Certificate Authority"
        }, 
        {
            "location": "/tech/attributes/#grpc-aca-api", 
            "text": "FetchAttributes       rpc FetchAttributes(ACAFetchAttrReq) returns (ACAFetchAttrResp);\n\n    message ACAFetchAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Cert eCert = 2;                  // ECert of involved user.\n        Signature signature = 3;         // Signed using the ECA private key.\n    }\n\n    message ACAFetchAttrResp {\n        enum StatusCode {\n            SUCCESS = 000;\n            FAILURE = 100;\n        }\n        StatusCode status = 1;\n    }   RequestAttributes       rpc RequestAttributes(ACAAttrReq) returns (ACAAttrResp);\n\n    message ACAAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Identity id = 2;\n        Cert eCert = 3;                                // ECert of involved user.\n        repeated TCertAttributeHash attributes = 4;    // Pairs attribute-key, attribute-value-hash\n        Signature signature = 5;                       // Signed using the TCA private key.\n    }\n\n    message ACAAttrResp {\n        enum StatusCode {\n            FULL_SUCCESSFUL     = 000;\n            PARTIAL_SUCCESSFUL  = 001;\n            NO_ATTRIBUTES_FOUND = 010;\n            FAILURE             = 100;\n        }\n        StatusCode status = 1;\n        Cert cert = 2;                  // ACert with the owned attributes.\n        Signature signature = 3;        // Signed using the ACA private key.\n    }   RefreshAttributes       rpc RefreshAttributes(ACARefreshReq) returns (ACARefreshResp);\n\n    message ACARefreshAttrReq {\n        google.protobuf.Timestamp ts = 1;\n        Cert eCert = 2;                              // ECert of the involved user.\n        Signature signature = 3;                     // Signed using enrollPrivKey\n    }\n\n    message ACARefreshAttrResp {\n        enum StatusCode {\n            SUCCESS = 000;\n            FAILURE = 100;\n        }\n        StatusCode status = 1;\n    }", 
            "title": "gRPC ACA API"
        }, 
        {
            "location": "/tech/attributes/#flow", 
            "text": "", 
            "title": "FLOW"
        }, 
        {
            "location": "/tech/attributes/#during-enrollment", 
            "text": "The user requests an Enrollment Certificate (ECert) to ECA  ECA creates the ECert and responds to the user with it.  ECA issues a fetch request under TLS to the ACA passing the newly generated ECert as a parameter. This request is signed with the ECA's private key.  The request triggers ACA asynchronous mechanism that fetches attributes' values from external sources and populates the attributes database (in the current implementation attributes are loaded from an internal configuration file).", 
            "title": "During enrollment"
        }, 
        {
            "location": "/tech/attributes/#during-tcert-generation", 
            "text": "When the user needs TCerts to create a new transaction it requests a batch of TCerts to the TCA, and provides the following:  The batch size (i.e. how many TCerts the user is expecting)  Its ECert  A list of attributes (e.g. Company, Position)  Under TLS TCA sends a RequestAttributes() to ACA to verify if the user is in possession of those attributes. This request is signed with TCA's private key and it contains:  User's ECert  A list of attribute names \"company, position, ...\"  ACA performs a query to the internal attributes database and there are three possible scenarios***:\n     a. The user does not have any of the specified attributes \u2013 An error is returned.\n     b. The user has all the specified attributes \u2013 An X.509 certificate (ACert) with all the specified attributes and the ECert public key is returned.\n     c. The user has a subset of the requested attributes \u2013 An X.509 certificate (ACert) with just the subset of the specified attributes and the ECert public key is returned.  TCA checks the validity period of the ACert's attributes and updates the list by eliminating those that are expired. Then for scenarios b and c from the previous item it checks how many (and which ones) of the attributes the user will actually receive inside each TCert. This information needs to be returned to the user in order to decide whether the TCerts are useful or if further actions needs to be performed (i.e. issue a RefreshAttributes command and request a new batch, throw an error or make use of the TCerts as they are).  TCA could have other criteria to update the valid list of attributes.  TCA creates the batch of TCerts. Each TCert contains the valid attributes encrypted with keys derived from the Prekey tree (each key is unique per attribute, per TCert and per user).  TCA returns the batch of TCerts to the user along with a root key (Prek0) from which each attribute encryption key was derived. There is a Prek0 per TCert. All the TCerts in the batch have the same attributes and the validity period of the TCerts is the same for the entire batch.   ***  In the current implementation an attributes refresh is executed automatically before this step, but once the refresh service is implemented the user will have the responsibility of keeping his/her attributes updated by invoking this method.", 
            "title": "During TCert generation"
        }, 
        {
            "location": "/tech/attributes/#assumptions", 
            "text": "An Attribute Certificate Authority (ACA) has been incorporated to the Membership Services internally to provide a trusted source for attribute values.  In the current implementation attributes are loaded from a configuration file (membersrvc.yml).  Refresh attributes service is not implemented yet, instead, attributes are refreshed in each RequestAttribute invocation.", 
            "title": "Assumptions"
        }, 
        {
            "location": "/tech/best-practices/", 
            "text": "Hyperledger Fabric Development Best Practices\n\n\n(This page is under construction.)", 
            "title": "Best practices"
        }, 
        {
            "location": "/tech/best-practices/#hyperledger-fabric-development-best-practices", 
            "text": "(This page is under construction.)", 
            "title": "Hyperledger Fabric Development Best Practices"
        }
    ]
}